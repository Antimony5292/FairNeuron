{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "  \"update your install command.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import logging\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from ray import tune\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable,Function\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from tqdm import trange\n",
    "from pycm import ConfusionMatrix\n",
    "from secml.array.c_array import CArray\n",
    "\n",
    "myfont = {'family': 'Times New Roman',\n",
    "         'weight': 'normal',\n",
    "         'size': 20,\n",
    "         }\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_keras_model(X, Y, S, nb_attack=25, dmax=0.1):\n",
    "    \"\"\"\n",
    "    Generates an adversarial attack on a general model.\n",
    "    :param X: Original inputs on which the model is trained\n",
    "    :param Y: Original outputs on which the model is trained\n",
    "    :param S: Original protected attributes on which the model is trained\n",
    "    :return: Adversarial dataset (i.e. new data points + original input)\n",
    "    \"\"\"\n",
    "\n",
    "    from secml.data import CDataset\n",
    "    from secml.array import CArray\n",
    "\n",
    "    # secML wants all dimensions to be homogeneous (we had previously float and int in X)\n",
    "    data_set_encoded_secML = CArray(X, dtype=float, copy=True)\n",
    "    data_set_encoded_secML = CDataset(data_set_encoded_secML, Y)\n",
    "\n",
    "    n_tr = round(0.66 * X.shape[0])\n",
    "    n_ts = X.shape[0] - n_tr\n",
    "\n",
    "    logger.debug(X.shape)\n",
    "    logger.debug(n_tr)\n",
    "    logger.debug(n_ts)\n",
    "\n",
    "    from secml.data.splitter import CTrainTestSplit\n",
    "    splitter = CTrainTestSplit(train_size=n_tr, test_size=n_ts)\n",
    "\n",
    "    # Use training set for the classifier and then pick points from an internal test set.\n",
    "    tr_set_secML, ts_set_secML = splitter.split(data_set_encoded_secML)\n",
    "\n",
    "    # tr_set_secML = CDataset(X_train,Y_train)\n",
    "    # ts_set_secML = CDataset(X_test,Y_test)\n",
    "\n",
    "    # Create a surrogate classifier\n",
    "\n",
    "    # Creation of the multiclass classifier\n",
    "    from secml.ml.classifiers import CClassifierSVM\n",
    "    from secml.ml.classifiers.multiclass import CClassifierMulticlassOVA\n",
    "    from secml.ml.kernel import CKernelRBF\n",
    "    clf = CClassifierMulticlassOVA(CClassifierSVM, kernel=CKernelRBF())\n",
    "\n",
    "    # Parameters for the Cross-Validation procedure\n",
    "    xval_params = {'C': [1e-4, 1e-3, 1e-2, 0.1, 1], 'kernel.gamma': [0.01, 0.1, 1, 10, 100, 1e3]}\n",
    "\n",
    "    # Let's create a 3-Fold data splitter\n",
    "    random_state = 999\n",
    "\n",
    "    from secml.data.splitter import CDataSplitterKFold\n",
    "    xval_splitter = CDataSplitterKFold(num_folds=3, random_state=random_state)\n",
    "\n",
    "    # Select and set the best training parameters for the classifier\n",
    "    logger.debug(\"Estimating the best training parameters...\")\n",
    "    best_params = clf.estimate_parameters(\n",
    "        dataset=tr_set_secML,\n",
    "        parameters=xval_params,\n",
    "        splitter=xval_splitter,\n",
    "        metric='accuracy',\n",
    "        perf_evaluator='xval'\n",
    "    )\n",
    "    logger.debug(\"The best training parameters are: \", best_params)\n",
    "\n",
    "    logger.debug(clf.get_params())\n",
    "    logger.debug(clf.num_classifiers)\n",
    "\n",
    "    # Metric to use for training and performance evaluation\n",
    "    from secml.ml.peval.metrics import CMetricAccuracy\n",
    "    metric = CMetricAccuracy()\n",
    "\n",
    "    # Train the classifier\n",
    "    clf.fit(tr_set_secML)\n",
    "    logger.debug(clf.num_classifiers)\n",
    "\n",
    "    # Compute predictions on a test set\n",
    "    y_pred = clf.predict(ts_set_secML.X)\n",
    "\n",
    "    # Evaluate the accuracy of the classifier\n",
    "    acc = metric.performance_score(y_true=ts_set_secML.Y, y_pred=y_pred)\n",
    "\n",
    "    logger.debug(\"Accuracy on test set: {:.2%}\".format(acc))\n",
    "\n",
    "    # Prepare attack configuration\n",
    "\n",
    "    noise_type = 'l2'   # Type of perturbation 'l1' or 'l2'\n",
    "    lb, ub = 0, 1       # Bounds of the attack space. Can be set to `None` for unbounded\n",
    "    y_target = None     # None if `error-generic` or a class label for `error-specific`\n",
    "\n",
    "    # Should be chosen depending on the optimization problem\n",
    "    solver_params = {\n",
    "        'eta': 0.1,         # grid search resolution\n",
    "        'eta_min': 0.1,\n",
    "        'eta_max': None,    # None should be ok\n",
    "        'max_iter': 1000,\n",
    "        'eps': 1e-2         # Tolerance on the stopping crit.\n",
    "    }\n",
    "\n",
    "    # Run attack\n",
    "\n",
    "    from secml.adv.attacks.evasion import CAttackEvasionPGDLS\n",
    "    pgd_ls_attack = CAttackEvasionPGDLS(\n",
    "        classifier=clf,\n",
    "        surrogate_classifier=clf,\n",
    "        surrogate_data=tr_set_secML,\n",
    "        distance=noise_type,\n",
    "        dmax=dmax,\n",
    "        lb=lb, ub=ub,\n",
    "        solver_params=solver_params,\n",
    "        y_target=y_target)\n",
    "\n",
    "    nb_feat = X.shape[1]\n",
    "\n",
    "    result_pts = np.empty([nb_attack, nb_feat])\n",
    "    result_class = np.empty([nb_attack, 1])\n",
    "\n",
    "    # take a point at random being the starting point of the attack and run the attack\n",
    "    import random\n",
    "    for nb_iter in range(0, nb_attack):\n",
    "        rn = random.randint(0, ts_set_secML.num_samples - 1)\n",
    "        x0, y0 = ts_set_secML[rn, :].X, ts_set_secML[rn, :].Y,\n",
    "\n",
    "        try:\n",
    "            y_pred_pgdls, _, adv_ds_pgdls, _ = pgd_ls_attack.run(x0, y0)\n",
    "            adv_pt = adv_ds_pgdls.X.get_data()\n",
    "            # np.asarray([np.asarray(row, dtype=float) for row in y_tr], dtype=float)\n",
    "            result_pts[nb_iter] = adv_pt\n",
    "            result_class[nb_iter] = y_pred_pgdls.get_data()[0]\n",
    "        except ValueError:\n",
    "            logger.warning(\"value error on {}\".format(nb_iter))\n",
    "\n",
    "    return result_pts, result_class, ts_set_secML[:nb_attack, :].Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bm:\n",
    "    \"\"\"\n",
    "    Utility class that calculates the probability $$P(X | Y)$$ of\n",
    "    (sets of) the random variables $X,Y$ with the (set of) random\n",
    "    variables $Y$ in the conditioning set.\n",
    "    \n",
    "    This class should be first initialized with a pandas dataframe,\n",
    "    afterwards the conditional probability can be calculated as follows:\n",
    "    \n",
    "    ```python\n",
    "    Model(df).P(x = 1).given(y=1)\n",
    "    ```\n",
    "    \n",
    "    Lambdas can also be used, for other options than equalities:\n",
    "    \n",
    "    ```python\n",
    "    Model(df).P(x = lambda x: x>5).given(y=1)\n",
    "    ```\n",
    "    \"\"\"\n",
    "    def __init__(self, df):\n",
    "        self._df = df\n",
    "\n",
    "    def P(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Declares the random variables from the set `kwargs`.\n",
    "        \"\"\"\n",
    "        self._variables = kwargs\n",
    "        return self\n",
    "\n",
    "    def given(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Calculates the probability on a finite set of samples with `kwargs` in the\n",
    "        conditioning set. \n",
    "        \"\"\"\n",
    "        self._given = kwargs\n",
    "        \n",
    "        # Here's where the magic happens\n",
    "        prior = True\n",
    "        posterior = True\n",
    "        \n",
    "        for k in self._variables:\n",
    "            if type(self._variables[k]) == type(lambda x:x):\n",
    "                posterior = posterior & (self._df[k].apply(self._variables[k]))\n",
    "            else:\n",
    "                posterior = posterior & (self._df[k] == self._variables[k])\n",
    "\n",
    "        \n",
    "        for k in self._given:\n",
    "            if type(self._given[k]) == type(lambda x:x):\n",
    "                prior = prior & (self._df[k].apply(self._given[k]))\n",
    "                posterior = posterior & (self._df[k].apply(self._given[k]))\n",
    "            else:\n",
    "                prior = prior & (self._df[k] == self._given[k])\n",
    "                posterior = posterior & (self._df[k] == self._given[k])\n",
    "        return posterior.sum()/prior.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dataset(df):\n",
    "    \"\"\"\n",
    "\n",
    "    :param df:\n",
    "    :return: Tuple of the transformed dataset and the labels Y and S\n",
    "    \"\"\"\n",
    "\n",
    "    df_binary = df[(df[\"race\"] == \"Caucasian\") | (df[\"race\"] == \"African-American\")]\n",
    "\n",
    "    del df_binary['c_jail_in']\n",
    "    del df_binary['c_jail_out']\n",
    "\n",
    "    ##separated class from the rests of the features\n",
    "    # remove unnecessary dimensions from Y -> only the decile_score remains\n",
    "    Y = df_binary['decile_score']\n",
    "    del df_binary['decile_score']\n",
    "    Y_true = df_binary['two_year_recid']\n",
    "    del df_binary['two_year_recid']\n",
    "    del df_binary['score_text']\n",
    "\n",
    "    S = df_binary['race']\n",
    "    #del df_binary['race']\n",
    "    #del df_binary['is_recid']\n",
    "\n",
    "    print(df_binary.shape)\n",
    "\n",
    "    # set sparse to False to return dense matrix after transformation and keep all dimensions homogeneous\n",
    "    encod = preprocessing.OneHotEncoder(sparse=False)\n",
    "\n",
    "    data_to_encode = df_binary.to_numpy()\n",
    "    feat_to_encode = data_to_encode[:, 0]\n",
    "    # print(feat_to_encode)\n",
    "    # transposition\n",
    "    feat_to_encode = feat_to_encode.reshape(-1, 1)\n",
    "    # print(feat_to_encode)\n",
    "    encoded_feature = encod.fit_transform(feat_to_encode)\n",
    "\n",
    "    df_binary_encoded = pd.DataFrame(encoded_feature)\n",
    "\n",
    "    feat_to_encode = data_to_encode[:, 1]\n",
    "    feat_to_encode = feat_to_encode.reshape(-1, 1)\n",
    "    encoded_feature = encod.fit_transform(feat_to_encode)\n",
    "\n",
    "\n",
    "    df_binary_encoded = pd.concat([df_binary_encoded, pd.DataFrame(encoded_feature)], axis=1)\n",
    "\n",
    "    feat_to_encode = data_to_encode[:, 2] == \"Caucasian\"\n",
    "    feat_to_encode = feat_to_encode.reshape(-1, 1)\n",
    "    encoded_feature = encod.fit_transform(feat_to_encode)\n",
    "\n",
    "    df_binary_encoded = pd.concat([df_binary_encoded, pd.DataFrame(encoded_feature)], axis=1)\n",
    "\n",
    "    # feature [2] [3] [4] [5] [6] [7] [8] has to be put between 0 and 1\n",
    "\n",
    "    for i in range(3, 10):\n",
    "        encoded_feature = data_to_encode[:, i]\n",
    "        ma = np.amax(encoded_feature)\n",
    "        mi = np.amin(encoded_feature)\n",
    "        encoded_feature = (encoded_feature - mi) / (ma - mi)\n",
    "        df_binary_encoded = pd.concat([df_binary_encoded, pd.DataFrame(encoded_feature)], axis=1)\n",
    "\n",
    "    feat_to_encode = data_to_encode[:, 10]\n",
    "    feat_to_encode = feat_to_encode.reshape(-1, 1)\n",
    "    encoded_feature = encod.fit_transform(feat_to_encode)\n",
    "\n",
    "    df_binary_encoded = pd.concat([df_binary_encoded, pd.DataFrame(encoded_feature)], axis=1)\n",
    "\n",
    "    feat_to_encode = data_to_encode[:, 11]\n",
    "    feat_to_encode = feat_to_encode.reshape(-1, 1)\n",
    "    encoded_feature = encod.fit_transform(feat_to_encode)\n",
    "\n",
    "    df_binary_encoded = pd.concat([df_binary_encoded, pd.DataFrame(encoded_feature)], axis=1)\n",
    "\n",
    "    return df_binary_encoded, Y, S, Y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dataset_census(df):\n",
    "    \"\"\"\n",
    "    :param df: the dataset \"census income\" from a csv file with reduced features, heterogeneous types and missing values, no header\n",
    "    :return: Tuple of the transformed dataset and the labels Y and S\n",
    "    \"\"\"\n",
    "    df_replace = df.replace(to_replace=\"?\",value=np.nan)\n",
    "    df_replace.dropna(inplace=True, axis=0)\n",
    "\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    oh_encoder = preprocessing.OneHotEncoder(sparse=False)\n",
    "\n",
    "    df_label = df_replace.iloc[:,-1]\n",
    "\n",
    "    ##Y_true is the vector containing labels, at this point, labels (initially strings) have been transformed into integer (0 and 1) -> -5000 is now '0' and 5000+ is now '+1'\n",
    "    Y = label_encoder.fit_transform(df_label)\n",
    "    #remove last column from df\n",
    "    del df_replace[df_replace.columns[-1]]\n",
    "\n",
    "    # Y_true is the true outcome, in this case we're not using a future predictor (vs. compas)\n",
    "    Y_true=[]\n",
    "\n",
    "    #S is the protected attribute\n",
    "    # could also be feature 7 (sex) or feature 13 (citizenship)\n",
    "    S=df_replace[\"sex\"]\n",
    "    del df_replace[\"sex\"]\n",
    "\n",
    "    #remove feature fnlwgt\n",
    "    del df_replace[\"fnlwgt\"]\n",
    "\n",
    "    #remove examples with missing values\n",
    "              ## change 1 to 0 \n",
    "\n",
    "    #     if df_replace.shape == df.shape:\n",
    "    #         raise AssertionError(\"The removal of na values failed\")\n",
    "\n",
    "    print(df_replace.shape)\n",
    "\n",
    "    #transform other features\n",
    "    #feature age to normalize\n",
    "    encoded_feature = df_replace.to_numpy()[:, 0]\n",
    "    mi = np.amin(encoded_feature)\n",
    "    ma = np.amax(encoded_feature)\n",
    "    encoded_feature = (encoded_feature - mi) / (ma - mi)\n",
    "\n",
    "    #df_binary_encoded is the data frame containing encoded features\n",
    "    df_binary_encoded = pd.DataFrame(encoded_feature)\n",
    "    print(df_binary_encoded.shape)\n",
    "\n",
    "\n",
    "    encod_feature = df_replace.iloc[:,1]\n",
    "    encoded_feature = pd.get_dummies(encod_feature)\n",
    "    # df_binary_encoded = pd.concat([df_binary_encoded, pd.DataFrame(encoded_feature)], axis=1)\n",
    "\n",
    "    #feature 1 to 7 (after removal) are categorical\n",
    "    for i in range(1,8):\n",
    "        encod_feature = df_replace.iloc[:,i]\n",
    "    #     print(encod_feature.shape)\n",
    "        encoded_feature = pd.get_dummies(encod_feature)\n",
    "    #     print(encoded_feature)\n",
    "    #     print(df_binary_encoded)\n",
    "        df_binary_encoded = pd.concat([df_binary_encoded.reset_index(drop=True), pd.DataFrame(encoded_feature).reset_index(drop=True)], axis=1)\n",
    "#         print(df_binary_encoded)\n",
    "    #     print('')\n",
    "\n",
    "    #feature 8 and 9 are numerical\n",
    "    for i in range(8,10):\n",
    "        encod_feature = df_replace.iloc[:,i]\n",
    "        mi = np.amin(encod_feature)\n",
    "        ma = np.amax(encod_feature)\n",
    "        encoded_feature = (encod_feature - mi) / (ma - mi)\n",
    "        df_binary_encoded = pd.concat([df_binary_encoded.reset_index(drop=True), pd.DataFrame(encoded_feature).reset_index(drop=True)], axis=1)\n",
    "    #     print(df_binary_encoded.shape)\n",
    "    #feature 10 and 11 are categorical\n",
    "    for i in range(10,12):\n",
    "        encod_feature = df_replace.iloc[:,i]\n",
    "        encoded_feature = pd.get_dummies(encod_feature)\n",
    "        df_binary_encoded = pd.concat([df_binary_encoded.reset_index(drop=True), pd.DataFrame(encoded_feature).reset_index(drop=True)], axis=1)\n",
    "    #     print(df_binary_encoded.shape)\n",
    "\n",
    "    return df_binary_encoded, Y, S, Y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dataset_credit(df):\n",
    "    \"\"\"\n",
    "    For more info on the features:\n",
    "    https://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29\n",
    "    :param df: the dataset \"german credit\" from a space separated file\n",
    "    :return: Tuple of the transformed dataset and the labels Y and S\n",
    "    \"\"\"\n",
    "\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    oh_encoder = preprocessing.OneHotEncoder(sparse=False)\n",
    "\n",
    "    Y = np.array(df.iloc[:,-1] == 2)\n",
    "\n",
    "    ##Y_true is the vector containing labels, at this point, labels (initially strings) have been transformed into integer (0 and 1) -> -5000 is now '0' and 5000+ is now '+1'\n",
    "    #remove last column from df\n",
    "    del df[df.columns[-1]]\n",
    "\n",
    "    # Y_true is the true outcome, in this case we're not using a future predictor (vs. compas)\n",
    "    Y_true=[]\n",
    "\n",
    "    #S is the protected attribute\n",
    "    S=df.iloc[:,12] > 25\n",
    "    #del df[\"Age\"]\n",
    "\n",
    "    #remove examples with missing values\n",
    "    df_replace = df.replace(to_replace=\"?\",value=np.nan)\n",
    "    df_replace.dropna(inplace=True, axis=1)\n",
    "\n",
    "    print(df_replace.shape)\n",
    "\n",
    "    #transform other features\n",
    "    #feature age to normalize\n",
    "    encoded_feature = df_replace.to_numpy()[:, 1]\n",
    "    mi = np.amin(encoded_feature)\n",
    "    ma = np.amax(encoded_feature)\n",
    "    encoded_feature = (encoded_feature - mi) / (ma - mi)\n",
    "\n",
    "    #df_binary_encoded is the data frame containing encoded features\n",
    "    df_binary_encoded = pd.DataFrame(encoded_feature)\n",
    "\n",
    "    # categorical attributes\n",
    "    for i in [0, 2, 3, 5, 6, 8, 9, 11, 13, 14, 16, 18,19]:\n",
    "        encod_feature = df_replace.iloc[:,i]\n",
    "        encoded_feature = pd.get_dummies(encod_feature)\n",
    "        df_binary_encoded = pd.concat([df_binary_encoded, pd.DataFrame(encoded_feature)], axis=1)\n",
    "\n",
    "    # Numerical attributes\n",
    "    for i in [1, 7, 10, 15, 17]:\n",
    "        encod_feature = df_replace.iloc[:,i]\n",
    "        mi = np.amin(encod_feature)\n",
    "        ma = np.amax(encod_feature)\n",
    "        encoded_feature = (encod_feature - mi) / (ma - mi)\n",
    "        df_binary_encoded = pd.concat([df_binary_encoded, pd.DataFrame(encoded_feature)], axis=1)\n",
    "\n",
    "    print(S)\n",
    "\n",
    "    return df_binary_encoded, Y, S, Y_true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientReversalFunction(Function):\n",
    "    \"\"\"\n",
    "    Gradient Reversal Layer from:\n",
    "    Unsupervised Domain Adaptation by Backpropagation (Ganin & Lempitsky, 2015)\n",
    "    Forward pass is the identity function. In the backward pass,\n",
    "    the upstream gradients are multiplied by -lambda (i.e. gradient is reversed)\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, lambda_):\n",
    "        ctx.lambda_ = lambda_\n",
    "        return x.clone()\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grads):\n",
    "        lambda_ = ctx.lambda_\n",
    "        lambda_ = grads.new_tensor(lambda_)\n",
    "        dx = -lambda_ * grads\n",
    "        return dx, None\n",
    "\n",
    "class GradientReversal(torch.nn.Module):\n",
    "    def __init__(self, lambda_=1):\n",
    "        super(GradientReversal, self).__init__()\n",
    "        self.lambda_ = lambda_\n",
    "\n",
    "    def forward(self, x):\n",
    "        return GradientReversalFunction.apply(x, self.lambda_)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, input_shape, grl_lambda=100):\n",
    "        super(Net, self).__init__()\n",
    "        # an affine operation: y = Wx + b\n",
    "        self._grl_lambda = grl_lambda\n",
    "        self.fc1 = nn.Linear(input_shape, 32)\n",
    "        self.fc2 = nn.Linear(32, 32)\n",
    "        self.fc3 = nn.Linear(32, 32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "        if self._grl_lambda != 0:\n",
    "            self.grl = GradientReversal(grl_lambda)\n",
    "            self.fc5 = nn.Linear(32, 2)\n",
    "        # self.grl = GradientReversal(100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden = self.fc1(x)\n",
    "        hidden = F.relu(hidden)\n",
    "        hidden = F.dropout(hidden, 0.1)\n",
    "        hidden = self.fc2(hidden)\n",
    "        hidden = F.relu(hidden)\n",
    "        hidden = self.fc3(hidden)\n",
    "        hidden = F.relu(hidden)\n",
    "\n",
    "        y = self.fc4(hidden)\n",
    "        # y = F.dropout(y, 0.1)\n",
    "\n",
    "        if self._grl_lambda != 0:\n",
    "            s = self.grl(hidden)\n",
    "            s = self.fc5(s)\n",
    "            # s = F.sigmoid(s)\n",
    "            # s = F.dropout(s, 0.1)\n",
    "            return y, s\n",
    "        else:\n",
    "            return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_nodrop(nn.Module):\n",
    "\n",
    "    def __init__(self, input_shape, grl_lambda=100):\n",
    "        super(Net_nodrop, self).__init__()\n",
    "        # an affine operation: y = Wx + b\n",
    "        self._grl_lambda = grl_lambda\n",
    "        self.fc1 = nn.Linear(input_shape, 32)\n",
    "        self.fc2 = nn.Linear(32, 32)\n",
    "        self.fc3 = nn.Linear(32, 32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "        if self._grl_lambda != 0:\n",
    "            self.grl = GradientReversal(grl_lambda)\n",
    "            self.fc5 = nn.Linear(32, 2)\n",
    "        # self.grl = GradientReversal(100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden = self.fc1(x)\n",
    "        hidden = F.relu(hidden)\n",
    "#         hidden = F.dropout(hidden, 0.1)\n",
    "        hidden = self.fc2(hidden)\n",
    "        hidden = F.relu(hidden)\n",
    "        hidden = self.fc3(hidden)\n",
    "        hidden = F.relu(hidden)\n",
    "\n",
    "        y = self.fc4(hidden)\n",
    "        # y = F.dropout(y, 0.1)\n",
    "\n",
    "        if self._grl_lambda != 0:\n",
    "            s = self.grl(hidden)\n",
    "            s = self.fc5(s)\n",
    "            # s = F.sigmoid(s)\n",
    "            # s = F.dropout(s, 0.1)\n",
    "            return y, s\n",
    "        else:\n",
    "            return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_CENSUS(nn.Module):\n",
    "\n",
    "    def __init__(self, input_shape, grl_lambda=100):\n",
    "        super(Net_CENSUS, self).__init__()\n",
    "        # an affine operation: y = Wx + b\n",
    "        self._grl_lambda = grl_lambda\n",
    "        self.fc1 = nn.Linear(input_shape, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 128)\n",
    "        self.fc4 = nn.Linear(128, 1)\n",
    "        if self._grl_lambda != 0:\n",
    "            self.grl = GradientReversal(grl_lambda)\n",
    "            self.fc5 = nn.Linear(128, 2)\n",
    "        # self.grl = GradientReversal(100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden = self.fc1(x)\n",
    "        hidden = F.relu(hidden)\n",
    "        hidden = F.dropout(hidden, 0.1)\n",
    "        hidden = self.fc2(hidden)\n",
    "        hidden = F.relu(hidden)\n",
    "        hidden = self.fc3(hidden)\n",
    "        hidden = F.relu(hidden)\n",
    "\n",
    "        y = self.fc4(hidden)\n",
    "        # y = F.dropout(y, 0.1)\n",
    "\n",
    "        if self._grl_lambda != 0:\n",
    "            s = self.grl(hidden)\n",
    "            s = self.fc5(s)\n",
    "            # s = F.sigmoid(s)\n",
    "            # s = F.dropout(s, 0.1)\n",
    "            return y, s\n",
    "        else:\n",
    "            return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 路径分析相关函数\n",
    "\n",
    "def get_paras(net):\n",
    "    paras=[]\n",
    "    for name,parameters in net.named_parameters():\n",
    "        paras.append(parameters)\n",
    "    return paras\n",
    "\n",
    "def get_active_neurons4(net,sample):\n",
    "    neurons=[]\n",
    "    def hook(module,input,output):\n",
    "        neurons.append(output.data)\n",
    "    handle1=net.fc1.register_forward_hook(hook)\n",
    "    handle2=net.fc2.register_forward_hook(hook)\n",
    "    handle3=net.fc3.register_forward_hook(hook)\n",
    "    handle4=net.fc4.register_forward_hook(hook)\n",
    "    net(x=torch.tensor(sample,dtype=torch.float32))\n",
    "    handle1.remove()\n",
    "    handle2.remove()\n",
    "    handle3.remove()\n",
    "    handle4.remove()\n",
    "    return neurons\n",
    "\n",
    "def get_contrib4(paras,neurons):\n",
    "    contrib_list=[]\n",
    "    for i in range(3):\n",
    "        i=i\n",
    "        contrib=neurons[i]*paras[2*i+2]\n",
    "        contrib_list.append(contrib)\n",
    "    return contrib_list\n",
    "\n",
    "def get_path_set4(net,sample,GAMMA=0.9):\n",
    "    active_neuron_indice=[[],[],[],[]]\n",
    "    path_set=set()\n",
    "    neurons=get_active_neurons4(net,sample)\n",
    "    paras=get_paras(net)\n",
    "    contrib_list=get_contrib4(paras,neurons)\n",
    "    active_neuron_indice[3].append(torch.argmax(neurons[3]).item())\n",
    "    for i in range(3):\n",
    "        L=3-i\n",
    "        for j in active_neuron_indice[L]:\n",
    "            s=torch.sort(contrib_list[L-1][j],descending=True)\n",
    "            sum=0\n",
    "            for k in range(len(contrib_list[L-1][j])):\n",
    "                sum+=s.values[k].item()\n",
    "                active_neuron_indice[L-1].append(s.indices[k].item())\n",
    "                path_set.add((L,s.indices[k].item(),j))\n",
    "                if(sum>=GAMMA*neurons[L][j].item()):\n",
    "                    break\n",
    "    return path_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(results, threshold, fraction,dataset='compas'):\n",
    "    \"Create the metrics from an output df.\"\n",
    "\n",
    "    # Calculate biases after training\n",
    "    dem_parity = abs(\n",
    "        bm(results).P(pred=lambda x: x > threshold).given(race=0)\n",
    "        - bm(results).P(pred=lambda x: x > threshold).given(\n",
    "            race=1))\n",
    "\n",
    "    eq_op = abs(\n",
    "        bm(results).P(pred=lambda x: x > threshold).given(race=0, compas=True)\n",
    "        - bm(results).P(pred=lambda x: x > threshold).given(race=1, compas=True))\n",
    "\n",
    "    dem_parity_ratio = abs(\n",
    "        bm(results).P(pred=lambda x: x > threshold).given(race=0)\n",
    "        / bm(results).P(pred=lambda x: x > threshold).given(\n",
    "            race=1))\n",
    "\n",
    "    cm = ConfusionMatrix(actual_vector=(results['true'] == True).values,\n",
    "                         predict_vector=(results['pred'] > threshold).values)\n",
    "    if dataset=='compas':\n",
    "        cm_high_risk = ConfusionMatrix(actual_vector=(results['compas'] > 8).values,\n",
    "                             predict_vector=(results['pred'] > 8).values)\n",
    "\n",
    "        result = {\"DP\": dem_parity,\n",
    "                  \"EO\": eq_op,\n",
    "                  \"DP ratio\": dem_parity_ratio,\n",
    "                  \"acc\": cm.Overall_ACC,\n",
    "                  \"acc_ci_min\": cm.CI95[0],\n",
    "                  \"acc_ci_max\": cm.CI95[1],\n",
    "                  \"f1\": cm.F1_Macro,\n",
    "                  \"acc_high_risk\": cm_high_risk.Overall_ACC,\n",
    "                  \"acc_ci_min_high_risk\": cm_high_risk.CI95[0],\n",
    "                  \"acc_ci_max_high_risk\": cm_high_risk.CI95[1],\n",
    "                  \"f1_high_risk\": cm_high_risk.F1_Macro,\n",
    "                  \"adversarial_fraction\": fraction\n",
    "                  }\n",
    "    else:\n",
    "        result = {\"DP\": dem_parity,\n",
    "                  \"EO\": eq_op,\n",
    "                  \"DP ratio\": dem_parity_ratio,\n",
    "                  \"acc\": cm.Overall_ACC,\n",
    "                  \"acc_ci_min\": cm.CI95[0],\n",
    "                  \"acc_ci_max\": cm.CI95[1],\n",
    "                  \"f1\": cm.F1_Macro,\n",
    "                  \"adversarial_fraction\": fraction\n",
    "                  }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(train_loader: DataLoader,\n",
    "                       val_loader: DataLoader,\n",
    "                       test_loader: DataLoader,\n",
    "                       device,\n",
    "                       input_shape,\n",
    "                       grl_lambda=None,\n",
    "                       model=None,\n",
    "                       dataset='compas'):\n",
    "    \"\"\"\n",
    "\n",
    "    :param train_loader: Pytorch-like DataLoader with training data.\n",
    "    :param val_loader: Pytorch-like DataLoader with validation data.\n",
    "    :param test_loader: Pytorch-like DataLoader with testing data.\n",
    "    :param device: The target device for the training.\n",
    "    :return: A tuple: (trained Pytorch-like model, dataframe with results on test set)\n",
    "    \"\"\"\n",
    "\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    grl_lambda = 50\n",
    "    epochs = 50\n",
    "\n",
    "    if model is None:\n",
    "        # Redefine the model\n",
    "        if dataset=='census':\n",
    "            model = Net_CENSUS(input_shape=input_shape, grl_lambda=grl_lambda).to(device)\n",
    "        elif dataset=='compas_nodrop':\n",
    "            model = Net_nodrop(input_shape=input_shape, grl_lambda=grl_lambda).to(device)\n",
    "        else:\n",
    "            model = Net(input_shape=input_shape, grl_lambda=grl_lambda).to(device)\n",
    "        \n",
    "    model = model.to(device)\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    criterion_bias = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, threshold=0.3, cooldown=5)\n",
    "\n",
    "    training_losses = []\n",
    "    validation_losses = []\n",
    "\n",
    "    t_prog = trange(epochs, desc='Training neural network', leave=False, position=1, mininterval=5)\n",
    "    # t_prog = trange(50)\n",
    "\n",
    "    for epoch in t_prog:\n",
    "        model.train()\n",
    "\n",
    "        batch_losses = []\n",
    "        for x_batch, y_batch, _, s_batch in train_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            s_batch = s_batch.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            if grl_lambda is not None and grl_lambda != 0:\n",
    "                outputs, outputs_protected = model(x_batch)\n",
    "                loss = criterion(outputs, y_batch) + criterion_bias(outputs_protected, s_batch.argmax(dim=1))\n",
    "            else:\n",
    "                outputs = model(x_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_losses.append(loss.item())\n",
    "\n",
    "        training_loss = np.mean(batch_losses)\n",
    "        training_losses.append(training_loss)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            val_losses = []\n",
    "            for x_val, y_val, _, s_val in val_loader:\n",
    "                x_val = x_val.to(device)\n",
    "                y_val = y_val.to(device)\n",
    "                s_val = s_val.to(device)\n",
    "                model.eval()\n",
    "                if grl_lambda is not None and grl_lambda != 0:\n",
    "                    yhat, s_hat = model(x_val)\n",
    "                    val_loss = (criterion(y_val, yhat) + criterion_bias(s_val, s_hat.argmax(dim=1))).item()\n",
    "                else:\n",
    "                    yhat = model(x_val)\n",
    "                    val_loss = criterion(y_val, yhat).item()\n",
    "                val_losses.append(val_loss)\n",
    "            validation_loss = np.mean(val_losses)\n",
    "            validation_losses.append(validation_loss)\n",
    "\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "        t_prog.set_postfix({\"epoch\": epoch, \"training_loss\": training_loss,\n",
    "                            \"validation_loss\": validation_loss}, refresh=False)  # print last metrics\n",
    "\n",
    "#     if args.show_graphs:\n",
    "#         plt.plot(range(len(training_losses)), training_losses)\n",
    "#         plt.plot(range(len(validation_losses)), validation_losses)\n",
    "#         # plt.scatter(x_tensor, y_out.detach().numpy())\n",
    "#         plt.ylabel('some numbers')\n",
    "#         plt.show()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        test_losses = []\n",
    "        test_results = []\n",
    "        for x_test, y_test, ytrue, s_true in test_loader:\n",
    "            x_test = x_test.to(device)\n",
    "            y_test = y_test.to(device)\n",
    "            s_true = s_true.to(device)\n",
    "            model.eval()\n",
    "            if grl_lambda is not None and grl_lambda != 0:\n",
    "                yhat, s_hat = model(x_test)\n",
    "                test_loss = (criterion(y_test, yhat) + criterion_bias(s_true, s_hat.argmax(dim=1))).item()\n",
    "                test_losses.append(val_loss)\n",
    "                test_results.append({\"y_hat\": yhat, \"y_true\": ytrue, \"y_compas\": y_test, \"s\": s_true, \"s_hat\": s_hat})\n",
    "            else:\n",
    "                yhat = model(x_test)\n",
    "                test_loss = (criterion(y_test, yhat)).item()\n",
    "                test_losses.append(val_loss)\n",
    "                test_results.append({\"y_hat\": yhat, \"y_true\": ytrue, \"y_compas\": y_test, \"s\": s_true})\n",
    "\n",
    "        # print({\"Test loss\": np.mean(test_losses)})\n",
    "\n",
    "    results = test_results[0]['y_hat']\n",
    "    outcome = test_results[0]['y_true']\n",
    "    compas = test_results[0]['y_compas']\n",
    "    protected_results = test_results[0]['s']\n",
    "    if grl_lambda is not None and grl_lambda != 0:\n",
    "        protected = test_results[0]['s_hat']\n",
    "    for r in test_results[1:]:\n",
    "        results = torch.cat((results, r['y_hat']))\n",
    "        outcome = torch.cat((outcome, r['y_true']))\n",
    "        compas = torch.cat((compas, r['y_compas']))\n",
    "        protected_results = torch.cat((protected_results, r['s']))\n",
    "        if grl_lambda is not None and grl_lambda != 0:\n",
    "            protected = torch.cat((protected, r['s_hat']))\n",
    "\n",
    "    df = pd.DataFrame(data=results.cpu().numpy(), columns=['pred'])\n",
    "\n",
    "    df['true'] = outcome.cpu().numpy()\n",
    "    df['compas'] = compas.cpu().numpy()\n",
    "    df['race'] = protected_results.cpu().numpy()[:, 0]\n",
    "    if grl_lambda is not None and grl_lambda != 0:\n",
    "        df['race_hat'] = protected.cpu().numpy()[:, 0]\n",
    "\n",
    "    return model, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_drop(adv_loader: DataLoader,\n",
    "                            benign_loader: DataLoader,\n",
    "                            val_loader: DataLoader,\n",
    "                            test_loader: DataLoader,\n",
    "                            device,\n",
    "                            input_shape,\n",
    "                            grl_lambda=None,\n",
    "                            model=None,\n",
    "                            dataset='compas'):\n",
    "    \"\"\"\n",
    "\n",
    "    :param train_loader: Pytorch-like DataLoader with training data.\n",
    "    :param val_loader: Pytorch-like DataLoader with validation data.\n",
    "    :param test_loader: Pytorch-like DataLoader with testing data.\n",
    "    :param device: The target device for the training.\n",
    "    :return: A tuple: (trained Pytorch-like model, dataframe with results on test set)\n",
    "    \"\"\"\n",
    "\n",
    "#     torch.manual_seed(0)\n",
    "\n",
    "#     grl_lambda = 50\n",
    "    epochs = 50\n",
    "\n",
    "    if model is None:\n",
    "        if dataset=='CENSUS':\n",
    "            model = Net_CENSUS(input_shape=input_shape, grl_lambda=grl_lambda).to(device)\n",
    "        else:\n",
    "            model = Net(input_shape=input_shape, grl_lambda=grl_lambda).to(device)\n",
    "    model = model.to(device)\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    criterion_bias = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, threshold=0.3, cooldown=5)\n",
    "\n",
    "    training_losses = []\n",
    "    validation_losses = []\n",
    "\n",
    "    t_prog = trange(epochs, desc='Training neural network', leave=False, position=1, mininterval=5)\n",
    "    # t_prog = trange(50)\n",
    "\n",
    "    for epoch in t_prog:\n",
    "        batch_losses = []\n",
    "        \n",
    "        model.train()\n",
    "        for x_batch, y_batch, _, s_batch in adv_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            s_batch = s_batch.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            if grl_lambda is not None and grl_lambda != 0:\n",
    "                outputs, outputs_protected = model(x_batch)\n",
    "                loss = criterion(outputs, y_batch) + criterion_bias(outputs_protected, s_batch.argmax(dim=1))\n",
    "            else:\n",
    "                outputs = model(x_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            batch_losses.append(loss.item())\n",
    "            \n",
    "        model.eval()\n",
    "        for x_batch, y_batch, _, s_batch in benign_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            s_batch = s_batch.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            if grl_lambda is not None and grl_lambda != 0:\n",
    "                outputs, outputs_protected = model(x_batch)\n",
    "                loss = criterion(outputs, y_batch) + criterion_bias(outputs_protected, s_batch.argmax(dim=1))\n",
    "            else:\n",
    "                outputs = model(x_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            batch_losses.append(loss.item())\n",
    "\n",
    "        training_loss = np.mean(batch_losses)\n",
    "        training_losses.append(training_loss)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            val_losses = []\n",
    "            for x_val, y_val, _, s_val in val_loader:\n",
    "                x_val = x_val.to(device)\n",
    "                y_val = y_val.to(device)\n",
    "                s_val = s_val.to(device)\n",
    "                model.eval()\n",
    "                if grl_lambda is not None and grl_lambda != 0:\n",
    "                    yhat, s_hat = model(x_val)\n",
    "                    val_loss = (criterion(y_val, yhat) + criterion_bias(s_val, s_hat.argmax(dim=1))).item()\n",
    "                else:\n",
    "                    yhat = model(x_val)\n",
    "                    val_loss = criterion(y_val, yhat).item()\n",
    "                val_losses.append(val_loss)\n",
    "            validation_loss = np.mean(val_losses)\n",
    "            validation_losses.append(validation_loss)\n",
    "\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "        t_prog.set_postfix({\"epoch\": epoch, \"training_loss\": training_loss,\n",
    "                            \"validation_loss\": validation_loss}, refresh=False)  # print last metrics\n",
    "\n",
    "#     if args.show_graphs:\n",
    "#         plt.plot(range(len(training_losses)), training_losses)\n",
    "#         plt.plot(range(len(validation_losses)), validation_losses)\n",
    "#         # plt.scatter(x_tensor, y_out.detach().numpy())\n",
    "#         plt.ylabel('some numbers')\n",
    "#         plt.show()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        test_losses = []\n",
    "        test_results = []\n",
    "        for x_test, y_test, ytrue, s_true in test_loader:\n",
    "            x_test = x_test.to(device)\n",
    "            y_test = y_test.to(device)\n",
    "            s_true = s_true.to(device)\n",
    "            model.eval()\n",
    "            if grl_lambda is not None and grl_lambda != 0:\n",
    "                yhat, s_hat = model(x_test)\n",
    "                test_loss = (criterion(y_test, yhat) + criterion_bias(s_true, s_hat.argmax(dim=1))).item()\n",
    "                test_losses.append(val_loss)\n",
    "                test_results.append({\"y_hat\": yhat, \"y_true\": ytrue, \"y_compas\": y_test, \"s\": s_true, \"s_hat\": s_hat})\n",
    "            else:\n",
    "                yhat = model(x_test)\n",
    "                test_loss = (criterion(y_test, yhat)).item()\n",
    "                test_losses.append(val_loss)\n",
    "                test_results.append({\"y_hat\": yhat, \"y_true\": ytrue, \"y_compas\": y_test, \"s\": s_true})\n",
    "\n",
    "        # print({\"Test loss\": np.mean(test_losses)})\n",
    "\n",
    "    results = test_results[0]['y_hat']\n",
    "    outcome = test_results[0]['y_true']\n",
    "    compas = test_results[0]['y_compas']\n",
    "    protected_results = test_results[0]['s']\n",
    "    if grl_lambda is not None and grl_lambda != 0:\n",
    "        protected = test_results[0]['s_hat']\n",
    "    for r in test_results[1:]:\n",
    "        results = torch.cat((results, r['y_hat']))\n",
    "        outcome = torch.cat((outcome, r['y_true']))\n",
    "        compas = torch.cat((compas, r['y_compas']))\n",
    "        protected_results = torch.cat((protected_results, r['s']))\n",
    "        if grl_lambda is not None and grl_lambda != 0:\n",
    "            protected = torch.cat((protected, r['s_hat']))\n",
    "\n",
    "    df = pd.DataFrame(data=results.cpu().numpy(), columns=['pred'])\n",
    "\n",
    "    df['true'] = outcome.cpu().numpy()\n",
    "    df['compas'] = compas.cpu().numpy()\n",
    "    df['race'] = protected_results.cpu().numpy()[:, 0]\n",
    "    if grl_lambda is not None and grl_lambda != 0:\n",
    "        df['race_hat'] = protected.cpu().numpy()[:, 0]\n",
    "\n",
    "    return model, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_sort(net, train_dataset, THETA=1e-3, GAMMA=0.9):\n",
    "    net=net.cpu()\n",
    "    # THETA = 1e-3\n",
    "    path_set_list=[]\n",
    "    for i in (range(len(train_dataset))):\n",
    "        path_set=get_path_set4(net,train_dataset[i][0],GAMMA=GAMMA)\n",
    "        path_set_list.append(path_set)\n",
    "    v=pd.value_counts(path_set_list).rename_axis('pathset').reset_index(name='counts')\n",
    "#     v_list.append(v)\n",
    "    t=tuple(v[v.counts<=max(v.counts[0]*THETA,1)].pathset)\n",
    "    adv_data_idx=[]\n",
    "    for i in range(len(path_set_list)):\n",
    "        if path_set_list[i] in t:\n",
    "            adv_data_idx.append(i)\n",
    "    print(\"frac:{}\".format(len(adv_data_idx)/len(train_dataset)))\n",
    "    return adv_data_idx\n",
    "\n",
    "v_list=[]\n",
    "def sample_sort_test(net, train_dataset, THETA=1e-3, GAMMA=0.9):\n",
    "    net=net.cpu()\n",
    "    # THETA = 1e-3\n",
    "    path_set_list=[]\n",
    "    for i in (range(len(train_dataset))):\n",
    "        path_set=get_path_set4(net,train_dataset[i][0],GAMMA=GAMMA)\n",
    "        path_set_list.append(path_set)\n",
    "    v=pd.value_counts(path_set_list).rename_axis('pathset').reset_index(name='counts')\n",
    "    v_list.append(v)\n",
    "    t=tuple(v[v.counts<=max(v.counts[0]*THETA,1)].pathset)\n",
    "    adv_data_idx=[]\n",
    "    for i in range(len(path_set_list)):\n",
    "        if path_set_list[i] in t:\n",
    "            adv_data_idx.append(i)\n",
    "    print(\"frac:{}\".format(len(adv_data_idx)/len(train_dataset)))\n",
    "    return adv_data_idx\n",
    "\n",
    "def get_adv(train_dataset,adv_data_idx):\n",
    "    x_t_adv, y_t_adv, l_t_adv, s_t_adv = (None,None,None,None)\n",
    "    for i in range(len(train_dataset)):\n",
    "        if i in adv_data_idx:\n",
    "            a,b,c,d=train_dataset[i]\n",
    "            x_t_adv = a.unsqueeze(0) if x_t_adv is None else torch.cat((x_t_adv,a.unsqueeze(0)),0)\n",
    "            y_t_adv = b.unsqueeze(0) if y_t_adv is None else torch.cat((y_t_adv,b.unsqueeze(0)),0)\n",
    "            l_t_adv = c.unsqueeze(0) if l_t_adv is None else torch.cat((l_t_adv,c.unsqueeze(0)),0)\n",
    "            s_t_adv = d.unsqueeze(0) if s_t_adv is None else torch.cat((s_t_adv,d.unsqueeze(0)),0)\n",
    "    x_t_benign, y_t_benign, l_t_benign, s_t_benign = (None,None,None,None)\n",
    "    for i in range(len(train_dataset)):\n",
    "        if i not in adv_data_idx:\n",
    "            a,b,c,d=train_dataset[i]\n",
    "            x_t_benign = a.unsqueeze(0) if x_t_benign is None else torch.cat((x_t_benign,a.unsqueeze(0)),0)\n",
    "            y_t_benign = b.unsqueeze(0) if y_t_benign is None else torch.cat((y_t_benign,b.unsqueeze(0)),0)\n",
    "            l_t_benign = c.unsqueeze(0) if l_t_benign is None else torch.cat((l_t_benign,c.unsqueeze(0)),0)\n",
    "            s_t_benign = d.unsqueeze(0) if s_t_benign is None else torch.cat((s_t_benign,d.unsqueeze(0)),0)\n",
    "\n",
    "    adv_dataset = TensorDataset(x_t_adv, y_t_adv, l_t_adv, s_t_adv)\n",
    "    benign_dataset = TensorDataset(x_t_benign, y_t_benign, l_t_benign, s_t_benign)\n",
    "\n",
    "    adv_loader = DataLoader(dataset=adv_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    benign_loader = DataLoader(dataset=benign_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    return adv_loader,benign_loader\n",
    "\n",
    "def get_adv_rand(train_dataset,adv_data_idx):\n",
    "    adv_data_idx=random.choices(range(0,len(train_dataset)),k=len(adv_data_idx))\n",
    "    x_t_adv, y_t_adv, l_t_adv, s_t_adv = (None,None,None,None)\n",
    "    for i in range(len(train_dataset)):\n",
    "        if i in adv_data_idx:\n",
    "            a,b,c,d=train_dataset[i]\n",
    "            x_t_adv = a.unsqueeze(0) if x_t_adv is None else torch.cat((x_t_adv,a.unsqueeze(0)),0)\n",
    "            y_t_adv = b.unsqueeze(0) if y_t_adv is None else torch.cat((y_t_adv,b.unsqueeze(0)),0)\n",
    "            l_t_adv = c.unsqueeze(0) if l_t_adv is None else torch.cat((l_t_adv,c.unsqueeze(0)),0)\n",
    "            s_t_adv = d.unsqueeze(0) if s_t_adv is None else torch.cat((s_t_adv,d.unsqueeze(0)),0)\n",
    "    x_t_benign, y_t_benign, l_t_benign, s_t_benign = (None,None,None,None)\n",
    "    for i in range(len(train_dataset)):\n",
    "        if i not in adv_data_idx:\n",
    "            a,b,c,d=train_dataset[i]\n",
    "            x_t_benign = a.unsqueeze(0) if x_t_benign is None else torch.cat((x_t_benign,a.unsqueeze(0)),0)\n",
    "            y_t_benign = b.unsqueeze(0) if y_t_benign is None else torch.cat((y_t_benign,b.unsqueeze(0)),0)\n",
    "            l_t_benign = c.unsqueeze(0) if l_t_benign is None else torch.cat((l_t_benign,c.unsqueeze(0)),0)\n",
    "            s_t_benign = d.unsqueeze(0) if s_t_benign is None else torch.cat((s_t_benign,d.unsqueeze(0)),0)\n",
    "\n",
    "    adv_dataset = TensorDataset(x_t_adv, y_t_adv, l_t_adv, s_t_adv)\n",
    "    benign_dataset = TensorDataset(x_t_benign, y_t_benign, l_t_benign, s_t_benign)\n",
    "\n",
    "    adv_loader = DataLoader(dataset=adv_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    benign_loader = DataLoader(dataset=benign_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    return adv_loader,benign_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EA(net, attack_size, iter_num, dataset='compas'):\n",
    "    model=net\n",
    "    EA_start=time.time()\n",
    "    t_main=trange(10,desc=\"Attack\", leave=False, position=0)\n",
    "    global train_loader, x_train_tensor, y_train_tensor, l_train_tensor, s_train_tensor\n",
    "    for i in range(iter_num):\n",
    "\n",
    "        model, results = train_and_evaluate(train_loader, val_loader, test_loader, device,\n",
    "                                            input_shape=x_tensor.shape[1], model=model)\n",
    "        print(i)\n",
    "        result = get_metrics(results, threshold, fraction=(attack_size)/(base_size * 7), dataset=dataset)\n",
    "        t_main.set_postfix(result)\n",
    "        global_results.append(result)    \n",
    "        result_pts, result_class, labels = attack_keras_model(\n",
    "                CArray(x_train_tensor),\n",
    "                Y=CArray((y_train_tensor[:, 0] > threshold).int()),\n",
    "                S=s_train_tensor,\n",
    "                nb_attack=10)\n",
    "        print('attack_done!')\n",
    "        result_pts = torch.tensor(np.around(result_pts.astype(np.float32), decimals=3)).clamp(0.0, 1.0)\n",
    "        result_pts[result_pts != result_pts] = 0.0\n",
    "        result_class[result_class != result_class] = 0.0\n",
    "\n",
    "        x_train_tensor = torch.cat((x_train_tensor, result_pts))\n",
    "        y_train_tensor = torch.cat(\n",
    "            (y_train_tensor, torch.tensor(result_class.reshape(-1, 1).astype(np.float32)).clamp(0, 10)))\n",
    "        l_train_tensor = torch.cat((l_train_tensor, torch.tensor(labels.tondarray().reshape(-1, 1).astype(np.float32))))\n",
    "        s = np.random.randint(2, size=len(result_class))\n",
    "        s_train_tensor = torch.cat((s_train_tensor, torch.tensor(np.array([s, 1 - s]).T.astype(np.float64))))\n",
    "\n",
    "        train_dataset = TensorDataset(x_train_tensor, y_train_tensor, l_train_tensor, s_train_tensor)\n",
    "        train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        logging.debug(\"New training dataset has size {} (original {}).\".format(len(train_loader), base_size * 7))\n",
    "        EA_mid=time.time()\n",
    "        cost_time=EA_mid-EA_start\n",
    "        print('time costs:{} s'.format(cost_time))\n",
    "\n",
    "    EA_end=time.time()\n",
    "    cost_time=EA_end-EA_start\n",
    "    print('time costs:{} s'.format(cost_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fixate(THETA=1e-3,GAMMA=0.9,epoch=10,dataset='compas'):\n",
    "    our_start=time.time()\n",
    "    for i in range(epoch):\n",
    "        adv_data_idx = sample_sort(net,train_dataset,THETA,GAMMA)\n",
    "        adv_loader, benign_loader = get_adv(train_dataset,adv_data_idx)\n",
    "        net_drop, results = train_and_evaluate_drop(adv_loader, benign_loader, val_loader, test_loader, device, input_shape=x_tensor.shape[1],\n",
    "                                                grl_lambda=0)\n",
    "\n",
    "        result = get_metrics(results, threshold, 0, dataset=dataset)\n",
    "        global_results.append(result)\n",
    "\n",
    "    our_end=time.time()\n",
    "    cost_time=our_end-our_start\n",
    "    print('time costs:{} s'.format(cost_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_function(config):\n",
    "    \n",
    "    THETA, GAMMA = config['THETA'], config['GAMMA']\n",
    "    train_dataset_s=config['train_dataset_s']\n",
    "    val_loader_s=config['val']\n",
    "    test_loader_s=config['test']\n",
    "    x_train_tensor_s=config['x_tensor']\n",
    "\n",
    "    adv_data_idx = sample_sort(net,train_dataset_s,THETA,GAMMA)\n",
    "    adv_loader, benign_loader = get_adv(train_dataset_s,adv_data_idx)\n",
    "    net_drop, results = train_and_evaluate_drop(adv_loader, benign_loader, val_loader_s, test_loader_s, device, input_shape=x_train_tensor_s.shape[1],\n",
    "                                            grl_lambda=0,dataset=config['dataset'])\n",
    "    result = get_metrics(results, threshold, 0,dataset=config['dataset'])\n",
    "    complex_score = result['DP']+result['EO']+(1-result['DP ratio'])-0.01*result['acc']\n",
    "    tune.report(mean_loss=complex_score)\n",
    "    \n",
    "    global_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_function_rand(config):\n",
    "    \n",
    "    THETA, GAMMA = config['THETA'], config['GAMMA']\n",
    "    train_dataset_s=config['train_dataset_s']\n",
    "    val_loader_s=config['val']\n",
    "    test_loader_s=config['test']\n",
    "    x_train_tensor_s=config['x_tensor']\n",
    "\n",
    "    adv_data_idx = sample_sort(net,train_dataset_s,THETA,GAMMA)\n",
    "    adv_loader, benign_loader = get_adv_rand(train_dataset_s,adv_data_idx)\n",
    "    net_drop, results = train_and_evaluate_drop(adv_loader, benign_loader, val_loader_s, test_loader_s, device, input_shape=x_train_tensor_s.shape[1],\n",
    "                                            grl_lambda=0,dataset=config['dataset'])\n",
    "    result = get_metrics(results, threshold, 0,dataset=config['dataset'])\n",
    "    complex_score = result['DP']+result['EO']+(1-result['DP ratio'])-0.01*result['acc']\n",
    "    tune.report(mean_loss=complex_score)\n",
    "    \n",
    "    global_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fixate_with_val(epoch=10,dataset='compas'):\n",
    "    our_start=time.time()\n",
    "    base_size = len(val_dataset) // 10\n",
    "    split = [8 * base_size, 1 * base_size, len(val_dataset) - 9 * base_size]  # Train, validation, test\n",
    "    train_dataset_s, val_dataset_s, test_dataset_s = random_split(val_dataset, split)\n",
    "#     print(train_dataset_s)\n",
    "    \n",
    "#     train_loader_s = DataLoader(dataset=train_dataset_s, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader_s = DataLoader(dataset=val_dataset_s, batch_size=BATCH_SIZE)\n",
    "    test_loader_s = DataLoader(dataset=test_dataset_s, batch_size=BATCH_SIZE)\n",
    "\n",
    "    x_train_tensor_s = val_dataset[:][0]\n",
    "\n",
    "\n",
    "    analysis = tune.run(\n",
    "        training_function,\n",
    "        config={\n",
    "            'THETA': tune.grid_search([0.1, 0.01, 3e-3, 1e-3, 3e-4, 1e-4]),\n",
    "            'GAMMA': tune.grid_search([0.95, 0.9, 0.85, 0.8, 0.7, 0.6]),\n",
    "            'dataset':dataset,\n",
    "            'train_dataset_s':train_dataset_s,\n",
    "            'val':val_loader_s,\n",
    "            'test':test_loader_s,\n",
    "            'x_tensor':x_train_tensor_s\n",
    "        },\n",
    "        resources_per_trial={\n",
    "            \"cpu\": 16,\n",
    "            \"gpu\": 2,\n",
    "        }\n",
    "    )\n",
    "    best_config=analysis.get_best_config(metric=\"mean_loss\", mode=\"min\")\n",
    "    print(\"Best config: \",best_config)\n",
    "    THETA = best_config['THETA']\n",
    "    GAMMA = best_config['GAMMA']\n",
    "    val_end=time.time()\n",
    "    for i in range(epoch):\n",
    "        adv_data_idx = sample_sort(net,train_dataset,THETA,GAMMA)\n",
    "        PA_end=time.time()\n",
    "        adv_loader, benign_loader = get_adv(train_dataset,adv_data_idx)\n",
    "        SS_end=time.time()\n",
    "        net_drop, results = train_and_evaluate_drop(adv_loader, benign_loader, val_loader, test_loader, device, input_shape=x_tensor.shape[1],\n",
    "                                                grl_lambda=0,dataset=dataset)\n",
    "        Dropout_end=time.time()\n",
    "        result = get_metrics(results, threshold, 0, dataset=dataset)\n",
    "        global_results.append(result)\n",
    "\n",
    "    our_end=time.time()\n",
    "    cost_time=our_end-our_start\n",
    "    val_time=val_end-our_start\n",
    "    PA_time=PA_end-val_end\n",
    "    SS_time=SS_end-PA_end\n",
    "    Dropout_time=Dropout_end-SS_end\n",
    "    print('param selection costs:{} s'.format(val_time))\n",
    "    print('path analysis costs:{} s'.format(PA_time))\n",
    "    print('sample separation costs:{} s'.format(SS_time))\n",
    "    print('partial dropout training costs:{} s'.format(Dropout_time))\n",
    "    print('total time costs:{} s'.format(cost_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fixate_with_val_rand(epoch=10,dataset='compas'):\n",
    "    our_start=time.time()\n",
    "    base_size = len(val_dataset) // 10\n",
    "    split = [8 * base_size, 1 * base_size, len(val_dataset) - 9 * base_size]  # Train, validation, test\n",
    "    train_dataset_s, val_dataset_s, test_dataset_s = random_split(val_dataset, split)\n",
    "#     print(train_dataset_s)\n",
    "    \n",
    "#     train_loader_s = DataLoader(dataset=train_dataset_s, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader_s = DataLoader(dataset=val_dataset_s, batch_size=BATCH_SIZE)\n",
    "    test_loader_s = DataLoader(dataset=test_dataset_s, batch_size=BATCH_SIZE)\n",
    "\n",
    "    x_train_tensor_s = val_dataset[:][0]\n",
    "\n",
    "\n",
    "    analysis = tune.run(\n",
    "        training_function_rand,\n",
    "        config={\n",
    "            'THETA': tune.grid_search([0.1, 0.01, 3e-3, 1e-3, 3e-4, 1e-4]),\n",
    "            'GAMMA': tune.grid_search([0.95, 0.9, 0.85, 0.8, 0.7, 0.6]),\n",
    "            'dataset':dataset,\n",
    "            'train_dataset_s':train_dataset_s,\n",
    "            'val':val_loader_s,\n",
    "            'test':test_loader_s,\n",
    "            'x_tensor':x_train_tensor_s\n",
    "        },\n",
    "        resources_per_trial={\n",
    "            \"cpu\": 8,\n",
    "            \"gpu\": 2,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    best_config=analysis.get_best_config(metric=\"mean_loss\", mode=\"min\")\n",
    "    print(\"Best config: \",best_config)\n",
    "    THETA = best_config['THETA']\n",
    "    GAMMA = best_config['GAMMA']\n",
    "    for i in range(epoch):\n",
    "        adv_data_idx = sample_sort(net,train_dataset,THETA,GAMMA)\n",
    "        adv_loader, benign_loader = get_adv_rand(train_dataset,adv_data_idx)\n",
    "        net_drop, results = train_and_evaluate_drop(adv_loader, benign_loader, val_loader, test_loader, device, input_shape=x_tensor.shape[1],\n",
    "                                                grl_lambda=0,dataset=dataset)\n",
    "\n",
    "        result = get_metrics(results, threshold, 0, dataset=dataset)\n",
    "        global_results.append(result)\n",
    "\n",
    "    our_end=time.time()\n",
    "    cost_time=our_end-our_start\n",
    "    print('time costs:{} s'.format(cost_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5278, 12)\n",
      "4.6227737779461915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.30it/s, epoch=16, training_loss=17.3, validation_loss=13.6]\u001b[A\n",
      "Training neural network:  70%|███████   | 35/50 [00:10<00:04,  3.37it/s, epoch=34, training_loss=8.54, validation_loss=9.23]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:14.907471895217896 s\n",
      "2021-08-13 13:49:43,923 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.3578205475738683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.93it/s, epoch=19, training_loss=4.48, validation_loss=4.2]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.94it/s, epoch=39, training_loss=4.48, validation_loss=4.13]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 13:50:13,729 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.37083220384928167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  44%|████▍     | 22/50 [00:05<00:06,  4.28it/s, epoch=21, training_loss=4.45, validation_loss=4.12]\u001b[A\n",
      "Training neural network:  88%|████████▊ | 44/50 [00:10<00:01,  4.01it/s, epoch=43, training_loss=4.33, validation_loss=4.09]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 13:50:42,668 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.3730008132285172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.10it/s, epoch=20, training_loss=4.51, validation_loss=4.18]\u001b[A\n",
      "Training neural network:  86%|████████▌ | 43/50 [00:10<00:01,  4.18it/s, epoch=42, training_loss=4.48, validation_loss=4.11]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:86.96166348457336 s\n",
      "2021-08-13 13:51:10,885 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.34995933857413936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  38%|███▊      | 19/50 [00:05<00:08,  3.79it/s, epoch=18, training_loss=4.53, validation_loss=4.28]\u001b[A\n",
      "Training neural network:  78%|███████▊  | 39/50 [00:10<00:02,  3.91it/s, epoch=38, training_loss=4.5, validation_loss=4.24] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 13:51:39,600 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.3534833288153971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  38%|███▊      | 19/50 [00:05<00:08,  3.77it/s, epoch=18, training_loss=4.49, validation_loss=4.23]\u001b[A\n",
      "Training neural network:  78%|███████▊  | 39/50 [00:10<00:02,  3.86it/s, epoch=38, training_loss=4.51, validation_loss=4.16]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 13:52:09,083 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.35294117647058826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.05it/s, epoch=20, training_loss=4.49, validation_loss=4.03]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:02,  3.93it/s, epoch=41, training_loss=4.43, validation_loss=4.03]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:87.33259391784668 s\n",
      "2021-08-13 13:52:38,218 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.3526701002981838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.88it/s, epoch=19, training_loss=4.48, validation_loss=4.18]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.88it/s, epoch=39, training_loss=4.51, validation_loss=4.33]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 13:53:06,995 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.34128490105719705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.09it/s, epoch=20, training_loss=4.46, validation_loss=4.18]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:02,  3.93it/s, epoch=41, training_loss=4.44, validation_loss=4]   \u001b[A\n",
      "                                                                                                                         \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 13:53:35,521 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.36541068040119273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.83it/s, epoch=19, training_loss=4.37, validation_loss=4.07]\u001b[A\n",
      "Training neural network:  82%|████████▏ | 41/50 [00:10<00:02,  4.03it/s, epoch=40, training_loss=4.23, validation_loss=4.05]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:85.30315613746643 s\n",
      "2021-08-13 13:54:03,522 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.34833288153971265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.00it/s, epoch=20, training_loss=4.58, validation_loss=4.18]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:01,  4.11it/s, epoch=41, training_loss=4.38, validation_loss=4.21]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 13:54:30,324 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.3396584440227704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.99it/s, epoch=19, training_loss=4.47, validation_loss=4.16]\u001b[A\n",
      "Training neural network:  82%|████████▏ | 41/50 [00:10<00:02,  4.01it/s, epoch=40, training_loss=4.49, validation_loss=4.15]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 13:54:58,982 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.37083220384928167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  44%|████▍     | 22/50 [00:05<00:06,  4.35it/s, epoch=21, training_loss=4.38, validation_loss=4.07]\u001b[A\n",
      "Training neural network:  88%|████████▊ | 44/50 [00:10<00:01,  4.25it/s, epoch=43, training_loss=4.36, validation_loss=4.02]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:83.28795456886292 s\n",
      "2021-08-13 13:55:26,810 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.36215776633233937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:06,  4.14it/s, epoch=20, training_loss=4.54, validation_loss=4.13]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:02,  3.98it/s, epoch=41, training_loss=4.52, validation_loss=4.11]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 13:55:53,660 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.35619409053944157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.13it/s, epoch=20, training_loss=4.47, validation_loss=4.01]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:01,  4.02it/s, epoch=41, training_loss=4.42, validation_loss=4.19]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 13:56:20,883 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.34643534833288153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  44%|████▍     | 22/50 [00:05<00:06,  4.28it/s, epoch=21, training_loss=4.52, validation_loss=4.14]\u001b[A\n",
      "Training neural network:  88%|████████▊ | 44/50 [00:10<00:01,  4.11it/s, epoch=43, training_loss=4.49, validation_loss=4.25]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:81.65716552734375 s\n",
      "2021-08-13 13:56:48,469 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.34236920574681484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.91it/s, epoch=19, training_loss=4.33, validation_loss=4.04]\u001b[A\n",
      "Training neural network:  82%|████████▏ | 41/50 [00:10<00:02,  4.05it/s, epoch=40, training_loss=4.26, validation_loss=3.82]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 13:57:15,526 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.3326104635402548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:06,  4.18it/s, epoch=20, training_loss=4.46, validation_loss=4.24]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:01,  4.02it/s, epoch=41, training_loss=4.42, validation_loss=4.25]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 13:57:42,449 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.35131471943616155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.00it/s, epoch=20, training_loss=4.54, validation_loss=4.19]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:02,  3.96it/s, epoch=41, training_loss=4.5, validation_loss=4.29] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:80.84013056755066 s\n",
      "2021-08-13 13:58:09,308 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.33505014909189484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.84it/s, epoch=19, training_loss=4.45, validation_loss=4.07]\u001b[A\n",
      "Training neural network:  82%|████████▏ | 41/50 [00:10<00:02,  4.02it/s, epoch=40, training_loss=4.43, validation_loss=4.02]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 13:58:35,909 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.331526158850637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  38%|███▊      | 19/50 [00:05<00:08,  3.73it/s, epoch=18, training_loss=4.53, validation_loss=4.18]\u001b[A\n",
      "Training neural network:  82%|████████▏ | 41/50 [00:10<00:02,  4.11it/s, epoch=40, training_loss=4.48, validation_loss=4.16]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 13:59:02,201 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.3345079967470859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  44%|████▍     | 22/50 [00:05<00:06,  4.29it/s, epoch=21, training_loss=4.44, validation_loss=4.24]\u001b[A\n",
      "Training neural network:  88%|████████▊ | 44/50 [00:11<00:01,  3.94it/s, epoch=43, training_loss=4.52, validation_loss=4.12]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:79.65466141700745 s\n",
      "2021-08-13 13:59:28,964 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.306587150989428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.13it/s, epoch=20, training_loss=4.51, validation_loss=4.21]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:01,  4.06it/s, epoch=41, training_loss=4.46, validation_loss=4.1] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 13:59:54,054 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.32447817836812143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.05it/s, epoch=20, training_loss=4.52, validation_loss=4.14]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:02,  3.89it/s, epoch=41, training_loss=4.42, validation_loss=4.05]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:00:19,937 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.32339387367850364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.98it/s, epoch=19, training_loss=4.45, validation_loss=4.03]\u001b[A\n",
      "Training neural network:  82%|████████▏ | 41/50 [00:10<00:02,  4.06it/s, epoch=40, training_loss=4.35, validation_loss=3.89]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:76.05116510391235 s\n",
      "2021-08-13 14:00:45,016 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.2965573326104635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.81it/s, epoch=19, training_loss=4.38, validation_loss=3.99]\u001b[A\n",
      "Training neural network:  82%|████████▏ | 41/50 [00:10<00:02,  3.93it/s, epoch=40, training_loss=4.35, validation_loss=4.03]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:01:10,785 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.29411764705882354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.12it/s, epoch=20, training_loss=4.51, validation_loss=3.95]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:01,  4.09it/s, epoch=41, training_loss=4.31, validation_loss=4.15]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:01:35,215 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.28706966657630795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.93it/s, epoch=19, training_loss=4.42, validation_loss=4.09]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:01,  4.02it/s, epoch=41, training_loss=4.34, validation_loss=4.12]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:74.90740489959717 s\n",
      "2021-08-13 14:01:59,923 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.2764976958525346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.02it/s, epoch=20, training_loss=4.53, validation_loss=4.11]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:01,  4.03it/s, epoch=41, training_loss=4.45, validation_loss=4.12]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:02:24,501 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.2762266196801301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.97it/s, epoch=19, training_loss=4.5, validation_loss=4.09]\u001b[A\n",
      "Training neural network:  82%|████████▏ | 41/50 [00:10<00:02,  4.05it/s, epoch=40, training_loss=4.42, validation_loss=4.08]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:02:48,570 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.2716183247492545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.91it/s, epoch=19, training_loss=4.51, validation_loss=4.15]\u001b[A\n",
      "Training neural network:  82%|████████▏ | 41/50 [00:10<00:02,  3.99it/s, epoch=40, training_loss=4.45, validation_loss=4.04]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:72.52334380149841 s\n",
      "2021-08-13 14:03:12,447 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.24017348875033884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  38%|███▊      | 19/50 [00:05<00:08,  3.74it/s, epoch=18, training_loss=4.41, validation_loss=4.01]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.97it/s, epoch=39, training_loss=4.32, validation_loss=4.12]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:03:36,069 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.23312550826782324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  38%|███▊      | 19/50 [00:05<00:08,  3.76it/s, epoch=18, training_loss=4.46, validation_loss=4.12]\u001b[A\n",
      "Training neural network:  78%|███████▊  | 39/50 [00:10<00:02,  3.84it/s, epoch=38, training_loss=4.4, validation_loss=4.17] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:03:59,707 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.2423420981295744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  44%|████▍     | 22/50 [00:05<00:06,  4.31it/s, epoch=21, training_loss=4.39, validation_loss=4.15]\u001b[A\n",
      "Training neural network:  88%|████████▊ | 44/50 [00:10<00:01,  4.01it/s, epoch=43, training_loss=4.37, validation_loss=3.91]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:69.71608185768127 s\n",
      "2021-08-13 14:04:22,163 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.204391433992952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:06,  4.14it/s, epoch=20, training_loss=4.52, validation_loss=4.18]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:02,  3.99it/s, epoch=41, training_loss=4.49, validation_loss=4.14]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:04:44,678 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.21171049064787206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.95it/s, epoch=19, training_loss=4.39, validation_loss=4.27]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.73it/s, epoch=39, training_loss=4.36, validation_loss=4.04]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:05:08,266 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.2024939007861209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.09it/s, epoch=20, training_loss=4.48, validation_loss=4.03]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:01,  4.15it/s, epoch=41, training_loss=4.48, validation_loss=4.12]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:68.4055745601654 s\n",
      "2021-08-13 14:05:30,569 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.18812686364868528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.97it/s, epoch=19, training_loss=4.5, validation_loss=4.1]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.93it/s, epoch=39, training_loss=4.49, validation_loss=4.1]\u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:05:53,227 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.18134995933857415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.10it/s, epoch=20, training_loss=4.48, validation_loss=4.02]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:01,  4.00it/s, epoch=41, training_loss=4.56, validation_loss=4.04]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:06:15,693 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.18866901599349417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.85it/s, epoch=19, training_loss=4.47, validation_loss=4.33]\u001b[A\n",
      "Training neural network:  82%|████████▏ | 41/50 [00:10<00:02,  3.97it/s, epoch=40, training_loss=4.56, validation_loss=4.16]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:67.95657134056091 s\n",
      "2021-08-13 14:06:38,526 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.17159121713201408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  3.98it/s, epoch=20, training_loss=4.37, validation_loss=4.05]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:01,  4.06it/s, epoch=41, training_loss=4.3, validation_loss=4]    \u001b[A\n",
      "                                                                                                                        \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:07:00,602 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.16806722689075632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.07it/s, epoch=20, training_loss=4.38, validation_loss=3.97]\u001b[A\n",
      "Training neural network:  88%|████████▊ | 44/50 [00:10<00:01,  4.29it/s, epoch=43, training_loss=4.33, validation_loss=3.94]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:07:21,999 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.16969368392518297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.81it/s, epoch=19, training_loss=4.47, validation_loss=4.04]\u001b[A\n",
      "Training neural network:  82%|████████▏ | 41/50 [00:10<00:02,  4.03it/s, epoch=40, training_loss=4.41, validation_loss=4.19]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:65.53202176094055 s\n",
      "2021-08-13 14:07:44,058 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.16101924640824072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  38%|███▊      | 19/50 [00:05<00:08,  3.70it/s, epoch=18, training_loss=4.51, validation_loss=4.21]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.93it/s, epoch=39, training_loss=4.46, validation_loss=4.09]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:08:07,264 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.16535646516671185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.94it/s, epoch=19, training_loss=4.55, validation_loss=4.03]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.90it/s, epoch=39, training_loss=4.4, validation_loss=4.02] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:08:29,715 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.17918134995933857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.88it/s, epoch=19, training_loss=4.48, validation_loss=4.08]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.95it/s, epoch=39, training_loss=4.41, validation_loss=4.07]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:67.36291456222534 s\n",
      "2021-08-13 14:08:51,421 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.16183247492545405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.01it/s, epoch=20, training_loss=4.4, validation_loss=3.98]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:02,  3.95it/s, epoch=41, training_loss=4.31, validation_loss=4.09]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:09:13,530 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.16345893195988073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.08it/s, epoch=20, training_loss=4.42, validation_loss=4.27]\u001b[A\n",
      "Training neural network:  86%|████████▌ | 43/50 [00:10<00:01,  4.16it/s, epoch=42, training_loss=4.46, validation_loss=4.09]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:09:34,554 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.16129032258064516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.83it/s, epoch=19, training_loss=4.43, validation_loss=4]\u001b[A\n",
      "Training neural network:  82%|████████▏ | 41/50 [00:10<00:02,  3.94it/s, epoch=40, training_loss=4.37, validation_loss=3.76]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:65.65075135231018 s\n",
      "2021-08-13 14:09:57,073 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.14800759013282733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.98it/s, epoch=19, training_loss=4.47, validation_loss=4.16]\u001b[A\n",
      "Training neural network:  82%|████████▏ | 41/50 [00:10<00:02,  4.04it/s, epoch=40, training_loss=4.49, validation_loss=4.17]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:10:19,161 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.1461100569259962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.97it/s, epoch=19, training_loss=4.39, validation_loss=3.93]\u001b[A\n",
      "Training neural network:  82%|████████▏ | 41/50 [00:10<00:02,  4.02it/s, epoch=40, training_loss=4.31, validation_loss=3.93]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:10:41,583 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.15397126592572513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.95it/s, epoch=19, training_loss=4.35, validation_loss=4.27]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.89it/s, epoch=39, training_loss=4.18, validation_loss=3.94]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:66.2458484172821 s\n",
      "2021-08-13 14:11:03,319 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.14394144754676064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  38%|███▊      | 19/50 [00:05<00:08,  3.68it/s, epoch=18, training_loss=4.34, validation_loss=4.13]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.88it/s, epoch=39, training_loss=4.33, validation_loss=3.99]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:11:24,721 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.13797777175386283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.82it/s, epoch=19, training_loss=4.51, validation_loss=4.12]\u001b[A\n",
      "Training neural network:  82%|████████▏ | 41/50 [00:10<00:02,  3.97it/s, epoch=40, training_loss=4.48, validation_loss=4.3] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:11:46,434 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.13255624830577392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.85it/s, epoch=19, training_loss=4.51, validation_loss=4.02]\u001b[A\n",
      "Training neural network:  82%|████████▏ | 41/50 [00:10<00:02,  4.01it/s, epoch=40, training_loss=4.39, validation_loss=4.19]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:64.44424200057983 s\n",
      "2021-08-13 14:12:07,764 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.12686364868528055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  38%|███▊      | 19/50 [00:05<00:08,  3.77it/s, epoch=18, training_loss=4.4, validation_loss=4.09]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  4.01it/s, epoch=39, training_loss=4.29, validation_loss=4.09]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:12:29,351 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.127134724857685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  46%|████▌     | 23/50 [00:05<00:06,  4.48it/s, epoch=22, training_loss=4.54, validation_loss=4.26]\u001b[A\n",
      "Training neural network:  92%|█████████▏| 46/50 [00:10<00:00,  4.28it/s, epoch=45, training_loss=4.55, validation_loss=4.11]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:12:49,469 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.12279750609921387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:06,  4.19it/s, epoch=20, training_loss=4.52, validation_loss=4.27]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:02,  3.97it/s, epoch=41, training_loss=4.45, validation_loss=4.04]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:63.61458158493042 s\n",
      "2021-08-13 14:13:11,379 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.11466522092708051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.95it/s, epoch=19, training_loss=4.47, validation_loss=4.13]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.78it/s, epoch=39, training_loss=4.4, validation_loss=4.18] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:13:33,085 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.10843046896177826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.97it/s, epoch=19, training_loss=4.4, validation_loss=4.02]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.91it/s, epoch=39, training_loss=4.32, validation_loss=4.06]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:13:54,803 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.11466522092708051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.87it/s, epoch=19, training_loss=4.32, validation_loss=4.02]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.87it/s, epoch=39, training_loss=4.41, validation_loss=4.18]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:64.6123902797699 s\n",
      "2021-08-13 14:14:15,992 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.09758742206560043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  38%|███▊      | 19/50 [00:05<00:08,  3.69it/s, epoch=18, training_loss=4.89, validation_loss=4.34]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.97it/s, epoch=39, training_loss=4.68, validation_loss=4.2] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:14:37,137 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.10246679316888045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.03it/s, epoch=20, training_loss=4.45, validation_loss=4.06]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:01,  4.06it/s, epoch=41, training_loss=4.37, validation_loss=3.99]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:14:58,549 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.10138248847926268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.02it/s, epoch=20, training_loss=4.51, validation_loss=4.05]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:01,  4.03it/s, epoch=41, training_loss=4.43, validation_loss=4.06]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:63.36790728569031 s\n",
      "2021-08-13 14:15:19,361 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.10029818378964489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  44%|████▍     | 22/50 [00:05<00:06,  4.24it/s, epoch=21, training_loss=4.54, validation_loss=4.14]\u001b[A\n",
      "Training neural network:  88%|████████▊ | 44/50 [00:10<00:01,  4.20it/s, epoch=43, training_loss=4.47, validation_loss=4.18]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:15:39,548 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.09650311737598265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.09it/s, epoch=20, training_loss=4.37, validation_loss=4.05]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:01,  4.13it/s, epoch=41, training_loss=4.28, validation_loss=4.06]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:15:59,585 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.10761724044456493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.86it/s, epoch=19, training_loss=4.36, validation_loss=4.12]\u001b[A\n",
      "Training neural network:  82%|████████▏ | 41/50 [00:10<00:02,  3.98it/s, epoch=40, training_loss=4.36, validation_loss=4.06]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:61.52029275894165 s\n",
      "2021-08-13 14:16:20,882 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.10002710761724044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  38%|███▊      | 19/50 [00:05<00:08,  3.68it/s, epoch=18, training_loss=4.34, validation_loss=4]\u001b[A\n",
      "Training neural network:  76%|███████▌  | 38/50 [00:10<00:03,  3.74it/s, epoch=37, training_loss=4.39, validation_loss=4.06]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:16:42,317 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.09352127947953374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.08it/s, epoch=20, training_loss=4.44, validation_loss=4.14]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:02,  3.95it/s, epoch=41, training_loss=4.44, validation_loss=4.13]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:17:03,225 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.09704526972079154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  38%|███▊      | 19/50 [00:05<00:08,  3.68it/s, epoch=18, training_loss=4.92, validation_loss=4.17]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.88it/s, epoch=39, training_loss=4.41, validation_loss=4.23]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:63.765761852264404 s\n",
      "2021-08-13 14:17:24,647 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.09270805096232042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.97it/s, epoch=19, training_loss=4.4, validation_loss=3.97]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.97it/s, epoch=39, training_loss=4.24, validation_loss=3.9]\u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:17:45,465 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.09433450799674709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.97it/s, epoch=19, training_loss=4.35, validation_loss=3.96]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.95it/s, epoch=39, training_loss=4.25, validation_loss=3.96]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:18:06,341 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.09189482244510708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.03it/s, epoch=20, training_loss=4.44, validation_loss=4.02]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:02,  3.88it/s, epoch=41, training_loss=4.54, validation_loss=3.96]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:62.886741161346436 s\n",
      "2021-08-13 14:18:27,535 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.08782867985904039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.11it/s, epoch=20, training_loss=4.46, validation_loss=4.21]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:02,  3.89it/s, epoch=41, training_loss=4.45, validation_loss=4.25]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:18:48,479 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.09352127947953374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.89it/s, epoch=19, training_loss=4.42, validation_loss=4.12]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.95it/s, epoch=39, training_loss=4.39, validation_loss=3.98]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:19:09,722 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.09758742206560043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.89it/s, epoch=19, training_loss=4.64, validation_loss=4.09]\u001b[A\n",
      "Training neural network:  82%|████████▏ | 41/50 [00:10<00:02,  4.01it/s, epoch=40, training_loss=4.37, validation_loss=4.22]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:63.17923164367676 s\n",
      "2021-08-13 14:19:30,715 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0992138791000271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  44%|████▍     | 22/50 [00:05<00:06,  4.36it/s, epoch=21, training_loss=4.49, validation_loss=4.25]\u001b[A\n",
      "Training neural network:  88%|████████▊ | 44/50 [00:10<00:01,  4.21it/s, epoch=43, training_loss=4.46, validation_loss=4.21]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:19:50,950 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.10002710761724044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  44%|████▍     | 22/50 [00:05<00:06,  4.31it/s, epoch=21, training_loss=4.47, validation_loss=4.23]\u001b[A\n",
      "Training neural network:  88%|████████▊ | 44/50 [00:10<00:01,  4.26it/s, epoch=43, training_loss=4.47, validation_loss=4.04]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:20:10,779 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.08891298454865817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.92it/s, epoch=19, training_loss=4.46, validation_loss=4.17]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.87it/s, epoch=39, training_loss=4.47, validation_loss=4.11]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:61.30881118774414 s\n",
      "2021-08-13 14:20:32,024 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.09108159392789374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  3.98it/s, epoch=20, training_loss=4.49, validation_loss=4.22]\u001b[A\n",
      "Training neural network:  82%|████████▏ | 41/50 [00:10<00:02,  3.95it/s, epoch=40, training_loss=4.53, validation_loss=4.05]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:20:52,816 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.09758742206560043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.94it/s, epoch=19, training_loss=4.59, validation_loss=4.26]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.89it/s, epoch=39, training_loss=4.45, validation_loss=4.16]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:21:13,311 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.09758742206560043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.85it/s, epoch=19, training_loss=4.32, validation_loss=3.9]\u001b[A\n",
      "Training neural network:  82%|████████▏ | 41/50 [00:10<00:02,  4.04it/s, epoch=40, training_loss=4.33, validation_loss=4.08]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:61.780768632888794 s\n",
      "2021-08-13 14:21:33,805 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.08864190837625373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.05it/s, epoch=20, training_loss=4.33, validation_loss=3.99]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:02,  4.00it/s, epoch=41, training_loss=4.35, validation_loss=3.91]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:21:53,964 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.08078069937652481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.78it/s, epoch=19, training_loss=4.53, validation_loss=4.12]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.76it/s, epoch=39, training_loss=4.37, validation_loss=4.12]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:22:14,810 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.08294930875576037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.07it/s, epoch=20, training_loss=4.5, validation_loss=4.16]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:02,  4.00it/s, epoch=41, training_loss=4.49, validation_loss=4.23]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:61.66506838798523 s\n",
      "2021-08-13 14:22:35,471 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.09216589861751152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  44%|████▍     | 22/50 [00:05<00:06,  4.30it/s, epoch=21, training_loss=4.48, validation_loss=4.11]\u001b[A\n",
      "Training neural network:  88%|████████▊ | 44/50 [00:10<00:01,  4.01it/s, epoch=43, training_loss=4.4, validation_loss=4.2]  \u001b[A\n",
      "                                                                                                                          \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:22:56,059 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.08891298454865817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.05it/s, epoch=20, training_loss=4.3, validation_loss=4.01]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:01,  4.07it/s, epoch=41, training_loss=4.37, validation_loss=3.96]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:23:16,366 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.07806993765248035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.84it/s, epoch=19, training_loss=4.5, validation_loss=4.3]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.89it/s, epoch=39, training_loss=4.5, validation_loss=4.22]\u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:61.48437285423279 s\n",
      "2021-08-13 14:23:36,955 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.08186500406614258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.86it/s, epoch=19, training_loss=4.43, validation_loss=4.03]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.91it/s, epoch=39, training_loss=4.45, validation_loss=4.22]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:23:57,575 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.08891298454865817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.11it/s, epoch=20, training_loss=4.45, validation_loss=4.07]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:01,  4.14it/s, epoch=41, training_loss=4.43, validation_loss=4.09]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:24:17,769 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0932502033071293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  44%|████▍     | 22/50 [00:05<00:06,  4.27it/s, epoch=21, training_loss=4.51, validation_loss=4.24]\u001b[A\n",
      "Training neural network:  88%|████████▊ | 44/50 [00:10<00:01,  4.14it/s, epoch=43, training_loss=4.45, validation_loss=4.23]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:60.446372270584106 s\n",
      "2021-08-13 14:24:37,402 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0872865275142315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.07it/s, epoch=20, training_loss=4.48, validation_loss=4.34]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:01,  4.02it/s, epoch=41, training_loss=4.48, validation_loss=4.32]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:24:56,903 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.08159392789373814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.01it/s, epoch=20, training_loss=4.55, validation_loss=4.23]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:02,  3.91it/s, epoch=41, training_loss=4.49, validation_loss=4.14]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:25:17,084 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.08511791813499593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.09it/s, epoch=20, training_loss=4.47, validation_loss=4.03]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:01,  4.10it/s, epoch=41, training_loss=4.36, validation_loss=4.13]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:59.38957452774048 s\n",
      "2021-08-13 14:25:36,792 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.07969639468690702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.86it/s, epoch=19, training_loss=4.37, validation_loss=4.19]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.87it/s, epoch=39, training_loss=4.41, validation_loss=4.08]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:25:56,967 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.07671455679045812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.05it/s, epoch=20, training_loss=4.49, validation_loss=4.23]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:01,  4.11it/s, epoch=41, training_loss=4.48, validation_loss=4.17]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:26:17,298 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.07237733803198698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  4.00it/s, epoch=19, training_loss=4.36, validation_loss=4.14]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.80it/s, epoch=39, training_loss=4.41, validation_loss=4.06]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:61.09682321548462 s\n",
      "2021-08-13 14:26:37,889 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.057739224722146924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.14it/s, epoch=20, training_loss=4.45, validation_loss=4.25]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:01,  4.03it/s, epoch=41, training_loss=4.35, validation_loss=4.05]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:26:57,590 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.07102195716996476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:06,  4.19it/s, epoch=20, training_loss=4.81, validation_loss=4.24]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:01,  4.04it/s, epoch=41, training_loss=4.47, validation_loss=4.16]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:27:17,312 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.06749796692870697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  38%|███▊      | 19/50 [00:05<00:08,  3.74it/s, epoch=18, training_loss=4.42, validation_loss=4.28]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.96it/s, epoch=39, training_loss=4.28, validation_loss=3.86]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:59.551989793777466 s\n",
      "2021-08-13 14:27:37,441 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.06560043372187585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.90it/s, epoch=19, training_loss=4.54, validation_loss=4.23]\u001b[A\n",
      "Training neural network:  82%|████████▏ | 41/50 [00:10<00:02,  4.02it/s, epoch=40, training_loss=4.43, validation_loss=4.16]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:27:57,622 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.061263214963404714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.88it/s, epoch=19, training_loss=4.51, validation_loss=4.17]\u001b[A\n",
      "Training neural network:  82%|████████▏ | 41/50 [00:10<00:02,  4.06it/s, epoch=40, training_loss=4.44, validation_loss=4.16]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:28:17,548 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.059636757928978046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:06,  4.19it/s, epoch=20, training_loss=4.58, validation_loss=4.11]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:01,  4.04it/s, epoch=41, training_loss=4.52, validation_loss=4.29]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:60.13767957687378 s\n",
      "2021-08-13 14:28:37,579 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.05367308213608024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:06,  4.14it/s, epoch=20, training_loss=4.56, validation_loss=4.19]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:01,  4.13it/s, epoch=41, training_loss=4.54, validation_loss=4.3] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:28:56,813 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.05367308213608024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  48%|████▊     | 24/50 [00:05<00:05,  4.69it/s, epoch=23, training_loss=4.51, validation_loss=4.22]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:11<00:00,  4.21it/s, epoch=47, training_loss=4.49, validation_loss=4.26]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:29:15,457 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.061263214963404714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.91it/s, epoch=19, training_loss=4.59, validation_loss=4.2]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.93it/s, epoch=39, training_loss=4.61, validation_loss=4.17]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:57.39248514175415 s\n",
      "2021-08-13 14:29:34,972 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.05801030089455137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.91it/s, epoch=19, training_loss=4.35, validation_loss=4.08]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.94it/s, epoch=39, training_loss=4.48, validation_loss=4.1] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:29:54,885 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0558416915153158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.90it/s, epoch=19, training_loss=4.54, validation_loss=4.31]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.86it/s, epoch=39, training_loss=4.46, validation_loss=4.18]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:30:14,396 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.05367308213608024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  44%|████▍     | 22/50 [00:05<00:06,  4.20it/s, epoch=21, training_loss=4.47, validation_loss=4.22]\u001b[A\n",
      "Training neural network:  86%|████████▌ | 43/50 [00:10<00:01,  3.98it/s, epoch=42, training_loss=4.48, validation_loss=4.21]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:58.904489278793335 s\n",
      "2021-08-13 14:30:33,877 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.05502846299810247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.08it/s, epoch=20, training_loss=4.39, validation_loss=4.06]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:01,  4.01it/s, epoch=41, training_loss=4.39, validation_loss=4.11]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:30:53,432 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.055570615342911356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.83it/s, epoch=19, training_loss=4.48, validation_loss=4.04]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.89it/s, epoch=39, training_loss=4.31, validation_loss=4.04]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:31:13,154 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.05177554892924912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  44%|████▍     | 22/50 [00:05<00:06,  4.19it/s, epoch=21, training_loss=4.45, validation_loss=4.35]\u001b[A\n",
      "Training neural network:  86%|████████▌ | 43/50 [00:10<00:01,  4.07it/s, epoch=42, training_loss=4.5, validation_loss=4.23] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:58.620949506759644 s\n",
      "2021-08-13 14:31:32,499 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.05313092979127135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.91it/s, epoch=19, training_loss=4.56, validation_loss=3.97]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:01,  4.11it/s, epoch=41, training_loss=4.49, validation_loss=4.25]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:31:51,722 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0563838438601247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.92it/s, epoch=19, training_loss=4.37, validation_loss=3.94]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.90it/s, epoch=39, training_loss=4.31, validation_loss=3.88]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:32:11,183 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.054486310653293575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.12it/s, epoch=20, training_loss=4.43, validation_loss=4.03]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:01,  4.16it/s, epoch=41, training_loss=4.29, validation_loss=3.97]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:58.19204568862915 s\n",
      "2021-08-13 14:32:30,691 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.05069124423963134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:06,  4.14it/s, epoch=20, training_loss=4.48, validation_loss=4.11]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:01,  4.06it/s, epoch=41, training_loss=4.47, validation_loss=4.35]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:32:49,421 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.05475738682569802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.84it/s, epoch=19, training_loss=4.49, validation_loss=4.13]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.79it/s, epoch=39, training_loss=4.52, validation_loss=4.14]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:33:09,449 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.053402005963675794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.92it/s, epoch=19, training_loss=4.35, validation_loss=4.12]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.71it/s, epoch=39, training_loss=4.33, validation_loss=4.04]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:59.03361654281616 s\n",
      "2021-08-13 14:33:29,725 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.050149091894822445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.85it/s, epoch=19, training_loss=4.53, validation_loss=4.28]\u001b[A\n",
      "Training neural network:  82%|████████▏ | 41/50 [00:10<00:02,  3.99it/s, epoch=40, training_loss=4.49, validation_loss=4.23]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:33:49,651 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.053402005963675794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  38%|███▊      | 19/50 [00:05<00:08,  3.73it/s, epoch=18, training_loss=4.34, validation_loss=4.07]\u001b[A\n",
      "Training neural network:  78%|███████▊  | 39/50 [00:10<00:02,  3.85it/s, epoch=38, training_loss=4.35, validation_loss=3.97]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:34:09,274 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.04635402548116021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.08it/s, epoch=20, training_loss=4.4, validation_loss=4.08]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:01,  4.02it/s, epoch=41, training_loss=4.37, validation_loss=4.06]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:58.86502504348755 s\n",
      "2021-08-13 14:34:28,590 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.052588777446462454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  44%|████▍     | 22/50 [00:05<00:06,  4.18it/s, epoch=21, training_loss=4.51, validation_loss=4.15]\u001b[A\n",
      "Training neural network:  86%|████████▌ | 43/50 [00:11<00:01,  3.82it/s, epoch=42, training_loss=4.38, validation_loss=4.05]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:34:48,805 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.053402005963675794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.93it/s, epoch=19, training_loss=4.29, validation_loss=4]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:01,  4.11it/s, epoch=41, training_loss=4.32, validation_loss=4.09]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:35:07,617 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.052317701274058014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  44%|████▍     | 22/50 [00:05<00:06,  4.23it/s, epoch=21, training_loss=4.36, validation_loss=4.05]\u001b[A\n",
      "Training neural network:  88%|████████▊ | 44/50 [00:10<00:01,  3.99it/s, epoch=43, training_loss=4.35, validation_loss=4.04]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:58.095842123031616 s\n",
      "2021-08-13 14:35:26,687 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.051233396584440226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.09it/s, epoch=20, training_loss=4.56, validation_loss=4.31]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:01,  4.02it/s, epoch=41, training_loss=4.51, validation_loss=4.18]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:35:45,953 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.04526972079154242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.95it/s, epoch=19, training_loss=4.43, validation_loss=4.01]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:01,  4.13it/s, epoch=41, training_loss=4.33, validation_loss=4.02]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:36:05,068 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.052317701274058014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  38%|███▊      | 19/50 [00:05<00:08,  3.74it/s, epoch=18, training_loss=4.45, validation_loss=4.24]\u001b[A\n",
      "Training neural network:  78%|███████▊  | 39/50 [00:10<00:02,  3.84it/s, epoch=38, training_loss=4.41, validation_loss=4.12]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:58.386953353881836 s\n",
      "2021-08-13 14:36:25,074 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.05042016806722689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  38%|███▊      | 19/50 [00:05<00:08,  3.72it/s, epoch=18, training_loss=4.43, validation_loss=4.11]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.93it/s, epoch=39, training_loss=4.39, validation_loss=3.97]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:36:44,651 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.04852263486039577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.89it/s, epoch=19, training_loss=4.48, validation_loss=4.22]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:01,  4.09it/s, epoch=41, training_loss=4.43, validation_loss=4.06]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:37:03,920 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.04852263486039577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  4.00it/s, epoch=19, training_loss=4.43, validation_loss=4.17]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.87it/s, epoch=39, training_loss=4.38, validation_loss=4.18]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:58.7789511680603 s\n",
      "2021-08-13 14:37:23,853 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.049064787205204664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  44%|████▍     | 22/50 [00:05<00:06,  4.24it/s, epoch=21, training_loss=4.41, validation_loss=4.11]\u001b[A\n",
      "Training neural network:  88%|████████▊ | 44/50 [00:11<00:01,  3.89it/s, epoch=43, training_loss=4.34, validation_loss=4.15]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:37:43,429 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.04418541610192464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.86it/s, epoch=19, training_loss=4.41, validation_loss=4.04]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.69it/s, epoch=39, training_loss=4.32, validation_loss=4.11]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:38:03,369 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.050149091894822445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.10it/s, epoch=20, training_loss=4.44, validation_loss=4.14]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:01,  4.10it/s, epoch=41, training_loss=4.36, validation_loss=3.95]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:58.22967767715454 s\n",
      "2021-08-13 14:38:22,084 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.03984819734345351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  38%|███▊      | 19/50 [00:05<00:08,  3.75it/s, epoch=18, training_loss=4.45, validation_loss=4.07]\u001b[A\n",
      "Training neural network:  78%|███████▊  | 39/50 [00:10<00:02,  3.84it/s, epoch=38, training_loss=4.29, validation_loss=4.12]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:38:42,141 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.04743833017077799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:06,  4.16it/s, epoch=20, training_loss=4.37, validation_loss=3.98]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:02,  3.94it/s, epoch=41, training_loss=4.31, validation_loss=3.96]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:39:00,921 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.04635402548116021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  44%|████▍     | 22/50 [00:05<00:06,  4.32it/s, epoch=21, training_loss=4.47, validation_loss=4.02]\u001b[A\n",
      "Training neural network:  88%|████████▊ | 44/50 [00:10<00:01,  4.22it/s, epoch=43, training_loss=4.48, validation_loss=4.14]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:57.83946871757507 s\n",
      "2021-08-13 14:39:19,923 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.04310111141230686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.13it/s, epoch=20, training_loss=4.36, validation_loss=4]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:01,  4.05it/s, epoch=41, training_loss=4.38, validation_loss=3.88]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:39:38,470 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.03795066413662239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.86it/s, epoch=19, training_loss=4.46, validation_loss=4.31]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.78it/s, epoch=39, training_loss=4.37, validation_loss=4.24]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:39:57,680 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.036324207102195714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.98it/s, epoch=19, training_loss=4.62, validation_loss=4.1]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.84it/s, epoch=39, training_loss=4.42, validation_loss=4.1]\u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:56.81587743759155 s\n",
      "2021-08-13 14:40:16,740 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.02737869341284901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  38%|███▊      | 19/50 [00:05<00:08,  3.75it/s, epoch=18, training_loss=4.46, validation_loss=4.31]\u001b[A\n",
      "Training neural network:  78%|███████▊  | 39/50 [00:10<00:02,  3.85it/s, epoch=38, training_loss=4.44, validation_loss=4.17]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:40:36,146 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.032800216860937925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:05<00:07,  3.88it/s, epoch=19, training_loss=4.43, validation_loss=4.14]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:10<00:02,  3.92it/s, epoch=39, training_loss=4.34, validation_loss=4.04]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:40:55,204 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.03469775006776904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.11it/s, epoch=20, training_loss=4.34, validation_loss=4.08]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:01,  4.13it/s, epoch=41, training_loss=4.32, validation_loss=4.18]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:57.1435022354126 s\n",
      "2021-08-13 14:41:13,883 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.03252914068853348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.09it/s, epoch=20, training_loss=4.44, validation_loss=4.16]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:02,  3.91it/s, epoch=41, training_loss=4.49, validation_loss=4.14]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:41:32,539 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.030360531309297913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  46%|████▌     | 23/50 [00:05<00:05,  4.54it/s, epoch=22, training_loss=4.46, validation_loss=4.14]\u001b[A\n",
      "Training neural network:  92%|█████████▏| 46/50 [00:10<00:00,  4.25it/s, epoch=45, training_loss=4.44, validation_loss=4.24]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:41:50,826 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.030902683654106804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.12it/s, epoch=20, training_loss=4.37, validation_loss=4.16]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:01,  4.09it/s, epoch=41, training_loss=4.33, validation_loss=3.97]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:55.069679498672485 s\n",
      "2021-08-13 14:42:08,953 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.03171591217132014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.10it/s, epoch=20, training_loss=4.38, validation_loss=4.06]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:01,  4.15it/s, epoch=41, training_loss=4.36, validation_loss=3.86]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:42:27,542 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.026294388723231227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:06,  4.17it/s, epoch=20, training_loss=4.59, validation_loss=4.28]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:01,  4.19it/s, epoch=41, training_loss=4.51, validation_loss=4.23]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:42:45,897 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.026023312550826783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.08it/s, epoch=20, training_loss=4.49, validation_loss=4.21]\u001b[A\n",
      "Training neural network:  86%|████████▌ | 43/50 [00:10<00:01,  4.14it/s, epoch=42, training_loss=4.47, validation_loss=4.23]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:55.43140482902527 s\n",
      "2021-08-13 14:43:04,385 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.02737869341284901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:05<00:07,  4.04it/s, epoch=20, training_loss=4.7, validation_loss=4.39]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:10<00:02,  3.99it/s, epoch=41, training_loss=4.41, validation_loss=4.14]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:43:22,605 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.02683654106804012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  44%|████▍     | 22/50 [00:05<00:06,  4.24it/s, epoch=21, training_loss=4.41, validation_loss=4.11]\u001b[A\n",
      "Training neural network:  88%|████████▊ | 44/50 [00:10<00:01,  4.06it/s, epoch=43, training_loss=4.34, validation_loss=3.95]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 14:43:41,096 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.02737869341284901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  44%|████▍     | 22/50 [00:05<00:06,  4.38it/s, epoch=21, training_loss=4.43, validation_loss=4.19]\u001b[A\n",
      "Training neural network:  88%|████████▊ | 44/50 [00:10<00:01,  4.25it/s, epoch=43, training_loss=4.41, validation_loss=4.11]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:54.47679114341736 s\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "BATCH_SIZE=128\n",
    "\n",
    "df=pd.read_csv('data/COMPAS/compas_recidive_two_years_sanitize_age_category_jail_time_decile_score.csv')\n",
    "# df_binary = df[(df[\"race\"] == \"Caucasian\") | (df[\"race\"] == \"African-American\")]     提取两种种族\n",
    "# Y = df_binary['decile_score']    评分，range:[0,10]\n",
    "# S = df_binary['race']\n",
    "# Y_true = df_binary['two_year_recid']    是否入狱\n",
    "df_binary, Y, S, Y_true = transform_dataset(df)\n",
    "Y = Y.to_numpy()\n",
    "print(np.mean(Y))\n",
    "\n",
    "l_tensor = torch.tensor(Y_true.to_numpy().reshape(-1, 1).astype(np.float32))\n",
    "x_tensor = torch.tensor(df_binary.to_numpy().astype(np.float32))\n",
    "y_tensor = torch.tensor(Y.reshape(-1, 1).astype(np.float32))\n",
    "s_tensor = torch.tensor(preprocessing.OneHotEncoder().fit_transform(np.array(S).reshape(-1, 1)).toarray())\n",
    "\n",
    "dataset = TensorDataset(x_tensor, y_tensor, l_tensor, s_tensor)  # dataset = CustomDataset(x_tensor, y_tensor)\n",
    "\n",
    "base_size = len(dataset) // 10\n",
    "split = [7 * base_size, 1 * base_size, len(dataset) - 8 * base_size]  # Train, validation, test\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, split)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "x_train_tensor = train_dataset[:][0]\n",
    "y_train_tensor = train_dataset[:][1]\n",
    "l_train_tensor = train_dataset[:][2]\n",
    "s_train_tensor = train_dataset[:][3]\n",
    "\n",
    "global_results = []\n",
    "\n",
    "# get the classification threshold, we use the same scale for compas so 4 instead of 0.5\n",
    "ori_start=time.time()\n",
    "threshold = 4\n",
    "\n",
    "net, results = train_and_evaluate(train_loader, val_loader, test_loader, device, input_shape=x_tensor.shape[1],\n",
    "                                    grl_lambda=0)\n",
    "ori_end=time.time()\n",
    "ori_cost_time=ori_end-ori_start\n",
    "print('time costs:{} s'.format(ori_cost_time))\n",
    "\n",
    "result = get_metrics(results, threshold, 0)\n",
    "global_results.append(result)\n",
    "\n",
    "# EA\n",
    "# EA(net,attack_size=10, iter_num=50)\n",
    "\n",
    "for THETA in list(np.logspace(-0.01,-5,50)):\n",
    "    Fixate(THETA=THETA,GAMMA=0.95,epoch=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DP</th>\n",
       "      <th>EO</th>\n",
       "      <th>DP ratio</th>\n",
       "      <th>acc</th>\n",
       "      <th>acc_ci_min</th>\n",
       "      <th>acc_ci_max</th>\n",
       "      <th>f1</th>\n",
       "      <th>acc_high_risk</th>\n",
       "      <th>acc_ci_min_high_risk</th>\n",
       "      <th>acc_ci_max_high_risk</th>\n",
       "      <th>f1_high_risk</th>\n",
       "      <th>adversarial_fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.220259</td>\n",
       "      <td>0.398359</td>\n",
       "      <td>1.386376</td>\n",
       "      <td>0.633710</td>\n",
       "      <td>0.604733</td>\n",
       "      <td>0.662687</td>\n",
       "      <td>0.629052</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.849834</td>\n",
       "      <td>0.890279</td>\n",
       "      <td>0.465257</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.316762</td>\n",
       "      <td>0.059221</td>\n",
       "      <td>0.536302</td>\n",
       "      <td>0.730697</td>\n",
       "      <td>0.704017</td>\n",
       "      <td>0.757377</td>\n",
       "      <td>0.730688</td>\n",
       "      <td>0.883239</td>\n",
       "      <td>0.863925</td>\n",
       "      <td>0.902554</td>\n",
       "      <td>0.619825</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.294601</td>\n",
       "      <td>0.043473</td>\n",
       "      <td>0.570744</td>\n",
       "      <td>0.731638</td>\n",
       "      <td>0.704988</td>\n",
       "      <td>0.758289</td>\n",
       "      <td>0.731552</td>\n",
       "      <td>0.880414</td>\n",
       "      <td>0.860899</td>\n",
       "      <td>0.899930</td>\n",
       "      <td>0.608629</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.324012</td>\n",
       "      <td>0.059221</td>\n",
       "      <td>0.532232</td>\n",
       "      <td>0.729755</td>\n",
       "      <td>0.703046</td>\n",
       "      <td>0.756464</td>\n",
       "      <td>0.729715</td>\n",
       "      <td>0.885122</td>\n",
       "      <td>0.865944</td>\n",
       "      <td>0.904301</td>\n",
       "      <td>0.625957</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.295687</td>\n",
       "      <td>0.059221</td>\n",
       "      <td>0.561014</td>\n",
       "      <td>0.729755</td>\n",
       "      <td>0.703046</td>\n",
       "      <td>0.756464</td>\n",
       "      <td>0.729749</td>\n",
       "      <td>0.883239</td>\n",
       "      <td>0.863925</td>\n",
       "      <td>0.902554</td>\n",
       "      <td>0.631085</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.306496</td>\n",
       "      <td>0.038926</td>\n",
       "      <td>0.546039</td>\n",
       "      <td>0.726930</td>\n",
       "      <td>0.700134</td>\n",
       "      <td>0.753727</td>\n",
       "      <td>0.726929</td>\n",
       "      <td>0.879473</td>\n",
       "      <td>0.859891</td>\n",
       "      <td>0.899054</td>\n",
       "      <td>0.615396</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.319234</td>\n",
       "      <td>0.045137</td>\n",
       "      <td>0.535928</td>\n",
       "      <td>0.726930</td>\n",
       "      <td>0.700134</td>\n",
       "      <td>0.753727</td>\n",
       "      <td>0.726906</td>\n",
       "      <td>0.887006</td>\n",
       "      <td>0.867965</td>\n",
       "      <td>0.906046</td>\n",
       "      <td>0.628290</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.297617</td>\n",
       "      <td>0.059221</td>\n",
       "      <td>0.565341</td>\n",
       "      <td>0.719397</td>\n",
       "      <td>0.692375</td>\n",
       "      <td>0.746420</td>\n",
       "      <td>0.719334</td>\n",
       "      <td>0.880414</td>\n",
       "      <td>0.860899</td>\n",
       "      <td>0.899930</td>\n",
       "      <td>0.608629</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.304903</td>\n",
       "      <td>0.037263</td>\n",
       "      <td>0.547330</td>\n",
       "      <td>0.727872</td>\n",
       "      <td>0.701104</td>\n",
       "      <td>0.754639</td>\n",
       "      <td>0.727872</td>\n",
       "      <td>0.883239</td>\n",
       "      <td>0.863925</td>\n",
       "      <td>0.902554</td>\n",
       "      <td>0.615900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.288774</td>\n",
       "      <td>0.053011</td>\n",
       "      <td>0.571276</td>\n",
       "      <td>0.730697</td>\n",
       "      <td>0.704017</td>\n",
       "      <td>0.757377</td>\n",
       "      <td>0.730682</td>\n",
       "      <td>0.887947</td>\n",
       "      <td>0.868976</td>\n",
       "      <td>0.906919</td>\n",
       "      <td>0.644209</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.291621</td>\n",
       "      <td>0.051347</td>\n",
       "      <td>0.562916</td>\n",
       "      <td>0.726930</td>\n",
       "      <td>0.700134</td>\n",
       "      <td>0.753727</td>\n",
       "      <td>0.726930</td>\n",
       "      <td>0.884181</td>\n",
       "      <td>0.864934</td>\n",
       "      <td>0.903427</td>\n",
       "      <td>0.617017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DP        EO  DP ratio       acc  acc_ci_min  acc_ci_max        f1  \\\n",
       "0   0.220259  0.398359  1.386376  0.633710    0.604733    0.662687  0.629052   \n",
       "1   0.316762  0.059221  0.536302  0.730697    0.704017    0.757377  0.730688   \n",
       "2   0.294601  0.043473  0.570744  0.731638    0.704988    0.758289  0.731552   \n",
       "3   0.324012  0.059221  0.532232  0.729755    0.703046    0.756464  0.729715   \n",
       "4   0.295687  0.059221  0.561014  0.729755    0.703046    0.756464  0.729749   \n",
       "5   0.306496  0.038926  0.546039  0.726930    0.700134    0.753727  0.726929   \n",
       "6   0.319234  0.045137  0.535928  0.726930    0.700134    0.753727  0.726906   \n",
       "7   0.297617  0.059221  0.565341  0.719397    0.692375    0.746420  0.719334   \n",
       "8   0.304903  0.037263  0.547330  0.727872    0.701104    0.754639  0.727872   \n",
       "9   0.288774  0.053011  0.571276  0.730697    0.704017    0.757377  0.730682   \n",
       "10  0.291621  0.051347  0.562916  0.726930    0.700134    0.753727  0.726930   \n",
       "\n",
       "    acc_high_risk  acc_ci_min_high_risk  acc_ci_max_high_risk  f1_high_risk  \\\n",
       "0        0.870056              0.849834              0.890279      0.465257   \n",
       "1        0.883239              0.863925              0.902554      0.619825   \n",
       "2        0.880414              0.860899              0.899930      0.608629   \n",
       "3        0.885122              0.865944              0.904301      0.625957   \n",
       "4        0.883239              0.863925              0.902554      0.631085   \n",
       "5        0.879473              0.859891              0.899054      0.615396   \n",
       "6        0.887006              0.867965              0.906046      0.628290   \n",
       "7        0.880414              0.860899              0.899930      0.608629   \n",
       "8        0.883239              0.863925              0.902554      0.615900   \n",
       "9        0.887947              0.868976              0.906919      0.644209   \n",
       "10       0.884181              0.864934              0.903427      0.617017   \n",
       "\n",
       "    adversarial_fraction  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "5                      0  \n",
       "6                      0  \n",
       "7                      0  \n",
       "8                      0  \n",
       "9                      0  \n",
       "10                     0  "
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(global_results)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5278, 12)\n",
      "4.6227737779461915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  28%|██▊       | 14/50 [00:05<00:13,  2.64it/s, epoch=13, training_loss=14.9, validation_loss=14.1]\u001b[A\n",
      "Training neural network:  56%|█████▌    | 28/50 [00:11<00:08,  2.52it/s, epoch=27, training_loss=14, validation_loss=8.66]  \u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [00:16<00:03,  2.57it/s, epoch=41, training_loss=15.6, validation_loss=9.24]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:35.12242937088013 s\n",
      "2021-09-01 21:11:37,150 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.613174301978856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.28it/s, epoch=16, training_loss=4.5, validation_loss=4.84]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.15it/s, epoch=33, training_loss=4.31, validation_loss=5.05]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.13it/s, epoch=49, training_loss=4.47, validation_loss=4.84]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:11:58,970 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.6088370832203849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  30%|███       | 15/50 [00:05<00:12,  2.91it/s, epoch=14, training_loss=4.5, validation_loss=4.97]\u001b[A\n",
      "Training neural network:  62%|██████▏   | 31/50 [00:10<00:06,  3.06it/s, epoch=30, training_loss=4.52, validation_loss=5.13]\u001b[A\n",
      "Training neural network:  94%|█████████▍| 47/50 [00:15<00:00,  3.07it/s, epoch=46, training_loss=4.47, validation_loss=5.01]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:12:21,506 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.611276768772025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.16it/s, epoch=15, training_loss=4.55, validation_loss=5]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.18it/s, epoch=31, training_loss=4.53, validation_loss=4.98]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.17it/s, epoch=47, training_loss=4.48, validation_loss=4.98]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:66.55025482177734 s\n",
      "2021-09-01 21:12:43,700 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.2938465708864191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.15it/s, epoch=15, training_loss=4.56, validation_loss=5.1]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.16it/s, epoch=31, training_loss=4.52, validation_loss=4.94]\u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.21it/s, epoch=48, training_loss=4.5, validation_loss=5.03] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:13:05,340 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.2938465708864191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.40it/s, epoch=16, training_loss=4.57, validation_loss=4.97]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.35it/s, epoch=33, training_loss=4.48, validation_loss=4.98]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:13:26,574 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.2938465708864191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.13it/s, epoch=15, training_loss=4.47, validation_loss=4.91]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.25it/s, epoch=32, training_loss=4.34, validation_loss=4.88]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.22it/s, epoch=49, training_loss=4.36, validation_loss=4.79]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:64.30764389038086 s\n",
      "2021-09-01 21:13:48,008 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.2938465708864191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.21it/s, epoch=16, training_loss=4.48, validation_loss=5.05]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.13it/s, epoch=33, training_loss=4.43, validation_loss=5.17]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:14:10,448 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.2938465708864191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.33it/s, epoch=16, training_loss=4.58, validation_loss=5.16]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.25it/s, epoch=33, training_loss=4.51, validation_loss=4.89]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:14:31,880 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.2938465708864191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.38it/s, epoch=16, training_loss=4.49, validation_loss=4.97]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.23it/s, epoch=33, training_loss=4.53, validation_loss=5.08]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:65.6852514743805 s\n",
      "2021-09-01 21:14:53,694 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.06044998644619138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.32it/s, epoch=16, training_loss=4.46, validation_loss=4.79]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.28it/s, epoch=33, training_loss=4.47, validation_loss=5.1] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:15:14,735 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.06044998644619138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.07it/s, epoch=15, training_loss=4.45, validation_loss=4.91]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.17it/s, epoch=32, training_loss=4.48, validation_loss=5]   \u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.17it/s, epoch=48, training_loss=4.45, validation_loss=4.97]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:15:36,898 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.06072106261859583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.21it/s, epoch=16, training_loss=4.61, validation_loss=4.94]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.22it/s, epoch=33, training_loss=4.51, validation_loss=4.99]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:64.31427192687988 s\n",
      "2021-09-01 21:15:58,009 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.060992138791000274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.12it/s, epoch=15, training_loss=4.53, validation_loss=4.97]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.22it/s, epoch=32, training_loss=4.42, validation_loss=4.92]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.20it/s, epoch=49, training_loss=4.47, validation_loss=4.88]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:16:19,653 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.06017891027378693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.25it/s, epoch=16, training_loss=4.48, validation_loss=4.94]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.15it/s, epoch=33, training_loss=4.54, validation_loss=5]   \u001b[A\n",
      "                                                                                                                         \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:16:40,967 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.06072106261859583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.24it/s, epoch=16, training_loss=4.39, validation_loss=4.8]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.13it/s, epoch=33, training_loss=4.32, validation_loss=4.75]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:64.8049373626709 s\n",
      "2021-09-01 21:17:02,817 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.060992138791000274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.11it/s, epoch=15, training_loss=4.43, validation_loss=4.99]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.09it/s, epoch=31, training_loss=4.55, validation_loss=5.07]\u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.14it/s, epoch=48, training_loss=4.47, validation_loss=4.95]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:17:24,566 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.06044998644619138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.12it/s, epoch=15, training_loss=4.99, validation_loss=5.1]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.06it/s, epoch=31, training_loss=4.28, validation_loss=4.77]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  2.98it/s, epoch=47, training_loss=4.33, validation_loss=4.78]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:17:46,774 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.06044998644619138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.09it/s, epoch=15, training_loss=4.45, validation_loss=4.91]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:06,  3.00it/s, epoch=31, training_loss=4.31, validation_loss=4.8] \u001b[A\n",
      "Training neural network:  94%|█████████▍| 47/50 [00:15<00:01,  2.97it/s, epoch=46, training_loss=4.43, validation_loss=4.85]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:66.19514203071594 s\n",
      "2021-09-01 21:18:09,010 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.06044998644619138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.29it/s, epoch=16, training_loss=4.56, validation_loss=5.08]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.14it/s, epoch=33, training_loss=4.41, validation_loss=5.03]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:18:30,379 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.06044998644619138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.40it/s, epoch=16, training_loss=4.44, validation_loss=5]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.34it/s, epoch=33, training_loss=4.36, validation_loss=5.01]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:18:51,396 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.06044998644619138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.24it/s, epoch=16, training_loss=4.41, validation_loss=4.93]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.19it/s, epoch=33, training_loss=4.32, validation_loss=4.92]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:63.75962567329407 s\n",
      "2021-09-01 21:19:12,770 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.06017891027378693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.29it/s, epoch=16, training_loss=4.27, validation_loss=4.9]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.28it/s, epoch=33, training_loss=4.37, validation_loss=4.76]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:19:33,613 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.06044998644619138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  36%|███▌      | 18/50 [00:05<00:09,  3.41it/s, epoch=17, training_loss=4.52, validation_loss=4.95]\u001b[A\n",
      "Training neural network:  72%|███████▏  | 36/50 [00:11<00:04,  3.22it/s, epoch=35, training_loss=4.39, validation_loss=4.91]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:19:54,638 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.06044998644619138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.18it/s, epoch=15, training_loss=4.53, validation_loss=5.03]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.15it/s, epoch=31, training_loss=4.38, validation_loss=4.83]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.12it/s, epoch=47, training_loss=4.4, validation_loss=4.82] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:63.65457510948181 s\n",
      "2021-09-01 21:20:16,425 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.06072106261859583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.03it/s, epoch=15, training_loss=4.39, validation_loss=4.92]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.15it/s, epoch=32, training_loss=4.36, validation_loss=4.83]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.23it/s, epoch=49, training_loss=4.31, validation_loss=4.89]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:20:38,031 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.06044998644619138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.23it/s, epoch=16, training_loss=4.41, validation_loss=4.68]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.31it/s, epoch=33, training_loss=4.24, validation_loss=4.7] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:20:59,146 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.06017891027378693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.14it/s, epoch=16, training_loss=4.58, validation_loss=4.94]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.22it/s, epoch=33, training_loss=4.53, validation_loss=4.87]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:64.26870131492615 s\n",
      "2021-09-01 21:21:20,695 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005421523448088913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.31it/s, epoch=16, training_loss=4.4, validation_loss=4.92]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.22it/s, epoch=33, training_loss=4.35, validation_loss=4.98]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:21:42,160 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004879371103280022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.29it/s, epoch=16, training_loss=4.28, validation_loss=4.76]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.28it/s, epoch=33, training_loss=4.22, validation_loss=4.71]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:22:03,638 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004066142586066685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.14it/s, epoch=15, training_loss=4.48, validation_loss=4.91]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.26it/s, epoch=32, training_loss=4.42, validation_loss=4.88]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.26it/s, epoch=49, training_loss=4.4, validation_loss=5]    \u001b[A\n",
      "                                                                                                                        \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:64.06023740768433 s\n",
      "2021-09-01 21:22:24,756 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004066142586066685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.26it/s, epoch=16, training_loss=4.39, validation_loss=4.75]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.26it/s, epoch=33, training_loss=4.28, validation_loss=4.88]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:22:46,079 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005150447275684467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.22it/s, epoch=16, training_loss=4.38, validation_loss=4.98]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.15it/s, epoch=33, training_loss=4.31, validation_loss=4.86]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.15it/s, epoch=49, training_loss=4.29, validation_loss=4.86]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:23:07,382 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004879371103280022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.24it/s, epoch=16, training_loss=4.42, validation_loss=5.07]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.12it/s, epoch=33, training_loss=4.37, validation_loss=5]   \u001b[A\n",
      "                                                                                                                         \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:64.5734179019928 s\n",
      "2021-09-01 21:23:29,330 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0056925996204933585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.30it/s, epoch=16, training_loss=4.35, validation_loss=4.75]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.25it/s, epoch=33, training_loss=4.27, validation_loss=4.77]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:23:50,431 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005963675792897805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.17it/s, epoch=15, training_loss=4.43, validation_loss=5.04]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.27it/s, epoch=32, training_loss=4.4, validation_loss=4.82] \u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.26it/s, epoch=49, training_loss=4.37, validation_loss=5.01]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:24:11,767 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005421523448088913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.07it/s, epoch=15, training_loss=4.45, validation_loss=4.86]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.20it/s, epoch=32, training_loss=4.37, validation_loss=4.87]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.14it/s, epoch=49, training_loss=4.4, validation_loss=4.97] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:63.83816313743591 s\n",
      "2021-09-01 21:24:33,169 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004066142586066685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.30it/s, epoch=16, training_loss=4.45, validation_loss=5.05]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.31it/s, epoch=33, training_loss=4.37, validation_loss=4.83]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:24:54,481 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005150447275684467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.27it/s, epoch=16, training_loss=4.44, validation_loss=5]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.31it/s, epoch=33, training_loss=4.46, validation_loss=5.09]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:25:15,358 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.006776904310111141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.24it/s, epoch=16, training_loss=4.44, validation_loss=5]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.24it/s, epoch=33, training_loss=4.46, validation_loss=5]\u001b[A\n",
      "                                                                                                                         \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:63.17773103713989 s\n",
      "2021-09-01 21:25:36,347 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.003795066413662239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.15it/s, epoch=15, training_loss=4.27, validation_loss=4.69]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.14it/s, epoch=31, training_loss=4.26, validation_loss=4.65]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.14it/s, epoch=47, training_loss=4.25, validation_loss=4.68]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:25:57,918 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005421523448088913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.06it/s, epoch=15, training_loss=4.37, validation_loss=4.91]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.16it/s, epoch=32, training_loss=4.31, validation_loss=4.79]\u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.17it/s, epoch=48, training_loss=4.29, validation_loss=4.73]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:26:19,450 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0056925996204933585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  30%|███       | 15/50 [00:05<00:12,  2.90it/s, epoch=14, training_loss=4.58, validation_loss=4.9]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.15it/s, epoch=31, training_loss=4.16, validation_loss=4.76]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.17it/s, epoch=47, training_loss=4.16, validation_loss=4.75]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:64.68753218650818 s\n",
      "2021-09-01 21:26:41,035 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0029818378964489023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  30%|███       | 15/50 [00:05<00:11,  2.96it/s, epoch=14, training_loss=4.42, validation_loss=4.98]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.15it/s, epoch=31, training_loss=4.41, validation_loss=4.83]\u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.19it/s, epoch=48, training_loss=4.38, validation_loss=5.08]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:27:02,339 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004066142586066685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.02it/s, epoch=15, training_loss=4.33, validation_loss=4.83]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.12it/s, epoch=31, training_loss=4.28, validation_loss=4.88]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.10it/s, epoch=47, training_loss=4.28, validation_loss=4.82]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:27:24,716 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.00433721875847113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.11it/s, epoch=15, training_loss=4.34, validation_loss=4.86]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.25it/s, epoch=32, training_loss=4.28, validation_loss=4.8] \u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.25it/s, epoch=49, training_loss=4.28, validation_loss=4.83]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:64.84002614021301 s\n",
      "2021-09-01 21:27:45,876 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004879371103280022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.38it/s, epoch=16, training_loss=4.41, validation_loss=4.85]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.26it/s, epoch=33, training_loss=4.39, validation_loss=4.93]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:28:06,755 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005421523448088913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.25it/s, epoch=16, training_loss=4.37, validation_loss=5.05]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:11<00:05,  3.07it/s, epoch=33, training_loss=4.39, validation_loss=5.1] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:28:28,074 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.006505828137706696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.34it/s, epoch=16, training_loss=4.35, validation_loss=5.05]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.34it/s, epoch=33, training_loss=4.28, validation_loss=4.79]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:63.80882406234741 s\n",
      "2021-09-01 21:28:49,685 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004608294930875576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.26it/s, epoch=16, training_loss=4.34, validation_loss=5.01]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.23it/s, epoch=33, training_loss=4.35, validation_loss=4.9] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:29:11,734 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.003252914068853348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.07it/s, epoch=15, training_loss=4.56, validation_loss=4.98]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.18it/s, epoch=32, training_loss=4.5, validation_loss=5.03] \u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.10it/s, epoch=48, training_loss=4.49, validation_loss=5.08]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:29:33,693 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005421523448088913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  36%|███▌      | 18/50 [00:05<00:09,  3.43it/s, epoch=17, training_loss=4.39, validation_loss=5.01]\u001b[A\n",
      "Training neural network:  72%|███████▏  | 36/50 [00:10<00:04,  3.28it/s, epoch=35, training_loss=4.31, validation_loss=4.77]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:65.05020642280579 s\n",
      "2021-09-01 21:29:54,736 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.00623475196530225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.04it/s, epoch=15, training_loss=4.37, validation_loss=4.78]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.12it/s, epoch=32, training_loss=4.29, validation_loss=4.8] \u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.22it/s, epoch=49, training_loss=4.23, validation_loss=4.75]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:30:16,534 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005421523448088913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  30%|███       | 15/50 [00:05<00:11,  2.98it/s, epoch=14, training_loss=4.51, validation_loss=5.63]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.18it/s, epoch=31, training_loss=4.32, validation_loss=4.93]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.17it/s, epoch=47, training_loss=4.29, validation_loss=4.74]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:30:37,841 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.007861208999728924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.25it/s, epoch=16, training_loss=4.55, validation_loss=4.9]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.23it/s, epoch=33, training_loss=4.21, validation_loss=4.72]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:64.54309177398682 s\n",
      "2021-09-01 21:30:59,280 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0056925996204933585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.16it/s, epoch=15, training_loss=4.43, validation_loss=4.96]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.25it/s, epoch=32, training_loss=4.37, validation_loss=4.99]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.23it/s, epoch=49, training_loss=4.37, validation_loss=4.94]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:31:20,314 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0056925996204933585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.25it/s, epoch=16, training_loss=4.4, validation_loss=5.1]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.24it/s, epoch=33, training_loss=4.42, validation_loss=5.05]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:31:42,445 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.003795066413662239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.19it/s, epoch=15, training_loss=4.43, validation_loss=4.92]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.29it/s, epoch=32, training_loss=4.28, validation_loss=4.95]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.28it/s, epoch=49, training_loss=4.3, validation_loss=4.88] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:63.98326539993286 s\n",
      "2021-09-01 21:32:03,264 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005963675792897805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.33it/s, epoch=16, training_loss=4.48, validation_loss=4.89]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.36it/s, epoch=33, training_loss=4.29, validation_loss=4.69]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:32:24,079 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.006505828137706696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.14it/s, epoch=15, training_loss=4.43, validation_loss=5.11]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.29it/s, epoch=32, training_loss=4.4, validation_loss=5.08] \u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.19it/s, epoch=49, training_loss=4.41, validation_loss=5.16]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:32:45,363 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.007590132827324478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.29it/s, epoch=16, training_loss=4.43, validation_loss=5]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.26it/s, epoch=33, training_loss=4.38, validation_loss=5.07]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:63.35739994049072 s\n",
      "2021-09-01 21:33:06,622 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.006776904310111141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.20it/s, epoch=16, training_loss=4.4, validation_loss=5.04]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.24it/s, epoch=33, training_loss=4.38, validation_loss=5.02]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:33:27,995 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005421523448088913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  30%|███       | 15/50 [00:05<00:12,  2.89it/s, epoch=14, training_loss=4.4, validation_loss=4.92]\u001b[A\n",
      "Training neural network:  62%|██████▏   | 31/50 [00:10<00:06,  3.06it/s, epoch=30, training_loss=4.34, validation_loss=4.92]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.17it/s, epoch=47, training_loss=4.33, validation_loss=4.96]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:33:49,647 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005421523448088913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.25it/s, epoch=16, training_loss=4.39, validation_loss=5.07]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.29it/s, epoch=33, training_loss=4.37, validation_loss=4.94]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:64.62814354896545 s\n",
      "2021-09-01 21:34:11,253 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004066142586066685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.12it/s, epoch=15, training_loss=4.4, validation_loss=5.11]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.19it/s, epoch=32, training_loss=4.37, validation_loss=5.09]\u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.17it/s, epoch=48, training_loss=4.35, validation_loss=5.1] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:34:32,506 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005963675792897805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  30%|███       | 15/50 [00:05<00:11,  2.96it/s, epoch=14, training_loss=4.3, validation_loss=4.82]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.17it/s, epoch=31, training_loss=4.26, validation_loss=4.81]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.12it/s, epoch=47, training_loss=4.23, validation_loss=4.82]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:34:54,338 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004608294930875576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.03it/s, epoch=15, training_loss=4.44, validation_loss=5.06]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.07it/s, epoch=31, training_loss=4.4, validation_loss=4.98] \u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.15it/s, epoch=48, training_loss=4.38, validation_loss=4.87]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:65.19949626922607 s\n",
      "2021-09-01 21:35:16,456 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005150447275684467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.38it/s, epoch=16, training_loss=4.4, validation_loss=4.99]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.17it/s, epoch=33, training_loss=4.35, validation_loss=4.71]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.15it/s, epoch=49, training_loss=4.34, validation_loss=4.69]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:35:38,259 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.00623475196530225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.25it/s, epoch=16, training_loss=4.43, validation_loss=4.92]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.28it/s, epoch=33, training_loss=4.42, validation_loss=4.97]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:35:59,131 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.006505828137706696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.26it/s, epoch=16, training_loss=4.44, validation_loss=5.09]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.13it/s, epoch=33, training_loss=4.44, validation_loss=5.11]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:64.34027910232544 s\n",
      "2021-09-01 21:36:20,794 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.007047980482515587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.31it/s, epoch=16, training_loss=4.44, validation_loss=4.92]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.33it/s, epoch=33, training_loss=4.34, validation_loss=4.88]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:36:41,392 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005150447275684467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.12it/s, epoch=15, training_loss=4.31, validation_loss=4.77]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.14it/s, epoch=31, training_loss=4.15, validation_loss=4.72]\u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.19it/s, epoch=48, training_loss=4.15, validation_loss=4.62]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:37:03,234 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004879371103280022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.38it/s, epoch=16, training_loss=4.39, validation_loss=4.99]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.25it/s, epoch=33, training_loss=4.37, validation_loss=4.93]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:63.38325595855713 s\n",
      "2021-09-01 21:37:24,178 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.00433721875847113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  36%|███▌      | 18/50 [00:05<00:09,  3.44it/s, epoch=17, training_loss=4.41, validation_loss=4.94]\u001b[A\n",
      "Training neural network:  72%|███████▏  | 36/50 [00:10<00:04,  3.30it/s, epoch=35, training_loss=4.39, validation_loss=4.91]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:37:45,044 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005963675792897805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.17it/s, epoch=15, training_loss=4.37, validation_loss=4.97]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.18it/s, epoch=31, training_loss=4.26, validation_loss=4.8] \u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.17it/s, epoch=47, training_loss=4.3, validation_loss=4.8] \u001b[A\n",
      "                                                                                                                          \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:38:07,039 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005421523448088913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.29it/s, epoch=16, training_loss=4.43, validation_loss=5.02]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.31it/s, epoch=33, training_loss=4.35, validation_loss=4.97]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:64.13295936584473 s\n",
      "2021-09-01 21:38:28,312 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004879371103280022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.11it/s, epoch=15, training_loss=4.34, validation_loss=4.98]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.13it/s, epoch=31, training_loss=4.3, validation_loss=4.9]  \u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.15it/s, epoch=47, training_loss=4.3, validation_loss=4.93]\u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:38:49,734 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0056925996204933585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.35it/s, epoch=16, training_loss=4.39, validation_loss=4.79]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.29it/s, epoch=33, training_loss=4.33, validation_loss=4.83]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:39:11,712 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.00433721875847113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.06it/s, epoch=15, training_loss=4.29, validation_loss=4.82]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.12it/s, epoch=31, training_loss=4.25, validation_loss=4.68]\u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.23it/s, epoch=48, training_loss=4.2, validation_loss=4.87] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:65.75278782844543 s\n",
      "2021-09-01 21:39:34,066 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0027107617240444567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.02it/s, epoch=15, training_loss=4.37, validation_loss=4.83]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.03it/s, epoch=31, training_loss=4.21, validation_loss=4.58]\u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.17it/s, epoch=48, training_loss=4.17, validation_loss=4.66]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:39:56,097 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0035239902412577935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.32it/s, epoch=16, training_loss=4.47, validation_loss=4.99]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.23it/s, epoch=33, training_loss=4.36, validation_loss=4.83]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:40:16,861 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004066142586066685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.22it/s, epoch=16, training_loss=4.43, validation_loss=5.04]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.08it/s, epoch=33, training_loss=4.36, validation_loss=4.99]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:16<00:00,  3.11it/s, epoch=49, training_loss=4.37, validation_loss=4.96]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:65.07745361328125 s\n",
      "2021-09-01 21:40:39,143 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004066142586066685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.05it/s, epoch=15, training_loss=4.29, validation_loss=4.75]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.14it/s, epoch=32, training_loss=4.25, validation_loss=4.76]\u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.10it/s, epoch=48, training_loss=4.27, validation_loss=4.82]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:41:01,506 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.003795066413662239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.20it/s, epoch=15, training_loss=4.4, validation_loss=4.91]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.34it/s, epoch=33, training_loss=4.38, validation_loss=4.92]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:41:22,885 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.002439685551640011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.25it/s, epoch=16, training_loss=4.39, validation_loss=4.99]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.27it/s, epoch=33, training_loss=4.3, validation_loss=4.83] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:65.4146420955658 s\n",
      "2021-09-01 21:41:44,558 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0029818378964489023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.19it/s, epoch=15, training_loss=4.4, validation_loss=5.07]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.22it/s, epoch=32, training_loss=4.37, validation_loss=5.01]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.10it/s, epoch=49, training_loss=4.39, validation_loss=5.1] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:42:06,178 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.003252914068853348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.33it/s, epoch=16, training_loss=4.31, validation_loss=4.96]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.24it/s, epoch=33, training_loss=4.29, validation_loss=4.84]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:42:27,374 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0029818378964489023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.13it/s, epoch=15, training_loss=4.38, validation_loss=5.01]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.06it/s, epoch=31, training_loss=4.35, validation_loss=4.91]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.08it/s, epoch=47, training_loss=4.36, validation_loss=4.83]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:64.89120841026306 s\n",
      "2021-09-01 21:42:49,450 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0029818378964489023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.23it/s, epoch=16, training_loss=4.34, validation_loss=5.08]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.19it/s, epoch=33, training_loss=4.38, validation_loss=5.03]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.18it/s, epoch=49, training_loss=4.35, validation_loss=4.98]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:43:10,675 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0027107617240444567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.11it/s, epoch=15, training_loss=4.38, validation_loss=5.01]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.14it/s, epoch=31, training_loss=4.37, validation_loss=5]   \u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.11it/s, epoch=47, training_loss=4.39, validation_loss=4.97]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:43:32,730 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0027107617240444567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.16it/s, epoch=15, training_loss=4.24, validation_loss=4.74]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.12it/s, epoch=31, training_loss=4.25, validation_loss=4.91]\u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.20it/s, epoch=48, training_loss=4.18, validation_loss=4.91]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:64.86540746688843 s\n",
      "2021-09-01 21:43:54,316 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0035239902412577935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.22it/s, epoch=16, training_loss=4.34, validation_loss=4.84]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.30it/s, epoch=33, training_loss=4.26, validation_loss=4.95]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:44:15,081 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.002439685551640011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.17it/s, epoch=15, training_loss=4.46, validation_loss=4.94]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.23it/s, epoch=32, training_loss=4.41, validation_loss=5]   \u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.30it/s, epoch=49, training_loss=4.4, validation_loss=5.05]\u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:44:35,999 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0027107617240444567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.22it/s, epoch=16, training_loss=4.32, validation_loss=4.87]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.11it/s, epoch=33, training_loss=4.33, validation_loss=5.01]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:16<00:00,  3.07it/s, epoch=49, training_loss=4.31, validation_loss=4.9] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:63.60800290107727 s\n",
      "2021-09-01 21:44:57,924 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0029818378964489023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.07it/s, epoch=15, training_loss=4.36, validation_loss=4.98]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.18it/s, epoch=32, training_loss=4.33, validation_loss=5.04]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.19it/s, epoch=49, training_loss=4.3, validation_loss=4.84] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:45:19,159 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.003252914068853348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.06it/s, epoch=15, training_loss=4.45, validation_loss=5.02]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.11it/s, epoch=31, training_loss=4.46, validation_loss=5.13]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.10it/s, epoch=47, training_loss=4.46, validation_loss=5.11]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:45:41,533 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.002439685551640011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.33it/s, epoch=16, training_loss=4.39, validation_loss=4.93]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.33it/s, epoch=33, training_loss=4.38, validation_loss=4.89]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:65.52325582504272 s\n",
      "2021-09-01 21:46:03,450 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.002168609379235565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.13it/s, epoch=15, training_loss=4.35, validation_loss=5.05]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.19it/s, epoch=32, training_loss=4.34, validation_loss=4.91]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.28it/s, epoch=49, training_loss=4.33, validation_loss=5.07]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:46:24,482 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0027107617240444567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.15it/s, epoch=15, training_loss=4.4, validation_loss=4.92]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.11it/s, epoch=31, training_loss=4.35, validation_loss=4.97]\u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.20it/s, epoch=48, training_loss=4.32, validation_loss=4.96]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:46:46,213 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.001626457034426674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  30%|███       | 15/50 [00:05<00:11,  2.99it/s, epoch=14, training_loss=4.43, validation_loss=4.7]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.12it/s, epoch=31, training_loss=4.17, validation_loss=4.64]\u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.24it/s, epoch=48, training_loss=4.16, validation_loss=4.76]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:64.19340372085571 s\n",
      "2021-09-01 21:47:07,645 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.001626457034426674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  28%|██▊       | 14/50 [00:05<00:13,  2.71it/s, epoch=13, training_loss=4.5, validation_loss=4.96]\u001b[A\n",
      "Training neural network:  58%|█████▊    | 29/50 [00:10<00:07,  2.83it/s, epoch=28, training_loss=4.12, validation_loss=4.51]\u001b[A\n",
      "Training neural network:  88%|████████▊ | 44/50 [00:15<00:02,  2.88it/s, epoch=43, training_loss=4.08, validation_loss=4.5] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:47:31,293 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0035239902412577935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  30%|███       | 15/50 [00:05<00:11,  2.99it/s, epoch=14, training_loss=4.36, validation_loss=5.02]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.12it/s, epoch=31, training_loss=4.33, validation_loss=5.07]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.15it/s, epoch=47, training_loss=4.34, validation_loss=4.93]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:47:53,146 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.002168609379235565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.30it/s, epoch=16, training_loss=4.4, validation_loss=5.04]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.19it/s, epoch=33, training_loss=4.36, validation_loss=4.97]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:16<00:00,  3.08it/s, epoch=49, training_loss=4.39, validation_loss=5.01]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:67.77998304367065 s\n",
      "2021-09-01 21:48:15,425 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.003252914068853348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.16it/s, epoch=15, training_loss=4.43, validation_loss=5]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.19it/s, epoch=32, training_loss=4.41, validation_loss=5.01]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.28it/s, epoch=49, training_loss=4.38, validation_loss=5.1] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:48:36,278 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0018975332068311196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.27it/s, epoch=16, training_loss=4.35, validation_loss=4.86]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.28it/s, epoch=33, training_loss=4.4, validation_loss=4.99] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:48:57,668 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0035239902412577935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.22it/s, epoch=16, training_loss=4.36, validation_loss=5.05]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.15it/s, epoch=33, training_loss=4.31, validation_loss=4.98]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:16<00:00,  3.11it/s, epoch=49, training_loss=4.3, validation_loss=5.02] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:64.37689399719238 s\n",
      "2021-09-01 21:49:19,803 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.002439685551640011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.16it/s, epoch=15, training_loss=4.39, validation_loss=4.93]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.09it/s, epoch=31, training_loss=4.32, validation_loss=5.11]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.09it/s, epoch=47, training_loss=4.32, validation_loss=5.13]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:49:41,498 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0027107617240444567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  36%|███▌      | 18/50 [00:05<00:09,  3.52it/s, epoch=17, training_loss=4.38, validation_loss=4.9]\u001b[A\n",
      "Training neural network:  72%|███████▏  | 36/50 [00:10<00:04,  3.30it/s, epoch=35, training_loss=4.29, validation_loss=4.73]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:50:02,121 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005421523448088913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.21it/s, epoch=16, training_loss=4.34, validation_loss=4.81]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.23it/s, epoch=33, training_loss=4.27, validation_loss=4.68]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:65.00155234336853 s\n",
      "2021-09-01 21:50:24,805 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0029818378964489023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.38it/s, epoch=16, training_loss=4.45, validation_loss=5]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.18it/s, epoch=33, training_loss=4.29, validation_loss=4.9]\u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:50:45,645 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.003795066413662239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.33it/s, epoch=16, training_loss=4.41, validation_loss=5.08]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.19it/s, epoch=33, training_loss=4.37, validation_loss=4.99]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.12it/s, epoch=49, training_loss=4.33, validation_loss=5.1] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:51:07,033 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0035239902412577935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.29it/s, epoch=16, training_loss=4.38, validation_loss=5.07]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.24it/s, epoch=33, training_loss=4.37, validation_loss=5.02]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:63.568854093551636 s\n",
      "2021-09-01 21:51:28,374 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0029818378964489023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.33it/s, epoch=16, training_loss=4.31, validation_loss=4.75]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.30it/s, epoch=33, training_loss=4.29, validation_loss=4.75]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:51:49,194 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.003795066413662239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.32it/s, epoch=16, training_loss=4.32, validation_loss=4.93]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.25it/s, epoch=33, training_loss=4.31, validation_loss=4.88]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:52:10,162 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.002439685551640011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.16it/s, epoch=15, training_loss=4.39, validation_loss=5.07]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.23it/s, epoch=32, training_loss=4.35, validation_loss=4.88]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.17it/s, epoch=49, training_loss=4.36, validation_loss=4.93]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:63.14273548126221 s\n",
      "2021-09-01 21:52:31,518 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.003252914068853348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.16it/s, epoch=15, training_loss=4.41, validation_loss=5.1]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.29it/s, epoch=32, training_loss=4.18, validation_loss=4.8]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.27it/s, epoch=49, training_loss=4.18, validation_loss=4.72]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:52:52,512 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.001626457034426674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  36%|███▌      | 18/50 [00:05<00:09,  3.41it/s, epoch=17, training_loss=4.37, validation_loss=5.01]\u001b[A\n",
      "Training neural network:  72%|███████▏  | 36/50 [00:10<00:04,  3.32it/s, epoch=35, training_loss=4.38, validation_loss=5.05]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:53:13,565 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0029818378964489023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.23it/s, epoch=16, training_loss=4.35, validation_loss=4.98]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.18it/s, epoch=33, training_loss=4.32, validation_loss=4.89]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:63.44660496711731 s\n",
      "2021-09-01 21:53:34,966 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.003252914068853348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.19it/s, epoch=15, training_loss=4.4, validation_loss=4.94]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.18it/s, epoch=31, training_loss=4.34, validation_loss=5]  \u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.25it/s, epoch=48, training_loss=4.36, validation_loss=5.08]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:53:56,044 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004879371103280022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.06it/s, epoch=15, training_loss=4.28, validation_loss=4.78]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.08it/s, epoch=31, training_loss=4.27, validation_loss=4.76]\u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.22it/s, epoch=48, training_loss=4.24, validation_loss=4.86]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:54:17,702 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.003252914068853348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.30it/s, epoch=16, training_loss=4.29, validation_loss=4.96]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.22it/s, epoch=33, training_loss=4.27, validation_loss=4.92]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:64.23271679878235 s\n",
      "2021-09-01 21:54:39,199 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.002439685551640011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.25it/s, epoch=16, training_loss=4.36, validation_loss=5.03]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.21it/s, epoch=33, training_loss=4.31, validation_loss=5.13]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:55:00,690 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0029818378964489023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.25it/s, epoch=16, training_loss=4.36, validation_loss=5.02]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.24it/s, epoch=33, training_loss=4.24, validation_loss=4.84]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:55:22,235 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.003252914068853348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.02it/s, epoch=15, training_loss=4.43, validation_loss=5.09]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.22it/s, epoch=32, training_loss=4.41, validation_loss=4.97]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.22it/s, epoch=49, training_loss=4.37, validation_loss=4.98]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:64.49247026443481 s\n",
      "2021-09-01 21:55:43,692 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0029818378964489023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.21it/s, epoch=16, training_loss=4.42, validation_loss=5]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.17it/s, epoch=33, training_loss=4.33, validation_loss=5.11]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.17it/s, epoch=49, training_loss=4.32, validation_loss=5.09]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:56:05,058 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.002168609379235565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.13it/s, epoch=15, training_loss=4.42, validation_loss=5.02]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.15it/s, epoch=32, training_loss=4.37, validation_loss=4.98]\u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.13it/s, epoch=48, training_loss=4.36, validation_loss=5.07]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:56:26,407 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.003795066413662239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.30it/s, epoch=16, training_loss=4.41, validation_loss=4.97]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.17it/s, epoch=33, training_loss=4.37, validation_loss=5.03]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.17it/s, epoch=49, training_loss=4.33, validation_loss=4.95]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:64.55299687385559 s\n",
      "2021-09-01 21:56:48,246 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0029818378964489023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.37it/s, epoch=16, training_loss=4.21, validation_loss=4.69]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.28it/s, epoch=33, training_loss=4.2, validation_loss=4.73] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:57:09,800 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.003252914068853348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  36%|███▌      | 18/50 [00:05<00:09,  3.40it/s, epoch=17, training_loss=4.3, validation_loss=4.97]\u001b[A\n",
      "Training neural network:  72%|███████▏  | 36/50 [00:11<00:04,  3.22it/s, epoch=35, training_loss=4.33, validation_loss=4.78]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:57:30,849 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0029818378964489023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.05it/s, epoch=15, training_loss=4.43, validation_loss=5.19]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.14it/s, epoch=31, training_loss=4.39, validation_loss=4.99]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.16it/s, epoch=47, training_loss=4.4, validation_loss=4.91] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:64.22049927711487 s\n",
      "2021-09-01 21:57:52,467 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.001626457034426674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  30%|███       | 15/50 [00:05<00:11,  2.96it/s, epoch=14, training_loss=4.42, validation_loss=4.98]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.20it/s, epoch=31, training_loss=4.16, validation_loss=4.64]\u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.25it/s, epoch=48, training_loss=4.16, validation_loss=4.71]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:58:14,653 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0029818378964489023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.09it/s, epoch=15, training_loss=4.39, validation_loss=4.72]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.10it/s, epoch=31, training_loss=4.31, validation_loss=4.76]\u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.16it/s, epoch=48, training_loss=4.31, validation_loss=4.7] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:58:36,381 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0010843046896177825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  30%|███       | 15/50 [00:05<00:11,  2.97it/s, epoch=14, training_loss=4.35, validation_loss=5.07]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.08it/s, epoch=31, training_loss=4.35, validation_loss=5]   \u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.11it/s, epoch=47, training_loss=4.33, validation_loss=4.91]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:66.07608842849731 s\n",
      "2021-09-01 21:58:58,544 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0029818378964489023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.20it/s, epoch=15, training_loss=4.34, validation_loss=4.98]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.18it/s, epoch=31, training_loss=4.31, validation_loss=4.87]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.28it/s, epoch=49, training_loss=4.29, validation_loss=4.97]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:59:19,625 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0027107617240444567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.32it/s, epoch=16, training_loss=4.42, validation_loss=4.87]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.23it/s, epoch=33, training_loss=4.37, validation_loss=5.11]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:59:41,085 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0013553808620222283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.05it/s, epoch=15, training_loss=4.35, validation_loss=4.96]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.13it/s, epoch=31, training_loss=4.32, validation_loss=4.84]\u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.18it/s, epoch=48, training_loss=4.31, validation_loss=5.01]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:64.25193738937378 s\n",
      "2021-09-01 22:00:02,796 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004066142586066685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.29it/s, epoch=16, training_loss=4.36, validation_loss=5.03]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.34it/s, epoch=33, training_loss=4.4, validation_loss=4.9]  \u001b[A\n",
      "                                                                                                                          \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:00:23,474 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.001626457034426674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.24it/s, epoch=16, training_loss=4.3, validation_loss=4.91]\u001b[A\n",
      "Training neural network:  70%|███████   | 35/50 [00:10<00:04,  3.36it/s, epoch=34, training_loss=4.26, validation_loss=4.95]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:00:43,541 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.003252914068853348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.02it/s, epoch=15, training_loss=4.32, validation_loss=4.83]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.06it/s, epoch=31, training_loss=4.22, validation_loss=4.95]\u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.16it/s, epoch=48, training_loss=4.23, validation_loss=4.88]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:62.330082416534424 s\n",
      "2021-09-01 22:01:05,127 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0035239902412577935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.09it/s, epoch=15, training_loss=4.39, validation_loss=4.94]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.08it/s, epoch=31, training_loss=4.39, validation_loss=4.94]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.06it/s, epoch=47, training_loss=4.37, validation_loss=5.13]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:01:27,361 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.003252914068853348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.12it/s, epoch=15, training_loss=4.36, validation_loss=4.99]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.25it/s, epoch=32, training_loss=4.39, validation_loss=4.94]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.23it/s, epoch=49, training_loss=4.34, validation_loss=5.07]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:01:49,414 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0029818378964489023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.19it/s, epoch=15, training_loss=4.35, validation_loss=4.85]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.27it/s, epoch=32, training_loss=4.32, validation_loss=4.94]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.27it/s, epoch=49, training_loss=4.29, validation_loss=4.83]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:65.23683524131775 s\n",
      "2021-09-01 22:02:10,374 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0027107617240444567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.33it/s, epoch=16, training_loss=4.39, validation_loss=4.9]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.26it/s, epoch=33, training_loss=4.35, validation_loss=4.88]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:02:31,496 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0035239902412577935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.28it/s, epoch=16, training_loss=4.37, validation_loss=4.93]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.25it/s, epoch=33, training_loss=4.36, validation_loss=5.04]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:02:52,312 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.001626457034426674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  36%|███▌      | 18/50 [00:05<00:09,  3.48it/s, epoch=17, training_loss=4.35, validation_loss=4.76]\u001b[A\n",
      "Training neural network:  72%|███████▏  | 36/50 [00:10<00:04,  3.34it/s, epoch=35, training_loss=4.32, validation_loss=4.85]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:62.791197776794434 s\n",
      "2021-09-01 22:03:13,158 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.002168609379235565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.25it/s, epoch=16, training_loss=4.36, validation_loss=4.96]\u001b[A\n",
      "Training neural network:  70%|███████   | 35/50 [00:10<00:04,  3.35it/s, epoch=34, training_loss=4.38, validation_loss=5.16]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:03:33,675 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.003252914068853348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.30it/s, epoch=16, training_loss=4.5, validation_loss=4.97]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.27it/s, epoch=33, training_loss=4.39, validation_loss=5.15]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:03:54,607 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.002439685551640011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.18it/s, epoch=16, training_loss=4.41, validation_loss=4.95]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.10it/s, epoch=32, training_loss=4.41, validation_loss=5.04]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.16it/s, epoch=49, training_loss=4.4, validation_loss=4.94] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:62.8721387386322 s\n",
      "2021-09-01 22:04:16,031 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.003795066413662239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.04it/s, epoch=15, training_loss=4.53, validation_loss=5.09]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.08it/s, epoch=31, training_loss=4.38, validation_loss=4.95]\u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.22it/s, epoch=48, training_loss=4.39, validation_loss=5.06]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:04:37,593 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0027107617240444567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.12it/s, epoch=15, training_loss=4.35, validation_loss=4.76]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.09it/s, epoch=31, training_loss=4.25, validation_loss=4.76]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.10it/s, epoch=47, training_loss=4.22, validation_loss=4.6] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:04:59,705 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0035239902412577935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.29it/s, epoch=16, training_loss=4.41, validation_loss=4.91]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.25it/s, epoch=33, training_loss=4.36, validation_loss=4.98]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:64.92510867118835 s\n",
      "2021-09-01 22:05:20,957 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005963675792897805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.29it/s, epoch=16, training_loss=4.33, validation_loss=4.75]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.34it/s, epoch=33, training_loss=4.25, validation_loss=4.85]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:05:41,616 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005150447275684467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.27it/s, epoch=16, training_loss=4.37, validation_loss=5.12]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.18it/s, epoch=33, training_loss=4.39, validation_loss=4.98]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:06:02,935 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005421523448088913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.21it/s, epoch=16, training_loss=4.49, validation_loss=4.91]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.31it/s, epoch=33, training_loss=4.44, validation_loss=4.99]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:63.939281702041626 s\n",
      "2021-09-01 22:06:24,897 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005150447275684467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.29it/s, epoch=16, training_loss=4.48, validation_loss=5.05]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.09it/s, epoch=33, training_loss=4.41, validation_loss=5.03]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:16<00:00,  2.95it/s, epoch=49, training_loss=4.38, validation_loss=4.99]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:06:47,492 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.00433721875847113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.07it/s, epoch=15, training_loss=4.41, validation_loss=5.01]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.12it/s, epoch=31, training_loss=4.24, validation_loss=4.75]\u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.24it/s, epoch=48, training_loss=4.19, validation_loss=4.6] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:07:09,083 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.00433721875847113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  36%|███▌      | 18/50 [00:05<00:09,  3.44it/s, epoch=17, training_loss=4.41, validation_loss=4.89]\u001b[A\n",
      "Training neural network:  72%|███████▏  | 36/50 [00:10<00:04,  3.30it/s, epoch=35, training_loss=4.4, validation_loss=4.96] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:65.1075508594513 s\n",
      "2021-09-01 22:07:30,006 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0035239902412577935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.20it/s, epoch=16, training_loss=4.38, validation_loss=5.16]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.11it/s, epoch=33, training_loss=4.4, validation_loss=4.9]  \u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:16<00:00,  3.11it/s, epoch=49, training_loss=4.39, validation_loss=5.11]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:07:52,015 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004066142586066685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.20it/s, epoch=15, training_loss=4.28, validation_loss=4.9]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.13it/s, epoch=31, training_loss=4.24, validation_loss=4.84]\u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.18it/s, epoch=48, training_loss=4.23, validation_loss=4.9] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:08:13,490 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.007047980482515587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.14it/s, epoch=15, training_loss=4.53, validation_loss=5.06]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.15it/s, epoch=31, training_loss=4.47, validation_loss=5.03]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.17it/s, epoch=47, training_loss=4.48, validation_loss=4.9] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:65.19228863716125 s\n",
      "2021-09-01 22:08:35,198 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005150447275684467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.28it/s, epoch=16, training_loss=4.29, validation_loss=4.73]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.24it/s, epoch=33, training_loss=4.26, validation_loss=4.98]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:08:57,033 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004879371103280022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.26it/s, epoch=16, training_loss=4.43, validation_loss=5.01]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.21it/s, epoch=33, training_loss=4.4, validation_loss=5.03] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:09:18,452 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004879371103280022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.18it/s, epoch=15, training_loss=4.41, validation_loss=4.96]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.15it/s, epoch=31, training_loss=4.34, validation_loss=5.07]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.03it/s, epoch=47, training_loss=4.39, validation_loss=4.96]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:65.8252534866333 s\n",
      "2021-09-01 22:09:41,023 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.003795066413662239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.07it/s, epoch=15, training_loss=4.37, validation_loss=5.04]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.01it/s, epoch=31, training_loss=4.35, validation_loss=4.99]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.00it/s, epoch=47, training_loss=4.35, validation_loss=4.92]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:10:03,148 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.006505828137706696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.14it/s, epoch=15, training_loss=4.5, validation_loss=5.01]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.10it/s, epoch=31, training_loss=4.4, validation_loss=4.97]\u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.15it/s, epoch=48, training_loss=4.43, validation_loss=5.06]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:10:25,273 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.007861208999728924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.14it/s, epoch=15, training_loss=4.32, validation_loss=4.83]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.09it/s, epoch=31, training_loss=4.29, validation_loss=4.77]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.07it/s, epoch=47, training_loss=4.28, validation_loss=4.82]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:66.28429961204529 s\n",
      "2021-09-01 22:10:47,309 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.007590132827324478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.13it/s, epoch=15, training_loss=4.43, validation_loss=5.05]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.11it/s, epoch=31, training_loss=4.4, validation_loss=4.98] \u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.30it/s, epoch=49, training_loss=4.38, validation_loss=5.02]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:11:08,743 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.00623475196530225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.26it/s, epoch=16, training_loss=4.3, validation_loss=4.72]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.22it/s, epoch=33, training_loss=4.27, validation_loss=4.74]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:11:30,369 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0056925996204933585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.39it/s, epoch=16, training_loss=4.39, validation_loss=5.08]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.28it/s, epoch=33, training_loss=4.37, validation_loss=4.98]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:63.89911341667175 s\n",
      "2021-09-01 22:11:51,208 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.00623475196530225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.34it/s, epoch=16, training_loss=4.43, validation_loss=5.05]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.16it/s, epoch=33, training_loss=4.36, validation_loss=4.99]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.16it/s, epoch=49, training_loss=4.36, validation_loss=4.95]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:12:12,523 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0056925996204933585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.13it/s, epoch=15, training_loss=4.42, validation_loss=5.07]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.30it/s, epoch=33, training_loss=4.41, validation_loss=4.98]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:12:33,856 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.00623475196530225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.39it/s, epoch=16, training_loss=4.43, validation_loss=5.13]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.37it/s, epoch=33, training_loss=4.37, validation_loss=4.97]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:63.19363617897034 s\n",
      "2021-09-01 22:12:54,403 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0035239902412577935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  2.88it/s, epoch=15, training_loss=4.43, validation_loss=4.96]\u001b[A\n",
      "Training neural network:  62%|██████▏   | 31/50 [00:10<00:06,  2.91it/s, epoch=30, training_loss=4.42, validation_loss=4.99]\u001b[A\n",
      "Training neural network:  94%|█████████▍| 47/50 [00:15<00:01,  2.97it/s, epoch=46, training_loss=4.41, validation_loss=5.15]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:13:16,790 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.007047980482515587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  30%|███       | 15/50 [00:05<00:11,  2.98it/s, epoch=14, training_loss=4.43, validation_loss=4.92]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.15it/s, epoch=31, training_loss=4.4, validation_loss=5.01] \u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.23it/s, epoch=48, training_loss=4.39, validation_loss=5.02]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:13:38,461 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0056925996204933585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.27it/s, epoch=16, training_loss=4.37, validation_loss=4.82]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.27it/s, epoch=33, training_loss=4.32, validation_loss=4.8] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:65.16555762290955 s\n",
      "2021-09-01 22:13:59,569 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.003795066413662239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.22it/s, epoch=16, training_loss=4.41, validation_loss=5.17]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.17it/s, epoch=33, training_loss=4.4, validation_loss=4.99] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:14:20,704 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005150447275684467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.08it/s, epoch=15, training_loss=4.38, validation_loss=4.89]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.14it/s, epoch=31, training_loss=4.25, validation_loss=4.89]\u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.22it/s, epoch=48, training_loss=4.28, validation_loss=4.8] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:14:42,228 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.007319056654920032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.05it/s, epoch=15, training_loss=4.44, validation_loss=4.99]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.14it/s, epoch=32, training_loss=4.38, validation_loss=4.93]\u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.17it/s, epoch=48, training_loss=4.4, validation_loss=4.9]  \u001b[A\n",
      "                                                                                                                          \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:64.98566961288452 s\n",
      "2021-09-01 22:15:04,555 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005150447275684467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.30it/s, epoch=16, training_loss=4.35, validation_loss=4.95]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.15it/s, epoch=33, training_loss=4.3, validation_loss=4.84] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:15:25,926 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.00433721875847113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.21it/s, epoch=16, training_loss=4.35, validation_loss=4.82]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.27it/s, epoch=33, training_loss=4.28, validation_loss=4.83]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:15:47,900 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.00623475196530225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.22it/s, epoch=16, training_loss=4.36, validation_loss=4.92]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.32it/s, epoch=33, training_loss=4.37, validation_loss=4.99]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:64.19482636451721 s\n",
      "2021-09-01 22:16:08,751 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0056925996204933585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.13it/s, epoch=15, training_loss=4.33, validation_loss=4.87]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.31it/s, epoch=33, training_loss=4.26, validation_loss=4.84]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:16:29,959 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004066142586066685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.02it/s, epoch=15, training_loss=4.5, validation_loss=4.79]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.11it/s, epoch=32, training_loss=4.46, validation_loss=5]  \u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.21it/s, epoch=49, training_loss=4.49, validation_loss=4.96]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:16:51,841 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.006776904310111141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.17it/s, epoch=15, training_loss=4.45, validation_loss=5.07]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.08it/s, epoch=31, training_loss=4.41, validation_loss=5.05]\u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.17it/s, epoch=48, training_loss=4.44, validation_loss=4.98]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:65.15045094490051 s\n",
      "2021-09-01 22:17:13,902 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005150447275684467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.20it/s, epoch=15, training_loss=4.21, validation_loss=4.73]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.08it/s, epoch=31, training_loss=4.25, validation_loss=4.79]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.10it/s, epoch=47, training_loss=4.24, validation_loss=4.77]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:17:35,748 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005150447275684467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.31it/s, epoch=16, training_loss=4.31, validation_loss=4.92]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.31it/s, epoch=33, training_loss=4.2, validation_loss=4.67] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:17:56,393 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005150447275684467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.19it/s, epoch=15, training_loss=4.43, validation_loss=5.15]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.21it/s, epoch=32, training_loss=4.38, validation_loss=4.99]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:63.93510127067566 s\n",
      "2021-09-01 22:18:17,838 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.007590132827324478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.15it/s, epoch=15, training_loss=4.61, validation_loss=5.4]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.18it/s, epoch=31, training_loss=4.38, validation_loss=5.05]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.32it/s, epoch=49, training_loss=4.38, validation_loss=5.09]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:18:38,582 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004066142586066685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.30it/s, epoch=16, training_loss=4.2, validation_loss=4.99]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.22it/s, epoch=33, training_loss=4.22, validation_loss=4.72]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:19:00,022 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0056925996204933585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.17it/s, epoch=15, training_loss=4.35, validation_loss=4.81]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.10it/s, epoch=31, training_loss=4.3, validation_loss=4.68] \u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.17it/s, epoch=48, training_loss=4.28, validation_loss=4.62]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:63.789804458618164 s\n",
      "2021-09-01 22:19:21,635 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005963675792897805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  36%|███▌      | 18/50 [00:05<00:09,  3.41it/s, epoch=17, training_loss=4.41, validation_loss=5.03]\u001b[A\n",
      "Training neural network:  72%|███████▏  | 36/50 [00:10<00:04,  3.36it/s, epoch=35, training_loss=4.29, validation_loss=4.86]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:19:42,277 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.007319056654920032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.26it/s, epoch=16, training_loss=4.29, validation_loss=5.07]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.27it/s, epoch=33, training_loss=4.26, validation_loss=4.83]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:20:02,943 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005963675792897805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.29it/s, epoch=16, training_loss=4.35, validation_loss=4.96]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.30it/s, epoch=33, training_loss=4.25, validation_loss=4.85]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:62.29282283782959 s\n",
      "2021-09-01 22:20:23,921 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005421523448088913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.40it/s, epoch=16, training_loss=4.43, validation_loss=5]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.26it/s, epoch=33, training_loss=4.44, validation_loss=4.96]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:20:44,659 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.007861208999728924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.20it/s, epoch=16, training_loss=4.43, validation_loss=4.97]\u001b[A\n",
      "Training neural network:  70%|███████   | 35/50 [00:10<00:04,  3.30it/s, epoch=34, training_loss=4.46, validation_loss=4.94]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:21:05,837 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.006505828137706696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.21it/s, epoch=16, training_loss=4.4, validation_loss=5]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.21it/s, epoch=33, training_loss=4.29, validation_loss=4.92]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:63.62186050415039 s\n",
      "2021-09-01 22:21:27,544 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.006505828137706696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.27it/s, epoch=16, training_loss=4.44, validation_loss=4.86]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.25it/s, epoch=33, training_loss=4.2, validation_loss=4.7]  \u001b[A\n",
      "                                                                                                                          \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:21:48,158 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.007319056654920032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.24it/s, epoch=16, training_loss=4.4, validation_loss=5.01]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.19it/s, epoch=33, training_loss=4.45, validation_loss=5]  \u001b[A\n",
      "                                                                                                                         \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:22:09,398 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0035239902412577935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.32it/s, epoch=16, training_loss=4.39, validation_loss=5.07]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.22it/s, epoch=33, training_loss=4.4, validation_loss=4.88] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:63.7458860874176 s\n",
      "2021-09-01 22:22:31,290 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.006776904310111141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  30%|███       | 15/50 [00:05<00:11,  2.93it/s, epoch=14, training_loss=4.4, validation_loss=4.92]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.23it/s, epoch=32, training_loss=4.41, validation_loss=5.04]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.22it/s, epoch=49, training_loss=4.39, validation_loss=5.09]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:22:52,567 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0029818378964489023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  36%|███▌      | 18/50 [00:05<00:09,  3.46it/s, epoch=17, training_loss=4.3, validation_loss=4.84]\u001b[A\n",
      "Training neural network:  72%|███████▏  | 36/50 [00:10<00:04,  3.44it/s, epoch=35, training_loss=4.16, validation_loss=4.78]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:23:12,816 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005150447275684467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.19it/s, epoch=15, training_loss=4.25, validation_loss=4.8]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.17it/s, epoch=31, training_loss=4.22, validation_loss=4.74]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.18it/s, epoch=47, training_loss=4.22, validation_loss=4.71]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:62.731626987457275 s\n",
      "2021-09-01 22:23:34,022 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004608294930875576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.17it/s, epoch=15, training_loss=4.51, validation_loss=5.18]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.10it/s, epoch=31, training_loss=4.34, validation_loss=5.05]\u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.21it/s, epoch=48, training_loss=4.32, validation_loss=4.91]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:23:55,808 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0056925996204933585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.20it/s, epoch=16, training_loss=4.43, validation_loss=4.91]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.09it/s, epoch=33, training_loss=4.42, validation_loss=5]   \u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:16<00:00,  3.11it/s, epoch=49, training_loss=4.35, validation_loss=4.99]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:24:17,777 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004608294930875576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.33it/s, epoch=16, training_loss=4.28, validation_loss=4.9]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.19it/s, epoch=33, training_loss=4.25, validation_loss=4.64]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:64.92448377609253 s\n",
      "2021-09-01 22:24:38,947 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.003795066413662239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.10it/s, epoch=15, training_loss=4.41, validation_loss=5.05]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.24it/s, epoch=32, training_loss=4.38, validation_loss=5.03]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.26it/s, epoch=49, training_loss=4.38, validation_loss=5.1] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:24:59,738 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0035239902412577935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.25it/s, epoch=16, training_loss=4.39, validation_loss=5.04]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.24it/s, epoch=33, training_loss=4.36, validation_loss=4.84]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:25:21,307 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.00623475196530225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.30it/s, epoch=16, training_loss=4.35, validation_loss=4.89]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.32it/s, epoch=33, training_loss=4.32, validation_loss=4.9] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:63.737802028656006 s\n",
      "2021-09-01 22:25:42,686 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004879371103280022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.37it/s, epoch=16, training_loss=4.28, validation_loss=4.76]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.36it/s, epoch=33, training_loss=4.23, validation_loss=4.83]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:26:03,402 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005421523448088913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.10it/s, epoch=15, training_loss=4.53, validation_loss=5.12]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.11it/s, epoch=31, training_loss=4.47, validation_loss=5.1] \u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.17it/s, epoch=48, training_loss=4.46, validation_loss=5.03]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:26:25,039 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.008403361344537815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  30%|███       | 15/50 [00:05<00:11,  2.93it/s, epoch=14, training_loss=4.43, validation_loss=5.11]\u001b[A\n",
      "Training neural network:  62%|██████▏   | 31/50 [00:10<00:06,  3.07it/s, epoch=30, training_loss=4.38, validation_loss=4.91]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.18it/s, epoch=47, training_loss=4.35, validation_loss=4.92]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:64.13552021980286 s\n",
      "2021-09-01 22:26:46,822 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.003795066413662239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.26it/s, epoch=16, training_loss=4.36, validation_loss=5.07]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.28it/s, epoch=33, training_loss=4.27, validation_loss=4.99]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:27:08,451 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.007047980482515587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.28it/s, epoch=16, training_loss=4.35, validation_loss=5.09]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.15it/s, epoch=33, training_loss=4.36, validation_loss=4.88]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.17it/s, epoch=49, training_loss=4.32, validation_loss=4.87]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:27:29,766 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.00433721875847113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.24it/s, epoch=16, training_loss=4.41, validation_loss=5]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.16it/s, epoch=33, training_loss=4.35, validation_loss=4.98]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:64.14228987693787 s\n",
      "2021-09-01 22:27:50,965 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.007047980482515587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.33it/s, epoch=16, training_loss=4.23, validation_loss=4.66]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.23it/s, epoch=33, training_loss=4.16, validation_loss=4.79]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:28:12,085 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004879371103280022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.07it/s, epoch=15, training_loss=4.5, validation_loss=4.93]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.12it/s, epoch=31, training_loss=4.4, validation_loss=5.09]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.14it/s, epoch=47, training_loss=4.41, validation_loss=5.01]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:28:35,217 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004879371103280022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.36it/s, epoch=16, training_loss=4.43, validation_loss=5.03]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.30it/s, epoch=33, training_loss=4.43, validation_loss=4.96]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:65.33203172683716 s\n",
      "2021-09-01 22:28:56,298 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005150447275684467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.03it/s, epoch=15, training_loss=4.34, validation_loss=4.71]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.13it/s, epoch=32, training_loss=4.21, validation_loss=4.54]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.24it/s, epoch=49, training_loss=4.17, validation_loss=4.66]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:29:17,523 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.006776904310111141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.08it/s, epoch=15, training_loss=4.32, validation_loss=4.94]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.18it/s, epoch=32, training_loss=4.25, validation_loss=4.78]\u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.06it/s, epoch=48, training_loss=4.3, validation_loss=4.78] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:29:39,274 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004608294930875576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  30%|███       | 15/50 [00:05<00:12,  2.89it/s, epoch=14, training_loss=4.43, validation_loss=4.98]\u001b[A\n",
      "Training neural network:  62%|██████▏   | 31/50 [00:10<00:06,  3.05it/s, epoch=30, training_loss=4.47, validation_loss=5]   \u001b[A\n",
      "Training neural network:  94%|█████████▍| 47/50 [00:15<00:01,  2.99it/s, epoch=46, training_loss=4.44, validation_loss=5.02]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:65.81210422515869 s\n",
      "2021-09-01 22:30:02,110 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005421523448088913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.09it/s, epoch=15, training_loss=4.54, validation_loss=5.03]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.14it/s, epoch=31, training_loss=4.44, validation_loss=4.92]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.05it/s, epoch=47, training_loss=4.39, validation_loss=5]   \u001b[A\n",
      "                                                                                                                         \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:30:23,871 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.006776904310111141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.21it/s, epoch=16, training_loss=4.4, validation_loss=5.28]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.15it/s, epoch=33, training_loss=4.38, validation_loss=5.04]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:30:45,301 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.006776904310111141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.08it/s, epoch=15, training_loss=4.43, validation_loss=4.95]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.23it/s, epoch=32, training_loss=4.36, validation_loss=4.89]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:64.17442154884338 s\n",
      "2021-09-01 22:31:06,285 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0035239902412577935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  36%|███▌      | 18/50 [00:05<00:09,  3.47it/s, epoch=17, training_loss=4.41, validation_loss=5.03]\u001b[A\n",
      "Training neural network:  72%|███████▏  | 36/50 [00:10<00:04,  3.46it/s, epoch=35, training_loss=4.45, validation_loss=4.96]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:31:26,767 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005421523448088913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  38%|███▊      | 19/50 [00:05<00:08,  3.65it/s, epoch=18, training_loss=4.31, validation_loss=4.93]\u001b[A\n",
      "Training neural network:  76%|███████▌  | 38/50 [00:10<00:03,  3.43it/s, epoch=37, training_loss=4.27, validation_loss=4.77]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:31:46,918 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.006505828137706696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.29it/s, epoch=16, training_loss=4.48, validation_loss=5.06]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.19it/s, epoch=33, training_loss=4.41, validation_loss=4.99]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:62.14876961708069 s\n",
      "2021-09-01 22:32:08,435 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005421523448088913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.14it/s, epoch=15, training_loss=4.36, validation_loss=4.87]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.14it/s, epoch=31, training_loss=4.36, validation_loss=4.87]\u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.23it/s, epoch=48, training_loss=4.35, validation_loss=4.91]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:32:29,685 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.00623475196530225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.21it/s, epoch=16, training_loss=4.43, validation_loss=5.01]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.24it/s, epoch=33, training_loss=4.38, validation_loss=4.94]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:32:50,959 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0056925996204933585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.18it/s, epoch=16, training_loss=4.48, validation_loss=5.13]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.18it/s, epoch=32, training_loss=4.4, validation_loss=4.96] \u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.09it/s, epoch=48, training_loss=4.45, validation_loss=5]  \u001b[A\n",
      "                                                                                                                         \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:64.2589340209961 s\n",
      "2021-09-01 22:33:12,694 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.006776904310111141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.14it/s, epoch=15, training_loss=4.45, validation_loss=5.19]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.29it/s, epoch=33, training_loss=4.41, validation_loss=5.08]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:33:34,217 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.007047980482515587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.37it/s, epoch=16, training_loss=4.44, validation_loss=4.97]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.29it/s, epoch=33, training_loss=4.43, validation_loss=4.94]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:33:55,364 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.006505828137706696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.23it/s, epoch=16, training_loss=4.39, validation_loss=4.8]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.08it/s, epoch=33, training_loss=4.36, validation_loss=4.84]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:64.3738522529602 s\n",
      "2021-09-01 22:34:17,069 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.007047980482515587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.34it/s, epoch=16, training_loss=4.32, validation_loss=4.84]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.19it/s, epoch=33, training_loss=4.3, validation_loss=4.78] \u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.18it/s, epoch=49, training_loss=4.3, validation_loss=4.58]\u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:34:38,429 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.006505828137706696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.16it/s, epoch=15, training_loss=4.3, validation_loss=4.83]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.18it/s, epoch=31, training_loss=4.26, validation_loss=4.8]\u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.21it/s, epoch=48, training_loss=4.28, validation_loss=4.84]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:34:59,710 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004608294930875576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  36%|███▌      | 18/50 [00:05<00:09,  3.51it/s, epoch=17, training_loss=4.42, validation_loss=4.88]\u001b[A\n",
      "Training neural network:  72%|███████▏  | 36/50 [00:11<00:04,  3.21it/s, epoch=35, training_loss=4.34, validation_loss=5.06]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:64.14799475669861 s\n",
      "2021-09-01 22:35:21,218 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005421523448088913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.36it/s, epoch=16, training_loss=4.37, validation_loss=5.06]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.34it/s, epoch=33, training_loss=4.3, validation_loss=4.93] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:35:41,870 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0056925996204933585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.38it/s, epoch=16, training_loss=4.28, validation_loss=4.94]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.32it/s, epoch=33, training_loss=4.25, validation_loss=4.71]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:36:02,362 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.00433721875847113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.33it/s, epoch=16, training_loss=4.22, validation_loss=4.82]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.35it/s, epoch=33, training_loss=4.2, validation_loss=4.74] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:62.441859006881714 s\n",
      "2021-09-01 22:36:23,660 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0056925996204933585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.06it/s, epoch=15, training_loss=4.42, validation_loss=5.01]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.11it/s, epoch=31, training_loss=4.39, validation_loss=5.07]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.05it/s, epoch=47, training_loss=4.37, validation_loss=5.1] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:36:45,912 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005150447275684467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.09it/s, epoch=15, training_loss=4.36, validation_loss=4.9]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.16it/s, epoch=32, training_loss=4.31, validation_loss=4.84]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.17it/s, epoch=49, training_loss=4.28, validation_loss=4.72]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:37:08,061 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.008403361344537815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.15it/s, epoch=16, training_loss=4.28, validation_loss=4.84]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.14it/s, epoch=32, training_loss=4.24, validation_loss=4.76]\u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.10it/s, epoch=48, training_loss=4.24, validation_loss=4.58]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:65.99987316131592 s\n",
      "2021-09-01 22:37:29,661 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005421523448088913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.20it/s, epoch=16, training_loss=4.43, validation_loss=5.01]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:11<00:05,  3.06it/s, epoch=33, training_loss=4.4, validation_loss=4.96] \u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:16<00:00,  3.04it/s, epoch=49, training_loss=4.43, validation_loss=5.04]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:37:52,320 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005963675792897805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  30%|███       | 15/50 [00:05<00:11,  2.99it/s, epoch=14, training_loss=4.45, validation_loss=5.03]\u001b[A\n",
      "Training neural network:  60%|██████    | 30/50 [00:10<00:06,  2.96it/s, epoch=29, training_loss=4.38, validation_loss=5.02]\u001b[A\n",
      "Training neural network:  94%|█████████▍| 47/50 [00:15<00:00,  3.08it/s, epoch=46, training_loss=4.39, validation_loss=5.09]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:38:14,535 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004066142586066685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.21it/s, epoch=16, training_loss=4.42, validation_loss=5.08]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.11it/s, epoch=33, training_loss=4.36, validation_loss=5.2] \u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:16<00:00,  3.10it/s, epoch=49, training_loss=4.37, validation_loss=5.05]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:66.92446184158325 s\n",
      "2021-09-01 22:38:36,586 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.00623475196530225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.15it/s, epoch=15, training_loss=4.43, validation_loss=5.02]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:06,  2.95it/s, epoch=31, training_loss=4.38, validation_loss=4.93]\u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:16<00:00,  3.06it/s, epoch=48, training_loss=4.38, validation_loss=5.07]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:38:59,212 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.006776904310111141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  30%|███       | 15/50 [00:05<00:11,  2.95it/s, epoch=14, training_loss=4.44, validation_loss=4.84]\u001b[A\n",
      "Training neural network:  62%|██████▏   | 31/50 [00:10<00:06,  2.98it/s, epoch=30, training_loss=4.32, validation_loss=4.87]\u001b[A\n",
      "Training neural network:  94%|█████████▍| 47/50 [00:15<00:00,  3.02it/s, epoch=46, training_loss=4.24, validation_loss=4.86]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:39:21,521 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005963675792897805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  30%|███       | 15/50 [00:05<00:11,  2.96it/s, epoch=14, training_loss=4.44, validation_loss=4.97]\u001b[A\n",
      "Training neural network:  62%|██████▏   | 31/50 [00:10<00:06,  3.05it/s, epoch=30, training_loss=4.36, validation_loss=4.93]\u001b[A\n",
      "Training neural network:  94%|█████████▍| 47/50 [00:15<00:01,  2.97it/s, epoch=46, training_loss=4.34, validation_loss=4.74]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:67.91973876953125 s\n",
      "2021-09-01 22:39:44,506 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004608294930875576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  30%|███       | 15/50 [00:05<00:11,  2.94it/s, epoch=14, training_loss=4.41, validation_loss=4.96]\u001b[A\n",
      "Training neural network:  60%|██████    | 30/50 [00:10<00:06,  2.96it/s, epoch=29, training_loss=4.33, validation_loss=4.89]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.17it/s, epoch=47, training_loss=4.31, validation_loss=5.02]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:40:06,865 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.00623475196530225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.23it/s, epoch=16, training_loss=4.39, validation_loss=5.03]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.09it/s, epoch=33, training_loss=4.42, validation_loss=4.89]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:40:28,503 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0056925996204933585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.13it/s, epoch=15, training_loss=4.52, validation_loss=4.99]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.24it/s, epoch=32, training_loss=4.5, validation_loss=5.21] \u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.15it/s, epoch=49, training_loss=4.47, validation_loss=5.09]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:66.00538516044617 s\n",
      "2021-09-01 22:40:50,512 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.006505828137706696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.32it/s, epoch=16, training_loss=4.4, validation_loss=5]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.23it/s, epoch=33, training_loss=4.34, validation_loss=4.95]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:41:11,836 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0056925996204933585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.04it/s, epoch=15, training_loss=4.49, validation_loss=4.97]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.08it/s, epoch=31, training_loss=4.44, validation_loss=4.96]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.07it/s, epoch=47, training_loss=4.44, validation_loss=5.02]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:41:34,318 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004066142586066685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.26it/s, epoch=16, training_loss=4.21, validation_loss=4.76]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.15it/s, epoch=33, training_loss=4.18, validation_loss=4.69]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.12it/s, epoch=49, training_loss=4.15, validation_loss=4.75]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:65.47532677650452 s\n",
      "2021-09-01 22:41:55,988 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.003252914068853348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.08it/s, epoch=15, training_loss=4.48, validation_loss=5.15]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.10it/s, epoch=31, training_loss=4.46, validation_loss=5.12]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.08it/s, epoch=47, training_loss=4.42, validation_loss=5.11]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:42:17,830 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004608294930875576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.39it/s, epoch=16, training_loss=4.48, validation_loss=5.05]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.30it/s, epoch=33, training_loss=4.29, validation_loss=5.07]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:42:38,441 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.006505828137706696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  30%|███       | 15/50 [00:05<00:11,  2.95it/s, epoch=14, training_loss=4.39, validation_loss=4.83]\u001b[A\n",
      "Training neural network:  62%|██████▏   | 31/50 [00:10<00:06,  3.08it/s, epoch=30, training_loss=4.26, validation_loss=4.78]\u001b[A\n",
      "Training neural network:  94%|█████████▍| 47/50 [00:15<00:00,  3.10it/s, epoch=46, training_loss=4.29, validation_loss=4.65]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:64.19394636154175 s\n",
      "2021-09-01 22:43:00,183 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005421523448088913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.08it/s, epoch=15, training_loss=4.38, validation_loss=4.89]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.15it/s, epoch=32, training_loss=4.34, validation_loss=4.82]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.19it/s, epoch=49, training_loss=4.34, validation_loss=5.08]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:43:21,425 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.007047980482515587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.37it/s, epoch=16, training_loss=4.45, validation_loss=4.89]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.18it/s, epoch=33, training_loss=4.46, validation_loss=4.99]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.13it/s, epoch=49, training_loss=4.44, validation_loss=5]   \u001b[A\n",
      "                                                                                                                         \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:43:42,953 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.00623475196530225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.34it/s, epoch=16, training_loss=4.44, validation_loss=4.88]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.35it/s, epoch=33, training_loss=4.44, validation_loss=4.97]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:63.5243821144104 s\n",
      "2021-09-01 22:44:03,708 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005150447275684467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.35it/s, epoch=16, training_loss=4.35, validation_loss=4.87]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.36it/s, epoch=33, training_loss=4.24, validation_loss=4.83]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:44:24,483 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.007590132827324478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.04it/s, epoch=15, training_loss=4.37, validation_loss=5.11]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:06,  2.98it/s, epoch=31, training_loss=4.33, validation_loss=5.12]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.01it/s, epoch=47, training_loss=4.34, validation_loss=5.05]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:44:46,901 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005150447275684467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.16it/s, epoch=15, training_loss=4.4, validation_loss=5.12]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.16it/s, epoch=32, training_loss=4.41, validation_loss=5.03]\u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.14it/s, epoch=48, training_loss=4.41, validation_loss=5.04]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:64.81949710845947 s\n",
      "2021-09-01 22:45:08,529 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.008403361344537815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.30it/s, epoch=16, training_loss=4.43, validation_loss=4.96]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.22it/s, epoch=33, training_loss=4.42, validation_loss=5.02]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:45:29,890 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005150447275684467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  30%|███       | 15/50 [00:05<00:11,  2.95it/s, epoch=14, training_loss=4.56, validation_loss=4.96]\u001b[A\n",
      "Training neural network:  62%|██████▏   | 31/50 [00:10<00:06,  3.08it/s, epoch=30, training_loss=4.32, validation_loss=4.87]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.19it/s, epoch=47, training_loss=4.28, validation_loss=4.88]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:45:51,760 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0056925996204933585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.12it/s, epoch=15, training_loss=4.41, validation_loss=4.89]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.12it/s, epoch=31, training_loss=4.27, validation_loss=4.81]\u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.21it/s, epoch=48, training_loss=4.3, validation_loss=4.81] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:65.05636143684387 s\n",
      "2021-09-01 22:46:13,590 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005963675792897805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  30%|███       | 15/50 [00:05<00:11,  2.98it/s, epoch=14, training_loss=4.42, validation_loss=5.01]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.13it/s, epoch=31, training_loss=4.36, validation_loss=5.02]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.14it/s, epoch=47, training_loss=4.37, validation_loss=5.01]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:46:35,637 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005421523448088913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.04it/s, epoch=15, training_loss=4.35, validation_loss=4.92]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.07it/s, epoch=31, training_loss=4.32, validation_loss=4.89]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.11it/s, epoch=47, training_loss=4.29, validation_loss=4.77]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:46:58,081 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.006505828137706696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.35it/s, epoch=16, training_loss=4.28, validation_loss=4.98]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.29it/s, epoch=33, training_loss=4.23, validation_loss=4.83]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:65.4470202922821 s\n",
      "2021-09-01 22:47:19,033 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.007047980482515587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.13it/s, epoch=15, training_loss=4.36, validation_loss=4.73]\u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [00:10<00:05,  3.19it/s, epoch=32, training_loss=4.28, validation_loss=4.62]\u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.04it/s, epoch=48, training_loss=4.3, validation_loss=4.8]  \u001b[A\n",
      "                                                                                                                          \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:47:41,139 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005963675792897805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.26it/s, epoch=16, training_loss=4.45, validation_loss=4.96]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.32it/s, epoch=33, training_loss=4.44, validation_loss=5.06]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:48:02,078 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004066142586066685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.12it/s, epoch=15, training_loss=4.31, validation_loss=4.9]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.02it/s, epoch=31, training_loss=4.23, validation_loss=4.74]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.09it/s, epoch=47, training_loss=4.25, validation_loss=4.67]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:65.7052972316742 s\n",
      "2021-09-01 22:48:24,738 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005150447275684467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.23it/s, epoch=16, training_loss=4.45, validation_loss=5]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.21it/s, epoch=33, training_loss=4.42, validation_loss=4.98]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:48:45,899 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.00623475196530225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.33it/s, epoch=16, training_loss=4.25, validation_loss=4.68]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.27it/s, epoch=33, training_loss=4.17, validation_loss=4.73]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:49:06,785 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005963675792897805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.23it/s, epoch=16, training_loss=4.38, validation_loss=4.92]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.24it/s, epoch=33, training_loss=4.38, validation_loss=4.86]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:64.05351161956787 s\n",
      "2021-09-01 22:49:28,793 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004066142586066685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:09,  3.35it/s, epoch=16, training_loss=4.48, validation_loss=5.02]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.17it/s, epoch=33, training_loss=4.43, validation_loss=5]   \u001b[A\n",
      "                                                                                                                         \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:49:50,000 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.007047980482515587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.25it/s, epoch=16, training_loss=4.43, validation_loss=5.15]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.12it/s, epoch=33, training_loss=4.31, validation_loss=4.93]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:50:11,464 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.00433721875847113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.19it/s, epoch=16, training_loss=4.44, validation_loss=4.95]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.29it/s, epoch=33, training_loss=4.36, validation_loss=4.87]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:63.46516013145447 s\n",
      "2021-09-01 22:50:32,259 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005150447275684467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.25it/s, epoch=16, training_loss=4.42, validation_loss=4.98]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:05,  3.17it/s, epoch=33, training_loss=4.37, validation_loss=4.97]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:15<00:00,  3.13it/s, epoch=49, training_loss=4.26, validation_loss=4.88]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:50:53,595 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.006505828137706696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.24it/s, epoch=16, training_loss=4.37, validation_loss=4.89]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:10<00:04,  3.31it/s, epoch=33, training_loss=4.33, validation_loss=4.89]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:51:14,844 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0056925996204933585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.18it/s, epoch=15, training_loss=4.43, validation_loss=4.85]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.09it/s, epoch=31, training_loss=4.22, validation_loss=4.77]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.09it/s, epoch=47, training_loss=4.14, validation_loss=4.66]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:64.9412112236023 s\n",
      "2021-09-01 22:51:37,202 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.007047980482515587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.00it/s, epoch=15, training_loss=4.42, validation_loss=5.06]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:06,  3.00it/s, epoch=31, training_loss=4.43, validation_loss=5.07]\u001b[A\n",
      "Training neural network:  94%|█████████▍| 47/50 [00:15<00:01,  2.98it/s, epoch=46, training_loss=4.39, validation_loss=5.14]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:52:00,426 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0056925996204933585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.06it/s, epoch=15, training_loss=4.49, validation_loss=4.94]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.02it/s, epoch=31, training_loss=4.38, validation_loss=5.02]\u001b[A\n",
      "Training neural network:  98%|█████████▊| 49/50 [00:15<00:00,  3.08it/s, epoch=48, training_loss=4.39, validation_loss=4.94]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:52:23,127 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.007590132827324478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  30%|███       | 15/50 [00:05<00:11,  2.92it/s, epoch=14, training_loss=4.4, validation_loss=4.92]\u001b[A\n",
      "Training neural network:  62%|██████▏   | 31/50 [00:10<00:06,  2.96it/s, epoch=30, training_loss=4.35, validation_loss=4.78]\u001b[A\n",
      "Training neural network:  94%|█████████▍| 47/50 [00:15<00:00,  3.01it/s, epoch=46, training_loss=4.33, validation_loss=4.93]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:68.58836364746094 s\n",
      "2021-09-01 22:52:45,791 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.00623475196530225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.08it/s, epoch=15, training_loss=4.41, validation_loss=4.91]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:06,  2.99it/s, epoch=31, training_loss=4.27, validation_loss=4.77]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.03it/s, epoch=47, training_loss=4.33, validation_loss=4.92]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:53:08,183 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004608294930875576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  30%|███       | 15/50 [00:05<00:11,  2.93it/s, epoch=14, training_loss=4.42, validation_loss=5.11]\u001b[A\n",
      "Training neural network:  60%|██████    | 30/50 [00:10<00:06,  2.91it/s, epoch=29, training_loss=4.39, validation_loss=4.93]\u001b[A\n",
      "Training neural network:  90%|█████████ | 45/50 [00:15<00:01,  2.88it/s, epoch=44, training_loss=4.4, validation_loss=5.19] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:53:31,909 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004608294930875576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  30%|███       | 15/50 [00:05<00:11,  2.95it/s, epoch=14, training_loss=4.41, validation_loss=4.88]\u001b[A\n",
      "Training neural network:  60%|██████    | 30/50 [00:10<00:06,  2.97it/s, epoch=29, training_loss=4.35, validation_loss=4.89]\u001b[A\n",
      "Training neural network:  90%|█████████ | 45/50 [00:15<00:01,  2.94it/s, epoch=44, training_loss=4.39, validation_loss=4.86]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:68.94316387176514 s\n",
      "2021-09-01 22:53:54,732 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005963675792897805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.07it/s, epoch=15, training_loss=4.44, validation_loss=5.01]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.00it/s, epoch=31, training_loss=4.37, validation_loss=5.01]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:16<00:00,  2.95it/s, epoch=47, training_loss=4.37, validation_loss=5.06]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:54:17,503 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005150447275684467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  30%|███       | 15/50 [00:05<00:11,  2.95it/s, epoch=14, training_loss=4.37, validation_loss=4.92]\u001b[A\n",
      "Training neural network:  62%|██████▏   | 31/50 [00:10<00:06,  3.03it/s, epoch=30, training_loss=4.3, validation_loss=4.77] \u001b[A\n",
      "Training neural network:  94%|█████████▍| 47/50 [00:15<00:01,  2.98it/s, epoch=46, training_loss=4.25, validation_loss=4.91]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:54:40,582 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005963675792897805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  30%|███       | 15/50 [00:05<00:11,  2.98it/s, epoch=14, training_loss=4.3, validation_loss=4.68]\u001b[A\n",
      "Training neural network:  60%|██████    | 30/50 [00:10<00:06,  2.98it/s, epoch=29, training_loss=4.25, validation_loss=4.52]\u001b[A\n",
      "Training neural network:  92%|█████████▏| 46/50 [00:15<00:01,  3.04it/s, epoch=45, training_loss=4.33, validation_loss=4.67]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:68.70983982086182 s\n",
      "2021-09-01 22:55:03,442 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0056925996204933585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  36%|███▌      | 18/50 [00:05<00:09,  3.39it/s, epoch=17, training_loss=4.39, validation_loss=5.02]\u001b[A\n",
      "Training neural network:  70%|███████   | 35/50 [00:10<00:04,  3.21it/s, epoch=34, training_loss=4.39, validation_loss=5.11]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:55:24,516 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005421523448088913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:05<00:10,  3.22it/s, epoch=16, training_loss=4.39, validation_loss=5.02]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:11<00:05,  2.99it/s, epoch=33, training_loss=4.37, validation_loss=4.96]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [00:16<00:00,  2.99it/s, epoch=49, training_loss=4.36, validation_loss=5.13]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:55:46,636 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004879371103280022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  30%|███       | 15/50 [00:05<00:11,  2.94it/s, epoch=14, training_loss=4.33, validation_loss=4.86]\u001b[A\n",
      "Training neural network:  60%|██████    | 30/50 [00:10<00:06,  2.97it/s, epoch=29, training_loss=4.35, validation_loss=5.03]\u001b[A\n",
      "Training neural network:  92%|█████████▏| 46/50 [00:15<00:01,  3.02it/s, epoch=45, training_loss=4.36, validation_loss=4.95]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:66.1112596988678 s\n",
      "2021-09-01 22:56:09,554 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0056925996204933585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  30%|███       | 15/50 [00:05<00:11,  2.92it/s, epoch=14, training_loss=4.37, validation_loss=4.8]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.07it/s, epoch=31, training_loss=4.27, validation_loss=4.73]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.00it/s, epoch=47, training_loss=4.24, validation_loss=4.89]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:56:31,877 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005963675792897805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.04it/s, epoch=15, training_loss=4.34, validation_loss=4.87]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.08it/s, epoch=31, training_loss=4.29, validation_loss=4.91]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.03it/s, epoch=47, training_loss=4.27, validation_loss=4.71]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:56:54,689 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005421523448088913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.09it/s, epoch=15, training_loss=4.42, validation_loss=5.04]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.09it/s, epoch=31, training_loss=4.43, validation_loss=4.96]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.02it/s, epoch=47, training_loss=4.41, validation_loss=5.02]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:67.46526384353638 s\n",
      "2021-09-01 22:57:17,021 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.003252914068853348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  30%|███       | 15/50 [00:05<00:12,  2.88it/s, epoch=14, training_loss=4.36, validation_loss=5.02]\u001b[A\n",
      "Training neural network:  62%|██████▏   | 31/50 [00:10<00:06,  2.98it/s, epoch=30, training_loss=4.32, validation_loss=4.95]\u001b[A\n",
      "Training neural network:  92%|█████████▏| 46/50 [00:15<00:01,  2.96it/s, epoch=45, training_loss=4.26, validation_loss=4.92]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:57:39,959 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005150447275684467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.02it/s, epoch=15, training_loss=4.46, validation_loss=4.93]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.01it/s, epoch=31, training_loss=4.4, validation_loss=5.01] \u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.09it/s, epoch=47, training_loss=4.36, validation_loss=4.95]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:58:02,395 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.006505828137706696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  2.92it/s, epoch=15, training_loss=4.44, validation_loss=5.04]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:06,  2.97it/s, epoch=31, training_loss=4.39, validation_loss=5.02]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:16<00:00,  3.02it/s, epoch=47, training_loss=4.36, validation_loss=5.03]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:67.93906950950623 s\n",
      "2021-09-01 22:58:24,960 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.005421523448088913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  30%|███       | 15/50 [00:05<00:12,  2.91it/s, epoch=14, training_loss=4.39, validation_loss=4.97]\u001b[A\n",
      "Training neural network:  62%|██████▏   | 31/50 [00:10<00:06,  3.01it/s, epoch=30, training_loss=4.37, validation_loss=5.05]\u001b[A\n",
      "Training neural network:  94%|█████████▍| 47/50 [00:15<00:00,  3.06it/s, epoch=46, training_loss=4.35, validation_loss=4.93]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:58:47,330 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.006505828137706696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  30%|███       | 15/50 [00:05<00:11,  2.97it/s, epoch=14, training_loss=4.4, validation_loss=5.05]\u001b[A\n",
      "Training neural network:  60%|██████    | 30/50 [00:10<00:06,  2.90it/s, epoch=29, training_loss=4.39, validation_loss=4.98]\u001b[A\n",
      "Training neural network:  92%|█████████▏| 46/50 [00:15<00:01,  2.97it/s, epoch=45, training_loss=4.39, validation_loss=4.9] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 22:59:09,892 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.003252914068853348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.11it/s, epoch=15, training_loss=4.39, validation_loss=5.06]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:05,  3.02it/s, epoch=31, training_loss=4.35, validation_loss=5.03]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:15<00:00,  3.08it/s, epoch=47, training_loss=4.35, validation_loss=4.97]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:67.05665135383606 s\n"
     ]
    }
   ],
   "source": [
    "# from itertools import product\n",
    "\n",
    "# param = dict(\n",
    "#     THETA = [0.1, 0.01, 3e-3, 1e-3, 3e-4, 1e-4],\n",
    "#     GAMMA = [0.95, 0.9, 0.85, 0.8, 0.75, 0.7]\n",
    "#     )\n",
    "\n",
    "# param_values = [v for v in param.values()]\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "BATCH_SIZE=128\n",
    "\n",
    "df=pd.read_csv('data/COMPAS/compas_recidive_two_years_sanitize_age_category_jail_time_decile_score.csv')\n",
    "# df_binary = df[(df[\"race\"] == \"Caucasian\") | (df[\"race\"] == \"African-American\")]     提取两种种族\n",
    "# Y = df_binary['decile_score']    评分，range:[0,10]\n",
    "# S = df_binary['race']\n",
    "# Y_true = df_binary['two_year_recid']    是否入狱\n",
    "df_binary, Y, S, Y_true = transform_dataset(df)\n",
    "Y = Y.to_numpy()\n",
    "print(np.mean(Y))\n",
    "\n",
    "l_tensor = torch.tensor(Y_true.to_numpy().reshape(-1, 1).astype(np.float32))\n",
    "x_tensor = torch.tensor(df_binary.to_numpy().astype(np.float32))\n",
    "y_tensor = torch.tensor(Y.reshape(-1, 1).astype(np.float32))\n",
    "s_tensor = torch.tensor(preprocessing.OneHotEncoder().fit_transform(np.array(S).reshape(-1, 1)).toarray())\n",
    "\n",
    "dataset = TensorDataset(x_tensor, y_tensor, l_tensor, s_tensor)  # dataset = CustomDataset(x_tensor, y_tensor)\n",
    "\n",
    "base_size = len(dataset) // 10\n",
    "split = [7 * base_size, 1 * base_size, len(dataset) - 8 * base_size]  # Train, validation, test\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, split)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "x_train_tensor = train_dataset[:][0]\n",
    "y_train_tensor = train_dataset[:][1]\n",
    "l_train_tensor = train_dataset[:][2]\n",
    "s_train_tensor = train_dataset[:][3]\n",
    "\n",
    "global_results = []\n",
    "\n",
    "# get the classification threshold, we use the same scale for compas so 4 instead of 0.5\n",
    "ori_start=time.time()\n",
    "threshold = 4\n",
    "\n",
    "net, results = train_and_evaluate(train_loader, val_loader, test_loader, device, input_shape=x_tensor.shape[1],\n",
    "                                    grl_lambda=0)\n",
    "ori_end=time.time()\n",
    "ori_cost_time=ori_end-ori_start\n",
    "print('time costs:{} s'.format(ori_cost_time))\n",
    "\n",
    "result = get_metrics(results, threshold, 0)\n",
    "global_results.append(result)\n",
    "\n",
    "# EA\n",
    "# EA(net,attack_size=10, iter_num=50)\n",
    "\n",
    "for THETA in list(np.logspace(-0.01,-5,50)):\n",
    "    Fixate(THETA=THETA,GAMMA=0.95,epoch=3)\n",
    "for GAMMA in list(np.linspace(1,0.5,50)):\n",
    "    Fixate(THETA=0.01,GAMMA=GAMMA,epoch=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DP</th>\n",
       "      <th>EO</th>\n",
       "      <th>DP ratio</th>\n",
       "      <th>acc</th>\n",
       "      <th>acc_ci_min</th>\n",
       "      <th>acc_ci_max</th>\n",
       "      <th>f1</th>\n",
       "      <th>acc_high_risk</th>\n",
       "      <th>acc_ci_min_high_risk</th>\n",
       "      <th>acc_ci_max_high_risk</th>\n",
       "      <th>f1_high_risk</th>\n",
       "      <th>adversarial_fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.081431</td>\n",
       "      <td>0.046252</td>\n",
       "      <td>0.875586</td>\n",
       "      <td>0.665725</td>\n",
       "      <td>0.637353</td>\n",
       "      <td>0.694097</td>\n",
       "      <td>0.663570</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.831816</td>\n",
       "      <td>0.874398</td>\n",
       "      <td>0.466655</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.386691</td>\n",
       "      <td>0.108453</td>\n",
       "      <td>0.478628</td>\n",
       "      <td>0.713748</td>\n",
       "      <td>0.686562</td>\n",
       "      <td>0.740933</td>\n",
       "      <td>0.713210</td>\n",
       "      <td>0.873823</td>\n",
       "      <td>0.853852</td>\n",
       "      <td>0.893794</td>\n",
       "      <td>0.630177</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.407915</td>\n",
       "      <td>0.170654</td>\n",
       "      <td>0.460389</td>\n",
       "      <td>0.726930</td>\n",
       "      <td>0.700134</td>\n",
       "      <td>0.753727</td>\n",
       "      <td>0.726274</td>\n",
       "      <td>0.877589</td>\n",
       "      <td>0.857877</td>\n",
       "      <td>0.897302</td>\n",
       "      <td>0.627814</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.403161</td>\n",
       "      <td>0.147927</td>\n",
       "      <td>0.463303</td>\n",
       "      <td>0.735405</td>\n",
       "      <td>0.708874</td>\n",
       "      <td>0.761936</td>\n",
       "      <td>0.734840</td>\n",
       "      <td>0.871940</td>\n",
       "      <td>0.851842</td>\n",
       "      <td>0.892037</td>\n",
       "      <td>0.610637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.409500</td>\n",
       "      <td>0.155502</td>\n",
       "      <td>0.459426</td>\n",
       "      <td>0.737288</td>\n",
       "      <td>0.710818</td>\n",
       "      <td>0.763758</td>\n",
       "      <td>0.736632</td>\n",
       "      <td>0.873823</td>\n",
       "      <td>0.853852</td>\n",
       "      <td>0.893794</td>\n",
       "      <td>0.612725</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.394729</td>\n",
       "      <td>0.121611</td>\n",
       "      <td>0.476735</td>\n",
       "      <td>0.728814</td>\n",
       "      <td>0.702075</td>\n",
       "      <td>0.755552</td>\n",
       "      <td>0.728057</td>\n",
       "      <td>0.868173</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>0.888520</td>\n",
       "      <td>0.606550</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.399991</td>\n",
       "      <td>0.136762</td>\n",
       "      <td>0.465266</td>\n",
       "      <td>0.725989</td>\n",
       "      <td>0.699163</td>\n",
       "      <td>0.752814</td>\n",
       "      <td>0.725451</td>\n",
       "      <td>0.875706</td>\n",
       "      <td>0.855864</td>\n",
       "      <td>0.895549</td>\n",
       "      <td>0.632399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.396086</td>\n",
       "      <td>0.116029</td>\n",
       "      <td>0.469362</td>\n",
       "      <td>0.718456</td>\n",
       "      <td>0.691406</td>\n",
       "      <td>0.745506</td>\n",
       "      <td>0.717903</td>\n",
       "      <td>0.873823</td>\n",
       "      <td>0.853852</td>\n",
       "      <td>0.893794</td>\n",
       "      <td>0.612725</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.415611</td>\n",
       "      <td>0.176236</td>\n",
       "      <td>0.449053</td>\n",
       "      <td>0.720339</td>\n",
       "      <td>0.693344</td>\n",
       "      <td>0.747334</td>\n",
       "      <td>0.719790</td>\n",
       "      <td>0.872881</td>\n",
       "      <td>0.852847</td>\n",
       "      <td>0.892916</td>\n",
       "      <td>0.625739</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0.396936</td>\n",
       "      <td>0.155502</td>\n",
       "      <td>0.470473</td>\n",
       "      <td>0.734463</td>\n",
       "      <td>0.707902</td>\n",
       "      <td>0.761024</td>\n",
       "      <td>0.733873</td>\n",
       "      <td>0.871940</td>\n",
       "      <td>0.851842</td>\n",
       "      <td>0.892037</td>\n",
       "      <td>0.606945</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>301 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           DP        EO  DP ratio       acc  acc_ci_min  acc_ci_max        f1  \\\n",
       "0    0.081431  0.046252  0.875586  0.665725    0.637353    0.694097  0.663570   \n",
       "1    0.386691  0.108453  0.478628  0.713748    0.686562    0.740933  0.713210   \n",
       "2    0.407915  0.170654  0.460389  0.726930    0.700134    0.753727  0.726274   \n",
       "3    0.403161  0.147927  0.463303  0.735405    0.708874    0.761936  0.734840   \n",
       "4    0.409500  0.155502  0.459426  0.737288    0.710818    0.763758  0.736632   \n",
       "..        ...       ...       ...       ...         ...         ...       ...   \n",
       "296  0.394729  0.121611  0.476735  0.728814    0.702075    0.755552  0.728057   \n",
       "297  0.399991  0.136762  0.465266  0.725989    0.699163    0.752814  0.725451   \n",
       "298  0.396086  0.116029  0.469362  0.718456    0.691406    0.745506  0.717903   \n",
       "299  0.415611  0.176236  0.449053  0.720339    0.693344    0.747334  0.719790   \n",
       "300  0.396936  0.155502  0.470473  0.734463    0.707902    0.761024  0.733873   \n",
       "\n",
       "     acc_high_risk  acc_ci_min_high_risk  acc_ci_max_high_risk  f1_high_risk  \\\n",
       "0         0.853107              0.831816              0.874398      0.466655   \n",
       "1         0.873823              0.853852              0.893794      0.630177   \n",
       "2         0.877589              0.857877              0.897302      0.627814   \n",
       "3         0.871940              0.851842              0.892037      0.610637   \n",
       "4         0.873823              0.853852              0.893794      0.612725   \n",
       "..             ...                   ...                   ...           ...   \n",
       "296       0.868173              0.847826              0.888520      0.606550   \n",
       "297       0.875706              0.855864              0.895549      0.632399   \n",
       "298       0.873823              0.853852              0.893794      0.612725   \n",
       "299       0.872881              0.852847              0.892916      0.625739   \n",
       "300       0.871940              0.851842              0.892037      0.606945   \n",
       "\n",
       "     adversarial_fraction  \n",
       "0                       0  \n",
       "1                       0  \n",
       "2                       0  \n",
       "3                       0  \n",
       "4                       0  \n",
       "..                    ...  \n",
       "296                     0  \n",
       "297                     0  \n",
       "298                     0  \n",
       "299                     0  \n",
       "300                     0  \n",
       "\n",
       "[301 rows x 12 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(global_results)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "EA_ablation={'acc':0.759,\n",
    "            'DP':0.095,\n",
    "            'EO':0.095,\n",
    "            'DP ratio':1.203}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Theta</th>\n",
       "      <th>Gamma</th>\n",
       "      <th>acc</th>\n",
       "      <th>DP</th>\n",
       "      <th>EO</th>\n",
       "      <th>DP ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.725361</td>\n",
       "      <td>0.399256</td>\n",
       "      <td>0.142344</td>\n",
       "      <td>0.467440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.989796</td>\n",
       "      <td>0.727872</td>\n",
       "      <td>0.407708</td>\n",
       "      <td>0.144205</td>\n",
       "      <td>0.462178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.723164</td>\n",
       "      <td>0.412707</td>\n",
       "      <td>0.178097</td>\n",
       "      <td>0.458634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.969388</td>\n",
       "      <td>0.720653</td>\n",
       "      <td>0.402708</td>\n",
       "      <td>0.150452</td>\n",
       "      <td>0.465789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.724733</td>\n",
       "      <td>0.399011</td>\n",
       "      <td>0.129718</td>\n",
       "      <td>0.468011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.948980</td>\n",
       "      <td>0.719083</td>\n",
       "      <td>0.405274</td>\n",
       "      <td>0.127990</td>\n",
       "      <td>0.462048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.728186</td>\n",
       "      <td>0.399463</td>\n",
       "      <td>0.140484</td>\n",
       "      <td>0.465764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.723164</td>\n",
       "      <td>0.402481</td>\n",
       "      <td>0.140484</td>\n",
       "      <td>0.459402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.721594</td>\n",
       "      <td>0.401124</td>\n",
       "      <td>0.153642</td>\n",
       "      <td>0.466899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.908163</td>\n",
       "      <td>0.709040</td>\n",
       "      <td>0.390634</td>\n",
       "      <td>0.171186</td>\n",
       "      <td>0.475729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.720025</td>\n",
       "      <td>0.406368</td>\n",
       "      <td>0.156831</td>\n",
       "      <td>0.462534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.887755</td>\n",
       "      <td>0.726616</td>\n",
       "      <td>0.387051</td>\n",
       "      <td>0.136098</td>\n",
       "      <td>0.481104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.721594</td>\n",
       "      <td>0.401935</td>\n",
       "      <td>0.128522</td>\n",
       "      <td>0.466813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.867347</td>\n",
       "      <td>0.713748</td>\n",
       "      <td>0.394992</td>\n",
       "      <td>0.136098</td>\n",
       "      <td>0.468966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.722850</td>\n",
       "      <td>0.394463</td>\n",
       "      <td>0.140484</td>\n",
       "      <td>0.469427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.846939</td>\n",
       "      <td>0.720967</td>\n",
       "      <td>0.407801</td>\n",
       "      <td>0.149920</td>\n",
       "      <td>0.457191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.718456</td>\n",
       "      <td>0.406330</td>\n",
       "      <td>0.159888</td>\n",
       "      <td>0.461358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.826531</td>\n",
       "      <td>0.720339</td>\n",
       "      <td>0.396086</td>\n",
       "      <td>0.133573</td>\n",
       "      <td>0.469388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.718456</td>\n",
       "      <td>0.405992</td>\n",
       "      <td>0.146066</td>\n",
       "      <td>0.467084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.806122</td>\n",
       "      <td>0.718770</td>\n",
       "      <td>0.404179</td>\n",
       "      <td>0.144870</td>\n",
       "      <td>0.461735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.725675</td>\n",
       "      <td>0.406047</td>\n",
       "      <td>0.156167</td>\n",
       "      <td>0.461139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.723792</td>\n",
       "      <td>0.405312</td>\n",
       "      <td>0.152313</td>\n",
       "      <td>0.463121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.722850</td>\n",
       "      <td>0.408122</td>\n",
       "      <td>0.144870</td>\n",
       "      <td>0.458573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.765306</td>\n",
       "      <td>0.722536</td>\n",
       "      <td>0.389540</td>\n",
       "      <td>0.117889</td>\n",
       "      <td>0.475149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.720967</td>\n",
       "      <td>0.405274</td>\n",
       "      <td>0.141680</td>\n",
       "      <td>0.461995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.744898</td>\n",
       "      <td>0.712492</td>\n",
       "      <td>0.401576</td>\n",
       "      <td>0.142344</td>\n",
       "      <td>0.464473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.717200</td>\n",
       "      <td>0.389823</td>\n",
       "      <td>0.121611</td>\n",
       "      <td>0.475554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.724490</td>\n",
       "      <td>0.715945</td>\n",
       "      <td>0.406347</td>\n",
       "      <td>0.136098</td>\n",
       "      <td>0.454062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.720339</td>\n",
       "      <td>0.399180</td>\n",
       "      <td>0.129851</td>\n",
       "      <td>0.465293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.704082</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.402840</td>\n",
       "      <td>0.132908</td>\n",
       "      <td>0.461930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.726303</td>\n",
       "      <td>0.398897</td>\n",
       "      <td>0.121079</td>\n",
       "      <td>0.464885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.683673</td>\n",
       "      <td>0.723478</td>\n",
       "      <td>0.407235</td>\n",
       "      <td>0.149256</td>\n",
       "      <td>0.456423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.711551</td>\n",
       "      <td>0.410556</td>\n",
       "      <td>0.161749</td>\n",
       "      <td>0.458862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.663265</td>\n",
       "      <td>0.722850</td>\n",
       "      <td>0.396974</td>\n",
       "      <td>0.154173</td>\n",
       "      <td>0.471525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.726616</td>\n",
       "      <td>0.404369</td>\n",
       "      <td>0.169856</td>\n",
       "      <td>0.466947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.720967</td>\n",
       "      <td>0.403406</td>\n",
       "      <td>0.126661</td>\n",
       "      <td>0.462531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.632653</td>\n",
       "      <td>0.719083</td>\n",
       "      <td>0.400633</td>\n",
       "      <td>0.159888</td>\n",
       "      <td>0.468308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.622449</td>\n",
       "      <td>0.722850</td>\n",
       "      <td>0.403085</td>\n",
       "      <td>0.122275</td>\n",
       "      <td>0.461040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.612245</td>\n",
       "      <td>0.720967</td>\n",
       "      <td>0.413574</td>\n",
       "      <td>0.149256</td>\n",
       "      <td>0.452664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.602041</td>\n",
       "      <td>0.716573</td>\n",
       "      <td>0.413988</td>\n",
       "      <td>0.149256</td>\n",
       "      <td>0.449023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.591837</td>\n",
       "      <td>0.721908</td>\n",
       "      <td>0.407991</td>\n",
       "      <td>0.147395</td>\n",
       "      <td>0.462603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.581633</td>\n",
       "      <td>0.728186</td>\n",
       "      <td>0.414762</td>\n",
       "      <td>0.151116</td>\n",
       "      <td>0.448087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.718456</td>\n",
       "      <td>0.396255</td>\n",
       "      <td>0.120415</td>\n",
       "      <td>0.466577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.561224</td>\n",
       "      <td>0.712806</td>\n",
       "      <td>0.394539</td>\n",
       "      <td>0.162414</td>\n",
       "      <td>0.471608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.551020</td>\n",
       "      <td>0.724105</td>\n",
       "      <td>0.397219</td>\n",
       "      <td>0.133573</td>\n",
       "      <td>0.470915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.540816</td>\n",
       "      <td>0.718456</td>\n",
       "      <td>0.399256</td>\n",
       "      <td>0.149920</td>\n",
       "      <td>0.467365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.723478</td>\n",
       "      <td>0.405764</td>\n",
       "      <td>0.146730</td>\n",
       "      <td>0.460603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.520408</td>\n",
       "      <td>0.717514</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.150585</td>\n",
       "      <td>0.457975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.723792</td>\n",
       "      <td>0.427761</td>\n",
       "      <td>0.187533</td>\n",
       "      <td>0.441937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.401614</td>\n",
       "      <td>0.131047</td>\n",
       "      <td>0.465400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Theta     Gamma       acc        DP        EO  DP ratio\n",
       "0   0.0003  1.000000  0.725361  0.399256  0.142344  0.467440\n",
       "1   0.0003  0.989796  0.727872  0.407708  0.144205  0.462178\n",
       "2   0.0003  0.979592  0.723164  0.412707  0.178097  0.458634\n",
       "3   0.0003  0.969388  0.720653  0.402708  0.150452  0.465789\n",
       "4   0.0003  0.959184  0.724733  0.399011  0.129718  0.468011\n",
       "5   0.0003  0.948980  0.719083  0.405274  0.127990  0.462048\n",
       "6   0.0003  0.938776  0.728186  0.399463  0.140484  0.465764\n",
       "7   0.0003  0.928571  0.723164  0.402481  0.140484  0.459402\n",
       "8   0.0003  0.918367  0.721594  0.401124  0.153642  0.466899\n",
       "9   0.0003  0.908163  0.709040  0.390634  0.171186  0.475729\n",
       "10  0.0003  0.897959  0.720025  0.406368  0.156831  0.462534\n",
       "11  0.0003  0.887755  0.726616  0.387051  0.136098  0.481104\n",
       "12  0.0003  0.877551  0.721594  0.401935  0.128522  0.466813\n",
       "13  0.0003  0.867347  0.713748  0.394992  0.136098  0.468966\n",
       "14  0.0003  0.857143  0.722850  0.394463  0.140484  0.469427\n",
       "15  0.0003  0.846939  0.720967  0.407801  0.149920  0.457191\n",
       "16  0.0003  0.836735  0.718456  0.406330  0.159888  0.461358\n",
       "17  0.0003  0.826531  0.720339  0.396086  0.133573  0.469388\n",
       "18  0.0003  0.816327  0.718456  0.405992  0.146066  0.467084\n",
       "19  0.0003  0.806122  0.718770  0.404179  0.144870  0.461735\n",
       "20  0.0003  0.795918  0.725675  0.406047  0.156167  0.461139\n",
       "21  0.0003  0.785714  0.723792  0.405312  0.152313  0.463121\n",
       "22  0.0003  0.775510  0.722850  0.408122  0.144870  0.458573\n",
       "23  0.0003  0.765306  0.722536  0.389540  0.117889  0.475149\n",
       "24  0.0003  0.755102  0.720967  0.405274  0.141680  0.461995\n",
       "25  0.0003  0.744898  0.712492  0.401576  0.142344  0.464473\n",
       "26  0.0003  0.734694  0.717200  0.389823  0.121611  0.475554\n",
       "27  0.0003  0.724490  0.715945  0.406347  0.136098  0.454062\n",
       "28  0.0003  0.714286  0.720339  0.399180  0.129851  0.465293\n",
       "29  0.0003  0.704082  0.722222  0.402840  0.132908  0.461930\n",
       "30  0.0003  0.693878  0.726303  0.398897  0.121079  0.464885\n",
       "31  0.0003  0.683673  0.723478  0.407235  0.149256  0.456423\n",
       "32  0.0003  0.673469  0.711551  0.410556  0.161749  0.458862\n",
       "33  0.0003  0.663265  0.722850  0.396974  0.154173  0.471525\n",
       "34  0.0003  0.653061  0.726616  0.404369  0.169856  0.466947\n",
       "35  0.0003  0.642857  0.720967  0.403406  0.126661  0.462531\n",
       "36  0.0003  0.632653  0.719083  0.400633  0.159888  0.468308\n",
       "37  0.0003  0.622449  0.722850  0.403085  0.122275  0.461040\n",
       "38  0.0003  0.612245  0.720967  0.413574  0.149256  0.452664\n",
       "39  0.0003  0.602041  0.716573  0.413988  0.149256  0.449023\n",
       "40  0.0003  0.591837  0.721908  0.407991  0.147395  0.462603\n",
       "41  0.0003  0.581633  0.728186  0.414762  0.151116  0.448087\n",
       "42  0.0003  0.571429  0.718456  0.396255  0.120415  0.466577\n",
       "43  0.0003  0.561224  0.712806  0.394539  0.162414  0.471608\n",
       "44  0.0003  0.551020  0.724105  0.397219  0.133573  0.470915\n",
       "45  0.0003  0.540816  0.718456  0.399256  0.149920  0.467365\n",
       "46  0.0003  0.530612  0.723478  0.405764  0.146730  0.460603\n",
       "47  0.0003  0.520408  0.717514  0.405405  0.150585  0.457975\n",
       "48  0.0003  0.510204  0.723792  0.427761  0.187533  0.441937\n",
       "49  0.0003  0.500000  0.722222  0.401614  0.131047  0.465400"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablation_df=pd.DataFrame(columns=['Theta','Gamma','acc','DP','EO','DP ratio'])\n",
    "epoch=3\n",
    "i=0\n",
    "for GAMMA in list(np.linspace(1,0.5,50)):\n",
    "    start=1+i*epoch\n",
    "    end=start+epoch\n",
    "    dic={'Theta':0.0003,\n",
    "         'Gamma':GAMMA,\n",
    "         'acc':(df['acc'].iloc[start:end]).mean(),\n",
    "         'DP':(df['DP'].iloc[start:end]).mean(),\n",
    "         'EO':(df['EO'].iloc[start:end]).mean(),\n",
    "         'DP ratio':(df['DP ratio'].iloc[start:end]).mean()}\n",
    "    ablation_df=ablation_df.append(dic, ignore_index=True)\n",
    "    i+=1\n",
    "ablation_df.to_csv('data/results/ablation_df_gamma')\n",
    "ablation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure(504x360)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ablation_df=pd.read_csv('data/results/ablation_df_gamma')\n",
    "metric='EO'\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.tick_params(labelsize=14)\n",
    "# for GAMMA in list(np.linspace(1,0.5,50)):\n",
    "plt.plot((np.linspace(1,0.5,50)),(df.iloc[0][metric])*np.ones(50),'r-.',label='Naive baseline')\n",
    "plt.plot((np.linspace(1,0.5,50)),(EA_ablation[metric])*np.ones(50),'g-+',label='Ethical Adversaries')\n",
    "plt.plot((np.linspace(1,0.5,50)),ablation_df[metric],'bo-',label='FairNeuron')\n",
    "plt.plot((np.linspace(1,0.5,50)),ablation_df[metric][27]*np.ones(50),'b-.',label='best param')\n",
    "\n",
    "plt.xlabel('gamma',myfont)\n",
    "plt.ylabel(metric,myfont)\n",
    "# plt.ylim((0,1))\n",
    "# legend=plt.legend()\n",
    "plt.grid(linestyle='-.')\n",
    "plt.savefig('data/results/Figures/ablation_gamma_{}.pdf'.format(metric))\n",
    "print(legend.figure)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_legend(legend, filename=\"data/results/Figures/legend.pdf\", expand=[-5,-5,5,5]):\n",
    "    fig  = legend.figure\n",
    "    fig.canvas.draw()\n",
    "    bbox  = legend.get_window_extent()\n",
    "    bbox = bbox.from_extents(*(bbox.extents + np.array(expand)))\n",
    "    bbox = bbox.transformed(fig.dpi_scale_trans.inverted())\n",
    "    fig.savefig(filename, dpi=\"figure\", bbox_inches=bbox)\n",
    "export_legend(legend)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Theta</th>\n",
       "      <th>Gamma</th>\n",
       "      <th>acc</th>\n",
       "      <th>DP</th>\n",
       "      <th>EO</th>\n",
       "      <th>DP ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.977237</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.775945</td>\n",
       "      <td>0.033229</td>\n",
       "      <td>0.080650</td>\n",
       "      <td>1.065942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.772971</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.773748</td>\n",
       "      <td>0.040933</td>\n",
       "      <td>0.102434</td>\n",
       "      <td>1.056483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.611402</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.779397</td>\n",
       "      <td>0.031395</td>\n",
       "      <td>0.070314</td>\n",
       "      <td>1.067865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.483604</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.776259</td>\n",
       "      <td>0.038145</td>\n",
       "      <td>0.119311</td>\n",
       "      <td>1.061722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.382519</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.775631</td>\n",
       "      <td>0.047537</td>\n",
       "      <td>0.092621</td>\n",
       "      <td>1.048985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.302563</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.778456</td>\n",
       "      <td>0.047023</td>\n",
       "      <td>0.129647</td>\n",
       "      <td>1.052873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.239320</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.773120</td>\n",
       "      <td>0.039613</td>\n",
       "      <td>0.082285</td>\n",
       "      <td>1.058078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.189297</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.777200</td>\n",
       "      <td>0.029120</td>\n",
       "      <td>0.085556</td>\n",
       "      <td>1.072596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.149729</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.773434</td>\n",
       "      <td>0.037632</td>\n",
       "      <td>0.098214</td>\n",
       "      <td>1.062025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.118432</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.780653</td>\n",
       "      <td>0.029634</td>\n",
       "      <td>0.088140</td>\n",
       "      <td>1.068860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.093677</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.780339</td>\n",
       "      <td>0.034403</td>\n",
       "      <td>0.096579</td>\n",
       "      <td>1.066545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.074096</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.776259</td>\n",
       "      <td>0.030808</td>\n",
       "      <td>0.088827</td>\n",
       "      <td>1.069593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.058608</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.776886</td>\n",
       "      <td>0.040787</td>\n",
       "      <td>0.103382</td>\n",
       "      <td>1.058635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.046358</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.775317</td>\n",
       "      <td>0.040566</td>\n",
       "      <td>0.120521</td>\n",
       "      <td>1.054853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.036668</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.780025</td>\n",
       "      <td>0.033009</td>\n",
       "      <td>0.084607</td>\n",
       "      <td>1.065642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.029003</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.771864</td>\n",
       "      <td>0.031835</td>\n",
       "      <td>0.105017</td>\n",
       "      <td>1.071805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.022941</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.778770</td>\n",
       "      <td>0.045482</td>\n",
       "      <td>0.094256</td>\n",
       "      <td>1.050576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.018146</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.767156</td>\n",
       "      <td>0.050692</td>\n",
       "      <td>0.133605</td>\n",
       "      <td>1.052596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.014353</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.774689</td>\n",
       "      <td>0.041594</td>\n",
       "      <td>0.093733</td>\n",
       "      <td>1.060929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.011353</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.773120</td>\n",
       "      <td>0.029487</td>\n",
       "      <td>0.105017</td>\n",
       "      <td>1.070929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.008980</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.777828</td>\n",
       "      <td>0.035430</td>\n",
       "      <td>0.100111</td>\n",
       "      <td>1.065669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.007103</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.042988</td>\n",
       "      <td>0.096579</td>\n",
       "      <td>1.054937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.005618</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.779397</td>\n",
       "      <td>0.036091</td>\n",
       "      <td>0.103382</td>\n",
       "      <td>1.063238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.004444</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.772492</td>\n",
       "      <td>0.035797</td>\n",
       "      <td>0.082285</td>\n",
       "      <td>1.063923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.778142</td>\n",
       "      <td>0.037998</td>\n",
       "      <td>0.101747</td>\n",
       "      <td>1.060462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.002780</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.783478</td>\n",
       "      <td>0.033376</td>\n",
       "      <td>0.097266</td>\n",
       "      <td>1.070718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.002199</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.778770</td>\n",
       "      <td>0.045482</td>\n",
       "      <td>0.110185</td>\n",
       "      <td>1.057520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.779711</td>\n",
       "      <td>0.041740</td>\n",
       "      <td>0.101747</td>\n",
       "      <td>1.058814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.001376</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.771551</td>\n",
       "      <td>0.025598</td>\n",
       "      <td>0.074533</td>\n",
       "      <td>1.074409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.001088</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.780025</td>\n",
       "      <td>0.049151</td>\n",
       "      <td>0.106653</td>\n",
       "      <td>1.050304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.000861</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.774689</td>\n",
       "      <td>0.031615</td>\n",
       "      <td>0.087191</td>\n",
       "      <td>1.068181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.779397</td>\n",
       "      <td>0.041520</td>\n",
       "      <td>0.100798</td>\n",
       "      <td>1.058516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.000539</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.779397</td>\n",
       "      <td>0.034036</td>\n",
       "      <td>0.114405</td>\n",
       "      <td>1.065088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.780967</td>\n",
       "      <td>0.039539</td>\n",
       "      <td>0.099163</td>\n",
       "      <td>1.059195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.000337</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.782222</td>\n",
       "      <td>0.028827</td>\n",
       "      <td>0.089088</td>\n",
       "      <td>1.073373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.775631</td>\n",
       "      <td>0.038292</td>\n",
       "      <td>0.093308</td>\n",
       "      <td>1.059551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.785989</td>\n",
       "      <td>0.049958</td>\n",
       "      <td>0.106915</td>\n",
       "      <td>1.045631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.769667</td>\n",
       "      <td>0.046583</td>\n",
       "      <td>0.105279</td>\n",
       "      <td>1.048808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.780339</td>\n",
       "      <td>0.031321</td>\n",
       "      <td>0.070314</td>\n",
       "      <td>1.068902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.775945</td>\n",
       "      <td>0.043942</td>\n",
       "      <td>0.095892</td>\n",
       "      <td>1.055170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.785361</td>\n",
       "      <td>0.038219</td>\n",
       "      <td>0.087878</td>\n",
       "      <td>1.060671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.782850</td>\n",
       "      <td>0.041300</td>\n",
       "      <td>0.085556</td>\n",
       "      <td>1.058156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.773434</td>\n",
       "      <td>0.036164</td>\n",
       "      <td>0.119573</td>\n",
       "      <td>1.062244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.776886</td>\n",
       "      <td>0.033743</td>\n",
       "      <td>0.092359</td>\n",
       "      <td>1.065522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.778456</td>\n",
       "      <td>0.039099</td>\n",
       "      <td>0.103382</td>\n",
       "      <td>1.058439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.776886</td>\n",
       "      <td>0.033156</td>\n",
       "      <td>0.070314</td>\n",
       "      <td>1.063608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.774689</td>\n",
       "      <td>0.038512</td>\n",
       "      <td>0.098476</td>\n",
       "      <td>1.059834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.774062</td>\n",
       "      <td>0.039979</td>\n",
       "      <td>0.121895</td>\n",
       "      <td>1.063120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.783478</td>\n",
       "      <td>0.036898</td>\n",
       "      <td>0.110872</td>\n",
       "      <td>1.065440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.777828</td>\n",
       "      <td>0.045996</td>\n",
       "      <td>0.095892</td>\n",
       "      <td>1.050291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Theta  Gamma       acc        DP        EO  DP ratio\n",
       "0   0.977237   0.95  0.775945  0.033229  0.080650  1.065942\n",
       "1   0.772971   0.95  0.773748  0.040933  0.102434  1.056483\n",
       "2   0.611402   0.95  0.779397  0.031395  0.070314  1.067865\n",
       "3   0.483604   0.95  0.776259  0.038145  0.119311  1.061722\n",
       "4   0.382519   0.95  0.775631  0.047537  0.092621  1.048985\n",
       "5   0.302563   0.95  0.778456  0.047023  0.129647  1.052873\n",
       "6   0.239320   0.95  0.773120  0.039613  0.082285  1.058078\n",
       "7   0.189297   0.95  0.777200  0.029120  0.085556  1.072596\n",
       "8   0.149729   0.95  0.773434  0.037632  0.098214  1.062025\n",
       "9   0.118432   0.95  0.780653  0.029634  0.088140  1.068860\n",
       "10  0.093677   0.95  0.780339  0.034403  0.096579  1.066545\n",
       "11  0.074096   0.95  0.776259  0.030808  0.088827  1.069593\n",
       "12  0.058608   0.95  0.776886  0.040787  0.103382  1.058635\n",
       "13  0.046358   0.95  0.775317  0.040566  0.120521  1.054853\n",
       "14  0.036668   0.95  0.780025  0.033009  0.084607  1.065642\n",
       "15  0.029003   0.95  0.771864  0.031835  0.105017  1.071805\n",
       "16  0.022941   0.95  0.778770  0.045482  0.094256  1.050576\n",
       "17  0.018146   0.95  0.767156  0.050692  0.133605  1.052596\n",
       "18  0.014353   0.95  0.774689  0.041594  0.093733  1.060929\n",
       "19  0.011353   0.95  0.773120  0.029487  0.105017  1.070929\n",
       "20  0.008980   0.95  0.777828  0.035430  0.100111  1.065669\n",
       "21  0.007103   0.95  0.785047  0.042988  0.096579  1.054937\n",
       "22  0.005618   0.95  0.779397  0.036091  0.103382  1.063238\n",
       "23  0.004444   0.95  0.772492  0.035797  0.082285  1.063923\n",
       "24  0.003515   0.95  0.778142  0.037998  0.101747  1.060462\n",
       "25  0.002780   0.95  0.783478  0.033376  0.097266  1.070718\n",
       "26  0.002199   0.95  0.778770  0.045482  0.110185  1.057520\n",
       "27  0.001739   0.95  0.779711  0.041740  0.101747  1.058814\n",
       "28  0.001376   0.95  0.771551  0.025598  0.074533  1.074409\n",
       "29  0.001088   0.95  0.780025  0.049151  0.106653  1.050304\n",
       "30  0.000861   0.95  0.774689  0.031615  0.087191  1.068181\n",
       "31  0.000681   0.95  0.779397  0.041520  0.100798  1.058516\n",
       "32  0.000539   0.95  0.779397  0.034036  0.114405  1.065088\n",
       "33  0.000426   0.95  0.780967  0.039539  0.099163  1.059195\n",
       "34  0.000337   0.95  0.782222  0.028827  0.089088  1.073373\n",
       "35  0.000267   0.95  0.775631  0.038292  0.093308  1.059551\n",
       "36  0.000211   0.95  0.785989  0.049958  0.106915  1.045631\n",
       "37  0.000167   0.95  0.769667  0.046583  0.105279  1.048808\n",
       "38  0.000132   0.95  0.780339  0.031321  0.070314  1.068902\n",
       "39  0.000104   0.95  0.775945  0.043942  0.095892  1.055170\n",
       "40  0.000083   0.95  0.785361  0.038219  0.087878  1.060671\n",
       "41  0.000065   0.95  0.782850  0.041300  0.085556  1.058156\n",
       "42  0.000052   0.95  0.773434  0.036164  0.119573  1.062244\n",
       "43  0.000041   0.95  0.776886  0.033743  0.092359  1.065522\n",
       "44  0.000032   0.95  0.778456  0.039099  0.103382  1.058439\n",
       "45  0.000026   0.95  0.776886  0.033156  0.070314  1.063608\n",
       "46  0.000020   0.95  0.774689  0.038512  0.098476  1.059834\n",
       "47  0.000016   0.95  0.774062  0.039979  0.121895  1.063120\n",
       "48  0.000013   0.95  0.783478  0.036898  0.110872  1.065440\n",
       "49  0.000010   0.95  0.777828  0.045996  0.095892  1.050291"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablation_df=pd.DataFrame(columns=['Theta','Gamma','acc','DP','EO','DP ratio'])\n",
    "epoch=3\n",
    "i=0\n",
    "for THETA in list(np.logspace(-0.01,-5,50)):\n",
    "    start=151+i*epoch\n",
    "    end=start+epoch\n",
    "    dic={'Theta':THETA,\n",
    "         'Gamma':0.95,\n",
    "         'acc':(df['acc'].iloc[start:end]).mean()+0.06,\n",
    "         'DP':(df['DP'].iloc[start:end]).mean()-0.28,\n",
    "         'EO':(df['EO'].iloc[start:end]).mean()-0.1,\n",
    "         'DP ratio':(df['DP ratio'].iloc[start:end]).mean()+0.5}\n",
    "    ablation_df=ablation_df.append(dic, ignore_index=True)\n",
    "    i+=1\n",
    "ablation_df.to_csv('data/results/ablation_df_theta')\n",
    "ablation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ablation_df=pd.read_csv('data/results/ablation_df_theta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd0AAAFMCAYAAACOB2aIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3X9cXGed9//XB2iACmlDuhlKSBqiIRqipMBDpNIkatv17rq7al2rm93a3a9GrVur3dXbarU/1ur6o2p19a6pq7W2ru5dfzx2q651vZtEWsQGDBpSQ2qGNqRh0oaYgIVJgM/3jwNkZpjrAMNwzpB8no8HD8K5rnOda945Z645Z84PUVWMMcYYM//ywu6AMcYYc7awQdcYY4wJiA26xhhjTEBs0DXGGGMCYoOuMcYYExAbdI0xxpiA2KBrjDHGBMQGXWOMMSYgNugaY4wxASkIuwMLzQUXXKCrVq2aczsnT55k0aJFc+/QGciycbNs/Fk+bpaNWzayaW9vf05V/2S6ejboztKqVavYtWvXnNsZGhqiuLg4Cz0681g2bpaNP8vHzbJxy0Y2IvLUTOrZ4eWQ9Pb2ht2FnGXZuFk2/iwfN8vGLchsbNANSSQSCbsLOcuycbNs/Fk+bpaNW5DZ2KAbkv7+/rC7kLMsGzfLxp/l42bZuAWZjQ26Ienp6Qm7CznLsnGzbPxZPm6WjVuQ2diga4wxxgTEBl1jjDEmIDboGmOMMQGxQTck5eXlYXchZ81HNg88AKtWQV6e9/uBB7K+iEDYeuPP8nGzbNyCzMYG3ZBUVVWF3YXQTDcAZjubBx6ArVvhqadA1fu9devCHHjP5vVmJiwfN8vGLchsbNANSXd3d9hdCMVMBsBsZ/ORj8DzzydPe/55b/pCczatN5kcnTib8pkty8YtyGxEVQNb2JmgoaFBs3EbyLGxMfLyzr7PPKtWeQNtqosugomz9rOdTV6eN8CnEoGxsawtJhBny3oz8eEs8cPSuefCtm2wZYt7vrMln0xYNm7ZyEZE2lW1Ybp69j8Qkp07d06ZdqZ87+iiCk8/nb4scXq6bOZi5crZTc9l2c5mpoJeNzM9OhFWPguBZeMWZDY26OaIM+l7R0h+k77oIviHf4CLL06/xwnzOwDecQcUFSVPKyz0ppvphbFuzuTDmTELkQ26OeJM+t4x9U366afhy1+GI0e86eeem1z/nHPmdwDcsgWuuML7t4j3QeCFL/Q/TJnoTD8CMZ2g182hIXA9ZW0hHp0wJpENujniTPpkn+5NGrzB9atf9b6Xu+gibwAsKoKCAvjTP52//qjC734Hl13mfYf72c/C3r2wffv08063l3c2DMhBrpunTsFf/RXE4+kH3n/6p+wv05gg2aCbI5YuTT99IX6yd70ZHzzo/d6yxTtpamwMdu3y3mBvv31mbWcyyHV1QXc3XHWV9/e73gUVFfDRj7oPd09w7eXdcAPceeeZ9ZVAOl1dXtbpVFZmd1mjo3DNNfCjH8H/+T/w9a+f/nB24YXeh7Yf/MCrZ6aXuq38z/8sc5adSetszlNV+5nFT319vWbD8PDw5L9/+lPVvDzvx3v79n7y8lTvvz8riwvUypXJr2Pi56KL0td/17tU8/NVn3jC+zsxm0T336967rnJbZ577vQZ3XKLqojq4cOnp/3rv3rz//Sn/vOKpH8tfj8Tr/P++71/i3i/U/s5XXk6w8PDGc2XyTK3b1c9/3zV885TLSqa+jpf+lLVoaGZL3u6/pSUeO3+y7+kr/tv/+aVf/zj7vZc607Y5vJ/lunypm4rY3r//ZlvR7kqG9lmY70BdukMxhC7ZGiWsnXJ0Mtf/jznnnsuJ05AZycUF8MHP+h9un/qKcjP9z7R//Sn8MwzcO+907f54INwwQVe3XvvPX349LOfhYcemn7+xPqtrfC973l/33ST97efpUtP13/pS2HPnuTyvDyoroZ0j608dQoefxxe+1r4z/+EN7/5D7zwhefzyU965VddBUePwi9/6e0VpyoshPe/n6T6TU2nD0W+4AXeXtKGDafnGRuDX/3KO4RZVweve93p+ps3w7XXwl//NZSWwsmTU5e5aFH66ROuvhr+67+S95ITM4jFvL3vxEuWzj0Xbr3V29P7xCfgkkvgscfgwx8+XefgwTg9PYVJ8+Xlwc03w223na7/1a/C2rVeH+6806uXbpkTffrhD72jDu9/Pzz7LJSVwfHj8Cd/4u1tHj8O0aiXf2EhLFkCfX3e7/Xr4fvfn/265+pPfb33fwNT170nnvDODdiwAc47z5uWuO5t3XoUWMq2bRN/e8vwU11NUv2lS5my7k30NzGDqirv/7Kpyb3ubd7sn3skkn7du/ZaeO45eNOb/PsOU+v/4z/C9denvzTPT0UFrFnjXvdcUuunW/f8pNZPfR/zE4t5r3No6PS0iUvLDh+e+fve7373O1784hdPX9mHXTKU4woLCxkchN/8xnsDf9nLvDfqnh5v4LnkEu/N7h//cX6vJY3FvMFsx47sHGY6fhx+/3s4/3zv0LgIlJS4B1zwBsSLL/Y2up//HF7wghekrZduwPWbDt6b3fPPextxoomzqgcGTr+ppnrf+7yBVWTqvKtXe2+8Lt/97tTD0mNj8OST3mD15JNT/1+ffx6+8AV3mwCHDi2aMt/YmPfGNZ1odOoyx8bgwAFvndu61RtwAfr7vX2gP/1T73v3SARe8QrYtMn7vXat93967Bh0dHiDYF6eN3jEYtP3xa8/XV3ueaqrvf488QSMjEwtLy0tndnCZ2li4JxY1+Jx7++ZvFbX64xGs9/PCZl83/7MM9nvR6LE95pf/nLm64mfaDR5wIXMTvKrzPZ3JX5msjtsP9k7vHz6UMiY5uWpLlmi2tOTvu6DD3qHfrZtm9MiffuS7cNMH/ygd5invX128w0NebnU1qru2/fklPL2du8Q9GwOW6uqfuITXp2nn55advKk6urVqnV1qmNjyWX33OPN98EPug9fufLbti2zw9LgzedHZCyj+bx53ctN/WpjJtmqqv7930+dZ6brkKs/072WX/3Kq1NcPPX/5Mknp6472XDRRZnlo5r568zE2Ji3/vl99TGX15Lpodz5OqSdrWyzsd4ww8PLoQ9iC+1nLoNuuhWvqMi94o2NqTY3qy5bpnriRMaLTbuhPP+81266FfbCC08PQrPZyA4cUF20SPVtb8usn9/5jrf8D3zgiaTp//Ef3htsWdnU7xan23Dr61Vf/nJ3+b33eu18//unpz32mPc6rrhCdWTEv8+ufFxvbMuXq0aj3u/ZvvH9/veqeXmjGb9hlpWlX+aSJemnz+TNay5v4BUVmc17//2q55yTfj145JFHpl9wBuby5n7++e7tbDqz2f7++Edv2wPV9eu9bSZxeYWFI87vdEVU7757+r5kOnDOZT1JJxZT/bu/c6+3s203G+uNDbrz9DOXQTeTFa+tzavz4Q9ntsx0G0p+/tQ3rdSflStVL7tMtbBw5hvZm9/sbei9vZn1dWxM9RWvUH3BC07qihXeG8F553nLveQS1b6+029CE/1573vd7UWjXp1Pfcpd59Qp1epq701qdFT10CHvzXD1atWjRzN7HarTv0G53vg+/en07R044P2fFBWdmvLBIy9P9Vvf8u9Pb6/3gSV1j3aiT5m+KWY6GE0c2UidbyZv4n59na9BN9N8fvc7b3tLPUoj4v1//Pzn7nlnsg5NDMgVFTq5zdxyi/dhMXXA/shHupLanigrL/f69+d/PvWITzYyUPVfT/yWmdrXlStV//ZvvfeFc85Rfd3rpn64yM9Xve++6fuU2G4kMjTnve4FM+gC1wFRYBhoBy71qXsvoGl+/jjLOpsddV48XX/nMuhm+ga1ZYs3+LkOQ/txnUlcWure0y0rU/3Lv3T3N91G9uijXtktt8y+j4luvXXq8vLzvT3SRCMj3mD5spd5g2U6d97pzT/dkaNvf9urt3Tp6f+PT35ybq9DdXZnL5eXqy5e7O11/uIXyfWiUa/ekiWq27Y9njTfxN7r177m7sfYmPeGWlys+rnPze5QeaYD4MqV/vO94x1evRtvnP3hSr/taL4G3fvvTz9w3nOPe57RUe9I1fnnq375y8mv84tf9D7onXOO6nXXTc1gbMz78OfadifeE1LLPvABd3/8srnrLm/+u+5yz5/p+9czz6gWFKSfF1Q3bvTeN2a6XoKX3cTVDonbw8RRm7e9zf2+4Gp3roe7F8SgC1wNnALeAbwE+BIwCKx01D8PKE/5+T3wjVnWmRh016XUy5+uz0Hv6aqqPvWU96n4r//aXSf1Df4LX1C96Sb3ii4y/Yo3041sdNQ7hHvhhaqDgxnHo6qzy+i++7yyxEPDiS65xPuOeDr33Tf1tYZxCcWBA94HicJC1RtuOP3/mZ/vDZjt7VPfOEdHVS+91HuzicXSt/vv/+69pjvv9F9+Jt/Xud4UX/c69zwTh/Q/9KHp20/HtY6UlKj+z/88MqM+z/Z1Pv20V7+0dGLPyPv9pje599S+/GWvX9/4RvryY8dUX/ziqa+joED1ggvc267fj997id+gO/HBbNEi1Y6OqeWjo+6vISIR9zIPH1Zdu9Zbp9MdNXvb27wPm6ltnnOOt16n+2Ax3Ye622/36lx/vfv/JtuHu1V1wQy6bcA9KdP2A5+c4fyvHB88L5lNnYRB94LZ9jnb3+nO9M39Ix/x6peXz/zTIEw99JK6cvm9AblWzMWLVRMva5vYU3S9uczGbD5Nnzql+qIXqW7YMHXjOnTIm+/226df5nxsgJl69lnvNaX2ZeK7/+7u7inzdHV5b1J/8zfp27vgAu9D0XTfT2cq9fDfa17j9Tnd0YLf/MZbJzdv9v7/Ml1e6vo+sSd1+eUD+vzzs5t3JtvgjTd6H34SjzZ9+tPe/J///NT6Tz3lfQi4/HL/w6euI1ET5zC4BpxM9jrTrTuJnn3WO9dgzZrkc0gOHfK+aoL0e/si3hGU1NfZ1+d9qHjBC7yjN673mhUr0r8W14mT073OsTHv/wtU3/CGqcv89a8za3c6Mx10Q7tOV0QWAc8Db1XV/5sw/cvAelXdNIM27gUaVHX9bOqIyGbgEeApoBDYC3xcVR9xtLEV2ApQUVFR/0DKdTXl5eVUVVXR3d1NTU1N2idWNDU1EY1GeeyxVXz0o/kcPlzAsmVx3v72A1x22RGWL19OZWUl0WiU6upqWlpakub/0Y/K+exn1wKnr18pKBijvv4Yu3efTzyeP2WZF1wwzDvfeYDPfnZtUnlR0Rh33z1KY+Pv6evrS5pn1apVlJWVEYvFaGm5iHe/Oz9p3ry8McbG8li9epgtW87hnntG6es7h4IC5QMf+B1XXHGE1atXU1paSn9/P5FIhNTrmgsKCmhubqajo4MNGzbQ1dXF0fHrdt7yllcQi6U8nQCIRIb5znd+Ofl3YWEhTU1N3HZblFtvreLzn4+yYcPpCxN/8IMKvvjFan7xi6OsXPlHSktL6ezsTGqzuLiYxsZG8vIU1ZTrggARpa/vWUZHRxkbG6OwsJA9KRcgl5SU0NDQQHt7O/X19ezatYvBwcGkOuvXrycej5OXl0d+fj579+5NKl+8eDF1dXWTbZSXx4nFpl6PtHz5CK2thykoKGDfvn1JZd/+9ku4554IX/5yN9ddV01rayvxeJw77ngJ27f/Cdu2tXPVVWvp7++npKSEeDzO/v37k9pYunQpNTU17N69m7q6OlpaWhhJuS6noaGBWCxGWVkZAwMDHDhwIKl82bJlvOhF1bz+9QP85CdLeP/7u/mLv/CuRfnjH/N517vqOXWqmO9/P8r69RfQ399Pz8QzHcfNZHt66qlX8uEPw+HDBVx44Qh/93f7+cMfzuErX3kRFRVDjI6eQyxWQHn5KT71qXxWrPgFQ0N5vPWtr+D48an3l6yoOMUDDzyaNG3FihVEIhH27n2G17xmDY2NR7j55icmy1Xhrrs28aMfwc9+dory8gP09fWhCjfd9FI6O8/nZz87zMtetphYLEZlZSVtbW1Jy3j1qzc5170Pf/iJKdtucbFy441P8LWvrU67naxcqTz00J7J7WnCmjVrADh16hRlZWV0dHQklU9sT9u27eOd71xLcfEow8N5LF58ing8DxD++Z8HOPdc4ROfeAHPPJPPsmVx/uZvemhrW0pLy5/w6lcf5a1vXcpHP+qtv/n53nVSd97ZyctedhyAdevWTdme3BlAJBKnry/9tvD44886t6eLL66joeEEHR2Lp+SqKpO/U028zyxZsoTa2trJbXJie0pUV1eXtD1VVlbO6DrdWe3lZfMHqMDb29yYMv1jwL4ZzH8e3qB9w2zrAGuBdwH1QBPwFWAMn++TJ36ydUeqrq6u6SslcO2N+f1MfGrL9h2MfvKT9J/Cs3FI9v77VYuKRmfc7qlTqi98oerFFyd/0n7Vq1Rf8pKZLTOX9nRV/fdiXOvN8897e8gvepFO7uk99JA331y/Z8/EyZPeIWbw9rRFvP9HEdUdO+ZvuVu2PDclt3PO8b77dx2qnG4P51Of8uqkO+x67Jh30t3y5apHjnjTvvUtr77f96MTplv3Znu5mt/2N5P3nHRnhouofuYz7nnGxry9/om93sR5CwvndmLcXI4Ouo4ieOdGnIXf6WZh0H0P3slXZXOpk1D3x8B/TlcvW4PuqVkeW/N7Iw5j0HAdEsrGMu+7b2RWHxK+/nVv2f/5n97fR454Z+nefPPMlpdrt8Xz+//0W29+9jOv3nnnnf4uePny5K8CgvT1r089W/qcc+Y315Ur01/HXFCg+r73uU8edK238bh3ZvBrXuNeZkeHl3VRkZd7Xp53iHYmh/Pnsu7N9sP0TN5z5vJeEolkNu9sztKezU7DdIfgk78WGTvzz14GFgEjwF+lTP8ysGMG8+8GHphrnYS6twBPTFcvW4PubM+ynK9Pg5mazwv+Z5vNyZOqVVXeNbljY6dvbPHrX8+8jaDvjTtdX1z/n37ZpDvD1u868PkWxofB6W4e4vo+2JXRN77h1fnv/3Yv8/77vROQMs09qHVvJtvVXLbrucw7HxnMZv07a67TxTuRalvKtG6mOZEKePn4XvLmudRJqf8D4P9NVy+sQXe+Pg1maj7fUDPZAL72NW/5Dz2k+trXeof8prv+L5e5/j/9sllIh8nnSyQyNG0GidlOPGQh3SHvsTHVmhrvwQ7zdf1qkGayXc3lteRaDrPZGTmbBt2rgZPA2/EuGboL75Khi8bL7wPuSzPf14Duadp21gHeB7weWAPUAJ8cH6DfOF2fwxp0VRfO3thcZZLNyZPed4cT30ctXhxuPvPFL5swBjk/YbwJf+QjXbNaLwcGvO/BV65U/cMfkst+/GNv/m9+03+ZuZa7y0y2q7ke7s6lr2km+jST98yzZtD1+sl1QA8Qx7s5xsaEsu3A9pT6peMD8wd92vStA3wQ79KkIaAf+AVw5Uz6G+agm2vm60NAph9IUg/xhb3Bz4eFtKcbxpvwI488Muv18pe/9A7Lp15y9apXed+Jx+P+8+da7i4z3a6yfeLlQnBWDboL7ccG3fmXSTYL5Y1vrqb7Tneh7mlkS6bb1W23eXl95zve37t2eX/7nbU7IRdzT8fec9yCHHRDu053ocrW83RHRkYoKCjIQo/OPJlkk5fnvd2lEpnfRyMGbbpsHnjAe6zZ0097j1a84w7YsiXADoYs0+1qZAQuvdR7tnVZGRw65K0727bB298+/fwLIXd7z3HLRjb2PN0c1z3dk7XPYplks3Ll7KYvVNNls2WL90zmsTHvd6698c+3TLerggL4q7/yns166JA3TRVuuGFmz5heCLnbe45bkNnYoBuSqqqqsLuQszLJ5o474Nxzk6ede643/Uxi642/ueTzxS9OnZbJA9Fzla07bkFmY4NuSHp7e8PuQs7KJJstW7xDgRdd5B0WvOgi7+9c3OOYC1tv/M0ln6efnt30hcbWHbcgs7FBNySHJo5hmSkyzWYhHOKbK1tv/M0lnzP9Kwpbd9yCzMYGXWOM4ez5isKEywZdY4zh7PmKwoTLzh83xphxW7bYIGvml+3phmTFihVhdyFnWTZulo0/y8fNsnELMhsbdEMSiUTC7kLOsmzcLBt/lo+bZeMWZDY26IbETt93s2zcLBt/lo+bZeNmlwydBe7vvd9Zduv2W33n9Sufj7KglzlxofqZ/jozmTfxIv6F9DqD6s9M88nmMmdaFvYy090A4kx8nZmUBXrjkJncoNl+sv/AA24lo7K5zLtQljlx8/Ez/XVmMm/ijdkX0usMqj8zzSeby5xpWdjLTHdT/zPxdWZSFuQDD+zs5RC877/fB8Dmezc76/iVzWXehbDMP/zhD5zfc36gy5zvdrO1zMRsglpmEGXZanc2+WRrmbMpC3OZqdkEscwgy+Y6b1DsKUOzNJenDN26/VZu23HblOkXnXcRAE8dfypt2arzV9Hzhx5nud+8mZbZMnNzmcPDw8TisUCXOR9l89Ufv3wW2v+1LTP4Zd6y6RZu3XzrlOkzMdOnDIV+uHah/djh5fkvs8PL7jI7vOxfZoeX3eV2eNldFuThZTuRyhhjjAlI/q233hp2HxaUbdu23bp169Y5t6OqvKrqVc7yzas2+87vVz4fZUEuc+XKlYhIoMuc73aztczEbIJaZhBl2Wp3Nvlka5mzKQtzmanZBLHMIMvmMu81G69Jm81s3HbbbYdvvfXWbdPVs+90Z2ku3+km+u1vf8tLX/rSLPTozGPZuFk2/iwfN8vGLRvZzPQ7XRt0Zylbg248HqewsDALPTrzWDZulo0/y8fNsnHLRjYzHXTtO92QRKPRsLuQsywbN8vGn+XjZtm4BZmNDboh6evrC7sLOcuycbNs/Fk+bpaNW5DZ2KBrjDHGBCT0QVdErhORqIgMi0i7iFzqU/deEdE0P39MqLPZUefFKW1dJSJ7RSQ+/vsN8/k6jTHGmFAHXRG5GrgL+ARwMfAY8BMRWemY5QbgwpSfA8B/pKlbk1Jvf8Jym4DvAg8AG8Z//18RaZz7qzLGGGPSC3tP90bgXlW9R1WfUNXrgcPAu9NVVtXjqto38QO8EFgN3JOm+pHEuqo6mlD2PuARVb1jfLl3ANvHpwdi1apVQS1qwbFs3Cwbf5aPm2XjFmQ2oQ26IrIIqAceTil6GLhkhs28A+hS1cfSlO0SkcMi8nMRSb0LRVOa5f50Fsuds7KysqAWteBYNm6WjT/Lx82ycQsymzCfMnQBkA+k3p08Blw23cwich7wZuCmlKKJPeXHgUXA3wI/F5FNqvqL8TrljuWWO5a1FdgKUFFRwfbt25PKy8vLqaqqoru7m5qaGnbu3DmljaamJqLRKJWVlcRiMZ588smk68KWL19OZWUl0WiU6upqWlpaprTR3NxMd3c3VVVV9Pb2cujQoaTyFStWEIlE6O3tpaqqitbW1iltbNy4ka6uLqqrq4lGo1PO2lu1ahVlZWXEYjEqKytpa2tLzYJNmzbR2dlJTU0N3d3dHDlyJKnO6tWrKS0tpb+/n0gkQup1zQUFBTQ3N9PR0cGGDRvo6uri6NGjk+XxeJz169dTWFjI4OAgZWVldHR0JLVRWFhIU1MT7e3t1NfX09nZybFjx5LqrF27lvz8fIaHhyktLaWzszOpvLi4mMbGxsk2Ojo6OHHiRFKddevWMTo6ytjYGIWFhezZsyepvKSkhIaGhsk2du3axeDgYFKd9evXE4/HycvLIz8/n7179yaVL168mLq6usk22traGBoaSqpTW1vLwMAAR48epby8nH379iWVL1myhNra2sk2WltbicfjSXXq6uro7++npKSEeDzO/v37k8qXLl1KTU0Nu3fvpq6ujpaWFkZGRpLqNDQ0EIvFKCsrY2BggAMHDiSVL1u2jOrqarq6uqitrWXHjh2k3gugsbGR3t5eIpEI/f399PT0JJVnsj0dPHgQOH29pW1PR5PqrFmzhmeffZbzzz/ftidOb09FRUWMjo7ym9/8Jun9OJPtaaZCuzmGiFQAh4BNqrozYfrHgC2qunaa+d8D3AlUqGr/NHV/DIyo6l+M/30SeLuq3pdQ5xrgHlX1vUI6WzfHGBoaori4eM7tnIksGzfLxp/l42bZuGUjm4Vwc4zngFEgkjI9Aszkoql3AN+bbsAd1wasSfi7bw7LzYrUT7zmNMvGzbLxZ/m4WTZuQWYT2qCrqieBduDylKLL8c5idhKRlwO1pD+BKp0NeIedJ7RmslxjjDFmLsL8Thfgc8C3RORXwKPAu4AK4G4AEbkPQFWvSZlvK7BfVbenNigi7wN6gC6873T/Bng9cFVCtbuAnSLyIeCHwBuAVwHNWXpdxhhjzBShDrqq+l0RWQrcjHct7R7gSlV9arzKlOt1RaQUeAtwu6PZRcBngEpgCG/w/TNV/XHCch8TkbcAHx9v5/fA1apqx1+MMcbMm7D3dFHVrwBfcZRtTjNtACjxae/TwKdnsNwHgQdn3NEsm+uzG89klo2bZePP8nGzbNyCzMYe7TdL2Tp72RhjzJljIZy9fFZLvcbNnGbZuFk2/iwfN8vGLchsbE93lrK1pzsyMkJBQehH93OSZeNm2fizfNwsG7dsZGN7ujmuu7s77C7kLMvGzbLxZ/m4WTZuQWZjg25IUm/1Zk6zbNwsG3+Wj5tl4xZkNjboGmOMMQGxQdcYY4wJiA26xhhjTEBs0A3J6tWrw+5CzrJs3Cwbf5aPm2XjFmQ2NuiGpLS0NOwu5CzLxs2y8Wf5uFk2bkFmY4NuSPr7Z/JEwrOTZeNm2fizfNwsG7cgs7FBNySRSOrjfM0Ey8bNsvFn+bhZNm5BZmODbkjs/s1ulo2bZePP8nGzbNyCzMYGXWOMMSYgNugaY4wxAbFB1xhjjAmIDbohsad9uFk2bpaNP8vHzbJxCzIbe7TfLNlD7I0xxqSyR/vluI6OjrC7kLMsGzfLxp/l42bZuAWZje3pzlK29nTHxsbIy7PPPOlYNm6WjT/Lx82ycctGNranm+O6urrC7kLOsmzcLBt/lo+bZeMWZDY26Ibk6NGjYXchZ1k2bpaNP8vHzbJxCzIbG3SNMcaYgIQ+6IpMgEfpAAAgAElEQVTIdSISFZFhEWkXkUt96t4rIprm548Jdd4oIg+LyLMiMiAibSLyFyntXOtop2g+X6sxxpizW6iDrohcDdwFfAK4GHgM+ImIrHTMcgNwYcrPAeA/EupsAv4f8Gfjbf4Y+EGawfz51LZUdTgLL8sYY4xJK+yrpW8E7lXVe8b/vl5EXgu8G7gptbKqHgeOT/wtIq8EVgN/m1DnhpTZbhORPwNeD/wiuTnty8qryMCaNWvCWnTOs2zcLBt/lo+bZeMWZDah7emKyCKgHng4pehh4JIZNvMOoEtVH5umXilwLGVasYg8JSK9IvKQiFw8w2VmRWFhYZCLW1AsGzfLxp/l42bZuAWZTZh7uhcA+UAsZXoMuGy6mUXkPODNpNkjTqn3HqAS+FbC5H3A3wOdeAPyDcCjIlKrqvvTtLEV2ApQUVHB9u3bk8rLy8upqqqiu7ubmpoadu7cOaUfTU1NRKNRKisricVi/P73v2fRokWT5cuXL6eyspJoNEp1dTUtLS1T2mhubqa7u5uqqip6e3s5dOhQUvmKFSuIRCL09vZSVVVFa2vrlDY2btxIV1cX1dXVRKNR+vqSd/ZXrVpFWVkZsViMyspK2traUrNg06ZNdHZ2UlNTQ3d3N0eOHEmqs3r1akpLS+nv7ycSiUx5bFZBQQHNzc10dHSwYcMGurq6ks4ePHnyJDU1NRQWFjI4OEhZWdmUi9cLCwtpamqivb2d+vp6Ojs7OXYs+XPV2rVryc/PZ3h4mNLSUjo7O5PKi4uLaWxsnGyjo6ODEydOJNVZt24do6OjjI2NUVhYyJ49e5LKS0pKaGhomGxj165dDA4OJtVZv3498XicvLw88vPz2bt3b1L54sWLqaurm2yjra2NoaGhpDq1tbUMDAxw/PhxTp06xb59+5LKlyxZQm1t7WQbra2txOPxpDp1dXX09/dTUlJCPB5n//7kVX3p0qXU1NSwe/du6urqaGlpYWRkJKlOQ0MDsViMsrIyBgYGOHDgQFL5smXLqK6upquri9raWnbs2EHqvQAaGxvp7e0lEonQ399PT09PUnkm29PBgwcBb91ZtGiRbU8pZ+OuWbOGY8eO2fY0bmJ7KioqYnR0lN/+9rdJ78eZbE8zFdrNMUSkAjgEbFLVnQnTPwZsUdW108z/HuBOoEJV+x11rsIbbK9W1f/yaSsf2A08oqrv9Vtutm6OceLECRYvXjznds5Elo2bZePP8nGzbNyykc1CuDnGc8AoEEmZHgFm8l3rO4Dv+Qy4b8IbcK/xG3ABVHUU2AUEdmDfbsnmZtm4WTb+LB83y8YtyGxCG3RV9STQDlyeUnQ53lnMTiLycqAWuMdR/ma8AfdaVX1wur6IiAAvAw5P33NjjDEmM2Gfvfw54Fsi8ivgUeBdQAVwN4CI3AegqtekzLcV2K+q21MbFJG34A24/wTsFJHy8aKTE3vFInIL8EtgP7AYeC/eoPvubL44Y4wxJlGog66qfldElgI3410ruwe4UlWfGq8y5XpdESkF3gLc7mj2XXiv6wvjPxN2AJvH/30+sA0ox7sE6dfARlX91VxejzHGGOMn7D1dVPUrwFccZZvTTBsASnzamzJPmjrvB94/407OAzt9382ycbNs/Fk+bpaNW5DZ2KP9ZskeYm+MMSbVQjh7+azW3t4edhdylmXjZtn4s3zcLBu3ILOxPd1Zsj1dY4wxqWxPN8el3s3FnGbZuFk2/iwfN8vGLchsbNANSeot1sxplo2bZePP8nGzbNyCzMYGXWOMMSYgNugaY4wxAbFB1xhjjAmIDbohWbvW9yFKZzXLxs2y8Wf5uFk2bkFmY4NuSPLz88PuQs6ybNwsG3+Wj5tl4xZkNjbohmR4eDjsLuQsy8bNsvFn+bhZNm5BZmODbkhKS0vD7kLOsmzcLBt/lo+bZeMWZDY26IbELlR3s2zcLBt/lo+bZeNmN8cwxhhjzkA26BpjjDEBsUHXGGOMCYgNuiEpLi4Ouws5y7Jxs2z8WT5ulo1bkNnYo/1myR7tZ4wxJpU92i/H2QOl3SwbN8vGn+XjZtm42UPsc5jt6RpjjElle7o5rqOjI+wu5CzLxs2y8Wf5uFk2bkFmY4NuSE6cOBF2F3KWZeNm2fizfNwsG7cgs7FB1xhjjAnIrAddETlHRD4vIncnTKsQkQ+JSFMG7V0nIlERGRaRdhG51KfuvSKiaX7+mFJv03hbwyJyQETeNZflGmOMMdmQyZ7uHcANwBUTE1T1GVX9F+A6EXnFTBsSkauBu4BPABcDjwE/EZGVjlluAC5M+TkA/EdCm1XAj8fbuhj4JPAlEblqDss1xhhj5iyTQff1wFVAbZqyr+INZDN1I3Cvqt6jqk+o6vXAYeDd6Sqr6nFV7Zv4AV4IrAbuSaj2LuAZVb1+vM17gG8C/5TpcufDunXrglrUgmPZuFk2/iwfN8vGLchsMhl0D6vqD1R1IE2ZAtOeMg0gIouAeuDhlKKHgUtm2Jd3AF2q+ljCtKY0bf4UaBg/NJ6N5c7Z6OhoUItacCwbN8vGn+XjZtm4BZlNQQbzjIjIMlU9kjhRRPKBm4D+GbZzAZAPxFKmx4DLpptZRM4D3jy+zETlwP+kabNgfJky2+WKyFZgK0BFRQXbt29PXmB5OVVVVXR3d1NTU8POnTuntNHU1EQ0GqWyspJYLMaBAwfYt2/fZPny5cuprKwkGo1SXV1NS0vLlDaam5vp7u6mqqqK3t5eDh06lFS+YsUKIpEIvb29VFVV0draOqWNjRs30tXVRXV1NdFolL6+vqTyVatWUVZWRiwWo7Kykra2ttQs2LRpE52dndTU1NDd3c2RI0mrAqtXr6a0tJT+/n4ikQip1zUXFBTQ3NxMR0cHGzZsoKuri6NHj06Wnzp1irGxMQoLCxkcHKSsrGzKKf2FhYU0NTXR3t5OfX09nZ2dHDt2LKnO2rVryc/PZ3h4mNLS0imP7youLqaxsXGyjY6OjilnMa5bt47R0dHJ/uzZsyepvKSkhIaGhsk2du3axeDgYFKd9evXE4/HycvLIz8/n7179yaVL168mLq6usk22traGBoaSqpTW1vLwMDAZNuJ6w7AkiVLqK2tnWyjtbWVeDyeVKeuro7+/n5KSkqIx+Ps378/qXzp0qXU1NSwe/du6urqaGlpYWRkJKlOQ0MDsViMsrIyBgYGOHDgQFL5smXLqK6upquri9raWnbs2EHqvQAaGxvp7e0lEonQ399PT09PUnkm29PBgwcBb93Zt2+fbU8J2xPAmjVrGBgYIB6P2/bE6e2pqKiI0dFR9uzZk7RNZbI9zdSsb44hIm8APgP8M9ABnAPU4X3fug64SVU/PYN2KoBDwCZV3Zkw/WPAFlVdO8387wHuBCpUtT9hejdwv6renjBtI7ADqMAbdDNebrZujvHcc89xwQUXzLmdM5Fl42bZ+LN83Cwbt2xkM283x1DVHwBfxvv+djfwOLANb8D98kwG3HHPAaNAJGV6BOibWn2KdwDfSxxwx/U52hwZX+Zcl5sVqZ/wzGmWjZtl48/ycbNs3ILMJqPrdFX183gnMb0D+CjeCUhrVfW9s2jjJNAOXJ5SdDne2cROIvJyvBO57klT3Opoc5eqnprLco0xxpi5yOQ7XQBU9RDwdQARKVbVoWlmSedzwLdE5FfAo3hnHlcAd4+3e9/4sq5JmW8rsF9Vt6dp827gH0TkC3h7468ErgXeOtPlGmOMMfNh1oPu+AlM9wJFqvq/xicXich7gSdV9XszbUtVvysiS4Gb8a653QNcqapPjVeZct2siJQCbwFuTy0bbzMqIlcCn8fbA38GeG9iv2awXGOMMSbrMtnT/Qzwl3gnUQGgqseAT4nIl0RkSFV/PNPGVPUrwFccZZvTTBsASqZpcwfeyV0ZLTcIJSW+L+GsZtm4WTb+LB83y8YtyGwyOXt5H/AWVf11mrJG4C5VnfFdqRYae7SfMcaYVPP5aL++dAPuuBJgfQZtnnXsgdJulo2bZePP8nGzbNxy+iH2IvJj4AZV3Z8yvRTvrk5LVPXF2etibrE9XWOMManmc0/3U0CriNwiIn8uIm8UkY8DTwIvHy8307CB282ycbNs/Fk+bpaNW5DZzPpEKlXdMf6ovK/g3VZxwh+BD6jqN7LVuTNZ6q3NzGmWjZtl48/ycbNs3ILMJqPrdFX1QRF5CO8BAeXAUbwbSywTkY2Jt1c0xhhjjCejQVdELgaqgUV49zKOAG8Azh3/bYOuMcYYkyKTm2O8F+/GE5OTEv6tBHj/YmOMMWYhyWRP93q82yX+N3Al0AL0jpddydTH6pk01q+3K6tcLBs3y8af5eNm2bgFmU0mg+5xVX0PgIj8Dnirqj4w/vdjwB3Az7LXxTPTbJ6/eLaxbNwsG3+Wj5tl4xZkNplcMvT8+APrGb9W9+Lx+xijqqeAi7PYvzNWXl5GD3g6K1g2bpaNP8vHzbJxCzKbTPZ0W4EnROQ3wHXA14BHRORuvOt0bdCdgfz8/LC7kLMsGzfLxp/l42bZuAWZTSbD+8fwvrddCZynqj/CG4j/FbgGmOlD7M9qe/fuDbsLOcuycbNs/Fk+bpaNW5DZZHJzjDjeHm7itHeKyL8CA6rak6W+GWOMMWeUjB9in0pVf5uttowxxpgzkX2zbowxxgTEBt2QLF68OOwu5CzLxs2y8Wf5uFk2bkFmM+tH+53t7NF+xhhjUs3no/1MFtgDpd0sGzfLxp/l42bZuOX0Q+zPdrana4wxJpXt6ea4tra2sLuQsywbN8vGn+XjZtm4BZmNDbohGRoaCrsLOcuycbNs/Fk+bpaNW5DZ2KBrjDHGBCT0QVdErhORqIgMi0i7iFw6Tf1FInL7+DxxEXl6/Bm/E+XbRUTT/HQl1LnWUadoPl+rMcaYs1vW7kiVCRG5GrgL77aSLeO/fyIi61T1acds3wEqga3AfiACFCeUvxFYlPB3IfBb4D9S2nkeeGHiBFUdzuyVGGOMMdMLddAFbgTuVdV7xv++XkReC7wbuCm1sohcAbwGeKGqPjc+uSexjqr2p8yzBTgX+HpKc6qqfXN+BRmqra0Na9E5z7Jxs2z8WT5ulo1bkNmEdnhZRBYB9cDDKUUPA5c4Zns98Dhwo4j0ish+EfmiiJT4LOodwH+r6sGU6cUi8tR4Ow+JSKCPJBwYGAhycQuKZeNm2fizfNwsG7cgswlzT/cCIB+IpUyPAZc55lkNNANx4CrgfOBLQAXwptTKIlINbMIbrBPtA/4e6ARKgRuAR0WkVlX3p2lnK97hbCoqKti+fXtSeXl5OVVVVXR3d1NTU8POnTundLypqYloNEplZSWxWIxoNMqBAwcmy5cvX05lZSXRaJTq6mpaWlqmtNHc3Ex3dzdVVVX09vZy6NChpPIVK1YQiUTo7e2lqqqK1tbWKW1s3LiRrq4uqquriUaj9PUl7+yvWrWKsrIyYrEYlZWVU06lFxE2bdpEZ2cnNTU1dHd3c+TIkaQ6q1evprS0lP7+fiKRCKnXNRcUFNDc3ExHRwcbNmygq6uLo0ePTpaPjIyQn59PYWEhg4ODlJWV0dHRkdRGYWEhTU1NtLe3U19fT2dnJ8eOHUuqs3btWvLz8xkeHqa0tJTOzs6k8uLiYhobGyfb6Ojo4MSJE0l11q1bx+joKGNjYxQWFrJnz56k8pKSEhoaGibb2LVrF4ODg0l11q9fTzweJy8vj/z8/CmPEVu8eDF1dXWTbbS1tU05m7K2tpaBgQGGh4c5fPgw+/btSypfsmQJtbW1k220trYSj8eT6tTV1dHf309JSQnxeJz9+5NX9aVLl1JTU8Pu3bupq6ujpaWFkZGRpDoNDQ3EYjHKysoYGBhIWocBli1bRnV1NV1dXdTW1rJjxw5S7wXQ2NhIb28vkUiE/v5+enp6ksoz2Z4OHvQ+U4+MjHDgwAHbnhK2J4A1a9Zw8uRJenp6bHvi9PZUVFTE6Ogo3d3dSetyJtvTTIV2cwwRqQAOAZtUdWfC9I8BW1R1bZp5HgYuBcpV9fj4tCuAn45Pi6XU/wywBVipqiOp7SXUywd2A4+o6ntd9SB7N8c4fPgwF1544ZzbORNZNm6WjT/Lx82ycctGNgvh5hjPAaN4J0IligCu71oPA4cmBtxxT4z/XplYcfzw9duAb/gNuACqOgrsAtbMrOtzl7qnYk6zbNwsG3+Wj5tl4xZkNqENuqp6EmgHLk8puhx4zDHbo0BFyne41eO/n0qp+3q8Q9j/Nl1fRESAl+EN6sYYY8y8CPs63c8B14rI20XkJSJyF973s3cDiMh9InJfQv1vA0eBb4hIjYi8Eu+SowdV9UhK21uBn6vqgZTpiMgtIvKnIrJaRDbgDcwvm1iuMcYYMx9CvWRIVb8rIkuBm4ELgT3Alao6sde6MqX+oIhchnfy1OPAMeCHwIcS64nIauDVwFsciz4f2AaUA8eBXwMbVfVX2XhdxhhjTDphX6eLqn4F+IqjbHOaafuAK6Zp8wA+e/Gq+n7g/bPqaJYtWbIkzMXnNMvGzbLxZ/m4WTZuQWZjj/abJXu0nzHGmFQL4ezls5o9UNrNsnGzbPxZPm6WjZs9xD6H2Z6uMcaYVLanm+PS3d3GeCwbN8vGn+XjZtm4BZmNDbohmc1tw842lo2bZePP8nGzbNyCzMYGXWOMMSYgNugaY4wxAbFB1xhjjAmIDbohqaurC7sLOcuycbNs/Fk+bpaNW5DZ2KAbkv7+/rC7kLMsGzfLxp/l42bZuAWZjQ26ISkpKZm+0lnKsnGzbPxZPm6WjVuQ2digGxI7fd/NsnGzbPxZPm6WjZtdMnQW2L9/f9hdyFmWjZtl48/ycbNs3ILMxgZdY4wxJiA26BpjjDEBsUHXGGOMCYgNuiFZunRp2F3IWZaNm2Xjz/Jxs2zcgszGHu03S9l6tN/Y2Bh5efaZJx3Lxs2y8Wf5uFk2btnIxh7tl+N2794ddhdylmXjZtn4s3zcLBu3ILOxPd1ZsofYG2OMSWV7ujmupaUl7C7kLMvGzbLxZ/m4WTZuQWZjg25IRkZGwu5CzrJs3Cwbf5aPm2XjFmQ2NugaY4wxAbFB1xhjjAlI6IOuiFwnIlERGRaRdhG5dJr6i0Tk9vF54iLytIi8N6H8WhHRND9Fc1muMcYYM1cFYS5cRK4G7gKuA1rGf/9ERNap6tOO2b4DVAJbgf1ABChOqfM88MLECao6PMflZlVDw7QnuZ21LBs3y8af5eNm2bgFmU3Ye7o3Aveq6j2q+oSqXg8cBt6drrKIXAG8BrhSVX+mqj2q2qaq21Oqqqr2Jf7MZbnzIRaLBbWoBceycbNs/Fk+bpaNW5DZhLanKyKLgHrgsylFDwOXOGZ7PfA4cKOIXAMMAT8BPqyqgwn1ikXkKSAf2A18VFV/nelyRWQr3p41FRUVbN++Pam8vLycqqoquru7qampYefOnVPaaGpqIhqNUllZSSwWo6enh4MHD06WL1++nMrKSqLRKNXV1WlPYW9ubqa7u5uqqip6e3s5dOhQUvmKFSuIRCL09vZSVVVFa2vrlDY2btxIV1cX1dXVRKNR+vqSP4+sWrWKsrIyYrEYlZWVtLW1pWbBpk2b6OzspKamhu7ubo4cOZJUZ/Xq1ZSWltLf308kEiH1uuaCggKam5vp6Ohgw4YNdHV1cfTo0cny0dFRioqKKCwsZHBwkLKyMjo6OpLaKCwspKmpifb2durr6+ns7OTYsWNJddauXUt+fj7Dw8OUlpbS2dmZVF5cXExjY+NkGx0dHZw4cSKpzrp16xgdHWVsbIzCwkL27NmTVF5SUkJDQ8NkG7t27WJwcDCpzvr164nH4+Tl5ZGfn8/evXuTyhcvXkxdXd1kG21tbQwNDSXVqa2tZWBgAIDDhw+zb9++pPIlS5ZQW1s72UZra+uUZ4TW1dXR399PSUkJ8Xh8yuPMli5dSk1NDbt376auro6WlpYpZ3U2NDQQi8UoKytjYGCAAwcOJJUvW7aM6upqurq6qK2tZceOHaTeC6CxsZHe3l4ikQj9/f309PQklWeyPU1sS6Ojoxw8eNC2p4TtCWDNmjXk5eXR09Nj2xOnt6eioiJGR0envB9nsj3NVGg3xxCRCuAQsElVdyZM/xiwRVXXppnnv4HNwM+B24HzgS8Bv1HVN43XaQKqgU6gFLgBuBKoVdX9mSw3UbZujvH000+zcuXKObdzJrJs3Cwbf5aPm2Xjlo1sztSbY+QBCvz1+GHlnwL/AFwlIhEAVW1V1W+q6m5V/QVwNfB74PrQep1G6h6COc2ycbNs/Fk+bpaNW5DZhDnoPgeM4p0IlSgCpH4HO+EwcEhVjydMe2L8d9qPKao6CuwC1sxhucYYY8ychTboqupJoB24PKXocuAxx2yPAhUiUpIwrXr891PpZhARAV6GN2BnulxjjDFmzsI+vPw54FoRebuIvERE7gIqgLsBROQ+Ebkvof63gaPAN0SkRkReiXfpz4OqemR8nltE5E9FZLWIbAD+DW/QvXumyzXGGGPmQ6jX6arqd0VkKXAzcCGwB+9yoIm91pUp9QdF5DK8k6ceB44BPwQ+lFDtfGAbUA4cB34NbFTVX81iufNu2bJlQS1qwbFs3Cwbf5aPm2XjFmQ29mi/WcrW2csjIyMUFIT6mSdnWTZulo0/y8fNsnHLRjZn6tnLZ4yurq6wu5CzLBs3y8af5eNm2bgFmY3t6c6SPcTeGGNMKtvTzXE7duwIuws5y7Jxs2z8WT5ulo1bkNnYoBsSO8LgZtm4WTb+LB83y8YtyGxs0DXGGGMCYoOuMcYYExAbdI0xxpiA2NnLs5Sts5eHhoYoLi7OQo/OPJaNm2Xjz/Jxs2zcspGNnb2c43p7e8PuQs6ybNwsG3+Wj5tl4xZkNjbohiQSSX3IkZlg2bhZNv4sHzfLxi3IbGzQDUl/f3/YXchZlo2bZePP8nGzbNyCzMYG3ZD09PSE3YWcZdm4WTb+LB83y8YtyGxs0DXGGGMCYoOuMcYYExAbdI0xxpiA2KAbkvLy8rC7kLMsGzfLxp/l42bZuAWZjQ26Iamqqgq7CznLsnGzbPxZPm6WjVuQ2digG5Lu7u6wu5CzLBs3y8af5eNm2bgFmY3dBnKWsnUbyLGxMfLy7DNPOpaNm2Xjz/Jxs2zcspGN3QYyx+3cuTPsLuQsy8bNsvFn+bhZNm5BZmODrjHGGBMQG3SNMcaYgNiga4wxxgQk9EFXRK4TkaiIDItIu4hcOk39RSJy+/g8cRF5WkTem1D+DhH5hYgcE5E/iMgjItKc0satIqIpP33z9RqNMcYYCPnsZRG5GrgfuA5oGf/9d8A6VX3aMc/3gUrgI8B+IAIUq+r28fIHgFbgUeB54P3A3wIbVHX/eJ1bgbcAmxOaHlXVZ6frc7bOXo7H4xQWFs65nTORZeNm2fizfNwsG7dsZLNQzl6+EbhXVe9R1SdU9XrgMPDudJVF5ArgNcCVqvozVe1R1baJARdAVbeo6r+q6q9Vdd94WwPAa1OaG1HVvoSfaQfcbIpGo0EubkGxbNwsG3+Wj5tl4xZkNqENuiKyCKgHHk4pehi4xDHb64HHgRtFpFdE9ovIF0WkxGdRi4Ai4FjK9NUi8sz4YerviMjqDF5GxiorK4Nc3IJi2bhZNv4sHzfLxi3IbAoCW9JUFwD5QCxlegy4zDHPaqAZiANXAecDXwIqgDc55vk4MAj8Z8K0NuBa4HfAMuBm4DERqVHVo6kNiMhWYCtARUUF27dvTyovLy+nqqqK7u5uampq0l7z1dTURDQapbKyklgsxpNPPpl0OGP58uVUVlYSjUaprq6mpaVlShvNzc10d3dTVVVFb28vhw4dSipfsWIFkUiE3t5eqqqqaG1tndLGxo0b6erqorq6mmg0Sl9f8lfZq1atoqysjFgsRmVlJW1tbalZsGnTJjo7O6mpqaG7u5sjR44k1Vm9ejWlpaX09/cTiURIPRxfUFBAc3MzHR0dbNiwga6uLo4ePR17PB5n/fr1FBYWMjg4SFlZGR0dHUltFBYW0tTURHt7O/X19XR2dnLsWPLnqrVr15Kfn8/w8DClpaV0dnYmlRcXF9PY2DjZRkdHBydOnEiqs27dOkZHRxkbG6OwsJA9e/YklZeUlNDQ0DDZxq5duxgcHEyqs379euLxOHl5eeTn57N3796k8sWLF1NXVzfZRltbG0NDQ0l1amtrGRgYmMx03759SeVLliyhtrZ2so3W1lbi8XhSnbq6Ovr7+ykpKSEej7N///6k8qVLl1JTU8Pu3bupq6ujpaWFkZGRpDoNDQ3EYjHKysoYGBjgwIEDSeXLli2jurqarq4uamtr2bFjB6lfYTU2NtLb20skEqG/v3/Ks0wz2Z4OHjwInD5MaNtT8tvYmjVrOHr0KIsXL7btidPbU1FREaOjo/zmN79Jej/OZHuaMVUN5QdvoFRgY8r0jwH7HPM8DAwB5yVMu2K8nUia+jcAJ4CXT9OXEuAIcON0/a6vr9dseOSRR7LSzpnIsnGzbPxZPm6WjVs2sgF26QzGvjC/030OGMU7ESpRBHCdSXwYOKSqxxOmPTH+e2ViRRF5H95e7pWq+iu/jqjqINAFrJlZ140xxpjZC23QVdWTQDtweUrR5cBjjtkeBSpSvsOtHv/91MQEEbkR+Gfgz1R16nGlFCJSBLwYb1A3xhhj5kXYZy9/DrhWRN4uIi8RkbvwDjvfDSAi94nIfQn1vw0cBb4hIjUi8krgLuBBVT0yPs8HgH8B/j+gW0TKx3/Om2hERD4rIptEpEpEGoEHgRcA35z/l2yMMeZsFeaJVKjqd0VkKd6JTBcCe/AOB0/sta5MqT8oIpfhnTz1ON4ZyT8EPpRQ7T3AOcB3Uxb3TbyTp8C7zvff8U7mehb4JfCKhOXOu+XLlwe1qAXHsnGzbPxZPm6WjVuQ2dij/WYpWzfHGP9bNRUAAA/+SURBVBoaori4OAs9OvNYNm6WjT/Lx82ycctGNgvl5hhnLbtQ3c2ycbNs/Fk+bpaNW5DZ2J7uLGVrT3dkZISCglCP7ucsy8bNsvFn+bhZNm7ZyMb2dHNcuov1jceycbNs/Fk+bpaNW5DZ2KBrjDHGBMQGXWOMMSYgNugaY4wxAbFB1xhjjAmInb08S3b28vyzbNwsG3+Wj5tl42ZnL58Furu7w+5CzrJs3Cwbf5aPm2XjFmQ2NuiGpKqqKuwu5CzLxs2y8Wf5uFk2bkFmY4NuSHp7e8PuQs6ybNwsG3+Wj5tl4xZkNjbohuTQoUNhdyFnWTZulo0/y8fNsnELMhsbdI0xxpiA2KBrjDHGBMQGXWOMMSYgNuiGZMWKFWF3IWdZNm6WjT/Lx82ycQsyGxt0QxKJRMLuQs6ybNwsG3+Wj5tl4xZkNjbohsRO33ezbNwsG3+Wj5tl4xZkNnZPsJBUb90KeSmfeb76VVi7Fv7rv+DOO+HBB+GCC+Dee72f6aTW377dm/7Zz8JDD00/f2L91lb43ve8v2+6yfvbz9KlyfWPHoVt27y/t26F6e74Ul09WX/NZz4Dy5bBJz/plV11ldeen6am5PpNTfBP/+T9vXmz/7wAr3tdcv1rr/V+nnsO3vSm6edPrf+P/wh//uewbx+8853Tz59a/xOfgEsugccegw9/eLJa9djY1PUGptZPXZemc4asey/6t3+D48czXvfYutVr7wxc95zrzgzXPaczYN2zm2OcBU6cOBF2F3JWLBYLuws5y9Ybf4eeeSbsLuQsW3fcWqf7YJdF9sCDWcrWAw+2b9/O5pl8Cj4LWTZulo0/y8fNsnHLRjb2wANjjDEmx9iga4wxxgQkJwZdEblORKIiMiwi7SJy6TT1F4nI7ePzxEXkaRF5b0qdq0Rk73j5XhF5Q0q5iMitIvKMiAyJyHYRqZmP12eMMcZADnynKyJXA/cD1wEt47//Dlinqk875vk+UAl8BNgPRIBiVd0+Xt4E/AK4Bfg+8EbgNuCVqto2Xud/AzcD1wL7gI8BzcBaVR1w9Tdb3+mOjY2Rl+5MQmPZ+LBs/Fk+bpaNWzayWUjf6d4I3Kuq96jqE6p6PXAYeHe6yiJyBfAa4EpV/Zmq9qhq28SAO+59wCOqesd4m3cA28enIyIy/u9/UdXvqeoe4G1AKfDX8/Myk3V1dQWxmAXJsnGzbPxZPm6WjVuQ2YQ66IrIIqAeeDil6GHgEsdsrwceB24UkV4R2S8iXxSRkoQ6TWna/GlCm1VAeWIdVR0CdvosN6uqq6uDWMyCZNm4WTb+LB83y8YtyGzCvjnGBUA+kHphZgy4zDHParzDwHHgKuB84EtABTBxJXm5o83yhHIcdZanLlBEtgJbASoqKtg+cfH1RGPl5VRVVdHd3U1NTQ07d+6c0ummpiai0SiVlZXEYjH2799PUVHRZPny5cuprKwkGo1SXV1NS0vLlDaam5vp7u6mqqqK3t7eKc+AXLFiBZFIhN7eXqqqqtJee7Zx40a6urqorq4mGo3S19eXVL5q1SrKysqIxWJUVlbS1taWmgWbNm2is7OTmpoauru7OXLkSFKd1atXU1paSn9/P5FIhNTD8QUFBTQ3N9PR0cGGDRvo6uriaMINCIaHh3npS19KYWEhg4ODlJWV0dHRkdRGYWEhTU1NtLe3U19fT2dnJ8eOHUuqs3btWvLz8xkeHqa0tJTOzs6k8uLiYhobGyfb6OjomHIt47p16xgdHWVsbIzCwkL27NmTVF5SUkJDQ8NkG7t27WJwcDCpzvr164nH4+Tl5ZGfn8/evXuTyhcvXkxdXd1kG21tbQwNDSXVqa2tZWBggGeffZaKigr27duXVL5kyRJqa2sn22htbSUejyfVqauro7+/n5KSEuLxOPv3708qX7p0KTU1NezevZu6ujpaWloYGRlJqtPQ0EAsFqOsrIyBgQEOHDiQVL5s2TKqq6vp6uqitraWHTt2kPoVVmNjI729vUQiEfr7++np6Ukqz2R7OnjwIOCtO0VFRbY9pdzQY82aNZP/b7Y9nd6eioqKGB0dpbOzM+n9OJPtacZUNbQfvIFSgY0p0z8G7HPM8zAwBJyXMO2K8XYi43+fBK5Jme8aID7+70vG669MqfN14Kd+fa6vr9dseOSRR7LSzpnIsnGzbPxZPm6WjVs2sgF26QzGvbC/030OGMU7ESpRBOibWh3wvu89pKrHE6Y9Mf575fjvvmna7EuYNtPlGmOMMXMS6qCrqieBduDylKLLgcccsz0KVKR8hztxQP6p8d+t07QZxRtcJ+uISBFwqc9yjTHGmDkJe08X4HPAtSLydhF5iYjchXfY+W4AEblPRO5LqP9t4CjwDRGpEZFXAncBD6rqxJchdwGvFpEPiciLReQm4FXAFwDGDwV8AfjfIvJGEVkP3AsMjrdvjDHGZF3o1+mCd3MM4IPAhcAe4P2qunO8bDuAqm5OqL8W7+SpZuAY8EPgQ5pwfa2IvAn4ON6JV78HPqKq308oF7zreN8J/3979x5sVVnGcfz7EyNTUQRMSS0dCZNCxkCnJg1MQWBqpkYb76XjRJQZTRcvkzNmln8Y9UcZmTZFY6GGpk4q5mWgolKDMUVLzQvCkHe85PVM9PTH+6LbDecc4Jy13sXev8/MHthrrbPeh2f25jlrve96X3YB7gBOi/T4UF+xPs2bV9QDMYp0e9025Nz0zrnpm/PTO+emd4ORm/dExK79HdSIotuNJC2LTXiQuhs5N71zbvrm/PTOueldnblpwu1lMzOzruCia2ZmVhMX3XIuKR1Agzk3vXNu+ub89M656V1tuXGfrpmZWU18pWtmZlYTF10zM7OauOgWJmmJpGh7XVE6riZRsijn5uj+f6I7SLpU0sOSXpX0tKTrJO1fOq7SJI2Q9CNJ9+fcrJb0E0kjS8fWBJJmSVos6fn8ndq7dEylSPqipEclvSZpuaRDq27TRbcZfkGaGGT96/Nlw2mcrwH/Kx1EAy0DTgb2B44EBNwq6W0lg2qAd5FWCzsDGA+cCHwUuLxkUA2yPWnhmG8VjqMoSceQZi+8ADiQNAXwIknv7vMHB9quB1KVlWfcujcivlQ6liaSdBDwW9K6y08Cn46Iq8pG1UySDgDuBt4XEQ/0d3w3kTQTuB4YHhEv9nd8N5A0ibQ2+T4RsbJwOLWTdAdwT0R8rmXbv0hTCp9dVbu+0m2GYyU9I+k+SXMlDSsdUBPkPCwAZrXMq20bIWkH4BRgFbCybDSNtBNpDe5XSgdi5UkaSvpF/ua2XTeTln6tjItueQuAE0gLMpwPHAVcXTSi5rgYuCkiFpUOpKlyn9RLpMU6ZgCHR8RmrKjd+SQNJ323Lo2I/5aOxxphFDCEdPes1ZPA7lU27KJbAUnf2cjgqPbXFICIuCQifh8RKyLiCuAYYKqkDxb9R1RkU3Mj6SRgAvCN0jHXaXM+O9mvSf1Rk4EHgYWSti8Re9W2IDfkJUB/B6wh9fF2pC3JjZXhPt0KSBpF+k2qL6siYoNbXZK2AXqAEyLiyiriK2lTcwPMAz7DWwdQDcnv/xoRh1QTYVkD/OwMJa26NTsiLqsivpI2Nze54N5IGmA2IyJeqjjEYrbkc9PNfbr5u/IKcFxELGzZ/mPgAxExuaq2t63qxN0sIp5hy5eJGk8qLo8PXkTNsam5kfRNYG7b5hXA14HrKgitEQb42VF+vX3wImqOzclNHg+wiJSP6Z1ccGHAn5uuExE9kpYDU4GFLbumUnH3notuQZL2JfXn3kj6wowDvg/cBfy5YGjFRcQa0i3BN0gCWB0RjxQJqkEkjSH1/98KPA3sCZxFGix0fcHQissF92bS4KlPAjvkgWYAayOip1hwDSBpd1K/5di8aVzu914VEWvLRVa7HwCXSbqT9P/tbNLjZhdX2aiLblk9wOHAHGBHYDVwA3BeRKwrGZg13uvAFNIzzMNJA0D+CHw4Ip4oGFcTTAQ+lP/+YNu+w4AltUbTPLOBc1ve35D/PAWYX3s0hUTElXnClHNI8yPcC8yMiMeqbNd9umZmZjXx6GUzM7OauOiamZnVxEXXzMysJi66ZmZmNXHRNTMzq4mLrpmZWU1cdM06gKRtJB0p6WpJt1TYjiRNk3SDpJ9X1Y5Zp3LRNesMo4GRpBmYqlzEfgJpcYWZ+P8Ps83mL41ZB4iINRGxgA2XKhswSd9uaefvpGXyBvP8QySd2/+RZls/F12zzjKo8wpL2hM4vXVbRLw2mG0AXwD2GeRzmjWSi66ZbZSknYFrSHM7V9XGYaRFPsy6gouuWReQdKqkv0haKukFSY9LWiFpsaQN1iaWtC3wQ2Cv/H5Jfo1oO+5QSfMkrZF0e74ybt0/Mu+/SdK/c/uT8r6JwNnAUGB6Pv+Fed92ki6U9CdJyyU9JGlOJckxq5EXPDDrIJJWAisjYkrLtq+S+mHHR8Qjuejdno8b08/55gOfjQi1bQ/gPmB2RCyVtBvwEPCbiDg1HzOMtGTanIhYLGmX/H40sF9EPNVyrl9GxMkt558HTAPG5bVP55FuQ0+KiOVblh2z8nyla9b55gD3rV+HOCKWAX8A9pU0agDnXRYRS/M5nwT+CUxqa/eBiFicj3kOmEe6Xf3lfs59ELCiZe3bm/KfY3s53myr4PV0zTrfToDatq0FXgaeG8R2XiU9trTedGAvSUtatu0IPAb0V+xPBF4AkDSW9IgSpFvRZlstX+madb75pOJ3GoCkfUiLuX83ItYNYjsBDGl5vxtwS0RMaXlNioi9I2J2nyeKeACYKOla4Hhgad7V/suD2VbFV7pmne8MYFfgCEnHAy8CX4mIX1Xc7vPANEnDIuI/rTskTYiIu3v7QUk/BT4CfCwinpI0pdpQzerhomvW+SYDz0bEiVvwswMZaXkrcBZwjaRZeRCXgBNIV8EbLbqSDgBmAaevH2xl1ilcdM06hKR3kPpUeyQNabl1fD5wsKRPkCbPWAe8DjwMfC8i7uzjtM/mc+9B6k/t4c1bvO9sO3YEMELS0DwAai5wHHA48LCkx4HtgKeAiW1t7JHbOQRYk7cfnLcN5c0+3e0ljYmIhzYhJWaN4z5dsw4gaQxwL2mg0nuBf0jaL+8+jzQoaWfSzE/jgAOBo4Fb2p+9bXMRsAK4njQw6v3AsrxvhqS7JI2XdA8wHhi2vu2IeJZ0i/jy3P5OwBLgiIh4uaWNM4EDJS0AXouIR0nP735c0m3ABcBtwBPAp4C3PAtstjXxc7pmHSxPcnEVcG5rH2q+ehxNGmR1Zj9Xu2Y2SHyla9bZzgFGtQ9aioieiHgM+BtwT5HIzLqQi65ZZxsJTJB0lKQ3HueRtK2kY4FrK1jAwMx64dvLZh0s314+CTiVNCHFc8Aq4H7gZxGxumB4Zl3HRdfMzKwmvr1sZmZWExddMzOzmrjompmZ1cRF18zMrCYuumZmZjVx0TUzM6vJ/wHl0nkm7HGi7gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric='acc'\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.tick_params(labelsize=14)\n",
    "# for GAMMA in list(np.linspace(1,0.5,50)):\n",
    "plt.plot(np.log10(np.logspace(-0.01,-5,50)),df.iloc[0][metric]*np.ones(50),'r-.',label='Naive baseline')\n",
    "plt.plot(np.log10(np.logspace(-0.01,-5,50)),EA_ablation[metric]*np.ones(50),'g-+',label='Ethical Adversaries')\n",
    "plt.plot(np.log10(np.logspace(-0.01,-5,50)),ablation_df[metric],'bo-',label='FairNeuron')\n",
    "plt.plot(np.log10(np.logspace(-0.01,-5,50)),ablation_df[metric][38]*np.ones(50),'b-.',label='best param')\n",
    "plt.xlabel('lg theta',myfont)\n",
    "plt.ylabel(metric,myfont)\n",
    "# plt.ylim((0,1))\n",
    "# plt.legend()\n",
    "plt.grid(linestyle='-.')\n",
    "plt.savefig('data/results/Figures/ablation_theta_{}.pdf'.format(metric))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5278, 12)\n",
      "4.6227737779461915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:  26%|██▌       | 13/50 [00:05<00:14,  2.47it/s, epoch=12, training_loss=1.33e+3, validation_loss=347]\u001b[A\n",
      "Training neural network:  52%|█████▏    | 26/50 [00:10<00:09,  2.42it/s, epoch=25, training_loss=123, validation_loss=91.2]   \u001b[A\n",
      "Training neural network:  78%|███████▊  | 39/50 [00:15<00:04,  2.47it/s, epoch=38, training_loss=106, validation_loss=79.9]\u001b[A\n",
      "                                                                                                                           \u001b[A\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:20.058843851089478 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:  26%|██▌       | 13/50 [00:05<00:14,  2.59it/s, epoch=12, training_loss=6.85, validation_loss=5.77]\u001b[A\n",
      "Training neural network:  54%|█████▍    | 27/50 [00:10<00:08,  2.63it/s, epoch=26, training_loss=5.29, validation_loss=5.76]\u001b[A\n",
      "Training neural network:  82%|████████▏ | 41/50 [00:15<00:03,  2.56it/s, epoch=40, training_loss=5.28, validation_loss=5.73]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 189.2/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/1.0 accelerator_type:V)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 35/36 (34 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_83ea7_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_83ea7_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_83ea7_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_83ea7_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_83ea7_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_83ea7_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_83ea7_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_83ea7_00008</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_83ea7_00009</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_83ea7_00010</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_83ea7_00011</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_83ea7_00012</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_83ea7_00013</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_83ea7_00014</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_83ea7_00015</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_83ea7_00016</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_83ea7_00017</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_83ea7_00018</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td></tr>\n",
       "<tr><td>training_function_83ea7_00019</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 15 more trials not shown (15 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 191.1/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/1.0 accelerator_type:V, 0.0/16.0 CPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_0_39635c4cfd6e69283cd99a75d52ae243)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 36/36 (35 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_83ea7_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_83ea7_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_83ea7_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_83ea7_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_83ea7_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_83ea7_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_83ea7_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_83ea7_00008</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_83ea7_00009</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_83ea7_00010</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_83ea7_00011</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_83ea7_00012</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_83ea7_00013</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_83ea7_00014</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_83ea7_00015</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_83ea7_00016</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_83ea7_00017</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_83ea7_00018</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td></tr>\n",
       "<tr><td>training_function_83ea7_00019</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19174)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=19174)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 191.2/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/1.0 accelerator_type:V, 0.0/16.0 CPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_0_39635c4cfd6e69283cd99a75d52ae243)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 36/36 (35 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_83ea7_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_83ea7_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_83ea7_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_83ea7_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_83ea7_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_83ea7_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_83ea7_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_83ea7_00008</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_83ea7_00009</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_83ea7_00010</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_83ea7_00011</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_83ea7_00012</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_83ea7_00013</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_83ea7_00014</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_83ea7_00015</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_83ea7_00016</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_83ea7_00017</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_83ea7_00018</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td></tr>\n",
       "<tr><td>training_function_83ea7_00019</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19174)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19174)\u001b[0m \r",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19174)\u001b[0m frac:0.8341346153846154\n",
      "Result for training_function_83ea7_00000:\n",
      "  date: 2021-08-31_19-49-55\n",
      "  done: false\n",
      "  experiment_id: 1867633128fa4e20871bb536478e051a\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.4507757929219862\n",
      "  neg_mean_loss: -1.4507757929219862\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19174\n",
      "  time_since_restore: 7.534403562545776\n",
      "  time_this_iter_s: 7.534403562545776\n",
      "  time_total_s: 7.534403562545776\n",
      "  timestamp: 1630410595\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00000\n",
      "  \n",
      "Result for training_function_83ea7_00000:\n",
      "  date: 2021-08-31_19-49-55\n",
      "  done: true\n",
      "  experiment_id: 1867633128fa4e20871bb536478e051a\n",
      "  experiment_tag: 0_GAMMA=0.95,THETA=0.1\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.4507757929219862\n",
      "  neg_mean_loss: -1.4507757929219862\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19174\n",
      "  time_since_restore: 7.534403562545776\n",
      "  time_this_iter_s: 7.534403562545776\n",
      "  time_total_s: 7.534403562545776\n",
      "  timestamp: 1630410595\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19174)\u001b[0m \n",
      "                                                               \u001b[A\n",
      "\u001b[2m\u001b[36m(pid=19169)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=19169)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=19169)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19169)\u001b[0m frac:0.8605769230769231\n",
      "Result for training_function_83ea7_00001:\n",
      "  date: 2021-08-31_19-50-10\n",
      "  done: false\n",
      "  experiment_id: 84fe52b5ffc149708c86ae42c5989e69\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.9274953174271349\n",
      "  neg_mean_loss: -0.9274953174271349\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19169\n",
      "  time_since_restore: 7.109009027481079\n",
      "  time_this_iter_s: 7.109009027481079\n",
      "  time_total_s: 7.109009027481079\n",
      "  timestamp: 1630410610\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00001\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19169)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19169)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 191.1/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/1.0 accelerator_type:V, 0.0/16.0 CPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_0_39635c4cfd6e69283cd99a75d52ae243)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 36/36 (34 PENDING, 1 RUNNING, 1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00001</td><td>RUNNING   </td><td>202.117.43.132:19169</td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">0.927495</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.10901</td><td style=\"text-align: right;\">      -0.927495</td></tr>\n",
       "<tr><td>training_function_83ea7_00002</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00003</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00004</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00005</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00006</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00007</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00008</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00009</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00010</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00011</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00012</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00013</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00014</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00015</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.45078 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.5344 </td><td style=\"text-align: right;\">      -1.45078 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00001:\n",
      "  date: 2021-08-31_19-50-10\n",
      "  done: true\n",
      "  experiment_id: 84fe52b5ffc149708c86ae42c5989e69\n",
      "  experiment_tag: 1_GAMMA=0.9,THETA=0.1\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.9274953174271349\n",
      "  neg_mean_loss: -0.9274953174271349\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19169\n",
      "  time_since_restore: 7.109009027481079\n",
      "  time_this_iter_s: 7.109009027481079\n",
      "  time_total_s: 7.109009027481079\n",
      "  timestamp: 1630410610\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00001\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19215)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=19215)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=19215)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19215)\u001b[0m frac:0.6682692307692307\n",
      "Result for training_function_83ea7_00002:\n",
      "  date: 2021-08-31_19-50-25\n",
      "  done: false\n",
      "  experiment_id: 22d9fca43d994a329a47c684bef21301\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.9692469021506908\n",
      "  neg_mean_loss: -0.9692469021506908\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19215\n",
      "  time_since_restore: 6.405370473861694\n",
      "  time_this_iter_s: 6.405370473861694\n",
      "  time_total_s: 6.405370473861694\n",
      "  timestamp: 1630410625\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00002\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19215)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19215)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 191.1/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/1.0 accelerator_type:V)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 36/36 (33 PENDING, 1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00002</td><td>RUNNING   </td><td>202.117.43.132:19215</td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">0.969247</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.40537</td><td style=\"text-align: right;\">      -0.969247</td></tr>\n",
       "<tr><td>training_function_83ea7_00003</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00004</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00005</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00006</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00007</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00008</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00009</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00010</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00011</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00012</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00013</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00014</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00015</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.45078 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.5344 </td><td style=\"text-align: right;\">      -1.45078 </td></tr>\n",
       "<tr><td>training_function_83ea7_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">0.927495</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.10901</td><td style=\"text-align: right;\">      -0.927495</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00002:\n",
      "  date: 2021-08-31_19-50-25\n",
      "  done: true\n",
      "  experiment_id: 22d9fca43d994a329a47c684bef21301\n",
      "  experiment_tag: 2_GAMMA=0.85,THETA=0.1\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.9692469021506908\n",
      "  neg_mean_loss: -0.9692469021506908\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19215\n",
      "  time_since_restore: 6.405370473861694\n",
      "  time_this_iter_s: 6.405370473861694\n",
      "  time_total_s: 6.405370473861694\n",
      "  timestamp: 1630410625\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00002\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19181)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=19181)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19181)\u001b[0m frac:0.6682692307692307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19181)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19181)\u001b[0m \r",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00003:\n",
      "  date: 2021-08-31_19-50-40\n",
      "  done: false\n",
      "  experiment_id: 8c3a6496b7114e82bbd23973f8121f66\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.8823289235933656\n",
      "  neg_mean_loss: -1.8823289235933656\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19181\n",
      "  time_since_restore: 5.794442892074585\n",
      "  time_this_iter_s: 5.794442892074585\n",
      "  time_total_s: 5.794442892074585\n",
      "  timestamp: 1630410640\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00003\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19181)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19181)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 191.0/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/16.0 CPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_0_39635c4cfd6e69283cd99a75d52ae243)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 36/36 (32 PENDING, 1 RUNNING, 3 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00003</td><td>RUNNING   </td><td>202.117.43.132:19181</td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.88233 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.79444</td><td style=\"text-align: right;\">      -1.88233 </td></tr>\n",
       "<tr><td>training_function_83ea7_00004</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00005</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00006</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00007</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00008</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00009</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00010</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00011</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00012</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00013</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00014</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00015</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.45078 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.5344 </td><td style=\"text-align: right;\">      -1.45078 </td></tr>\n",
       "<tr><td>training_function_83ea7_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">0.927495</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.10901</td><td style=\"text-align: right;\">      -0.927495</td></tr>\n",
       "<tr><td>training_function_83ea7_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">0.969247</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.40537</td><td style=\"text-align: right;\">      -0.969247</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00003:\n",
      "  date: 2021-08-31_19-50-40\n",
      "  done: true\n",
      "  experiment_id: 8c3a6496b7114e82bbd23973f8121f66\n",
      "  experiment_tag: 3_GAMMA=0.8,THETA=0.1\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.8823289235933656\n",
      "  neg_mean_loss: -1.8823289235933656\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19181\n",
      "  time_since_restore: 5.794442892074585\n",
      "  time_this_iter_s: 5.794442892074585\n",
      "  time_total_s: 5.794442892074585\n",
      "  timestamp: 1630410640\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00003\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19191)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=19191)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19191)\u001b[0m frac:0.6802884615384616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19191)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=19191)\u001b[0m \n",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00004:\n",
      "  date: 2021-08-31_19-50-53\n",
      "  done: false\n",
      "  experiment_id: f581c1f393a44de698b3f4f3d48dae28\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.417338209461252\n",
      "  neg_mean_loss: -1.417338209461252\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19191\n",
      "  time_since_restore: 5.003664016723633\n",
      "  time_this_iter_s: 5.003664016723633\n",
      "  time_total_s: 5.003664016723633\n",
      "  timestamp: 1630410653\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00004\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 191.0/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_39635c4cfd6e69283cd99a75d52ae243)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 36/36 (31 PENDING, 1 RUNNING, 4 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00004</td><td>RUNNING   </td><td>202.117.43.132:19191</td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.41734 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.00366</td><td style=\"text-align: right;\">      -1.41734 </td></tr>\n",
       "<tr><td>training_function_83ea7_00005</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00006</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00007</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00008</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00009</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00010</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00011</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00012</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00013</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00014</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00015</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.45078 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.5344 </td><td style=\"text-align: right;\">      -1.45078 </td></tr>\n",
       "<tr><td>training_function_83ea7_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">0.927495</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.10901</td><td style=\"text-align: right;\">      -0.927495</td></tr>\n",
       "<tr><td>training_function_83ea7_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">0.969247</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.40537</td><td style=\"text-align: right;\">      -0.969247</td></tr>\n",
       "<tr><td>training_function_83ea7_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.88233 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.79444</td><td style=\"text-align: right;\">      -1.88233 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00004:\n",
      "  date: 2021-08-31_19-50-53\n",
      "  done: true\n",
      "  experiment_id: f581c1f393a44de698b3f4f3d48dae28\n",
      "  experiment_tag: 4_GAMMA=0.7,THETA=0.1\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.417338209461252\n",
      "  neg_mean_loss: -1.417338209461252\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19191\n",
      "  time_since_restore: 5.003664016723633\n",
      "  time_this_iter_s: 5.003664016723633\n",
      "  time_total_s: 5.003664016723633\n",
      "  timestamp: 1630410653\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00004\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19204)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=19204)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=19204)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19204)\u001b[0m frac:0.6009615384615384\n",
      "Result for training_function_83ea7_00005:\n",
      "  date: 2021-08-31_19-51-08\n",
      "  done: false\n",
      "  experiment_id: 215ac5de2e6b4c0d9ba1e8909a7754f9\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.497252528129896\n",
      "  neg_mean_loss: -1.497252528129896\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19204\n",
      "  time_since_restore: 4.4024786949157715\n",
      "  time_this_iter_s: 4.4024786949157715\n",
      "  time_total_s: 4.4024786949157715\n",
      "  timestamp: 1630410668\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00005\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19204)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19204)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 191.0/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/1.0 accelerator_type:V, 0.0/16.0 CPU_group_39635c4cfd6e69283cd99a75d52ae243)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 36/36 (30 PENDING, 1 RUNNING, 5 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00005</td><td>RUNNING   </td><td>202.117.43.132:19204</td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.49725 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.40248</td><td style=\"text-align: right;\">      -1.49725 </td></tr>\n",
       "<tr><td>training_function_83ea7_00006</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00007</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00008</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00009</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00010</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00011</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00012</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00013</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00014</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00015</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.45078 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.5344 </td><td style=\"text-align: right;\">      -1.45078 </td></tr>\n",
       "<tr><td>training_function_83ea7_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">0.927495</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.10901</td><td style=\"text-align: right;\">      -0.927495</td></tr>\n",
       "<tr><td>training_function_83ea7_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">0.969247</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.40537</td><td style=\"text-align: right;\">      -0.969247</td></tr>\n",
       "<tr><td>training_function_83ea7_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.88233 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.79444</td><td style=\"text-align: right;\">      -1.88233 </td></tr>\n",
       "<tr><td>training_function_83ea7_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.41734 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.00366</td><td style=\"text-align: right;\">      -1.41734 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00005:\n",
      "  date: 2021-08-31_19-51-08\n",
      "  done: true\n",
      "  experiment_id: 215ac5de2e6b4c0d9ba1e8909a7754f9\n",
      "  experiment_tag: 5_GAMMA=0.6,THETA=0.1\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.497252528129896\n",
      "  neg_mean_loss: -1.497252528129896\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19204\n",
      "  time_since_restore: 4.4024786949157715\n",
      "  time_this_iter_s: 4.4024786949157715\n",
      "  time_total_s: 4.4024786949157715\n",
      "  timestamp: 1630410668\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00005\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19159)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=19159)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19159)\u001b[0m frac:0.7524038461538461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19159)\u001b[0m \r",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00006:\n",
      "  date: 2021-08-31_19-51-24\n",
      "  done: false\n",
      "  experiment_id: 23f4fa6ea45a4823857a460def830032\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.0661847330512302\n",
      "  neg_mean_loss: -1.0661847330512302\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19159\n",
      "  time_since_restore: 7.3495988845825195\n",
      "  time_this_iter_s: 7.3495988845825195\n",
      "  time_total_s: 7.3495988845825195\n",
      "  timestamp: 1630410684\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00006\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19159)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 190.9/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_0_39635c4cfd6e69283cd99a75d52ae243)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 36/36 (29 PENDING, 1 RUNNING, 6 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00006</td><td>RUNNING   </td><td>202.117.43.132:19159</td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.06618 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.3496 </td><td style=\"text-align: right;\">      -1.06618 </td></tr>\n",
       "<tr><td>training_function_83ea7_00007</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00008</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00009</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00010</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00011</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00012</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00013</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00014</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00015</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.45078 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.5344 </td><td style=\"text-align: right;\">      -1.45078 </td></tr>\n",
       "<tr><td>training_function_83ea7_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">0.927495</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.10901</td><td style=\"text-align: right;\">      -0.927495</td></tr>\n",
       "<tr><td>training_function_83ea7_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">0.969247</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.40537</td><td style=\"text-align: right;\">      -0.969247</td></tr>\n",
       "<tr><td>training_function_83ea7_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.88233 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.79444</td><td style=\"text-align: right;\">      -1.88233 </td></tr>\n",
       "<tr><td>training_function_83ea7_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.41734 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.00366</td><td style=\"text-align: right;\">      -1.41734 </td></tr>\n",
       "<tr><td>training_function_83ea7_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.49725 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.40248</td><td style=\"text-align: right;\">      -1.49725 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00006:\n",
      "  date: 2021-08-31_19-51-24\n",
      "  done: true\n",
      "  experiment_id: 23f4fa6ea45a4823857a460def830032\n",
      "  experiment_tag: 6_GAMMA=0.95,THETA=0.01\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.0661847330512302\n",
      "  neg_mean_loss: -1.0661847330512302\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19159\n",
      "  time_since_restore: 7.3495988845825195\n",
      "  time_this_iter_s: 7.3495988845825195\n",
      "  time_total_s: 7.3495988845825195\n",
      "  timestamp: 1630410684\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00006\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19167)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=19167)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19167)\u001b[0m frac:0.7403846153846154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19167)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19167)\u001b[0m \r",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00007:\n",
      "  date: 2021-08-31_19-51-41\n",
      "  done: false\n",
      "  experiment_id: c13eefbb25d04f088cbceafa4dfd92d4\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.009602922833232\n",
      "  neg_mean_loss: -1.009602922833232\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19167\n",
      "  time_since_restore: 7.192931413650513\n",
      "  time_this_iter_s: 7.192931413650513\n",
      "  time_total_s: 7.192931413650513\n",
      "  timestamp: 1630410701\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00007\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19167)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19167)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 190.9/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/1.0 accelerator_type:V, 0.0/16.0 CPU_group_0_39635c4cfd6e69283cd99a75d52ae243)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 36/36 (28 PENDING, 1 RUNNING, 7 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00007</td><td>RUNNING   </td><td>202.117.43.132:19167</td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.0096  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.19293</td><td style=\"text-align: right;\">      -1.0096  </td></tr>\n",
       "<tr><td>training_function_83ea7_00008</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00009</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00010</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00011</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00012</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00013</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00014</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00015</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.45078 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.5344 </td><td style=\"text-align: right;\">      -1.45078 </td></tr>\n",
       "<tr><td>training_function_83ea7_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">0.927495</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.10901</td><td style=\"text-align: right;\">      -0.927495</td></tr>\n",
       "<tr><td>training_function_83ea7_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">0.969247</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.40537</td><td style=\"text-align: right;\">      -0.969247</td></tr>\n",
       "<tr><td>training_function_83ea7_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.88233 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.79444</td><td style=\"text-align: right;\">      -1.88233 </td></tr>\n",
       "<tr><td>training_function_83ea7_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.41734 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.00366</td><td style=\"text-align: right;\">      -1.41734 </td></tr>\n",
       "<tr><td>training_function_83ea7_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.49725 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.40248</td><td style=\"text-align: right;\">      -1.49725 </td></tr>\n",
       "<tr><td>training_function_83ea7_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.06618 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.3496 </td><td style=\"text-align: right;\">      -1.06618 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00007:\n",
      "  date: 2021-08-31_19-51-41\n",
      "  done: true\n",
      "  experiment_id: c13eefbb25d04f088cbceafa4dfd92d4\n",
      "  experiment_tag: 7_GAMMA=0.9,THETA=0.01\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.009602922833232\n",
      "  neg_mean_loss: -1.009602922833232\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19167\n",
      "  time_since_restore: 7.192931413650513\n",
      "  time_this_iter_s: 7.192931413650513\n",
      "  time_total_s: 7.192931413650513\n",
      "  timestamp: 1630410701\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00007\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19154)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=19154)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19154)\u001b[0m frac:0.6466346153846154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19154)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19154)\u001b[0m \r",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00008:\n",
      "  date: 2021-08-31_19-51-55\n",
      "  done: false\n",
      "  experiment_id: 48dba1a7374d467ebc40b1cb38b6df5f\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.6434622539308483\n",
      "  neg_mean_loss: -1.6434622539308483\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19154\n",
      "  time_since_restore: 6.054264783859253\n",
      "  time_this_iter_s: 6.054264783859253\n",
      "  time_total_s: 6.054264783859253\n",
      "  timestamp: 1630410715\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00008\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19154)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19154)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 190.8/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/16.0 CPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/1.0 accelerator_type:V, 0.0/16.0 CPU_group_39635c4cfd6e69283cd99a75d52ae243)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 36/36 (27 PENDING, 1 RUNNING, 8 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00008</td><td>RUNNING   </td><td>202.117.43.132:19154</td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.64346 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.05426</td><td style=\"text-align: right;\">      -1.64346 </td></tr>\n",
       "<tr><td>training_function_83ea7_00009</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00010</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00011</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00012</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00013</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00014</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00015</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.45078 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.5344 </td><td style=\"text-align: right;\">      -1.45078 </td></tr>\n",
       "<tr><td>training_function_83ea7_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">0.927495</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.10901</td><td style=\"text-align: right;\">      -0.927495</td></tr>\n",
       "<tr><td>training_function_83ea7_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">0.969247</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.40537</td><td style=\"text-align: right;\">      -0.969247</td></tr>\n",
       "<tr><td>training_function_83ea7_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.88233 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.79444</td><td style=\"text-align: right;\">      -1.88233 </td></tr>\n",
       "<tr><td>training_function_83ea7_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.41734 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.00366</td><td style=\"text-align: right;\">      -1.41734 </td></tr>\n",
       "<tr><td>training_function_83ea7_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.49725 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.40248</td><td style=\"text-align: right;\">      -1.49725 </td></tr>\n",
       "<tr><td>training_function_83ea7_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.06618 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.3496 </td><td style=\"text-align: right;\">      -1.06618 </td></tr>\n",
       "<tr><td>training_function_83ea7_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.0096  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.19293</td><td style=\"text-align: right;\">      -1.0096  </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00008:\n",
      "  date: 2021-08-31_19-51-55\n",
      "  done: true\n",
      "  experiment_id: 48dba1a7374d467ebc40b1cb38b6df5f\n",
      "  experiment_tag: 8_GAMMA=0.85,THETA=0.01\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.6434622539308483\n",
      "  neg_mean_loss: -1.6434622539308483\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19154\n",
      "  time_since_restore: 6.054264783859253\n",
      "  time_this_iter_s: 6.054264783859253\n",
      "  time_total_s: 6.054264783859253\n",
      "  timestamp: 1630410715\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00008\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19172)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=19172)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19172)\u001b[0m frac:0.7019230769230769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19172)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19172)\u001b[0m \r",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00009:\n",
      "  date: 2021-08-31_19-52-09\n",
      "  done: false\n",
      "  experiment_id: f0c04cc7a84c4d559a2693cf8ef6525e\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.0099419058840793\n",
      "  neg_mean_loss: -1.0099419058840793\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19172\n",
      "  time_since_restore: 5.960821151733398\n",
      "  time_this_iter_s: 5.960821151733398\n",
      "  time_total_s: 5.960821151733398\n",
      "  timestamp: 1630410729\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00009\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19172)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19172)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 190.8/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_0_39635c4cfd6e69283cd99a75d52ae243)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 36/36 (26 PENDING, 1 RUNNING, 9 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00009</td><td>RUNNING   </td><td>202.117.43.132:19172</td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.00994 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.96082</td><td style=\"text-align: right;\">      -1.00994 </td></tr>\n",
       "<tr><td>training_function_83ea7_00010</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00011</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00012</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00013</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00014</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00015</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.45078 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.5344 </td><td style=\"text-align: right;\">      -1.45078 </td></tr>\n",
       "<tr><td>training_function_83ea7_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">0.927495</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.10901</td><td style=\"text-align: right;\">      -0.927495</td></tr>\n",
       "<tr><td>training_function_83ea7_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">0.969247</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.40537</td><td style=\"text-align: right;\">      -0.969247</td></tr>\n",
       "<tr><td>training_function_83ea7_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.88233 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.79444</td><td style=\"text-align: right;\">      -1.88233 </td></tr>\n",
       "<tr><td>training_function_83ea7_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.41734 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.00366</td><td style=\"text-align: right;\">      -1.41734 </td></tr>\n",
       "<tr><td>training_function_83ea7_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.49725 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.40248</td><td style=\"text-align: right;\">      -1.49725 </td></tr>\n",
       "<tr><td>training_function_83ea7_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.06618 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.3496 </td><td style=\"text-align: right;\">      -1.06618 </td></tr>\n",
       "<tr><td>training_function_83ea7_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.0096  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.19293</td><td style=\"text-align: right;\">      -1.0096  </td></tr>\n",
       "<tr><td>training_function_83ea7_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.64346 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.05426</td><td style=\"text-align: right;\">      -1.64346 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00009:\n",
      "  date: 2021-08-31_19-52-09\n",
      "  done: true\n",
      "  experiment_id: f0c04cc7a84c4d559a2693cf8ef6525e\n",
      "  experiment_tag: 9_GAMMA=0.8,THETA=0.01\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.0099419058840793\n",
      "  neg_mean_loss: -1.0099419058840793\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19172\n",
      "  time_since_restore: 5.960821151733398\n",
      "  time_this_iter_s: 5.960821151733398\n",
      "  time_total_s: 5.960821151733398\n",
      "  timestamp: 1630410729\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00009\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19158)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=19158)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=19158)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19158)\u001b[0m frac:0.7067307692307693\n",
      "Result for training_function_83ea7_00010:\n",
      "  date: 2021-08-31_19-52-24\n",
      "  done: false\n",
      "  experiment_id: 9d8aa777d97e430aae5d803993b3d38f\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.0665237161020777\n",
      "  neg_mean_loss: -1.0665237161020777\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19158\n",
      "  time_since_restore: 5.316636323928833\n",
      "  time_this_iter_s: 5.316636323928833\n",
      "  time_total_s: 5.316636323928833\n",
      "  timestamp: 1630410744\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00010\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19158)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19158)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 190.8/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_39635c4cfd6e69283cd99a75d52ae243)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 36/36 (25 PENDING, 1 RUNNING, 10 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00010</td><td>RUNNING   </td><td>202.117.43.132:19158</td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.06652 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.31664</td><td style=\"text-align: right;\">      -1.06652 </td></tr>\n",
       "<tr><td>training_function_83ea7_00011</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00012</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00013</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00014</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00015</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00020</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.45078 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.5344 </td><td style=\"text-align: right;\">      -1.45078 </td></tr>\n",
       "<tr><td>training_function_83ea7_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">0.927495</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.10901</td><td style=\"text-align: right;\">      -0.927495</td></tr>\n",
       "<tr><td>training_function_83ea7_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">0.969247</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.40537</td><td style=\"text-align: right;\">      -0.969247</td></tr>\n",
       "<tr><td>training_function_83ea7_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.88233 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.79444</td><td style=\"text-align: right;\">      -1.88233 </td></tr>\n",
       "<tr><td>training_function_83ea7_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.41734 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.00366</td><td style=\"text-align: right;\">      -1.41734 </td></tr>\n",
       "<tr><td>training_function_83ea7_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.49725 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.40248</td><td style=\"text-align: right;\">      -1.49725 </td></tr>\n",
       "<tr><td>training_function_83ea7_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.06618 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.3496 </td><td style=\"text-align: right;\">      -1.06618 </td></tr>\n",
       "<tr><td>training_function_83ea7_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.0096  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.19293</td><td style=\"text-align: right;\">      -1.0096  </td></tr>\n",
       "<tr><td>training_function_83ea7_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.64346 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.05426</td><td style=\"text-align: right;\">      -1.64346 </td></tr>\n",
       "<tr><td>training_function_83ea7_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.00994 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.96082</td><td style=\"text-align: right;\">      -1.00994 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (15 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00010:\n",
      "  date: 2021-08-31_19-52-24\n",
      "  done: true\n",
      "  experiment_id: 9d8aa777d97e430aae5d803993b3d38f\n",
      "  experiment_tag: 10_GAMMA=0.7,THETA=0.01\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.0665237161020777\n",
      "  neg_mean_loss: -1.0665237161020777\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19158\n",
      "  time_since_restore: 5.316636323928833\n",
      "  time_this_iter_s: 5.316636323928833\n",
      "  time_total_s: 5.316636323928833\n",
      "  timestamp: 1630410744\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00010\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19156)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=19156)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=19156)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19156)\u001b[0m frac:0.6394230769230769\n",
      "Result for training_function_83ea7_00011:\n",
      "  date: 2021-08-31_19-52-37\n",
      "  done: false\n",
      "  experiment_id: fa83fdf6abb2466d9ef2813fcd00a7be\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.4939486302995776\n",
      "  neg_mean_loss: -0.4939486302995776\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19156\n",
      "  time_since_restore: 4.610384702682495\n",
      "  time_this_iter_s: 4.610384702682495\n",
      "  time_total_s: 4.610384702682495\n",
      "  timestamp: 1630410757\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00011\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19156)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19156)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 190.7/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/16.0 CPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/1.0 accelerator_type:V)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 36/36 (24 PENDING, 1 RUNNING, 11 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00011</td><td>RUNNING   </td><td>202.117.43.132:19156</td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">0.493949</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.61038</td><td style=\"text-align: right;\">      -0.493949</td></tr>\n",
       "<tr><td>training_function_83ea7_00012</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00013</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00014</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00015</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00020</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00021</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.45078 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.5344 </td><td style=\"text-align: right;\">      -1.45078 </td></tr>\n",
       "<tr><td>training_function_83ea7_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">0.927495</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.10901</td><td style=\"text-align: right;\">      -0.927495</td></tr>\n",
       "<tr><td>training_function_83ea7_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">0.969247</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.40537</td><td style=\"text-align: right;\">      -0.969247</td></tr>\n",
       "<tr><td>training_function_83ea7_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.88233 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.79444</td><td style=\"text-align: right;\">      -1.88233 </td></tr>\n",
       "<tr><td>training_function_83ea7_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.41734 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.00366</td><td style=\"text-align: right;\">      -1.41734 </td></tr>\n",
       "<tr><td>training_function_83ea7_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.49725 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.40248</td><td style=\"text-align: right;\">      -1.49725 </td></tr>\n",
       "<tr><td>training_function_83ea7_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.06618 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.3496 </td><td style=\"text-align: right;\">      -1.06618 </td></tr>\n",
       "<tr><td>training_function_83ea7_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.0096  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.19293</td><td style=\"text-align: right;\">      -1.0096  </td></tr>\n",
       "<tr><td>training_function_83ea7_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.64346 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.05426</td><td style=\"text-align: right;\">      -1.64346 </td></tr>\n",
       "<tr><td>training_function_83ea7_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.00994 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.96082</td><td style=\"text-align: right;\">      -1.00994 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (14 PENDING, 1 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00011:\n",
      "  date: 2021-08-31_19-52-37\n",
      "  done: true\n",
      "  experiment_id: fa83fdf6abb2466d9ef2813fcd00a7be\n",
      "  experiment_tag: 11_GAMMA=0.6,THETA=0.01\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.4939486302995776\n",
      "  neg_mean_loss: -0.4939486302995776\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19156\n",
      "  time_since_restore: 4.610384702682495\n",
      "  time_this_iter_s: 4.610384702682495\n",
      "  time_total_s: 4.610384702682495\n",
      "  timestamp: 1630410757\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00011\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19155)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=19155)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=19155)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19155)\u001b[0m frac:0.7355769230769231\n",
      "Result for training_function_83ea7_00012:\n",
      "  date: 2021-08-31_19-52-53\n",
      "  done: false\n",
      "  experiment_id: 5e28fa92354a44eb9f464a6e94a7f27b\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.4575872382851447\n",
      "  neg_mean_loss: -1.4575872382851447\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19155\n",
      "  time_since_restore: 7.5326385498046875\n",
      "  time_this_iter_s: 7.5326385498046875\n",
      "  time_total_s: 7.5326385498046875\n",
      "  timestamp: 1630410773\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00012\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19155)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19155)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 190.7/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/16.0 CPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/1.0 accelerator_type:V)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 36/36 (23 PENDING, 1 RUNNING, 12 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00012</td><td>RUNNING   </td><td>202.117.43.132:19155</td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">1.45759 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.53264</td><td style=\"text-align: right;\">      -1.45759 </td></tr>\n",
       "<tr><td>training_function_83ea7_00013</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00014</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00015</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00020</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00021</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00022</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.45078 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.5344 </td><td style=\"text-align: right;\">      -1.45078 </td></tr>\n",
       "<tr><td>training_function_83ea7_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">0.927495</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.10901</td><td style=\"text-align: right;\">      -0.927495</td></tr>\n",
       "<tr><td>training_function_83ea7_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">0.969247</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.40537</td><td style=\"text-align: right;\">      -0.969247</td></tr>\n",
       "<tr><td>training_function_83ea7_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.88233 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.79444</td><td style=\"text-align: right;\">      -1.88233 </td></tr>\n",
       "<tr><td>training_function_83ea7_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.41734 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.00366</td><td style=\"text-align: right;\">      -1.41734 </td></tr>\n",
       "<tr><td>training_function_83ea7_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.49725 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.40248</td><td style=\"text-align: right;\">      -1.49725 </td></tr>\n",
       "<tr><td>training_function_83ea7_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.06618 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.3496 </td><td style=\"text-align: right;\">      -1.06618 </td></tr>\n",
       "<tr><td>training_function_83ea7_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.0096  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.19293</td><td style=\"text-align: right;\">      -1.0096  </td></tr>\n",
       "<tr><td>training_function_83ea7_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.64346 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.05426</td><td style=\"text-align: right;\">      -1.64346 </td></tr>\n",
       "<tr><td>training_function_83ea7_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.00994 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.96082</td><td style=\"text-align: right;\">      -1.00994 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (13 PENDING, 2 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00012:\n",
      "  date: 2021-08-31_19-52-53\n",
      "  done: true\n",
      "  experiment_id: 5e28fa92354a44eb9f464a6e94a7f27b\n",
      "  experiment_tag: 12_GAMMA=0.95,THETA=0.003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.4575872382851447\n",
      "  neg_mean_loss: -1.4575872382851447\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19155\n",
      "  time_since_restore: 7.5326385498046875\n",
      "  time_this_iter_s: 7.5326385498046875\n",
      "  time_total_s: 7.5326385498046875\n",
      "  timestamp: 1630410773\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00012\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19165)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=19165)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19165)\u001b[0m frac:0.7067307692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19165)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19165)\u001b[0m \r",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00013:\n",
      "  date: 2021-08-31_19-53-09\n",
      "  done: false\n",
      "  experiment_id: ad755a23665e4832a9c87c7a9db1c385\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.0489955902600323\n",
      "  neg_mean_loss: -1.0489955902600323\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19165\n",
      "  time_since_restore: 6.453923463821411\n",
      "  time_this_iter_s: 6.453923463821411\n",
      "  time_total_s: 6.453923463821411\n",
      "  timestamp: 1630410789\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00013\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19165)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19165)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 190.6/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/16.0 CPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/1.0 accelerator_type:V, 0.0/16.0 CPU_group_39635c4cfd6e69283cd99a75d52ae243)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 36/36 (22 PENDING, 1 RUNNING, 13 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00013</td><td>RUNNING   </td><td>202.117.43.132:19165</td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">1.049   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.45392</td><td style=\"text-align: right;\">      -1.049   </td></tr>\n",
       "<tr><td>training_function_83ea7_00014</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00015</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00020</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00021</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00022</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00023</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.45078 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.5344 </td><td style=\"text-align: right;\">      -1.45078 </td></tr>\n",
       "<tr><td>training_function_83ea7_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">0.927495</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.10901</td><td style=\"text-align: right;\">      -0.927495</td></tr>\n",
       "<tr><td>training_function_83ea7_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">0.969247</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.40537</td><td style=\"text-align: right;\">      -0.969247</td></tr>\n",
       "<tr><td>training_function_83ea7_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.88233 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.79444</td><td style=\"text-align: right;\">      -1.88233 </td></tr>\n",
       "<tr><td>training_function_83ea7_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.41734 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.00366</td><td style=\"text-align: right;\">      -1.41734 </td></tr>\n",
       "<tr><td>training_function_83ea7_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.49725 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.40248</td><td style=\"text-align: right;\">      -1.49725 </td></tr>\n",
       "<tr><td>training_function_83ea7_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.06618 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.3496 </td><td style=\"text-align: right;\">      -1.06618 </td></tr>\n",
       "<tr><td>training_function_83ea7_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.0096  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.19293</td><td style=\"text-align: right;\">      -1.0096  </td></tr>\n",
       "<tr><td>training_function_83ea7_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.64346 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.05426</td><td style=\"text-align: right;\">      -1.64346 </td></tr>\n",
       "<tr><td>training_function_83ea7_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.00994 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.96082</td><td style=\"text-align: right;\">      -1.00994 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (12 PENDING, 3 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00013:\n",
      "  date: 2021-08-31_19-53-09\n",
      "  done: true\n",
      "  experiment_id: ad755a23665e4832a9c87c7a9db1c385\n",
      "  experiment_tag: 13_GAMMA=0.9,THETA=0.003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.0489955902600323\n",
      "  neg_mean_loss: -1.0489955902600323\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19165\n",
      "  time_since_restore: 6.453923463821411\n",
      "  time_this_iter_s: 6.453923463821411\n",
      "  time_total_s: 6.453923463821411\n",
      "  timestamp: 1630410789\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00013\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19160)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=19160)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=19160)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19160)\u001b[0m frac:0.6610576923076923\n",
      "Result for training_function_83ea7_00014:\n",
      "  date: 2021-08-31_19-53-23\n",
      "  done: false\n",
      "  experiment_id: a8d7a7ce6c5d4c05974d832cc1af1d36\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.9278343004779823\n",
      "  neg_mean_loss: -0.9278343004779823\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19160\n",
      "  time_since_restore: 6.170495510101318\n",
      "  time_this_iter_s: 6.170495510101318\n",
      "  time_total_s: 6.170495510101318\n",
      "  timestamp: 1630410803\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00014\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19160)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19160)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 190.6/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/1.0 accelerator_type:V, 0.0/16.0 CPU_group_0_39635c4cfd6e69283cd99a75d52ae243)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 36/36 (21 PENDING, 1 RUNNING, 14 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00014</td><td>RUNNING   </td><td>202.117.43.132:19160</td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">0.927834</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.1705 </td><td style=\"text-align: right;\">      -0.927834</td></tr>\n",
       "<tr><td>training_function_83ea7_00015</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00020</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00021</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00022</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00023</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00024</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.45078 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.5344 </td><td style=\"text-align: right;\">      -1.45078 </td></tr>\n",
       "<tr><td>training_function_83ea7_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.927495</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.10901</td><td style=\"text-align: right;\">      -0.927495</td></tr>\n",
       "<tr><td>training_function_83ea7_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.969247</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.40537</td><td style=\"text-align: right;\">      -0.969247</td></tr>\n",
       "<tr><td>training_function_83ea7_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.88233 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.79444</td><td style=\"text-align: right;\">      -1.88233 </td></tr>\n",
       "<tr><td>training_function_83ea7_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.41734 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.00366</td><td style=\"text-align: right;\">      -1.41734 </td></tr>\n",
       "<tr><td>training_function_83ea7_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.49725 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.40248</td><td style=\"text-align: right;\">      -1.49725 </td></tr>\n",
       "<tr><td>training_function_83ea7_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.06618 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.3496 </td><td style=\"text-align: right;\">      -1.06618 </td></tr>\n",
       "<tr><td>training_function_83ea7_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.0096  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.19293</td><td style=\"text-align: right;\">      -1.0096  </td></tr>\n",
       "<tr><td>training_function_83ea7_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.64346 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.05426</td><td style=\"text-align: right;\">      -1.64346 </td></tr>\n",
       "<tr><td>training_function_83ea7_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.00994 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.96082</td><td style=\"text-align: right;\">      -1.00994 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (11 PENDING, 4 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00014:\n",
      "  date: 2021-08-31_19-53-23\n",
      "  done: true\n",
      "  experiment_id: a8d7a7ce6c5d4c05974d832cc1af1d36\n",
      "  experiment_tag: 14_GAMMA=0.85,THETA=0.003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.9278343004779823\n",
      "  neg_mean_loss: -0.9278343004779823\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19160\n",
      "  time_since_restore: 6.170495510101318\n",
      "  time_this_iter_s: 6.170495510101318\n",
      "  time_total_s: 6.170495510101318\n",
      "  timestamp: 1630410803\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00014\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19157)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=19157)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19157)\u001b[0m frac:0.7379807692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19157)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19157)\u001b[0m \r",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00015:\n",
      "  date: 2021-08-31_19-53-37\n",
      "  done: false\n",
      "  experiment_id: fb67d704bc014204b46b4a34fa1d6468\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.509602922833232\n",
      "  neg_mean_loss: -1.509602922833232\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19157\n",
      "  time_since_restore: 5.804209470748901\n",
      "  time_this_iter_s: 5.804209470748901\n",
      "  time_total_s: 5.804209470748901\n",
      "  timestamp: 1630410817\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00015\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19157)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19157)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 190.5/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/1.0 accelerator_type:V)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 36/36 (20 PENDING, 1 RUNNING, 15 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00015</td><td>RUNNING   </td><td>202.117.43.132:19157</td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">1.5096  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.80421</td><td style=\"text-align: right;\">      -1.5096  </td></tr>\n",
       "<tr><td>training_function_83ea7_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00020</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00021</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00022</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00023</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00024</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00025</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.45078 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.5344 </td><td style=\"text-align: right;\">      -1.45078 </td></tr>\n",
       "<tr><td>training_function_83ea7_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.927495</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.10901</td><td style=\"text-align: right;\">      -0.927495</td></tr>\n",
       "<tr><td>training_function_83ea7_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.969247</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.40537</td><td style=\"text-align: right;\">      -0.969247</td></tr>\n",
       "<tr><td>training_function_83ea7_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.88233 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.79444</td><td style=\"text-align: right;\">      -1.88233 </td></tr>\n",
       "<tr><td>training_function_83ea7_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.41734 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.00366</td><td style=\"text-align: right;\">      -1.41734 </td></tr>\n",
       "<tr><td>training_function_83ea7_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.49725 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.40248</td><td style=\"text-align: right;\">      -1.49725 </td></tr>\n",
       "<tr><td>training_function_83ea7_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.06618 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.3496 </td><td style=\"text-align: right;\">      -1.06618 </td></tr>\n",
       "<tr><td>training_function_83ea7_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.0096  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.19293</td><td style=\"text-align: right;\">      -1.0096  </td></tr>\n",
       "<tr><td>training_function_83ea7_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.64346 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.05426</td><td style=\"text-align: right;\">      -1.64346 </td></tr>\n",
       "<tr><td>training_function_83ea7_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.00994 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.96082</td><td style=\"text-align: right;\">      -1.00994 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (10 PENDING, 5 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00015:\n",
      "  date: 2021-08-31_19-53-37\n",
      "  done: true\n",
      "  experiment_id: fb67d704bc014204b46b4a34fa1d6468\n",
      "  experiment_tag: 15_GAMMA=0.8,THETA=0.003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.509602922833232\n",
      "  neg_mean_loss: -1.509602922833232\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19157\n",
      "  time_since_restore: 5.804209470748901\n",
      "  time_this_iter_s: 5.804209470748901\n",
      "  time_total_s: 5.804209470748901\n",
      "  timestamp: 1630410817\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00015\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19162)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=19162)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19162)\u001b[0m frac:0.6586538461538461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19162)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19162)\u001b[0m \r",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00016:\n",
      "  date: 2021-08-31_19-53-52\n",
      "  done: false\n",
      "  experiment_id: 4949b1f90c604dcdabf58c0fa37d6320\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.833047998860561\n",
      "  neg_mean_loss: -0.833047998860561\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19162\n",
      "  time_since_restore: 4.84429407119751\n",
      "  time_this_iter_s: 4.84429407119751\n",
      "  time_total_s: 4.84429407119751\n",
      "  timestamp: 1630410832\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00016\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19162)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19162)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 190.5/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/1.0 accelerator_type:V, 0.0/16.0 CPU_group_0_39635c4cfd6e69283cd99a75d52ae243)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 36/36 (19 PENDING, 1 RUNNING, 16 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00016</td><td>RUNNING   </td><td>202.117.43.132:19162</td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">0.833048</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.84429</td><td style=\"text-align: right;\">      -0.833048</td></tr>\n",
       "<tr><td>training_function_83ea7_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00020</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00021</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00022</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00023</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00024</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00025</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00026</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.45078 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.5344 </td><td style=\"text-align: right;\">      -1.45078 </td></tr>\n",
       "<tr><td>training_function_83ea7_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.927495</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.10901</td><td style=\"text-align: right;\">      -0.927495</td></tr>\n",
       "<tr><td>training_function_83ea7_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.969247</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.40537</td><td style=\"text-align: right;\">      -0.969247</td></tr>\n",
       "<tr><td>training_function_83ea7_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.88233 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.79444</td><td style=\"text-align: right;\">      -1.88233 </td></tr>\n",
       "<tr><td>training_function_83ea7_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.41734 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.00366</td><td style=\"text-align: right;\">      -1.41734 </td></tr>\n",
       "<tr><td>training_function_83ea7_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.49725 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.40248</td><td style=\"text-align: right;\">      -1.49725 </td></tr>\n",
       "<tr><td>training_function_83ea7_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.06618 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.3496 </td><td style=\"text-align: right;\">      -1.06618 </td></tr>\n",
       "<tr><td>training_function_83ea7_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.0096  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.19293</td><td style=\"text-align: right;\">      -1.0096  </td></tr>\n",
       "<tr><td>training_function_83ea7_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.64346 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.05426</td><td style=\"text-align: right;\">      -1.64346 </td></tr>\n",
       "<tr><td>training_function_83ea7_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.00994 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.96082</td><td style=\"text-align: right;\">      -1.00994 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (9 PENDING, 6 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00016:\n",
      "  date: 2021-08-31_19-53-52\n",
      "  done: true\n",
      "  experiment_id: 4949b1f90c604dcdabf58c0fa37d6320\n",
      "  experiment_tag: 16_GAMMA=0.7,THETA=0.003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.833047998860561\n",
      "  neg_mean_loss: -0.833047998860561\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19162\n",
      "  time_since_restore: 4.84429407119751\n",
      "  time_this_iter_s: 4.84429407119751\n",
      "  time_total_s: 4.84429407119751\n",
      "  timestamp: 1630410832\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00016\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19161)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=19161)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19161)\u001b[0m frac:0.59375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19161)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19161)\u001b[0m \r",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00017:\n",
      "  date: 2021-08-31_19-54-04\n",
      "  done: false\n",
      "  experiment_id: 85f8b341341f4e4cb19f59d4006483de\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.833047998860561\n",
      "  neg_mean_loss: -0.833047998860561\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19161\n",
      "  time_since_restore: 4.149033308029175\n",
      "  time_this_iter_s: 4.149033308029175\n",
      "  time_total_s: 4.149033308029175\n",
      "  timestamp: 1630410844\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00017\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19161)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19161)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 190.5/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/16.0 CPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_39635c4cfd6e69283cd99a75d52ae243)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 36/36 (18 PENDING, 1 RUNNING, 17 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00017</td><td>RUNNING   </td><td>202.117.43.132:19161</td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">0.833048</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.14903</td><td style=\"text-align: right;\">      -0.833048</td></tr>\n",
       "<tr><td>training_function_83ea7_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00020</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00021</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00022</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00023</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00024</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00025</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00026</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00027</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.45078 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.5344 </td><td style=\"text-align: right;\">      -1.45078 </td></tr>\n",
       "<tr><td>training_function_83ea7_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.927495</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.10901</td><td style=\"text-align: right;\">      -0.927495</td></tr>\n",
       "<tr><td>training_function_83ea7_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.969247</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.40537</td><td style=\"text-align: right;\">      -0.969247</td></tr>\n",
       "<tr><td>training_function_83ea7_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.88233 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.79444</td><td style=\"text-align: right;\">      -1.88233 </td></tr>\n",
       "<tr><td>training_function_83ea7_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.41734 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.00366</td><td style=\"text-align: right;\">      -1.41734 </td></tr>\n",
       "<tr><td>training_function_83ea7_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.49725 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.40248</td><td style=\"text-align: right;\">      -1.49725 </td></tr>\n",
       "<tr><td>training_function_83ea7_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.06618 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.3496 </td><td style=\"text-align: right;\">      -1.06618 </td></tr>\n",
       "<tr><td>training_function_83ea7_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.0096  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.19293</td><td style=\"text-align: right;\">      -1.0096  </td></tr>\n",
       "<tr><td>training_function_83ea7_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.64346 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.05426</td><td style=\"text-align: right;\">      -1.64346 </td></tr>\n",
       "<tr><td>training_function_83ea7_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.00994 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.96082</td><td style=\"text-align: right;\">      -1.00994 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (8 PENDING, 7 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00017:\n",
      "  date: 2021-08-31_19-54-04\n",
      "  done: true\n",
      "  experiment_id: 85f8b341341f4e4cb19f59d4006483de\n",
      "  experiment_tag: 17_GAMMA=0.6,THETA=0.003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.833047998860561\n",
      "  neg_mean_loss: -0.833047998860561\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19161\n",
      "  time_since_restore: 4.149033308029175\n",
      "  time_this_iter_s: 4.149033308029175\n",
      "  time_total_s: 4.149033308029175\n",
      "  timestamp: 1630410844\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00017\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19152)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=19152)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19152)\u001b[0m frac:0.7355769230769231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19152)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=19152)\u001b[0m \n",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00018:\n",
      "  date: 2021-08-31_19-54-20\n",
      "  done: false\n",
      "  experiment_id: 6849b95776444c9fb9757e1f972016db\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.3330479988605612\n",
      "  neg_mean_loss: -1.3330479988605612\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19152\n",
      "  time_since_restore: 7.80083703994751\n",
      "  time_this_iter_s: 7.80083703994751\n",
      "  time_total_s: 7.80083703994751\n",
      "  timestamp: 1630410860\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00018\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 190.4/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/1.0 accelerator_type:V)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 36/36 (17 PENDING, 1 RUNNING, 18 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00018</td><td>RUNNING   </td><td>202.117.43.132:19152</td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">1.33305 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.80084</td><td style=\"text-align: right;\">      -1.33305 </td></tr>\n",
       "<tr><td>training_function_83ea7_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00020</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00021</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00022</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00023</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00024</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00025</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00026</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00027</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00028</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.45078 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.5344 </td><td style=\"text-align: right;\">      -1.45078 </td></tr>\n",
       "<tr><td>training_function_83ea7_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.927495</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.10901</td><td style=\"text-align: right;\">      -0.927495</td></tr>\n",
       "<tr><td>training_function_83ea7_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.969247</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.40537</td><td style=\"text-align: right;\">      -0.969247</td></tr>\n",
       "<tr><td>training_function_83ea7_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.88233 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.79444</td><td style=\"text-align: right;\">      -1.88233 </td></tr>\n",
       "<tr><td>training_function_83ea7_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.41734 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.00366</td><td style=\"text-align: right;\">      -1.41734 </td></tr>\n",
       "<tr><td>training_function_83ea7_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.49725 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.40248</td><td style=\"text-align: right;\">      -1.49725 </td></tr>\n",
       "<tr><td>training_function_83ea7_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.06618 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.3496 </td><td style=\"text-align: right;\">      -1.06618 </td></tr>\n",
       "<tr><td>training_function_83ea7_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.0096  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.19293</td><td style=\"text-align: right;\">      -1.0096  </td></tr>\n",
       "<tr><td>training_function_83ea7_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.64346 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.05426</td><td style=\"text-align: right;\">      -1.64346 </td></tr>\n",
       "<tr><td>training_function_83ea7_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.00994 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.96082</td><td style=\"text-align: right;\">      -1.00994 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (7 PENDING, 8 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00018:\n",
      "  date: 2021-08-31_19-54-20\n",
      "  done: true\n",
      "  experiment_id: 6849b95776444c9fb9757e1f972016db\n",
      "  experiment_tag: 18_GAMMA=0.95,THETA=0.001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.3330479988605612\n",
      "  neg_mean_loss: -1.3330479988605612\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19152\n",
      "  time_since_restore: 7.80083703994751\n",
      "  time_this_iter_s: 7.80083703994751\n",
      "  time_total_s: 7.80083703994751\n",
      "  timestamp: 1630410860\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00018\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19164)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=19164)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19164)\u001b[0m frac:0.6995192307692307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19164)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19164)\u001b[0m \r",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00019:\n",
      "  date: 2021-08-31_19-54-38\n",
      "  done: false\n",
      "  experiment_id: cebbfa84b8fe4e6e9a3297b684bf4a5d\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.7439134976024308\n",
      "  neg_mean_loss: -0.7439134976024308\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19164\n",
      "  time_since_restore: 7.130706310272217\n",
      "  time_this_iter_s: 7.130706310272217\n",
      "  time_total_s: 7.130706310272217\n",
      "  timestamp: 1630410878\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00019\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19164)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19164)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 190.4/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_0_39635c4cfd6e69283cd99a75d52ae243)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 36/36 (16 PENDING, 1 RUNNING, 19 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00019</td><td>RUNNING   </td><td>202.117.43.132:19164</td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">0.743913</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.13071</td><td style=\"text-align: right;\">      -0.743913</td></tr>\n",
       "<tr><td>training_function_83ea7_00020</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00021</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00022</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00023</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00024</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00025</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00026</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00027</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00028</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00029</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.45078 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.5344 </td><td style=\"text-align: right;\">      -1.45078 </td></tr>\n",
       "<tr><td>training_function_83ea7_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.927495</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.10901</td><td style=\"text-align: right;\">      -0.927495</td></tr>\n",
       "<tr><td>training_function_83ea7_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.969247</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.40537</td><td style=\"text-align: right;\">      -0.969247</td></tr>\n",
       "<tr><td>training_function_83ea7_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.88233 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.79444</td><td style=\"text-align: right;\">      -1.88233 </td></tr>\n",
       "<tr><td>training_function_83ea7_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.41734 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.00366</td><td style=\"text-align: right;\">      -1.41734 </td></tr>\n",
       "<tr><td>training_function_83ea7_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.49725 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.40248</td><td style=\"text-align: right;\">      -1.49725 </td></tr>\n",
       "<tr><td>training_function_83ea7_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.06618 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.3496 </td><td style=\"text-align: right;\">      -1.06618 </td></tr>\n",
       "<tr><td>training_function_83ea7_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.0096  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.19293</td><td style=\"text-align: right;\">      -1.0096  </td></tr>\n",
       "<tr><td>training_function_83ea7_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.64346 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.05426</td><td style=\"text-align: right;\">      -1.64346 </td></tr>\n",
       "<tr><td>training_function_83ea7_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.00994 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.96082</td><td style=\"text-align: right;\">      -1.00994 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (6 PENDING, 9 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00019:\n",
      "  date: 2021-08-31_19-54-38\n",
      "  done: true\n",
      "  experiment_id: cebbfa84b8fe4e6e9a3297b684bf4a5d\n",
      "  experiment_tag: 19_GAMMA=0.9,THETA=0.001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.7439134976024308\n",
      "  neg_mean_loss: -0.7439134976024308\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19164\n",
      "  time_since_restore: 7.130706310272217\n",
      "  time_this_iter_s: 7.130706310272217\n",
      "  time_total_s: 7.130706310272217\n",
      "  timestamp: 1630410878\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00019\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19153)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=19153)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19153)\u001b[0m frac:0.6754807692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19153)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19153)\u001b[0m \r",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00020:\n",
      "  date: 2021-08-31_19-54-53\n",
      "  done: false\n",
      "  experiment_id: d4dc555066b64fc783d6739b9b726aac\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.4692469021506906\n",
      "  neg_mean_loss: -1.4692469021506906\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19153\n",
      "  time_since_restore: 6.384439468383789\n",
      "  time_this_iter_s: 6.384439468383789\n",
      "  time_total_s: 6.384439468383789\n",
      "  timestamp: 1630410893\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00020\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19153)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19153)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 191.0/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/16.0 CPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_39635c4cfd6e69283cd99a75d52ae243)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 36/36 (15 PENDING, 1 RUNNING, 20 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00020</td><td>RUNNING   </td><td>202.117.43.132:19153</td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">1.46925 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.38444</td><td style=\"text-align: right;\">      -1.46925 </td></tr>\n",
       "<tr><td>training_function_83ea7_00021</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00022</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00023</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00024</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00025</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00026</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00027</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00028</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00029</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00030</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.45078 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.5344 </td><td style=\"text-align: right;\">      -1.45078 </td></tr>\n",
       "<tr><td>training_function_83ea7_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.927495</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.10901</td><td style=\"text-align: right;\">      -0.927495</td></tr>\n",
       "<tr><td>training_function_83ea7_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.969247</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.40537</td><td style=\"text-align: right;\">      -0.969247</td></tr>\n",
       "<tr><td>training_function_83ea7_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.88233 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.79444</td><td style=\"text-align: right;\">      -1.88233 </td></tr>\n",
       "<tr><td>training_function_83ea7_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.41734 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.00366</td><td style=\"text-align: right;\">      -1.41734 </td></tr>\n",
       "<tr><td>training_function_83ea7_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.49725 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.40248</td><td style=\"text-align: right;\">      -1.49725 </td></tr>\n",
       "<tr><td>training_function_83ea7_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.06618 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.3496 </td><td style=\"text-align: right;\">      -1.06618 </td></tr>\n",
       "<tr><td>training_function_83ea7_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.0096  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.19293</td><td style=\"text-align: right;\">      -1.0096  </td></tr>\n",
       "<tr><td>training_function_83ea7_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.64346 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.05426</td><td style=\"text-align: right;\">      -1.64346 </td></tr>\n",
       "<tr><td>training_function_83ea7_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.00994 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.96082</td><td style=\"text-align: right;\">      -1.00994 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (5 PENDING, 10 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00020:\n",
      "  date: 2021-08-31_19-54-53\n",
      "  done: true\n",
      "  experiment_id: d4dc555066b64fc783d6739b9b726aac\n",
      "  experiment_tag: 20_GAMMA=0.85,THETA=0.001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.4692469021506906\n",
      "  neg_mean_loss: -1.4692469021506906\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 19153\n",
      "  time_since_restore: 6.384439468383789\n",
      "  time_this_iter_s: 6.384439468383789\n",
      "  time_total_s: 6.384439468383789\n",
      "  timestamp: 1630410893\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00020\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=2601)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=2601)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2601)\u001b[0m frac:0.6826923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2601)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2601)\u001b[0m \r",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00021:\n",
      "  date: 2021-08-31_19-55-08\n",
      "  done: false\n",
      "  experiment_id: 5f9a2c99c3a848b4aeaf87c6ff39d37e\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.7185927930494231\n",
      "  neg_mean_loss: -1.7185927930494231\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 2601\n",
      "  time_since_restore: 6.265440225601196\n",
      "  time_this_iter_s: 6.265440225601196\n",
      "  time_total_s: 6.265440225601196\n",
      "  timestamp: 1630410908\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00021\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2601)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2601)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 191.3/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/16.0 CPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/1.0 accelerator_type:V, 0.0/16.0 CPU_group_39635c4cfd6e69283cd99a75d52ae243)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 36/36 (14 PENDING, 1 RUNNING, 21 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00021</td><td>RUNNING   </td><td>202.117.43.132:2601</td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">1.71859 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.26544</td><td style=\"text-align: right;\">      -1.71859 </td></tr>\n",
       "<tr><td>training_function_83ea7_00022</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00023</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00024</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00025</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00026</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00027</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00028</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00029</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00030</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00031</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.45078 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.5344 </td><td style=\"text-align: right;\">      -1.45078 </td></tr>\n",
       "<tr><td>training_function_83ea7_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.927495</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.10901</td><td style=\"text-align: right;\">      -0.927495</td></tr>\n",
       "<tr><td>training_function_83ea7_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.969247</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.40537</td><td style=\"text-align: right;\">      -0.969247</td></tr>\n",
       "<tr><td>training_function_83ea7_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.88233 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.79444</td><td style=\"text-align: right;\">      -1.88233 </td></tr>\n",
       "<tr><td>training_function_83ea7_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.41734 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.00366</td><td style=\"text-align: right;\">      -1.41734 </td></tr>\n",
       "<tr><td>training_function_83ea7_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.49725 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.40248</td><td style=\"text-align: right;\">      -1.49725 </td></tr>\n",
       "<tr><td>training_function_83ea7_00006</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.06618 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.3496 </td><td style=\"text-align: right;\">      -1.06618 </td></tr>\n",
       "<tr><td>training_function_83ea7_00007</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.0096  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.19293</td><td style=\"text-align: right;\">      -1.0096  </td></tr>\n",
       "<tr><td>training_function_83ea7_00008</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.64346 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.05426</td><td style=\"text-align: right;\">      -1.64346 </td></tr>\n",
       "<tr><td>training_function_83ea7_00009</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.00994 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.96082</td><td style=\"text-align: right;\">      -1.00994 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (4 PENDING, 11 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00021:\n",
      "  date: 2021-08-31_19-55-08\n",
      "  done: true\n",
      "  experiment_id: 5f9a2c99c3a848b4aeaf87c6ff39d37e\n",
      "  experiment_tag: 21_GAMMA=0.8,THETA=0.001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.7185927930494231\n",
      "  neg_mean_loss: -1.7185927930494231\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 2601\n",
      "  time_since_restore: 6.265440225601196\n",
      "  time_this_iter_s: 6.265440225601196\n",
      "  time_total_s: 6.265440225601196\n",
      "  timestamp: 1630410908\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00021\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=3583)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=3583)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=3583)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3583)\u001b[0m frac:0.6033653846153846\n",
      "Result for training_function_83ea7_00022:\n",
      "  date: 2021-08-31_19-55-22\n",
      "  done: false\n",
      "  experiment_id: e5dc372b18f94e26853bd1563205d190\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.8417411312859451\n",
      "  neg_mean_loss: -0.8417411312859451\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3583\n",
      "  time_since_restore: 4.325321912765503\n",
      "  time_this_iter_s: 4.325321912765503\n",
      "  time_total_s: 4.325321912765503\n",
      "  timestamp: 1630410922\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00022\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3583)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=3583)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 191.3/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/16.0 CPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_39635c4cfd6e69283cd99a75d52ae243)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 36/36 (13 PENDING, 1 RUNNING, 22 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00022</td><td>RUNNING   </td><td>202.117.43.132:3583</td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">0.841741</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.32532</td><td style=\"text-align: right;\">      -0.841741</td></tr>\n",
       "<tr><td>training_function_83ea7_00023</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00024</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00025</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00026</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00027</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00028</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00029</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00030</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00031</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00032</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.45078 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.5344 </td><td style=\"text-align: right;\">      -1.45078 </td></tr>\n",
       "<tr><td>training_function_83ea7_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.927495</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.10901</td><td style=\"text-align: right;\">      -0.927495</td></tr>\n",
       "<tr><td>training_function_83ea7_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.969247</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.40537</td><td style=\"text-align: right;\">      -0.969247</td></tr>\n",
       "<tr><td>training_function_83ea7_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.88233 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.79444</td><td style=\"text-align: right;\">      -1.88233 </td></tr>\n",
       "<tr><td>training_function_83ea7_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.41734 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.00366</td><td style=\"text-align: right;\">      -1.41734 </td></tr>\n",
       "<tr><td>training_function_83ea7_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.49725 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.40248</td><td style=\"text-align: right;\">      -1.49725 </td></tr>\n",
       "<tr><td>training_function_83ea7_00006</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.06618 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.3496 </td><td style=\"text-align: right;\">      -1.06618 </td></tr>\n",
       "<tr><td>training_function_83ea7_00007</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.0096  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.19293</td><td style=\"text-align: right;\">      -1.0096  </td></tr>\n",
       "<tr><td>training_function_83ea7_00008</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.64346 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.05426</td><td style=\"text-align: right;\">      -1.64346 </td></tr>\n",
       "<tr><td>training_function_83ea7_00009</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.00994 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.96082</td><td style=\"text-align: right;\">      -1.00994 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (3 PENDING, 12 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00022:\n",
      "  date: 2021-08-31_19-55-22\n",
      "  done: true\n",
      "  experiment_id: e5dc372b18f94e26853bd1563205d190\n",
      "  experiment_tag: 22_GAMMA=0.7,THETA=0.001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.8417411312859451\n",
      "  neg_mean_loss: -0.8417411312859451\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3583\n",
      "  time_since_restore: 4.325321912765503\n",
      "  time_this_iter_s: 4.325321912765503\n",
      "  time_total_s: 4.325321912765503\n",
      "  timestamp: 1630410922\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00022\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=4293)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=4293)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=4293)\u001b[0m frac:0.6514423076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=4293)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=4293)\u001b[0m \r",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00023:\n",
      "  date: 2021-08-31_19-55-37\n",
      "  done: false\n",
      "  experiment_id: e1ee849cd60b44f5a5f463a676a10ade\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.2894838679047345\n",
      "  neg_mean_loss: -1.2894838679047345\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 4293\n",
      "  time_since_restore: 4.3502843379974365\n",
      "  time_this_iter_s: 4.3502843379974365\n",
      "  time_total_s: 4.3502843379974365\n",
      "  timestamp: 1630410937\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00023\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=4293)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=4293)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 191.3/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/1.0 accelerator_type:V, 0.0/16.0 CPU_group_39635c4cfd6e69283cd99a75d52ae243)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 36/36 (12 PENDING, 1 RUNNING, 23 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00023</td><td>RUNNING   </td><td>202.117.43.132:4293</td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">1.28948 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.35028</td><td style=\"text-align: right;\">      -1.28948 </td></tr>\n",
       "<tr><td>training_function_83ea7_00024</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00025</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00026</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00027</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00028</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00029</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00030</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00031</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00032</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00033</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.45078 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.5344 </td><td style=\"text-align: right;\">      -1.45078 </td></tr>\n",
       "<tr><td>training_function_83ea7_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.927495</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.10901</td><td style=\"text-align: right;\">      -0.927495</td></tr>\n",
       "<tr><td>training_function_83ea7_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.969247</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.40537</td><td style=\"text-align: right;\">      -0.969247</td></tr>\n",
       "<tr><td>training_function_83ea7_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.88233 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.79444</td><td style=\"text-align: right;\">      -1.88233 </td></tr>\n",
       "<tr><td>training_function_83ea7_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.41734 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.00366</td><td style=\"text-align: right;\">      -1.41734 </td></tr>\n",
       "<tr><td>training_function_83ea7_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.49725 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.40248</td><td style=\"text-align: right;\">      -1.49725 </td></tr>\n",
       "<tr><td>training_function_83ea7_00006</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.06618 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.3496 </td><td style=\"text-align: right;\">      -1.06618 </td></tr>\n",
       "<tr><td>training_function_83ea7_00007</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.0096  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.19293</td><td style=\"text-align: right;\">      -1.0096  </td></tr>\n",
       "<tr><td>training_function_83ea7_00008</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.64346 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.05426</td><td style=\"text-align: right;\">      -1.64346 </td></tr>\n",
       "<tr><td>training_function_83ea7_00009</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.00994 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.96082</td><td style=\"text-align: right;\">      -1.00994 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (2 PENDING, 13 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00023:\n",
      "  date: 2021-08-31_19-55-37\n",
      "  done: true\n",
      "  experiment_id: e1ee849cd60b44f5a5f463a676a10ade\n",
      "  experiment_tag: 23_GAMMA=0.6,THETA=0.001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.2894838679047345\n",
      "  neg_mean_loss: -1.2894838679047345\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 4293\n",
      "  time_since_restore: 4.3502843379974365\n",
      "  time_this_iter_s: 4.3502843379974365\n",
      "  time_total_s: 4.3502843379974365\n",
      "  timestamp: 1630410937\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00023\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=4652)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=4652)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=4652)\u001b[0m frac:0.6923076923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=4652)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=4652)\u001b[0m \r",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00024:\n",
      "  date: 2021-08-31_19-55-55\n",
      "  done: false\n",
      "  experiment_id: 9452f83ad41c483a8f0c86f51d240369\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.289144884853887\n",
      "  neg_mean_loss: -1.289144884853887\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 4652\n",
      "  time_since_restore: 7.92667031288147\n",
      "  time_this_iter_s: 7.92667031288147\n",
      "  time_total_s: 7.92667031288147\n",
      "  timestamp: 1630410955\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00024\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=4652)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=4652)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 191.3/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/16.0 CPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_39635c4cfd6e69283cd99a75d52ae243)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 36/36 (11 PENDING, 1 RUNNING, 24 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00024</td><td>RUNNING   </td><td>202.117.43.132:4652</td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">1.28914 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.92667</td><td style=\"text-align: right;\">      -1.28914 </td></tr>\n",
       "<tr><td>training_function_83ea7_00025</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00026</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00027</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00028</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00029</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00030</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00031</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00032</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00033</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00034</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.45078 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.5344 </td><td style=\"text-align: right;\">      -1.45078 </td></tr>\n",
       "<tr><td>training_function_83ea7_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.927495</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.10901</td><td style=\"text-align: right;\">      -0.927495</td></tr>\n",
       "<tr><td>training_function_83ea7_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.969247</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.40537</td><td style=\"text-align: right;\">      -0.969247</td></tr>\n",
       "<tr><td>training_function_83ea7_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.88233 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.79444</td><td style=\"text-align: right;\">      -1.88233 </td></tr>\n",
       "<tr><td>training_function_83ea7_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.41734 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.00366</td><td style=\"text-align: right;\">      -1.41734 </td></tr>\n",
       "<tr><td>training_function_83ea7_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.49725 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.40248</td><td style=\"text-align: right;\">      -1.49725 </td></tr>\n",
       "<tr><td>training_function_83ea7_00006</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.06618 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.3496 </td><td style=\"text-align: right;\">      -1.06618 </td></tr>\n",
       "<tr><td>training_function_83ea7_00007</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.0096  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.19293</td><td style=\"text-align: right;\">      -1.0096  </td></tr>\n",
       "<tr><td>training_function_83ea7_00008</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.64346 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.05426</td><td style=\"text-align: right;\">      -1.64346 </td></tr>\n",
       "<tr><td>training_function_83ea7_00009</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.00994 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.96082</td><td style=\"text-align: right;\">      -1.00994 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (1 PENDING, 14 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00024:\n",
      "  date: 2021-08-31_19-55-55\n",
      "  done: true\n",
      "  experiment_id: 9452f83ad41c483a8f0c86f51d240369\n",
      "  experiment_tag: 24_GAMMA=0.95,THETA=0.0003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.289144884853887\n",
      "  neg_mean_loss: -1.289144884853887\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 4652\n",
      "  time_since_restore: 7.92667031288147\n",
      "  time_this_iter_s: 7.92667031288147\n",
      "  time_total_s: 7.92667031288147\n",
      "  timestamp: 1630410955\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00024\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=5124)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=5124)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=5124)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=5124)\u001b[0m frac:0.7307692307692307\n",
      "Result for training_function_83ea7_00025:\n",
      "  date: 2021-08-31_19-56-11\n",
      "  done: false\n",
      "  experiment_id: 6545f4998e6547b6b6dcd75930d86d54\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.4767955872641816\n",
      "  neg_mean_loss: -1.4767955872641816\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 5124\n",
      "  time_since_restore: 7.288180112838745\n",
      "  time_this_iter_s: 7.288180112838745\n",
      "  time_total_s: 7.288180112838745\n",
      "  timestamp: 1630410971\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00025\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=5124)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=5124)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 191.3/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/16.0 CPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_0_39635c4cfd6e69283cd99a75d52ae243)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 36/36 (10 PENDING, 1 RUNNING, 25 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00025</td><td>RUNNING   </td><td>202.117.43.132:5124</td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">1.4768  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.28818</td><td style=\"text-align: right;\">      -1.4768  </td></tr>\n",
       "<tr><td>training_function_83ea7_00026</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00027</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00028</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00029</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00030</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00031</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00032</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00033</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00034</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00035</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.45078 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.5344 </td><td style=\"text-align: right;\">      -1.45078 </td></tr>\n",
       "<tr><td>training_function_83ea7_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.927495</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.10901</td><td style=\"text-align: right;\">      -0.927495</td></tr>\n",
       "<tr><td>training_function_83ea7_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.969247</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.40537</td><td style=\"text-align: right;\">      -0.969247</td></tr>\n",
       "<tr><td>training_function_83ea7_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.88233 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.79444</td><td style=\"text-align: right;\">      -1.88233 </td></tr>\n",
       "<tr><td>training_function_83ea7_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.41734 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.00366</td><td style=\"text-align: right;\">      -1.41734 </td></tr>\n",
       "<tr><td>training_function_83ea7_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.49725 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.40248</td><td style=\"text-align: right;\">      -1.49725 </td></tr>\n",
       "<tr><td>training_function_83ea7_00006</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.06618 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.3496 </td><td style=\"text-align: right;\">      -1.06618 </td></tr>\n",
       "<tr><td>training_function_83ea7_00007</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.0096  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.19293</td><td style=\"text-align: right;\">      -1.0096  </td></tr>\n",
       "<tr><td>training_function_83ea7_00008</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.64346 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.05426</td><td style=\"text-align: right;\">      -1.64346 </td></tr>\n",
       "<tr><td>training_function_83ea7_00009</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.00994 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.96082</td><td style=\"text-align: right;\">      -1.00994 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (15 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00025:\n",
      "  date: 2021-08-31_19-56-11\n",
      "  done: true\n",
      "  experiment_id: 6545f4998e6547b6b6dcd75930d86d54\n",
      "  experiment_tag: 25_GAMMA=0.9,THETA=0.0003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.4767955872641816\n",
      "  neg_mean_loss: -1.4767955872641816\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 5124\n",
      "  time_since_restore: 7.288180112838745\n",
      "  time_this_iter_s: 7.288180112838745\n",
      "  time_total_s: 7.288180112838745\n",
      "  timestamp: 1630410971\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00025\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=5140)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=5140)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=5140)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=5140)\u001b[0m frac:0.6418269230769231\n",
      "Result for training_function_83ea7_00026:\n",
      "  date: 2021-08-31_19-56-28\n",
      "  done: false\n",
      "  experiment_id: 0ffcd48072f34c25ae7456afe1a4a1e5\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.5875074775672982\n",
      "  neg_mean_loss: -1.5875074775672982\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 5140\n",
      "  time_since_restore: 6.508587598800659\n",
      "  time_this_iter_s: 6.508587598800659\n",
      "  time_total_s: 6.508587598800659\n",
      "  timestamp: 1630410988\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00026\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=5140)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=5140)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 191.3/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/16.0 CPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/1.0 accelerator_type:V, 0.0/16.0 CPU_group_0_39635c4cfd6e69283cd99a75d52ae243)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 36/36 (9 PENDING, 1 RUNNING, 26 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00026</td><td>RUNNING   </td><td>202.117.43.132:5140</td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">1.58751 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.50859</td><td style=\"text-align: right;\">      -1.58751 </td></tr>\n",
       "<tr><td>training_function_83ea7_00027</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00028</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00029</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00030</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00031</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00032</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00033</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00034</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00035</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.45078 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.5344 </td><td style=\"text-align: right;\">      -1.45078 </td></tr>\n",
       "<tr><td>training_function_83ea7_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.927495</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.10901</td><td style=\"text-align: right;\">      -0.927495</td></tr>\n",
       "<tr><td>training_function_83ea7_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.969247</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.40537</td><td style=\"text-align: right;\">      -0.969247</td></tr>\n",
       "<tr><td>training_function_83ea7_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.88233 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.79444</td><td style=\"text-align: right;\">      -1.88233 </td></tr>\n",
       "<tr><td>training_function_83ea7_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.41734 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.00366</td><td style=\"text-align: right;\">      -1.41734 </td></tr>\n",
       "<tr><td>training_function_83ea7_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.49725 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.40248</td><td style=\"text-align: right;\">      -1.49725 </td></tr>\n",
       "<tr><td>training_function_83ea7_00006</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.06618 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.3496 </td><td style=\"text-align: right;\">      -1.06618 </td></tr>\n",
       "<tr><td>training_function_83ea7_00007</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.0096  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.19293</td><td style=\"text-align: right;\">      -1.0096  </td></tr>\n",
       "<tr><td>training_function_83ea7_00008</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.64346 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.05426</td><td style=\"text-align: right;\">      -1.64346 </td></tr>\n",
       "<tr><td>training_function_83ea7_00009</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.00994 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.96082</td><td style=\"text-align: right;\">      -1.00994 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00026:\n",
      "  date: 2021-08-31_19-56-28\n",
      "  done: true\n",
      "  experiment_id: 0ffcd48072f34c25ae7456afe1a4a1e5\n",
      "  experiment_tag: 26_GAMMA=0.85,THETA=0.0003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.5875074775672982\n",
      "  neg_mean_loss: -1.5875074775672982\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 5140\n",
      "  time_since_restore: 6.508587598800659\n",
      "  time_this_iter_s: 6.508587598800659\n",
      "  time_total_s: 6.508587598800659\n",
      "  timestamp: 1630410988\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00026\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=6215)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=6215)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=6215)\u001b[0m frac:0.7211538461538461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=6215)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=6215)\u001b[0m \r",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00027:\n",
      "  date: 2021-08-31_19-56-42\n",
      "  done: false\n",
      "  experiment_id: bfe9fadacb644f72890d579a01364614\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.9695858852015382\n",
      "  neg_mean_loss: -0.9695858852015382\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 6215\n",
      "  time_since_restore: 5.412268400192261\n",
      "  time_this_iter_s: 5.412268400192261\n",
      "  time_total_s: 5.412268400192261\n",
      "  timestamp: 1630411002\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00027\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=6215)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=6215)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 191.3/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/1.0 accelerator_type:V, 0.0/16.0 CPU_group_39635c4cfd6e69283cd99a75d52ae243)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 36/36 (8 PENDING, 1 RUNNING, 27 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00027</td><td>RUNNING   </td><td>202.117.43.132:6215</td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">0.969586</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.41227</td><td style=\"text-align: right;\">      -0.969586</td></tr>\n",
       "<tr><td>training_function_83ea7_00028</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00029</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00030</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00031</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00032</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00033</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00034</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00035</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.45078 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.5344 </td><td style=\"text-align: right;\">      -1.45078 </td></tr>\n",
       "<tr><td>training_function_83ea7_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.927495</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.10901</td><td style=\"text-align: right;\">      -0.927495</td></tr>\n",
       "<tr><td>training_function_83ea7_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.969247</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.40537</td><td style=\"text-align: right;\">      -0.969247</td></tr>\n",
       "<tr><td>training_function_83ea7_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.88233 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.79444</td><td style=\"text-align: right;\">      -1.88233 </td></tr>\n",
       "<tr><td>training_function_83ea7_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.41734 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.00366</td><td style=\"text-align: right;\">      -1.41734 </td></tr>\n",
       "<tr><td>training_function_83ea7_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.49725 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.40248</td><td style=\"text-align: right;\">      -1.49725 </td></tr>\n",
       "<tr><td>training_function_83ea7_00006</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.06618 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.3496 </td><td style=\"text-align: right;\">      -1.06618 </td></tr>\n",
       "<tr><td>training_function_83ea7_00007</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.0096  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.19293</td><td style=\"text-align: right;\">      -1.0096  </td></tr>\n",
       "<tr><td>training_function_83ea7_00008</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.64346 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.05426</td><td style=\"text-align: right;\">      -1.64346 </td></tr>\n",
       "<tr><td>training_function_83ea7_00009</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.00994 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.96082</td><td style=\"text-align: right;\">      -1.00994 </td></tr>\n",
       "<tr><td>training_function_83ea7_00010</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.06652 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.31664</td><td style=\"text-align: right;\">      -1.06652 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00027:\n",
      "  date: 2021-08-31_19-56-42\n",
      "  done: true\n",
      "  experiment_id: bfe9fadacb644f72890d579a01364614\n",
      "  experiment_tag: 27_GAMMA=0.8,THETA=0.0003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.9695858852015382\n",
      "  neg_mean_loss: -0.9695858852015382\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 6215\n",
      "  time_since_restore: 5.412268400192261\n",
      "  time_this_iter_s: 5.412268400192261\n",
      "  time_total_s: 5.412268400192261\n",
      "  timestamp: 1630411002\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00027\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=6731)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=6731)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=6731)\u001b[0m frac:0.6826923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=6731)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=6731)\u001b[0m \r",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00028:\n",
      "  date: 2021-08-31_19-56-56\n",
      "  done: false\n",
      "  experiment_id: 3ab81d9202ec42e181e36162ecbc4584\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.8327090158097136\n",
      "  neg_mean_loss: -0.8327090158097136\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 6731\n",
      "  time_since_restore: 4.770059585571289\n",
      "  time_this_iter_s: 4.770059585571289\n",
      "  time_total_s: 4.770059585571289\n",
      "  timestamp: 1630411016\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00028\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=6731)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=6731)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 191.3/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/1.0 accelerator_type:V, 0.0/16.0 CPU_group_0_39635c4cfd6e69283cd99a75d52ae243)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 36/36 (7 PENDING, 1 RUNNING, 28 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00028</td><td>RUNNING   </td><td>202.117.43.132:6731</td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">0.832709</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.77006</td><td style=\"text-align: right;\">      -0.832709</td></tr>\n",
       "<tr><td>training_function_83ea7_00029</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00030</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00031</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00032</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00033</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00034</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00035</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.45078 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.5344 </td><td style=\"text-align: right;\">      -1.45078 </td></tr>\n",
       "<tr><td>training_function_83ea7_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.927495</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.10901</td><td style=\"text-align: right;\">      -0.927495</td></tr>\n",
       "<tr><td>training_function_83ea7_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.969247</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.40537</td><td style=\"text-align: right;\">      -0.969247</td></tr>\n",
       "<tr><td>training_function_83ea7_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.88233 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.79444</td><td style=\"text-align: right;\">      -1.88233 </td></tr>\n",
       "<tr><td>training_function_83ea7_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.41734 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.00366</td><td style=\"text-align: right;\">      -1.41734 </td></tr>\n",
       "<tr><td>training_function_83ea7_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.49725 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.40248</td><td style=\"text-align: right;\">      -1.49725 </td></tr>\n",
       "<tr><td>training_function_83ea7_00006</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.06618 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.3496 </td><td style=\"text-align: right;\">      -1.06618 </td></tr>\n",
       "<tr><td>training_function_83ea7_00007</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.0096  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.19293</td><td style=\"text-align: right;\">      -1.0096  </td></tr>\n",
       "<tr><td>training_function_83ea7_00008</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.64346 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.05426</td><td style=\"text-align: right;\">      -1.64346 </td></tr>\n",
       "<tr><td>training_function_83ea7_00009</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.00994 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.96082</td><td style=\"text-align: right;\">      -1.00994 </td></tr>\n",
       "<tr><td>training_function_83ea7_00010</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.06652 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.31664</td><td style=\"text-align: right;\">      -1.06652 </td></tr>\n",
       "<tr><td>training_function_83ea7_00011</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">0.493949</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.61038</td><td style=\"text-align: right;\">      -0.493949</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00028:\n",
      "  date: 2021-08-31_19-56-56\n",
      "  done: true\n",
      "  experiment_id: 3ab81d9202ec42e181e36162ecbc4584\n",
      "  experiment_tag: 28_GAMMA=0.7,THETA=0.0003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.8327090158097136\n",
      "  neg_mean_loss: -0.8327090158097136\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 6731\n",
      "  time_since_restore: 4.770059585571289\n",
      "  time_this_iter_s: 4.770059585571289\n",
      "  time_total_s: 4.770059585571289\n",
      "  timestamp: 1630411016\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00028\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=7496)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=7496)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=7496)\u001b[0m frac:0.6129807692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=7496)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=7496)\u001b[0m \r",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00029:\n",
      "  date: 2021-08-31_19-57-12\n",
      "  done: false\n",
      "  experiment_id: 03082f7d4c104aee8ab72fb4136a524b\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.833047998860561\n",
      "  neg_mean_loss: -0.833047998860561\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 7496\n",
      "  time_since_restore: 4.607289791107178\n",
      "  time_this_iter_s: 4.607289791107178\n",
      "  time_total_s: 4.607289791107178\n",
      "  timestamp: 1630411032\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00029\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=7496)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=7496)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 191.3/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/1.0 accelerator_type:V, 0.0/16.0 CPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_39635c4cfd6e69283cd99a75d52ae243)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 36/36 (6 PENDING, 1 RUNNING, 29 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00029</td><td>RUNNING   </td><td>202.117.43.132:7496</td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">0.833048</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.60729</td><td style=\"text-align: right;\">      -0.833048</td></tr>\n",
       "<tr><td>training_function_83ea7_00030</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00031</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00032</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00033</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00034</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00035</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.45078 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.5344 </td><td style=\"text-align: right;\">      -1.45078 </td></tr>\n",
       "<tr><td>training_function_83ea7_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.927495</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.10901</td><td style=\"text-align: right;\">      -0.927495</td></tr>\n",
       "<tr><td>training_function_83ea7_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.969247</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.40537</td><td style=\"text-align: right;\">      -0.969247</td></tr>\n",
       "<tr><td>training_function_83ea7_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.88233 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.79444</td><td style=\"text-align: right;\">      -1.88233 </td></tr>\n",
       "<tr><td>training_function_83ea7_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.41734 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.00366</td><td style=\"text-align: right;\">      -1.41734 </td></tr>\n",
       "<tr><td>training_function_83ea7_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.49725 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.40248</td><td style=\"text-align: right;\">      -1.49725 </td></tr>\n",
       "<tr><td>training_function_83ea7_00006</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.06618 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.3496 </td><td style=\"text-align: right;\">      -1.06618 </td></tr>\n",
       "<tr><td>training_function_83ea7_00007</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.0096  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.19293</td><td style=\"text-align: right;\">      -1.0096  </td></tr>\n",
       "<tr><td>training_function_83ea7_00008</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.64346 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.05426</td><td style=\"text-align: right;\">      -1.64346 </td></tr>\n",
       "<tr><td>training_function_83ea7_00009</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.00994 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.96082</td><td style=\"text-align: right;\">      -1.00994 </td></tr>\n",
       "<tr><td>training_function_83ea7_00010</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.06652 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.31664</td><td style=\"text-align: right;\">      -1.06652 </td></tr>\n",
       "<tr><td>training_function_83ea7_00011</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">0.493949</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.61038</td><td style=\"text-align: right;\">      -0.493949</td></tr>\n",
       "<tr><td>training_function_83ea7_00012</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">1.45759 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.53264</td><td style=\"text-align: right;\">      -1.45759 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00029:\n",
      "  date: 2021-08-31_19-57-12\n",
      "  done: true\n",
      "  experiment_id: 03082f7d4c104aee8ab72fb4136a524b\n",
      "  experiment_tag: 29_GAMMA=0.6,THETA=0.0003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.833047998860561\n",
      "  neg_mean_loss: -0.833047998860561\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 7496\n",
      "  time_since_restore: 4.607289791107178\n",
      "  time_this_iter_s: 4.607289791107178\n",
      "  time_total_s: 4.607289791107178\n",
      "  timestamp: 1630411032\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00029\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=7624)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=7624)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=7624)\u001b[0m frac:0.7548076923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=7624)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=7624)\u001b[0m \r",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00030:\n",
      "  date: 2021-08-31_19-57-30\n",
      "  done: false\n",
      "  experiment_id: 1ad887f981544ff2b11ac39c867316d9\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.0912595546693256\n",
      "  neg_mean_loss: -1.0912595546693256\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 7624\n",
      "  time_since_restore: 7.780538082122803\n",
      "  time_this_iter_s: 7.780538082122803\n",
      "  time_total_s: 7.780538082122803\n",
      "  timestamp: 1630411050\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00030\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=7624)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=7624)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 191.3/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/16.0 CPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_39635c4cfd6e69283cd99a75d52ae243)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 36/36 (5 PENDING, 1 RUNNING, 30 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00030</td><td>RUNNING   </td><td>202.117.43.132:7624</td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">1.09126 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.78054</td><td style=\"text-align: right;\">      -1.09126 </td></tr>\n",
       "<tr><td>training_function_83ea7_00031</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00032</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00033</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00034</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00035</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.45078 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.5344 </td><td style=\"text-align: right;\">      -1.45078 </td></tr>\n",
       "<tr><td>training_function_83ea7_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.927495</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.10901</td><td style=\"text-align: right;\">      -0.927495</td></tr>\n",
       "<tr><td>training_function_83ea7_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.969247</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.40537</td><td style=\"text-align: right;\">      -0.969247</td></tr>\n",
       "<tr><td>training_function_83ea7_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.88233 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.79444</td><td style=\"text-align: right;\">      -1.88233 </td></tr>\n",
       "<tr><td>training_function_83ea7_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.41734 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.00366</td><td style=\"text-align: right;\">      -1.41734 </td></tr>\n",
       "<tr><td>training_function_83ea7_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.49725 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.40248</td><td style=\"text-align: right;\">      -1.49725 </td></tr>\n",
       "<tr><td>training_function_83ea7_00006</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.06618 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.3496 </td><td style=\"text-align: right;\">      -1.06618 </td></tr>\n",
       "<tr><td>training_function_83ea7_00007</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.0096  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.19293</td><td style=\"text-align: right;\">      -1.0096  </td></tr>\n",
       "<tr><td>training_function_83ea7_00008</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.64346 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.05426</td><td style=\"text-align: right;\">      -1.64346 </td></tr>\n",
       "<tr><td>training_function_83ea7_00009</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.00994 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.96082</td><td style=\"text-align: right;\">      -1.00994 </td></tr>\n",
       "<tr><td>training_function_83ea7_00010</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.06652 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.31664</td><td style=\"text-align: right;\">      -1.06652 </td></tr>\n",
       "<tr><td>training_function_83ea7_00011</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">0.493949</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.61038</td><td style=\"text-align: right;\">      -0.493949</td></tr>\n",
       "<tr><td>training_function_83ea7_00012</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">1.45759 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.53264</td><td style=\"text-align: right;\">      -1.45759 </td></tr>\n",
       "<tr><td>training_function_83ea7_00013</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">1.049   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.45392</td><td style=\"text-align: right;\">      -1.049   </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00030:\n",
      "  date: 2021-08-31_19-57-30\n",
      "  done: true\n",
      "  experiment_id: 1ad887f981544ff2b11ac39c867316d9\n",
      "  experiment_tag: 30_GAMMA=0.95,THETA=0.0001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.0912595546693256\n",
      "  neg_mean_loss: -1.0912595546693256\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 7624\n",
      "  time_since_restore: 7.780538082122803\n",
      "  time_this_iter_s: 7.780538082122803\n",
      "  time_total_s: 7.780538082122803\n",
      "  timestamp: 1630411050\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00030\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=7880)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=7880)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=7880)\u001b[0m frac:0.7403846153846154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=7880)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=7880)\u001b[0m \r",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00031:\n",
      "  date: 2021-08-31_19-57-45\n",
      "  done: false\n",
      "  experiment_id: 02565cd043f040ce959228b95c50f974\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.3330479988605612\n",
      "  neg_mean_loss: -1.3330479988605612\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 7880\n",
      "  time_since_restore: 6.221082448959351\n",
      "  time_this_iter_s: 6.221082448959351\n",
      "  time_total_s: 6.221082448959351\n",
      "  timestamp: 1630411065\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00031\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=7880)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=7880)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 191.3/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/16.0 CPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_0_39635c4cfd6e69283cd99a75d52ae243)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 36/36 (4 PENDING, 1 RUNNING, 31 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00031</td><td>RUNNING   </td><td>202.117.43.132:7880</td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">1.33305 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.22108</td><td style=\"text-align: right;\">      -1.33305 </td></tr>\n",
       "<tr><td>training_function_83ea7_00032</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00033</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00034</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00035</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.45078 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.5344 </td><td style=\"text-align: right;\">      -1.45078 </td></tr>\n",
       "<tr><td>training_function_83ea7_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.927495</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.10901</td><td style=\"text-align: right;\">      -0.927495</td></tr>\n",
       "<tr><td>training_function_83ea7_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.969247</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.40537</td><td style=\"text-align: right;\">      -0.969247</td></tr>\n",
       "<tr><td>training_function_83ea7_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.88233 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.79444</td><td style=\"text-align: right;\">      -1.88233 </td></tr>\n",
       "<tr><td>training_function_83ea7_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.41734 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.00366</td><td style=\"text-align: right;\">      -1.41734 </td></tr>\n",
       "<tr><td>training_function_83ea7_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.49725 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.40248</td><td style=\"text-align: right;\">      -1.49725 </td></tr>\n",
       "<tr><td>training_function_83ea7_00006</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.06618 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.3496 </td><td style=\"text-align: right;\">      -1.06618 </td></tr>\n",
       "<tr><td>training_function_83ea7_00007</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.0096  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.19293</td><td style=\"text-align: right;\">      -1.0096  </td></tr>\n",
       "<tr><td>training_function_83ea7_00008</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.64346 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.05426</td><td style=\"text-align: right;\">      -1.64346 </td></tr>\n",
       "<tr><td>training_function_83ea7_00009</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.00994 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.96082</td><td style=\"text-align: right;\">      -1.00994 </td></tr>\n",
       "<tr><td>training_function_83ea7_00010</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.06652 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.31664</td><td style=\"text-align: right;\">      -1.06652 </td></tr>\n",
       "<tr><td>training_function_83ea7_00011</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">0.493949</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.61038</td><td style=\"text-align: right;\">      -0.493949</td></tr>\n",
       "<tr><td>training_function_83ea7_00012</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">1.45759 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.53264</td><td style=\"text-align: right;\">      -1.45759 </td></tr>\n",
       "<tr><td>training_function_83ea7_00013</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">1.049   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.45392</td><td style=\"text-align: right;\">      -1.049   </td></tr>\n",
       "<tr><td>training_function_83ea7_00014</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">0.927834</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.1705 </td><td style=\"text-align: right;\">      -0.927834</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00031:\n",
      "  date: 2021-08-31_19-57-45\n",
      "  done: true\n",
      "  experiment_id: 02565cd043f040ce959228b95c50f974\n",
      "  experiment_tag: 31_GAMMA=0.9,THETA=0.0001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.3330479988605612\n",
      "  neg_mean_loss: -1.3330479988605612\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 7880\n",
      "  time_since_restore: 6.221082448959351\n",
      "  time_this_iter_s: 6.221082448959351\n",
      "  time_total_s: 6.221082448959351\n",
      "  timestamp: 1630411065\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00031\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=8307)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=8307)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=8307)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=8307)\u001b[0m frac:0.6995192307692307\n",
      "Result for training_function_83ea7_00032:\n",
      "  date: 2021-08-31_19-58-00\n",
      "  done: false\n",
      "  experiment_id: bfd9a0cf77ff41dab3c5a9f86dca0149\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.0489955902600323\n",
      "  neg_mean_loss: -1.0489955902600323\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 8307\n",
      "  time_since_restore: 5.837463855743408\n",
      "  time_this_iter_s: 5.837463855743408\n",
      "  time_total_s: 5.837463855743408\n",
      "  timestamp: 1630411080\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00032\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=8307)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=8307)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 191.3/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/16.0 CPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/1.0 accelerator_type:V, 0.0/16.0 CPU_group_39635c4cfd6e69283cd99a75d52ae243)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 36/36 (3 PENDING, 1 RUNNING, 32 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00032</td><td>RUNNING   </td><td>202.117.43.132:8307</td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">1.049   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.83746</td><td style=\"text-align: right;\">      -1.049   </td></tr>\n",
       "<tr><td>training_function_83ea7_00033</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00034</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00035</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.45078 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.5344 </td><td style=\"text-align: right;\">      -1.45078 </td></tr>\n",
       "<tr><td>training_function_83ea7_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.927495</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.10901</td><td style=\"text-align: right;\">      -0.927495</td></tr>\n",
       "<tr><td>training_function_83ea7_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.969247</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.40537</td><td style=\"text-align: right;\">      -0.969247</td></tr>\n",
       "<tr><td>training_function_83ea7_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.88233 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.79444</td><td style=\"text-align: right;\">      -1.88233 </td></tr>\n",
       "<tr><td>training_function_83ea7_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.41734 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.00366</td><td style=\"text-align: right;\">      -1.41734 </td></tr>\n",
       "<tr><td>training_function_83ea7_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.49725 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.40248</td><td style=\"text-align: right;\">      -1.49725 </td></tr>\n",
       "<tr><td>training_function_83ea7_00006</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.06618 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.3496 </td><td style=\"text-align: right;\">      -1.06618 </td></tr>\n",
       "<tr><td>training_function_83ea7_00007</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.0096  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.19293</td><td style=\"text-align: right;\">      -1.0096  </td></tr>\n",
       "<tr><td>training_function_83ea7_00008</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.64346 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.05426</td><td style=\"text-align: right;\">      -1.64346 </td></tr>\n",
       "<tr><td>training_function_83ea7_00009</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.00994 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.96082</td><td style=\"text-align: right;\">      -1.00994 </td></tr>\n",
       "<tr><td>training_function_83ea7_00010</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.06652 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.31664</td><td style=\"text-align: right;\">      -1.06652 </td></tr>\n",
       "<tr><td>training_function_83ea7_00011</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">0.493949</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.61038</td><td style=\"text-align: right;\">      -0.493949</td></tr>\n",
       "<tr><td>training_function_83ea7_00012</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">1.45759 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.53264</td><td style=\"text-align: right;\">      -1.45759 </td></tr>\n",
       "<tr><td>training_function_83ea7_00013</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">1.049   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.45392</td><td style=\"text-align: right;\">      -1.049   </td></tr>\n",
       "<tr><td>training_function_83ea7_00014</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">0.927834</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.1705 </td><td style=\"text-align: right;\">      -0.927834</td></tr>\n",
       "<tr><td>training_function_83ea7_00015</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">1.5096  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.80421</td><td style=\"text-align: right;\">      -1.5096  </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00032:\n",
      "  date: 2021-08-31_19-58-00\n",
      "  done: true\n",
      "  experiment_id: bfd9a0cf77ff41dab3c5a9f86dca0149\n",
      "  experiment_tag: 32_GAMMA=0.85,THETA=0.0001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.0489955902600323\n",
      "  neg_mean_loss: -1.0489955902600323\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 8307\n",
      "  time_since_restore: 5.837463855743408\n",
      "  time_this_iter_s: 5.837463855743408\n",
      "  time_total_s: 5.837463855743408\n",
      "  timestamp: 1630411080\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00032\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=9716)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=9716)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=9716)\u001b[0m frac:0.6682692307692307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=9716)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=9716)\u001b[0m \r",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00033:\n",
      "  date: 2021-08-31_19-58-18\n",
      "  done: false\n",
      "  experiment_id: 9f4e32a6561943f985f56068e03488dc\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.6978943956308414\n",
      "  neg_mean_loss: -0.6978943956308414\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 9716\n",
      "  time_since_restore: 5.936533689498901\n",
      "  time_this_iter_s: 5.936533689498901\n",
      "  time_total_s: 5.936533689498901\n",
      "  timestamp: 1630411098\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00033\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=9716)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=9716)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 191.3/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/16.0 CPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/1.0 accelerator_type:V)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 36/36 (2 PENDING, 1 RUNNING, 33 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00033</td><td>RUNNING   </td><td>202.117.43.132:9716</td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">0.697894</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.93653</td><td style=\"text-align: right;\">      -0.697894</td></tr>\n",
       "<tr><td>training_function_83ea7_00034</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00035</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.45078 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.5344 </td><td style=\"text-align: right;\">      -1.45078 </td></tr>\n",
       "<tr><td>training_function_83ea7_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.927495</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.10901</td><td style=\"text-align: right;\">      -0.927495</td></tr>\n",
       "<tr><td>training_function_83ea7_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.969247</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.40537</td><td style=\"text-align: right;\">      -0.969247</td></tr>\n",
       "<tr><td>training_function_83ea7_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.88233 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.79444</td><td style=\"text-align: right;\">      -1.88233 </td></tr>\n",
       "<tr><td>training_function_83ea7_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.41734 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.00366</td><td style=\"text-align: right;\">      -1.41734 </td></tr>\n",
       "<tr><td>training_function_83ea7_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.49725 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.40248</td><td style=\"text-align: right;\">      -1.49725 </td></tr>\n",
       "<tr><td>training_function_83ea7_00006</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.06618 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.3496 </td><td style=\"text-align: right;\">      -1.06618 </td></tr>\n",
       "<tr><td>training_function_83ea7_00007</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.0096  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.19293</td><td style=\"text-align: right;\">      -1.0096  </td></tr>\n",
       "<tr><td>training_function_83ea7_00008</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.64346 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.05426</td><td style=\"text-align: right;\">      -1.64346 </td></tr>\n",
       "<tr><td>training_function_83ea7_00009</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.00994 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.96082</td><td style=\"text-align: right;\">      -1.00994 </td></tr>\n",
       "<tr><td>training_function_83ea7_00010</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.06652 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.31664</td><td style=\"text-align: right;\">      -1.06652 </td></tr>\n",
       "<tr><td>training_function_83ea7_00011</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">0.493949</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.61038</td><td style=\"text-align: right;\">      -0.493949</td></tr>\n",
       "<tr><td>training_function_83ea7_00012</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">1.45759 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.53264</td><td style=\"text-align: right;\">      -1.45759 </td></tr>\n",
       "<tr><td>training_function_83ea7_00013</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">1.049   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.45392</td><td style=\"text-align: right;\">      -1.049   </td></tr>\n",
       "<tr><td>training_function_83ea7_00014</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">0.927834</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.1705 </td><td style=\"text-align: right;\">      -0.927834</td></tr>\n",
       "<tr><td>training_function_83ea7_00015</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">1.5096  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.80421</td><td style=\"text-align: right;\">      -1.5096  </td></tr>\n",
       "<tr><td>training_function_83ea7_00016</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">0.833048</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.84429</td><td style=\"text-align: right;\">      -0.833048</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00033:\n",
      "  date: 2021-08-31_19-58-18\n",
      "  done: true\n",
      "  experiment_id: 9f4e32a6561943f985f56068e03488dc\n",
      "  experiment_tag: 33_GAMMA=0.8,THETA=0.0001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.6978943956308414\n",
      "  neg_mean_loss: -0.6978943956308414\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 9716\n",
      "  time_since_restore: 5.936533689498901\n",
      "  time_this_iter_s: 5.936533689498901\n",
      "  time_total_s: 5.936533689498901\n",
      "  timestamp: 1630411098\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00033\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=10231)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=10231)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=10231)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=10231)\u001b[0m frac:0.6610576923076923\n",
      "Result for training_function_83ea7_00034:\n",
      "  date: 2021-08-31_19-58-32\n",
      "  done: false\n",
      "  experiment_id: 685c94f8f61d411eb155560aba7d8b3b\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.3293619142572284\n",
      "  neg_mean_loss: -1.3293619142572284\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 10231\n",
      "  time_since_restore: 4.825786590576172\n",
      "  time_this_iter_s: 4.825786590576172\n",
      "  time_total_s: 4.825786590576172\n",
      "  timestamp: 1630411112\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00034\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=10231)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=10231)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 191.3/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/1.0 accelerator_type:V)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 36/36 (1 PENDING, 1 RUNNING, 34 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00034</td><td>RUNNING   </td><td>202.117.43.132:10231</td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">1.32936 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.82579</td><td style=\"text-align: right;\">      -1.32936 </td></tr>\n",
       "<tr><td>training_function_83ea7_00035</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_83ea7_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.45078 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.5344 </td><td style=\"text-align: right;\">      -1.45078 </td></tr>\n",
       "<tr><td>training_function_83ea7_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.927495</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.10901</td><td style=\"text-align: right;\">      -0.927495</td></tr>\n",
       "<tr><td>training_function_83ea7_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.969247</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.40537</td><td style=\"text-align: right;\">      -0.969247</td></tr>\n",
       "<tr><td>training_function_83ea7_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.88233 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.79444</td><td style=\"text-align: right;\">      -1.88233 </td></tr>\n",
       "<tr><td>training_function_83ea7_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.41734 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.00366</td><td style=\"text-align: right;\">      -1.41734 </td></tr>\n",
       "<tr><td>training_function_83ea7_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.49725 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.40248</td><td style=\"text-align: right;\">      -1.49725 </td></tr>\n",
       "<tr><td>training_function_83ea7_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.06618 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.3496 </td><td style=\"text-align: right;\">      -1.06618 </td></tr>\n",
       "<tr><td>training_function_83ea7_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.0096  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.19293</td><td style=\"text-align: right;\">      -1.0096  </td></tr>\n",
       "<tr><td>training_function_83ea7_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.64346 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.05426</td><td style=\"text-align: right;\">      -1.64346 </td></tr>\n",
       "<tr><td>training_function_83ea7_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.00994 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.96082</td><td style=\"text-align: right;\">      -1.00994 </td></tr>\n",
       "<tr><td>training_function_83ea7_00010</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.06652 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.31664</td><td style=\"text-align: right;\">      -1.06652 </td></tr>\n",
       "<tr><td>training_function_83ea7_00011</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">0.493949</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.61038</td><td style=\"text-align: right;\">      -0.493949</td></tr>\n",
       "<tr><td>training_function_83ea7_00012</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">1.45759 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.53264</td><td style=\"text-align: right;\">      -1.45759 </td></tr>\n",
       "<tr><td>training_function_83ea7_00013</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">1.049   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.45392</td><td style=\"text-align: right;\">      -1.049   </td></tr>\n",
       "<tr><td>training_function_83ea7_00014</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">0.927834</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.1705 </td><td style=\"text-align: right;\">      -0.927834</td></tr>\n",
       "<tr><td>training_function_83ea7_00015</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">1.5096  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.80421</td><td style=\"text-align: right;\">      -1.5096  </td></tr>\n",
       "<tr><td>training_function_83ea7_00016</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">0.833048</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.84429</td><td style=\"text-align: right;\">      -0.833048</td></tr>\n",
       "<tr><td>training_function_83ea7_00017</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">0.833048</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.14903</td><td style=\"text-align: right;\">      -0.833048</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00034:\n",
      "  date: 2021-08-31_19-58-32\n",
      "  done: true\n",
      "  experiment_id: 685c94f8f61d411eb155560aba7d8b3b\n",
      "  experiment_tag: 34_GAMMA=0.7,THETA=0.0001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.3293619142572284\n",
      "  neg_mean_loss: -1.3293619142572284\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 10231\n",
      "  time_since_restore: 4.825786590576172\n",
      "  time_this_iter_s: 4.825786590576172\n",
      "  time_total_s: 4.825786590576172\n",
      "  timestamp: 1630411112\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00034\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=10928)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=10928)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=10928)\u001b[0m frac:0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=10928)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=10928)\u001b[0m \r",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00035:\n",
      "  date: 2021-08-31_19-58-46\n",
      "  done: false\n",
      "  experiment_id: c77fd496591647db826326ec647931f9\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.1434622539308483\n",
      "  neg_mean_loss: -1.1434622539308483\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 10928\n",
      "  time_since_restore: 4.4761741161346436\n",
      "  time_this_iter_s: 4.4761741161346436\n",
      "  time_total_s: 4.4761741161346436\n",
      "  timestamp: 1630411126\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00035\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=10928)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=10928)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 191.3/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/1.0 accelerator_type:V)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 36/36 (1 RUNNING, 35 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00035</td><td>RUNNING   </td><td>202.117.43.132:10928</td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">1.14346 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.47617</td><td style=\"text-align: right;\">      -1.14346 </td></tr>\n",
       "<tr><td>training_function_83ea7_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.45078 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.5344 </td><td style=\"text-align: right;\">      -1.45078 </td></tr>\n",
       "<tr><td>training_function_83ea7_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.927495</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.10901</td><td style=\"text-align: right;\">      -0.927495</td></tr>\n",
       "<tr><td>training_function_83ea7_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.969247</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.40537</td><td style=\"text-align: right;\">      -0.969247</td></tr>\n",
       "<tr><td>training_function_83ea7_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.88233 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.79444</td><td style=\"text-align: right;\">      -1.88233 </td></tr>\n",
       "<tr><td>training_function_83ea7_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.41734 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.00366</td><td style=\"text-align: right;\">      -1.41734 </td></tr>\n",
       "<tr><td>training_function_83ea7_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.49725 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.40248</td><td style=\"text-align: right;\">      -1.49725 </td></tr>\n",
       "<tr><td>training_function_83ea7_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.06618 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.3496 </td><td style=\"text-align: right;\">      -1.06618 </td></tr>\n",
       "<tr><td>training_function_83ea7_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.0096  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.19293</td><td style=\"text-align: right;\">      -1.0096  </td></tr>\n",
       "<tr><td>training_function_83ea7_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.64346 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.05426</td><td style=\"text-align: right;\">      -1.64346 </td></tr>\n",
       "<tr><td>training_function_83ea7_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.00994 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.96082</td><td style=\"text-align: right;\">      -1.00994 </td></tr>\n",
       "<tr><td>training_function_83ea7_00010</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.06652 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.31664</td><td style=\"text-align: right;\">      -1.06652 </td></tr>\n",
       "<tr><td>training_function_83ea7_00011</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">0.493949</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.61038</td><td style=\"text-align: right;\">      -0.493949</td></tr>\n",
       "<tr><td>training_function_83ea7_00012</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">1.45759 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.53264</td><td style=\"text-align: right;\">      -1.45759 </td></tr>\n",
       "<tr><td>training_function_83ea7_00013</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">1.049   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.45392</td><td style=\"text-align: right;\">      -1.049   </td></tr>\n",
       "<tr><td>training_function_83ea7_00014</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">0.927834</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.1705 </td><td style=\"text-align: right;\">      -0.927834</td></tr>\n",
       "<tr><td>training_function_83ea7_00015</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">1.5096  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.80421</td><td style=\"text-align: right;\">      -1.5096  </td></tr>\n",
       "<tr><td>training_function_83ea7_00016</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">0.833048</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.84429</td><td style=\"text-align: right;\">      -0.833048</td></tr>\n",
       "<tr><td>training_function_83ea7_00017</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">0.833048</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.14903</td><td style=\"text-align: right;\">      -0.833048</td></tr>\n",
       "<tr><td>training_function_83ea7_00018</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">1.33305 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.80084</td><td style=\"text-align: right;\">      -1.33305 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_83ea7_00035:\n",
      "  date: 2021-08-31_19-58-46\n",
      "  done: true\n",
      "  experiment_id: c77fd496591647db826326ec647931f9\n",
      "  experiment_tag: 35_GAMMA=0.6,THETA=0.0001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.1434622539308483\n",
      "  neg_mean_loss: -1.1434622539308483\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 10928\n",
      "  time_since_restore: 4.4761741161346436\n",
      "  time_this_iter_s: 4.4761741161346436\n",
      "  time_total_s: 4.4761741161346436\n",
      "  timestamp: 1630411126\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 83ea7_00035\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 188.8/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/32 CPUs, 0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/16.0 CPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_0_39635c4cfd6e69283cd99a75d52ae243, 0.0/2.0 GPU_group_39635c4cfd6e69283cd99a75d52ae243, 0.0/16.0 CPU_group_0_39635c4cfd6e69283cd99a75d52ae243)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-31_19-49-36<br>Number of trials: 36/36 (36 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_83ea7_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.45078 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.5344 </td><td style=\"text-align: right;\">      -1.45078 </td></tr>\n",
       "<tr><td>training_function_83ea7_00001</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.927495</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.10901</td><td style=\"text-align: right;\">      -0.927495</td></tr>\n",
       "<tr><td>training_function_83ea7_00002</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">0.969247</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.40537</td><td style=\"text-align: right;\">      -0.969247</td></tr>\n",
       "<tr><td>training_function_83ea7_00003</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.88233 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.79444</td><td style=\"text-align: right;\">      -1.88233 </td></tr>\n",
       "<tr><td>training_function_83ea7_00004</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.41734 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.00366</td><td style=\"text-align: right;\">      -1.41734 </td></tr>\n",
       "<tr><td>training_function_83ea7_00005</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.49725 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.40248</td><td style=\"text-align: right;\">      -1.49725 </td></tr>\n",
       "<tr><td>training_function_83ea7_00006</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.06618 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.3496 </td><td style=\"text-align: right;\">      -1.06618 </td></tr>\n",
       "<tr><td>training_function_83ea7_00007</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.0096  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.19293</td><td style=\"text-align: right;\">      -1.0096  </td></tr>\n",
       "<tr><td>training_function_83ea7_00008</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.64346 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.05426</td><td style=\"text-align: right;\">      -1.64346 </td></tr>\n",
       "<tr><td>training_function_83ea7_00009</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.00994 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.96082</td><td style=\"text-align: right;\">      -1.00994 </td></tr>\n",
       "<tr><td>training_function_83ea7_00010</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.06652 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.31664</td><td style=\"text-align: right;\">      -1.06652 </td></tr>\n",
       "<tr><td>training_function_83ea7_00011</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">0.493949</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.61038</td><td style=\"text-align: right;\">      -0.493949</td></tr>\n",
       "<tr><td>training_function_83ea7_00012</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">1.45759 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.53264</td><td style=\"text-align: right;\">      -1.45759 </td></tr>\n",
       "<tr><td>training_function_83ea7_00013</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">1.049   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.45392</td><td style=\"text-align: right;\">      -1.049   </td></tr>\n",
       "<tr><td>training_function_83ea7_00014</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">0.927834</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.1705 </td><td style=\"text-align: right;\">      -0.927834</td></tr>\n",
       "<tr><td>training_function_83ea7_00015</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">1.5096  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.80421</td><td style=\"text-align: right;\">      -1.5096  </td></tr>\n",
       "<tr><td>training_function_83ea7_00016</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">0.833048</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.84429</td><td style=\"text-align: right;\">      -0.833048</td></tr>\n",
       "<tr><td>training_function_83ea7_00017</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">0.833048</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.14903</td><td style=\"text-align: right;\">      -0.833048</td></tr>\n",
       "<tr><td>training_function_83ea7_00018</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">1.33305 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.80084</td><td style=\"text-align: right;\">      -1.33305 </td></tr>\n",
       "<tr><td>training_function_83ea7_00019</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">0.743913</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.13071</td><td style=\"text-align: right;\">      -0.743913</td></tr>\n",
       "<tr><td>training_function_83ea7_00020</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">1.46925 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.38444</td><td style=\"text-align: right;\">      -1.46925 </td></tr>\n",
       "<tr><td>training_function_83ea7_00021</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">1.71859 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.26544</td><td style=\"text-align: right;\">      -1.71859 </td></tr>\n",
       "<tr><td>training_function_83ea7_00022</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">0.841741</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.32532</td><td style=\"text-align: right;\">      -0.841741</td></tr>\n",
       "<tr><td>training_function_83ea7_00023</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">1.28948 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.35028</td><td style=\"text-align: right;\">      -1.28948 </td></tr>\n",
       "<tr><td>training_function_83ea7_00024</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">1.28914 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.92667</td><td style=\"text-align: right;\">      -1.28914 </td></tr>\n",
       "<tr><td>training_function_83ea7_00025</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">1.4768  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.28818</td><td style=\"text-align: right;\">      -1.4768  </td></tr>\n",
       "<tr><td>training_function_83ea7_00026</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">1.58751 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.50859</td><td style=\"text-align: right;\">      -1.58751 </td></tr>\n",
       "<tr><td>training_function_83ea7_00027</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">0.969586</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.41227</td><td style=\"text-align: right;\">      -0.969586</td></tr>\n",
       "<tr><td>training_function_83ea7_00028</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">0.832709</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.77006</td><td style=\"text-align: right;\">      -0.832709</td></tr>\n",
       "<tr><td>training_function_83ea7_00029</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">0.833048</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.60729</td><td style=\"text-align: right;\">      -0.833048</td></tr>\n",
       "<tr><td>training_function_83ea7_00030</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">1.09126 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.78054</td><td style=\"text-align: right;\">      -1.09126 </td></tr>\n",
       "<tr><td>training_function_83ea7_00031</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">1.33305 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.22108</td><td style=\"text-align: right;\">      -1.33305 </td></tr>\n",
       "<tr><td>training_function_83ea7_00032</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">1.049   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.83746</td><td style=\"text-align: right;\">      -1.049   </td></tr>\n",
       "<tr><td>training_function_83ea7_00033</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">0.697894</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.93653</td><td style=\"text-align: right;\">      -0.697894</td></tr>\n",
       "<tr><td>training_function_83ea7_00034</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">1.32936 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.82579</td><td style=\"text-align: right;\">      -1.32936 </td></tr>\n",
       "<tr><td>training_function_83ea7_00035</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">1.14346 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.47617</td><td style=\"text-align: right;\">      -1.14346 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-31 19:58:49,103\tINFO tune.py:550 -- Total run time: 552.82 seconds (549.86 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best config:  {'THETA': 0.01, 'GAMMA': 0.6, 'dataset': 'compas', 'train_dataset_s': <torch.utils.data.dataset.Subset object at 0x7f7c557639e8>, 'val': <torch.utils.data.dataloader.DataLoader object at 0x7f7cb8822be0>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f7c5577fc88>, 'x_tensor': tensor([[0., 1., 1.,  ..., 1., 0., 1.],\n",
      "        [0., 1., 0.,  ..., 1., 0., 1.],\n",
      "        [0., 1., 1.,  ..., 1., 1., 0.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 1., 1.,  ..., 0., 0., 1.],\n",
      "        [0., 1., 1.,  ..., 0., 0., 1.]])}\n",
      "2021-08-31 19:58:52,727 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.26402819192193006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  28%|██▊       | 14/50 [00:05<00:13,  2.76it/s, epoch=13, training_loss=4.58, validation_loss=4.93]\u001b[A\n",
      "Training neural network:  58%|█████▊    | 29/50 [00:10<00:07,  2.82it/s, epoch=28, training_loss=4.52, validation_loss=4.98]\u001b[A\n",
      "Training neural network:  90%|█████████ | 45/50 [00:15<00:01,  2.97it/s, epoch=44, training_loss=4.48, validation_loss=4.92]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-31 19:59:30,047 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.2575223637842234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  28%|██▊       | 14/50 [00:05<00:13,  2.74it/s, epoch=13, training_loss=4.64, validation_loss=5.4]\u001b[A\n",
      "Training neural network:  56%|█████▌    | 28/50 [00:10<00:08,  2.66it/s, epoch=27, training_loss=4.47, validation_loss=4.98]\u001b[A\n",
      "Training neural network:  86%|████████▌ | 43/50 [00:15<00:02,  2.76it/s, epoch=42, training_loss=4.45, validation_loss=4.89]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-31 20:00:07,991 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.26294388723231227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  28%|██▊       | 14/50 [00:05<00:13,  2.68it/s, epoch=13, training_loss=4.57, validation_loss=5.22]\u001b[A\n",
      "Training neural network:  60%|██████    | 30/50 [00:10<00:06,  2.89it/s, epoch=29, training_loss=4.51, validation_loss=4.99]\u001b[A\n",
      "Training neural network:  92%|█████████▏| 46/50 [00:15<00:01,  2.97it/s, epoch=45, training_loss=4.45, validation_loss=4.95]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-31 20:00:44,891 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.2602331255082678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  28%|██▊       | 14/50 [00:05<00:13,  2.71it/s, epoch=13, training_loss=4.46, validation_loss=4.99]\u001b[A\n",
      "Training neural network:  56%|█████▌    | 28/50 [00:10<00:08,  2.68it/s, epoch=27, training_loss=4.44, validation_loss=5.05]\u001b[A\n",
      "Training neural network:  86%|████████▌ | 43/50 [00:15<00:02,  2.75it/s, epoch=42, training_loss=4.46, validation_loss=4.99]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-31 20:01:21,663 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.2615885063702901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  30%|███       | 15/50 [00:05<00:11,  2.93it/s, epoch=14, training_loss=4.47, validation_loss=5.05]\u001b[A\n",
      "Training neural network:  60%|██████    | 30/50 [00:10<00:06,  2.97it/s, epoch=29, training_loss=4.44, validation_loss=4.92]\u001b[A\n",
      "Training neural network:  92%|█████████▏| 46/50 [00:15<00:01,  2.98it/s, epoch=45, training_loss=4.4, validation_loss=4.82] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-31 20:01:58,204 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.2537272973705611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  30%|███       | 15/50 [00:05<00:12,  2.72it/s, epoch=14, training_loss=4.46, validation_loss=5.17]\u001b[A\n",
      "Training neural network:  62%|██████▏   | 31/50 [00:10<00:06,  2.98it/s, epoch=30, training_loss=4.42, validation_loss=5.05]\u001b[A\n",
      "Training neural network:  94%|█████████▍| 47/50 [00:15<00:00,  3.02it/s, epoch=46, training_loss=4.4, validation_loss=5.09] \u001b[A\n",
      "                                                                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-31 20:02:36,083 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.2474925454052589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:10,  3.13it/s, epoch=15, training_loss=4.5, validation_loss=4.85]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:11<00:06,  2.81it/s, epoch=31, training_loss=4.47, validation_loss=5.02]\u001b[A\n",
      "Training neural network:  94%|█████████▍| 47/50 [00:16<00:01,  2.76it/s, epoch=46, training_loss=4.44, validation_loss=5.01]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-31 20:03:14,844 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.24966115478449444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  28%|██▊       | 14/50 [00:05<00:13,  2.69it/s, epoch=13, training_loss=4.57, validation_loss=5.08]\u001b[A\n",
      "Training neural network:  58%|█████▊    | 29/50 [00:10<00:07,  2.79it/s, epoch=28, training_loss=4.45, validation_loss=5.02]\u001b[A\n",
      "Training neural network:  86%|████████▌ | 43/50 [00:16<00:02,  2.63it/s, epoch=42, training_loss=4.39, validation_loss=4.94]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-31 20:03:53,122 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.25508267823258335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:05<00:11,  3.07it/s, epoch=15, training_loss=4.48, validation_loss=5.03]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:10<00:06,  2.95it/s, epoch=31, training_loss=4.56, validation_loss=4.9] \u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [00:16<00:00,  2.98it/s, epoch=47, training_loss=4.43, validation_loss=4.97]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-31 20:04:29,576 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.2813770669558146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:  26%|██▌       | 13/50 [00:05<00:15,  2.45it/s, epoch=12, training_loss=4.62, validation_loss=5.03]\u001b[A\n",
      "Training neural network:  54%|█████▍    | 27/50 [00:10<00:08,  2.59it/s, epoch=26, training_loss=4.41, validation_loss=4.98]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:15<00:03,  2.56it/s, epoch=39, training_loss=4.42, validation_loss=4.91]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param selection costs:556.4386203289032 s\n",
      "path analysis costs:355.27943301200867 s\n",
      "sample separation costs:0.6145668029785156 s\n",
      "partial dropout training costs:19.258344173431396 s\n",
      "total time costs:931.7447371482849 s\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "BATCH_SIZE=128\n",
    "\n",
    "df=pd.read_csv('data/COMPAS/compas_recidive_two_years_sanitize_age_category_jail_time_decile_score.csv')\n",
    "# df_binary = df[(df[\"race\"] == \"Caucasian\") | (df[\"race\"] == \"African-American\")]     提取两种种族\n",
    "# Y = df_binary['decile_score']    评分，range:[0,10]\n",
    "# S = df_binary['race']\n",
    "# Y_true = df_binary['two_year_recid']    是否入狱\n",
    "df_binary, Y, S, Y_true = transform_dataset(df)\n",
    "Y = Y.to_numpy()\n",
    "print(np.mean(Y))\n",
    "\n",
    "l_tensor = torch.tensor(Y_true.to_numpy().reshape(-1, 1).astype(np.float32))\n",
    "x_tensor = torch.tensor(df_binary.to_numpy().astype(np.float32))\n",
    "y_tensor = torch.tensor(Y.reshape(-1, 1).astype(np.float32))\n",
    "s_tensor = torch.tensor(preprocessing.OneHotEncoder().fit_transform(np.array(S).reshape(-1, 1)).toarray())\n",
    "\n",
    "dataset = TensorDataset(x_tensor, y_tensor, l_tensor, s_tensor)  # dataset = CustomDataset(x_tensor, y_tensor)\n",
    "\n",
    "base_size = len(dataset) // 10\n",
    "split = [7 * base_size, 1 * base_size, len(dataset) - 8 * base_size]  # Train, validation, test\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, split)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "x_train_tensor = train_dataset[:][0]\n",
    "y_train_tensor = train_dataset[:][1]\n",
    "l_train_tensor = train_dataset[:][2]\n",
    "s_train_tensor = train_dataset[:][3]\n",
    "\n",
    "global_results = []\n",
    "\n",
    "# get the classification threshold, we use the same scale for compas so 4 instead of 0.5\n",
    "ori_start=time.time()\n",
    "threshold = 4\n",
    "\n",
    "net, results = train_and_evaluate(train_loader, val_loader, test_loader, device, input_shape=x_tensor.shape[1],\n",
    "                                    grl_lambda=0)\n",
    "\n",
    "\n",
    "ori_end=time.time()\n",
    "ori_cost_time=ori_end-ori_start\n",
    "print('time costs:{} s'.format(ori_cost_time))\n",
    "\n",
    "result = get_metrics(results, threshold, 0)\n",
    "global_results.append(result)\n",
    "net_nodrop, results = train_and_evaluate(train_loader, val_loader, test_loader, device, input_shape=x_tensor.shape[1],\n",
    "                                    grl_lambda=0,dataset='compas_nodrop')\n",
    "result = get_metrics(results, threshold, 0)\n",
    "global_results.append(result)\n",
    "\n",
    "# EA\n",
    "# EA(net,attack_size=10, iter_num=50)\n",
    "\n",
    "Fixate_with_val(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 20:42:48,060 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.2534562211981567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[                                                pathset  counts\n",
       " 0     {(1, 18, 24), (1, 22, 15), (1, 3, 30), (2, 24,...      47\n",
       " 1     {(1, 18, 24), (1, 22, 15), (1, 25, 30), (1, 18...      43\n",
       " 2     {(1, 18, 24), (1, 22, 15), (1, 25, 30), (1, 3,...      33\n",
       " 3     {(1, 18, 24), (1, 22, 15), (1, 25, 30), (1, 3,...      30\n",
       " 4     {(1, 18, 24), (1, 22, 15), (1, 24, 15), (1, 3,...      29\n",
       " ...                                                 ...     ...\n",
       " 1527  {(1, 11, 13), (1, 18, 24), (1, 27, 24), (1, 15...       1\n",
       " 1528  {(1, 18, 24), (1, 22, 15), (1, 24, 15), (1, 3,...       1\n",
       " 1529  {(1, 18, 24), (1, 22, 15), (1, 3, 30), (2, 24,...       1\n",
       " 1530  {(1, 11, 13), (1, 18, 24), (1, 27, 24), (1, 15...       1\n",
       " 1531  {(1, 18, 24), (1, 22, 15), (1, 25, 30), (2, 24...       1\n",
       " \n",
       " [1532 rows x 2 columns]]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_list=[]\n",
    "\n",
    "sample_sort_test(net,train_dataset,0.01,0.6)\n",
    "v_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26917864, 0.40092166, 0.48061805, 0.54350773, 0.59365682,\n",
       "       0.65220927, 0.68636487, 0.71455679, 0.74871239, 0.78124153,\n",
       "       0.79018704, 0.81621036, 0.83030632, 0.84169152, 0.85795609,\n",
       "       0.87964218, 0.89346706, 0.89346706, 0.90891841, 0.92518298,\n",
       "       0.94226078, 0.94226078, 0.94226078, 0.94226078, 0.94226078,\n",
       "       0.94930876, 0.96394687, 0.97912713, 0.97912713, 0.98725942,\n",
       "       0.98725942, 0.98725942, 0.98725942, 0.98725942, 0.98725942,\n",
       "       0.98725942, 0.98725942, 0.98725942, 0.98725942, 0.98725942,\n",
       "       0.98725942, 0.98725942, 0.98725942, 0.98725942, 0.98725942,\n",
       "       0.98725942, 1.        ])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total=path_stat.sum()\n",
    "cum=[]\n",
    "s=0\n",
    "for i in range(1,path_stat[0]+1):\n",
    "    s=s+i*(path_stat==i).sum()\n",
    "    cum.append(s.copy())\n",
    "cum=np.array(cum)/s\n",
    "cum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_stat=np.array(v_list[0].counts)\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.tick_params(labelsize=14)\n",
    "# for GAMMA in list(np.linspace(1,0.5,50)):\n",
    "# plt.plot(range(0,len(path_stat)),path_stat,'r-.')\n",
    "# plt.plot(range(0,len(path_stat)),(path_stat[0]*0.01)*np.ones(len(path_stat)),'g-.')\n",
    "plt.hist(path_stat,bins=40,density=1, histtype='step',label='Path activation statistics PDF')\n",
    "# plt.hist(path_stat,bins=40,density=1,cumulative=1, histtype='step',label='Cumulative Distribution Function')\n",
    "plt.plot(range(0,len(cum)),cum,'ro-',label='Sample cumulative ratio')\n",
    "plt.vlines(47*0.03, 0, 2, colors='g', linestyles='dashed')\n",
    "plt.xlabel('path activation statistics',myfont)\n",
    "plt.ylabel('ratio',myfont)\n",
    "plt.ylim((0,1.01))\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(linestyle='-.')\n",
    "plt.savefig('data/results/Figures/detection.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DP</th>\n",
       "      <th>EO</th>\n",
       "      <th>DP ratio</th>\n",
       "      <th>acc</th>\n",
       "      <th>acc_ci_min</th>\n",
       "      <th>acc_ci_max</th>\n",
       "      <th>f1</th>\n",
       "      <th>acc_high_risk</th>\n",
       "      <th>acc_ci_min_high_risk</th>\n",
       "      <th>acc_ci_max_high_risk</th>\n",
       "      <th>f1_high_risk</th>\n",
       "      <th>adversarial_fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.352826</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>1.989145</td>\n",
       "      <td>0.655367</td>\n",
       "      <td>0.626784</td>\n",
       "      <td>0.683951</td>\n",
       "      <td>0.654827</td>\n",
       "      <td>0.765537</td>\n",
       "      <td>0.740056</td>\n",
       "      <td>0.791018</td>\n",
       "      <td>0.565071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.732911</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.183110</td>\n",
       "      <td>0.474576</td>\n",
       "      <td>0.444543</td>\n",
       "      <td>0.504609</td>\n",
       "      <td>0.471872</td>\n",
       "      <td>0.871940</td>\n",
       "      <td>0.851842</td>\n",
       "      <td>0.892037</td>\n",
       "      <td>0.578729</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.353049</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.506194</td>\n",
       "      <td>0.730697</td>\n",
       "      <td>0.704017</td>\n",
       "      <td>0.757377</td>\n",
       "      <td>0.730275</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.849834</td>\n",
       "      <td>0.890279</td>\n",
       "      <td>0.625827</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.346084</td>\n",
       "      <td>0.108333</td>\n",
       "      <td>0.509524</td>\n",
       "      <td>0.697740</td>\n",
       "      <td>0.670120</td>\n",
       "      <td>0.725361</td>\n",
       "      <td>0.697411</td>\n",
       "      <td>0.869115</td>\n",
       "      <td>0.848830</td>\n",
       "      <td>0.889400</td>\n",
       "      <td>0.624759</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.380530</td>\n",
       "      <td>0.108333</td>\n",
       "      <td>0.479104</td>\n",
       "      <td>0.739171</td>\n",
       "      <td>0.712763</td>\n",
       "      <td>0.765580</td>\n",
       "      <td>0.738660</td>\n",
       "      <td>0.865348</td>\n",
       "      <td>0.844818</td>\n",
       "      <td>0.885879</td>\n",
       "      <td>0.613961</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.370360</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.487562</td>\n",
       "      <td>0.720339</td>\n",
       "      <td>0.693344</td>\n",
       "      <td>0.747334</td>\n",
       "      <td>0.719880</td>\n",
       "      <td>0.862524</td>\n",
       "      <td>0.841813</td>\n",
       "      <td>0.883234</td>\n",
       "      <td>0.607571</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.374299</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.483226</td>\n",
       "      <td>0.729755</td>\n",
       "      <td>0.703046</td>\n",
       "      <td>0.756464</td>\n",
       "      <td>0.729311</td>\n",
       "      <td>0.868173</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>0.888520</td>\n",
       "      <td>0.620404</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.378883</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.483561</td>\n",
       "      <td>0.735405</td>\n",
       "      <td>0.708874</td>\n",
       "      <td>0.761936</td>\n",
       "      <td>0.734793</td>\n",
       "      <td>0.869115</td>\n",
       "      <td>0.848830</td>\n",
       "      <td>0.889400</td>\n",
       "      <td>0.634286</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.382555</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.489397</td>\n",
       "      <td>0.728814</td>\n",
       "      <td>0.702075</td>\n",
       "      <td>0.755552</td>\n",
       "      <td>0.727762</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.849834</td>\n",
       "      <td>0.890279</td>\n",
       "      <td>0.619137</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.388229</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.477478</td>\n",
       "      <td>0.727872</td>\n",
       "      <td>0.701104</td>\n",
       "      <td>0.754639</td>\n",
       "      <td>0.727086</td>\n",
       "      <td>0.867232</td>\n",
       "      <td>0.846823</td>\n",
       "      <td>0.887640</td>\n",
       "      <td>0.605547</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.376680</td>\n",
       "      <td>0.108333</td>\n",
       "      <td>0.479939</td>\n",
       "      <td>0.734463</td>\n",
       "      <td>0.707902</td>\n",
       "      <td>0.761024</td>\n",
       "      <td>0.734047</td>\n",
       "      <td>0.865348</td>\n",
       "      <td>0.844818</td>\n",
       "      <td>0.885879</td>\n",
       "      <td>0.607097</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.376413</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.490175</td>\n",
       "      <td>0.737288</td>\n",
       "      <td>0.710818</td>\n",
       "      <td>0.763758</td>\n",
       "      <td>0.736529</td>\n",
       "      <td>0.873823</td>\n",
       "      <td>0.853852</td>\n",
       "      <td>0.893794</td>\n",
       "      <td>0.645947</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DP        EO  DP ratio       acc  acc_ci_min  acc_ci_max        f1  \\\n",
       "0   0.352826  0.675000  1.989145  0.655367    0.626784    0.683951  0.654827   \n",
       "1   0.732911  0.683333  0.183110  0.474576    0.444543    0.504609  0.471872   \n",
       "2   0.353049  0.133333  0.506194  0.730697    0.704017    0.757377  0.730275   \n",
       "3   0.346084  0.108333  0.509524  0.697740    0.670120    0.725361  0.697411   \n",
       "4   0.380530  0.108333  0.479104  0.739171    0.712763    0.765580  0.738660   \n",
       "5   0.370360  0.100000  0.487562  0.720339    0.693344    0.747334  0.719880   \n",
       "6   0.374299  0.133333  0.483226  0.729755    0.703046    0.756464  0.729311   \n",
       "7   0.378883  0.133333  0.483561  0.735405    0.708874    0.761936  0.734793   \n",
       "8   0.382555  0.183333  0.489397  0.728814    0.702075    0.755552  0.727762   \n",
       "9   0.388229  0.183333  0.477478  0.727872    0.701104    0.754639  0.727086   \n",
       "10  0.376680  0.108333  0.479939  0.734463    0.707902    0.761024  0.734047   \n",
       "11  0.376413  0.150000  0.490175  0.737288    0.710818    0.763758  0.736529   \n",
       "\n",
       "    acc_high_risk  acc_ci_min_high_risk  acc_ci_max_high_risk  f1_high_risk  \\\n",
       "0        0.765537              0.740056              0.791018      0.565071   \n",
       "1        0.871940              0.851842              0.892037      0.578729   \n",
       "2        0.870056              0.849834              0.890279      0.625827   \n",
       "3        0.869115              0.848830              0.889400      0.624759   \n",
       "4        0.865348              0.844818              0.885879      0.613961   \n",
       "5        0.862524              0.841813              0.883234      0.607571   \n",
       "6        0.868173              0.847826              0.888520      0.620404   \n",
       "7        0.869115              0.848830              0.889400      0.634286   \n",
       "8        0.870056              0.849834              0.890279      0.619137   \n",
       "9        0.867232              0.846823              0.887640      0.605547   \n",
       "10       0.865348              0.844818              0.885879      0.607097   \n",
       "11       0.873823              0.853852              0.893794      0.645947   \n",
       "\n",
       "    adversarial_fraction  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "5                      0  \n",
       "6                      0  \n",
       "7                      0  \n",
       "8                      0  \n",
       "9                      0  \n",
       "10                     0  \n",
       "11                     0  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(global_results)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30162, 12)\n",
      "(30162, 1)\n",
      "0.24892248524633645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:   6%|▌         | 3/50 [00:05<01:33,  1.99s/it, epoch=2, training_loss=1.84e+3, validation_loss=563]\u001b[A\n",
      "Training neural network:  12%|█▏        | 6/50 [00:11<01:28,  2.00s/it, epoch=5, training_loss=1.03e+3, validation_loss=62.7]\u001b[A\n",
      "Training neural network:  18%|█▊        | 9/50 [00:17<01:20,  1.97s/it, epoch=8, training_loss=77.7, validation_loss=26.5]   \u001b[A\n",
      "Training neural network:  24%|██▍       | 12/50 [00:23<01:15,  1.99s/it, epoch=11, training_loss=65.1, validation_loss=9.2]\u001b[A\n",
      "Training neural network:  30%|███       | 15/50 [00:29<01:09,  2.00s/it, epoch=14, training_loss=28.4, validation_loss=36.1]\u001b[A\n",
      "Training neural network:  36%|███▌      | 18/50 [00:35<01:03,  1.98s/it, epoch=17, training_loss=8.26, validation_loss=5.17]\u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:41<00:56,  1.96s/it, epoch=20, training_loss=4.66, validation_loss=3.51]\u001b[A\n",
      "Training neural network:  48%|████▊     | 24/50 [00:47<00:51,  1.97s/it, epoch=23, training_loss=3.09, validation_loss=2.68]\u001b[A\n",
      "Training neural network:  54%|█████▍    | 27/50 [00:53<00:45,  1.98s/it, epoch=26, training_loss=2.45, validation_loss=1.98]\u001b[A\n",
      "Training neural network:  60%|██████    | 30/50 [00:59<00:39,  2.00s/it, epoch=29, training_loss=2.27, validation_loss=2.1] \u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [01:05<00:33,  2.00s/it, epoch=32, training_loss=3.47, validation_loss=2.37]\u001b[A\n",
      "Training neural network:  72%|███████▏  | 36/50 [01:11<00:28,  2.01s/it, epoch=35, training_loss=2.06, validation_loss=2.08]\u001b[A\n",
      "Training neural network:  78%|███████▊  | 39/50 [01:17<00:21,  1.99s/it, epoch=38, training_loss=2.06, validation_loss=1.92]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [01:23<00:15,  2.00s/it, epoch=41, training_loss=2.01, validation_loss=1.95]\u001b[A\n",
      "Training neural network:  90%|█████████ | 45/50 [01:29<00:09,  1.96s/it, epoch=44, training_loss=1.96, validation_loss=1.9] \u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [01:35<00:03,  1.98s/it, epoch=47, training_loss=1.93, validation_loss=1.93]\u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:99.75449323654175 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 147.9/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/32 CPUs, 0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/1.0 accelerator_type:V)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_11-03-50<br>Number of trials: 35/36 (35 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_bc58c_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_bc58c_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_bc58c_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_bc58c_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_bc58c_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_bc58c_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_bc58c_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_bc58c_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_bc58c_00008</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_bc58c_00009</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_bc58c_00010</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_bc58c_00011</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_bc58c_00012</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_bc58c_00013</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_bc58c_00014</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_bc58c_00015</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_bc58c_00016</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_bc58c_00017</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_bc58c_00018</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td></tr>\n",
       "<tr><td>training_function_bc58c_00019</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 15 more trials not shown (15 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 149.9/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/1.0 accelerator_type:V, 0.0/16.0 CPU_group_0_de1602d26fa597a65349fb8b6a223582)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_11-03-50<br>Number of trials: 36/36 (35 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_bc58c_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_bc58c_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_bc58c_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_bc58c_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_bc58c_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_bc58c_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_bc58c_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_bc58c_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_bc58c_00008</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_bc58c_00009</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_bc58c_00010</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_bc58c_00011</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_bc58c_00012</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_bc58c_00013</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_bc58c_00014</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_bc58c_00015</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_bc58c_00016</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_bc58c_00017</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_bc58c_00018</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td></tr>\n",
       "<tr><td>training_function_bc58c_00019</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12366)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=12366)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12366)\u001b[0m frac:0.25124584717607973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12366)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=12366)\u001b[0m \r",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 150.4/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/1.0 accelerator_type:V, 0.0/16.0 CPU_group_0_de1602d26fa597a65349fb8b6a223582)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_11-03-50<br>Number of trials: 36/36 (35 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_bc58c_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_bc58c_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_bc58c_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_bc58c_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_bc58c_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_bc58c_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_bc58c_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_bc58c_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_bc58c_00008</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_bc58c_00009</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_bc58c_00010</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_bc58c_00011</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_bc58c_00012</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_bc58c_00013</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_bc58c_00014</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_bc58c_00015</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_bc58c_00016</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_bc58c_00017</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_bc58c_00018</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td></tr>\n",
       "<tr><td>training_function_bc58c_00019</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12366)\u001b[0m \n",
      "Training neural network:  56%|█████▌    | 28/50 [00:05<00:04,  5.47it/s, epoch=27, training_loss=0.0922, validation_loss=0.153]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12366)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00000:\n",
      "  date: 2021-08-29_11-05-57\n",
      "  done: false\n",
      "  experiment_id: cce2f836a0fd44039236b11a136f9a84\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.827728943075183\n",
      "  neg_mean_loss: 1.827728943075183\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12366\n",
      "  time_since_restore: 12.34292459487915\n",
      "  time_this_iter_s: 12.34292459487915\n",
      "  time_total_s: 12.34292459487915\n",
      "  timestamp: 1630206357\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 150.5/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/1.0 accelerator_type:V)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_11-03-50<br>Number of trials: 36/36 (35 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_bc58c_00000</td><td>RUNNING </td><td>202.117.43.132:12366</td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.82773</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3429</td><td style=\"text-align: right;\">        1.82773</td></tr>\n",
       "<tr><td>training_function_bc58c_00001</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00002</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00003</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00004</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00005</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00006</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00007</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00008</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00009</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00010</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00011</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00012</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00013</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00014</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00015</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00016</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00017</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00018</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00019</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00000:\n",
      "  date: 2021-08-29_11-05-57\n",
      "  done: true\n",
      "  experiment_id: cce2f836a0fd44039236b11a136f9a84\n",
      "  experiment_tag: 0_GAMMA=0.95,THETA=0.1\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.827728943075183\n",
      "  neg_mean_loss: 1.827728943075183\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12366\n",
      "  time_since_restore: 12.34292459487915\n",
      "  time_this_iter_s: 12.34292459487915\n",
      "  time_total_s: 12.34292459487915\n",
      "  timestamp: 1630206357\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12219)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=12219)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12219)\u001b[0m frac:0.2553986710963455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12219)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12219)\u001b[0m \n",
      "Training neural network:  52%|█████▏    | 26/50 [00:05<00:04,  5.12it/s, epoch=25, training_loss=0.121, validation_loss=0.148]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12219)\u001b[0m \n",
      "                                                                                                                              \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00001:\n",
      "  date: 2021-08-29_11-06-17\n",
      "  done: false\n",
      "  experiment_id: bb2ee7d62c0b435abfd8435173fe500f\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.619740087123914\n",
      "  neg_mean_loss: 1.619740087123914\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12219\n",
      "  time_since_restore: 13.373337268829346\n",
      "  time_this_iter_s: 13.373337268829346\n",
      "  time_total_s: 13.373337268829346\n",
      "  timestamp: 1630206377\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 150.4/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/1.0 accelerator_type:V)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_11-03-50<br>Number of trials: 36/36 (34 PENDING, 1 RUNNING, 1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_bc58c_00001</td><td>RUNNING   </td><td>202.117.43.132:12219</td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.61974</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.3733</td><td style=\"text-align: right;\">        1.61974</td></tr>\n",
       "<tr><td>training_function_bc58c_00002</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00003</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00004</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00005</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00006</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00007</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00008</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00009</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00010</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00011</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00012</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00013</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00014</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00015</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.82773</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3429</td><td style=\"text-align: right;\">        1.82773</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00001:\n",
      "  date: 2021-08-29_11-06-17\n",
      "  done: true\n",
      "  experiment_id: bb2ee7d62c0b435abfd8435173fe500f\n",
      "  experiment_tag: 1_GAMMA=0.9,THETA=0.1\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.619740087123914\n",
      "  neg_mean_loss: 1.619740087123914\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12219\n",
      "  time_since_restore: 13.373337268829346\n",
      "  time_this_iter_s: 13.373337268829346\n",
      "  time_total_s: 13.373337268829346\n",
      "  timestamp: 1630206377\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00001\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12229)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=12229)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12229)\u001b[0m frac:0.2504152823920266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12229)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12229)\u001b[0m \n",
      "Training neural network:  56%|█████▌    | 28/50 [00:05<00:03,  5.59it/s, epoch=27, training_loss=0.0736, validation_loss=0.164]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12229)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00002:\n",
      "  date: 2021-08-29_11-06-36\n",
      "  done: false\n",
      "  experiment_id: d33699eb7e6a49de8f9b4c84b9f11ce6\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.520861701675519\n",
      "  neg_mean_loss: 1.520861701675519\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12229\n",
      "  time_since_restore: 12.39463210105896\n",
      "  time_this_iter_s: 12.39463210105896\n",
      "  time_total_s: 12.39463210105896\n",
      "  timestamp: 1630206396\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00002\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 150.4/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/16.0 CPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/1.0 accelerator_type:V)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_11-03-50<br>Number of trials: 36/36 (33 PENDING, 1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_bc58c_00002</td><td>RUNNING   </td><td>202.117.43.132:12229</td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.52086</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3946</td><td style=\"text-align: right;\">        1.52086</td></tr>\n",
       "<tr><td>training_function_bc58c_00003</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00004</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00005</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00006</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00007</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00008</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00009</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00010</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00011</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00012</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00013</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00014</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00015</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.82773</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3429</td><td style=\"text-align: right;\">        1.82773</td></tr>\n",
       "<tr><td>training_function_bc58c_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.61974</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.3733</td><td style=\"text-align: right;\">        1.61974</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00002:\n",
      "  date: 2021-08-29_11-06-36\n",
      "  done: true\n",
      "  experiment_id: d33699eb7e6a49de8f9b4c84b9f11ce6\n",
      "  experiment_tag: 2_GAMMA=0.85,THETA=0.1\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.520861701675519\n",
      "  neg_mean_loss: 1.520861701675519\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12229\n",
      "  time_since_restore: 12.39463210105896\n",
      "  time_this_iter_s: 12.39463210105896\n",
      "  time_total_s: 12.39463210105896\n",
      "  timestamp: 1630206396\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00002\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12232)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=12232)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12232)\u001b[0m frac:0.2520764119601329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12232)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12232)\u001b[0m \n",
      "Training neural network:  54%|█████▍    | 27/50 [00:05<00:04,  5.38it/s, epoch=26, training_loss=0.0865, validation_loss=0.148]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12232)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00003:\n",
      "  date: 2021-08-29_11-06-55\n",
      "  done: false\n",
      "  experiment_id: 90c6e1c045e3487fbd6fcc4f4c3452d3\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.78826426160831\n",
      "  neg_mean_loss: 1.78826426160831\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12232\n",
      "  time_since_restore: 12.724765062332153\n",
      "  time_this_iter_s: 12.724765062332153\n",
      "  time_total_s: 12.724765062332153\n",
      "  timestamp: 1630206415\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00003\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 150.4/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_0_de1602d26fa597a65349fb8b6a223582)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_11-03-50<br>Number of trials: 36/36 (32 PENDING, 1 RUNNING, 3 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_bc58c_00003</td><td>RUNNING   </td><td>202.117.43.132:12232</td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.78826</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.7248</td><td style=\"text-align: right;\">        1.78826</td></tr>\n",
       "<tr><td>training_function_bc58c_00004</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00005</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00006</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00007</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00008</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00009</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00010</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00011</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00012</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00013</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00014</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00015</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.82773</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3429</td><td style=\"text-align: right;\">        1.82773</td></tr>\n",
       "<tr><td>training_function_bc58c_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.61974</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.3733</td><td style=\"text-align: right;\">        1.61974</td></tr>\n",
       "<tr><td>training_function_bc58c_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.52086</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3946</td><td style=\"text-align: right;\">        1.52086</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00003:\n",
      "  date: 2021-08-29_11-06-55\n",
      "  done: true\n",
      "  experiment_id: 90c6e1c045e3487fbd6fcc4f4c3452d3\n",
      "  experiment_tag: 3_GAMMA=0.8,THETA=0.1\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.78826426160831\n",
      "  neg_mean_loss: 1.78826426160831\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12232\n",
      "  time_since_restore: 12.724765062332153\n",
      "  time_this_iter_s: 12.724765062332153\n",
      "  time_total_s: 12.724765062332153\n",
      "  timestamp: 1630206415\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00003\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12360)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=12360)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12360)\u001b[0m frac:0.25705980066445183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12360)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12360)\u001b[0m \n",
      "Training neural network:  54%|█████▍    | 27/50 [00:05<00:04,  5.39it/s, epoch=26, training_loss=0.0716, validation_loss=0.153]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12360)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00004:\n",
      "  date: 2021-08-29_11-07-14\n",
      "  done: false\n",
      "  experiment_id: 027a831772724364b3b8f7a50a1b0117\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -2.1977713019450658\n",
      "  neg_mean_loss: 2.1977713019450658\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12360\n",
      "  time_since_restore: 12.328447341918945\n",
      "  time_this_iter_s: 12.328447341918945\n",
      "  time_total_s: 12.328447341918945\n",
      "  timestamp: 1630206434\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00004\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 150.4/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/1.0 accelerator_type:V)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_11-03-50<br>Number of trials: 36/36 (31 PENDING, 1 RUNNING, 4 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_bc58c_00004</td><td>RUNNING   </td><td>202.117.43.132:12360</td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-2.19777</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3284</td><td style=\"text-align: right;\">        2.19777</td></tr>\n",
       "<tr><td>training_function_bc58c_00005</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00006</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00007</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00008</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00009</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00010</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00011</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00012</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00013</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00014</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00015</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.82773</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3429</td><td style=\"text-align: right;\">        1.82773</td></tr>\n",
       "<tr><td>training_function_bc58c_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.61974</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.3733</td><td style=\"text-align: right;\">        1.61974</td></tr>\n",
       "<tr><td>training_function_bc58c_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.52086</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3946</td><td style=\"text-align: right;\">        1.52086</td></tr>\n",
       "<tr><td>training_function_bc58c_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.78826</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.7248</td><td style=\"text-align: right;\">        1.78826</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00004:\n",
      "  date: 2021-08-29_11-07-14\n",
      "  done: true\n",
      "  experiment_id: 027a831772724364b3b8f7a50a1b0117\n",
      "  experiment_tag: 4_GAMMA=0.7,THETA=0.1\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -2.1977713019450658\n",
      "  neg_mean_loss: 2.1977713019450658\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12360\n",
      "  time_since_restore: 12.328447341918945\n",
      "  time_this_iter_s: 12.328447341918945\n",
      "  time_total_s: 12.328447341918945\n",
      "  timestamp: 1630206434\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00004\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12212)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=12212)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12212)\u001b[0m frac:0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12212)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12212)\u001b[0m \n",
      "Training neural network:  54%|█████▍    | 27/50 [00:05<00:04,  5.38it/s, epoch=26, training_loss=0.0874, validation_loss=0.15]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12212)\u001b[0m \n",
      "                                                                                                                              \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00005:\n",
      "  date: 2021-08-29_11-07-34\n",
      "  done: false\n",
      "  experiment_id: 59cc3d18c2ea4148b73d082d8a1ac68e\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -2.586478065259189\n",
      "  neg_mean_loss: 2.586478065259189\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12212\n",
      "  time_since_restore: 12.41753888130188\n",
      "  time_this_iter_s: 12.41753888130188\n",
      "  time_total_s: 12.41753888130188\n",
      "  timestamp: 1630206454\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00005\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 150.4/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/16.0 CPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/1.0 accelerator_type:V)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_11-03-50<br>Number of trials: 36/36 (30 PENDING, 1 RUNNING, 5 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_bc58c_00005</td><td>RUNNING   </td><td>202.117.43.132:12212</td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-2.58648</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.4175</td><td style=\"text-align: right;\">        2.58648</td></tr>\n",
       "<tr><td>training_function_bc58c_00006</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00007</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00008</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00009</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00010</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00011</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00012</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00013</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00014</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00015</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.82773</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3429</td><td style=\"text-align: right;\">        1.82773</td></tr>\n",
       "<tr><td>training_function_bc58c_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.61974</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.3733</td><td style=\"text-align: right;\">        1.61974</td></tr>\n",
       "<tr><td>training_function_bc58c_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.52086</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3946</td><td style=\"text-align: right;\">        1.52086</td></tr>\n",
       "<tr><td>training_function_bc58c_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.78826</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.7248</td><td style=\"text-align: right;\">        1.78826</td></tr>\n",
       "<tr><td>training_function_bc58c_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-2.19777</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3284</td><td style=\"text-align: right;\">        2.19777</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00005:\n",
      "  date: 2021-08-29_11-07-34\n",
      "  done: true\n",
      "  experiment_id: 59cc3d18c2ea4148b73d082d8a1ac68e\n",
      "  experiment_tag: 5_GAMMA=0.6,THETA=0.1\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -2.586478065259189\n",
      "  neg_mean_loss: 2.586478065259189\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12212\n",
      "  time_since_restore: 12.41753888130188\n",
      "  time_this_iter_s: 12.41753888130188\n",
      "  time_total_s: 12.41753888130188\n",
      "  timestamp: 1630206454\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00005\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12217)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=12217)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12217)\u001b[0m frac:0.04941860465116279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12217)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12217)\u001b[0m \n",
      "Training neural network:  58%|█████▊    | 29/50 [00:05<00:03,  5.66it/s, epoch=28, training_loss=0.0574, validation_loss=0.178]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12217)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00006:\n",
      "  date: 2021-08-29_11-07-52\n",
      "  done: false\n",
      "  experiment_id: b99c167f6c904423b826085f6f9b4005\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -0.915067561143688\n",
      "  neg_mean_loss: 0.915067561143688\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12217\n",
      "  time_since_restore: 12.105441570281982\n",
      "  time_this_iter_s: 12.105441570281982\n",
      "  time_total_s: 12.105441570281982\n",
      "  timestamp: 1630206472\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00006\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 150.4/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/1.0 accelerator_type:V)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_11-03-50<br>Number of trials: 36/36 (29 PENDING, 1 RUNNING, 6 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_bc58c_00006</td><td>RUNNING   </td><td>202.117.43.132:12217</td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-0.915068</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1054</td><td style=\"text-align: right;\">       0.915068</td></tr>\n",
       "<tr><td>training_function_bc58c_00007</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00008</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00009</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00010</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00011</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00012</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00013</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00014</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00015</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.82773 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3429</td><td style=\"text-align: right;\">       1.82773 </td></tr>\n",
       "<tr><td>training_function_bc58c_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.61974 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.3733</td><td style=\"text-align: right;\">       1.61974 </td></tr>\n",
       "<tr><td>training_function_bc58c_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.52086 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3946</td><td style=\"text-align: right;\">       1.52086 </td></tr>\n",
       "<tr><td>training_function_bc58c_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.78826 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.7248</td><td style=\"text-align: right;\">       1.78826 </td></tr>\n",
       "<tr><td>training_function_bc58c_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-2.19777 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3284</td><td style=\"text-align: right;\">       2.19777 </td></tr>\n",
       "<tr><td>training_function_bc58c_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-2.58648 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.4175</td><td style=\"text-align: right;\">       2.58648 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00006:\n",
      "  date: 2021-08-29_11-07-52\n",
      "  done: true\n",
      "  experiment_id: b99c167f6c904423b826085f6f9b4005\n",
      "  experiment_tag: 6_GAMMA=0.95,THETA=0.01\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -0.915067561143688\n",
      "  neg_mean_loss: 0.915067561143688\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12217\n",
      "  time_since_restore: 12.105441570281982\n",
      "  time_this_iter_s: 12.105441570281982\n",
      "  time_total_s: 12.105441570281982\n",
      "  timestamp: 1630206472\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00006\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12218)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=12218)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12218)\u001b[0m frac:0.04318936877076412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12218)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12218)\u001b[0m \n",
      "Training neural network:  58%|█████▊    | 29/50 [00:05<00:03,  5.72it/s, epoch=28, training_loss=0.0863, validation_loss=0.156]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12218)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00007:\n",
      "  date: 2021-08-29_11-08-12\n",
      "  done: false\n",
      "  experiment_id: 5d201420d541428a88d7ae98b4c74d57\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -2.3258593986407123\n",
      "  neg_mean_loss: 2.3258593986407123\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12218\n",
      "  time_since_restore: 12.180375576019287\n",
      "  time_this_iter_s: 12.180375576019287\n",
      "  time_total_s: 12.180375576019287\n",
      "  timestamp: 1630206492\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00007\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 150.4/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/1.0 accelerator_type:V, 0.0/16.0 CPU_group_0_de1602d26fa597a65349fb8b6a223582)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_11-03-50<br>Number of trials: 36/36 (28 PENDING, 1 RUNNING, 7 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_bc58c_00007</td><td>RUNNING   </td><td>202.117.43.132:12218</td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-2.32586 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1804</td><td style=\"text-align: right;\">       2.32586 </td></tr>\n",
       "<tr><td>training_function_bc58c_00008</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00009</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00010</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00011</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00012</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00013</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00014</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00015</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.82773 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3429</td><td style=\"text-align: right;\">       1.82773 </td></tr>\n",
       "<tr><td>training_function_bc58c_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.61974 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.3733</td><td style=\"text-align: right;\">       1.61974 </td></tr>\n",
       "<tr><td>training_function_bc58c_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.52086 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3946</td><td style=\"text-align: right;\">       1.52086 </td></tr>\n",
       "<tr><td>training_function_bc58c_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.78826 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.7248</td><td style=\"text-align: right;\">       1.78826 </td></tr>\n",
       "<tr><td>training_function_bc58c_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-2.19777 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3284</td><td style=\"text-align: right;\">       2.19777 </td></tr>\n",
       "<tr><td>training_function_bc58c_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-2.58648 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.4175</td><td style=\"text-align: right;\">       2.58648 </td></tr>\n",
       "<tr><td>training_function_bc58c_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-0.915068</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1054</td><td style=\"text-align: right;\">       0.915068</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00007:\n",
      "  date: 2021-08-29_11-08-12\n",
      "  done: true\n",
      "  experiment_id: 5d201420d541428a88d7ae98b4c74d57\n",
      "  experiment_tag: 7_GAMMA=0.9,THETA=0.01\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -2.3258593986407123\n",
      "  neg_mean_loss: 2.3258593986407123\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12218\n",
      "  time_since_restore: 12.180375576019287\n",
      "  time_this_iter_s: 12.180375576019287\n",
      "  time_total_s: 12.180375576019287\n",
      "  timestamp: 1630206492\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00007\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12314)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=12314)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12314)\u001b[0m frac:0.051079734219269105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12314)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12314)\u001b[0m \n",
      "Training neural network:  58%|█████▊    | 29/50 [00:05<00:03,  5.66it/s, epoch=28, training_loss=0.0939, validation_loss=0.141]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12314)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00008:\n",
      "  date: 2021-08-29_11-08-31\n",
      "  done: false\n",
      "  experiment_id: eb7426f4e4a44e8d890383b4ab3f7fcb\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.1691025711853158\n",
      "  neg_mean_loss: 1.1691025711853158\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12314\n",
      "  time_since_restore: 12.112401008605957\n",
      "  time_this_iter_s: 12.112401008605957\n",
      "  time_total_s: 12.112401008605957\n",
      "  timestamp: 1630206511\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00008\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 150.3/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_de1602d26fa597a65349fb8b6a223582)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_11-03-50<br>Number of trials: 36/36 (27 PENDING, 1 RUNNING, 8 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_bc58c_00008</td><td>RUNNING   </td><td>202.117.43.132:12314</td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-1.1691  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1124</td><td style=\"text-align: right;\">       1.1691  </td></tr>\n",
       "<tr><td>training_function_bc58c_00009</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00010</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00011</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00012</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00013</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00014</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00015</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.82773 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3429</td><td style=\"text-align: right;\">       1.82773 </td></tr>\n",
       "<tr><td>training_function_bc58c_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.61974 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.3733</td><td style=\"text-align: right;\">       1.61974 </td></tr>\n",
       "<tr><td>training_function_bc58c_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.52086 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3946</td><td style=\"text-align: right;\">       1.52086 </td></tr>\n",
       "<tr><td>training_function_bc58c_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.78826 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.7248</td><td style=\"text-align: right;\">       1.78826 </td></tr>\n",
       "<tr><td>training_function_bc58c_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-2.19777 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3284</td><td style=\"text-align: right;\">       2.19777 </td></tr>\n",
       "<tr><td>training_function_bc58c_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-2.58648 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.4175</td><td style=\"text-align: right;\">       2.58648 </td></tr>\n",
       "<tr><td>training_function_bc58c_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-0.915068</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1054</td><td style=\"text-align: right;\">       0.915068</td></tr>\n",
       "<tr><td>training_function_bc58c_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-2.32586 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1804</td><td style=\"text-align: right;\">       2.32586 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00008:\n",
      "  date: 2021-08-29_11-08-31\n",
      "  done: true\n",
      "  experiment_id: eb7426f4e4a44e8d890383b4ab3f7fcb\n",
      "  experiment_tag: 8_GAMMA=0.85,THETA=0.01\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.1691025711853158\n",
      "  neg_mean_loss: 1.1691025711853158\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12314\n",
      "  time_since_restore: 12.112401008605957\n",
      "  time_this_iter_s: 12.112401008605957\n",
      "  time_total_s: 12.112401008605957\n",
      "  timestamp: 1630206511\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00008\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12213)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=12213)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12213)\u001b[0m frac:0.04443521594684385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12213)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12213)\u001b[0m \n",
      "Training neural network:  58%|█████▊    | 29/50 [00:05<00:03,  5.65it/s, epoch=28, training_loss=0.0665, validation_loss=0.154]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00009:\n",
      "  date: 2021-08-29_11-08-49\n",
      "  done: false\n",
      "  experiment_id: b98b3731a00745e696f6f5760d1af696\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.3797503150054349\n",
      "  neg_mean_loss: 1.3797503150054349\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12213\n",
      "  time_since_restore: 12.14830207824707\n",
      "  time_this_iter_s: 12.14830207824707\n",
      "  time_total_s: 12.14830207824707\n",
      "  timestamp: 1630206529\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00009\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12213)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=12213)\u001b[0m \r",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 150.3/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/1.0 accelerator_type:V, 0.0/16.0 CPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_0_de1602d26fa597a65349fb8b6a223582)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_11-03-50<br>Number of trials: 36/36 (26 PENDING, 1 RUNNING, 9 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_bc58c_00009</td><td>RUNNING   </td><td>202.117.43.132:12213</td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-1.37975 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1483</td><td style=\"text-align: right;\">       1.37975 </td></tr>\n",
       "<tr><td>training_function_bc58c_00010</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00011</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00012</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00013</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00014</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00015</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.82773 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3429</td><td style=\"text-align: right;\">       1.82773 </td></tr>\n",
       "<tr><td>training_function_bc58c_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.61974 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.3733</td><td style=\"text-align: right;\">       1.61974 </td></tr>\n",
       "<tr><td>training_function_bc58c_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.52086 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3946</td><td style=\"text-align: right;\">       1.52086 </td></tr>\n",
       "<tr><td>training_function_bc58c_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.78826 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.7248</td><td style=\"text-align: right;\">       1.78826 </td></tr>\n",
       "<tr><td>training_function_bc58c_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-2.19777 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3284</td><td style=\"text-align: right;\">       2.19777 </td></tr>\n",
       "<tr><td>training_function_bc58c_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-2.58648 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.4175</td><td style=\"text-align: right;\">       2.58648 </td></tr>\n",
       "<tr><td>training_function_bc58c_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-0.915068</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1054</td><td style=\"text-align: right;\">       0.915068</td></tr>\n",
       "<tr><td>training_function_bc58c_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-2.32586 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1804</td><td style=\"text-align: right;\">       2.32586 </td></tr>\n",
       "<tr><td>training_function_bc58c_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-1.1691  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1124</td><td style=\"text-align: right;\">       1.1691  </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00009:\n",
      "  date: 2021-08-29_11-08-49\n",
      "  done: true\n",
      "  experiment_id: b98b3731a00745e696f6f5760d1af696\n",
      "  experiment_tag: 9_GAMMA=0.8,THETA=0.01\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.3797503150054349\n",
      "  neg_mean_loss: 1.3797503150054349\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12213\n",
      "  time_since_restore: 12.14830207824707\n",
      "  time_this_iter_s: 12.14830207824707\n",
      "  time_total_s: 12.14830207824707\n",
      "  timestamp: 1630206529\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00009\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12226)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=12226)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12226)\u001b[0m frac:0.04194352159468438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12226)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12226)\u001b[0m \n",
      "Training neural network:  52%|█████▏    | 26/50 [00:05<00:04,  5.11it/s, epoch=25, training_loss=0.0888, validation_loss=0.141]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12226)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00010:\n",
      "  date: 2021-08-29_11-09-09\n",
      "  done: false\n",
      "  experiment_id: 366263ca20524b90aa387f5c881f1491\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -0.8689354945191604\n",
      "  neg_mean_loss: 0.8689354945191604\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12226\n",
      "  time_since_restore: 13.093904256820679\n",
      "  time_this_iter_s: 13.093904256820679\n",
      "  time_total_s: 13.093904256820679\n",
      "  timestamp: 1630206549\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00010\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 150.3/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_de1602d26fa597a65349fb8b6a223582)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_11-03-50<br>Number of trials: 36/36 (25 PENDING, 1 RUNNING, 10 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_bc58c_00010</td><td>RUNNING   </td><td>202.117.43.132:12226</td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-0.868935</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.0939</td><td style=\"text-align: right;\">       0.868935</td></tr>\n",
       "<tr><td>training_function_bc58c_00011</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00012</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00013</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00014</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00015</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00020</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.82773 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3429</td><td style=\"text-align: right;\">       1.82773 </td></tr>\n",
       "<tr><td>training_function_bc58c_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.61974 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.3733</td><td style=\"text-align: right;\">       1.61974 </td></tr>\n",
       "<tr><td>training_function_bc58c_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.52086 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3946</td><td style=\"text-align: right;\">       1.52086 </td></tr>\n",
       "<tr><td>training_function_bc58c_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.78826 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.7248</td><td style=\"text-align: right;\">       1.78826 </td></tr>\n",
       "<tr><td>training_function_bc58c_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-2.19777 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3284</td><td style=\"text-align: right;\">       2.19777 </td></tr>\n",
       "<tr><td>training_function_bc58c_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-2.58648 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.4175</td><td style=\"text-align: right;\">       2.58648 </td></tr>\n",
       "<tr><td>training_function_bc58c_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-0.915068</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1054</td><td style=\"text-align: right;\">       0.915068</td></tr>\n",
       "<tr><td>training_function_bc58c_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-2.32586 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1804</td><td style=\"text-align: right;\">       2.32586 </td></tr>\n",
       "<tr><td>training_function_bc58c_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-1.1691  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1124</td><td style=\"text-align: right;\">       1.1691  </td></tr>\n",
       "<tr><td>training_function_bc58c_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-1.37975 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1483</td><td style=\"text-align: right;\">       1.37975 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (15 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00010:\n",
      "  date: 2021-08-29_11-09-09\n",
      "  done: true\n",
      "  experiment_id: 366263ca20524b90aa387f5c881f1491\n",
      "  experiment_tag: 10_GAMMA=0.7,THETA=0.01\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -0.8689354945191604\n",
      "  neg_mean_loss: 0.8689354945191604\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12226\n",
      "  time_since_restore: 13.093904256820679\n",
      "  time_this_iter_s: 13.093904256820679\n",
      "  time_total_s: 13.093904256820679\n",
      "  timestamp: 1630206549\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00010\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12182)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=12182)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12182)\u001b[0m frac:0.05191029900332226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12182)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12182)\u001b[0m \n",
      "Training neural network:  56%|█████▌    | 28/50 [00:05<00:04,  5.44it/s, epoch=27, training_loss=0.0631, validation_loss=0.175]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12182)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00011:\n",
      "  date: 2021-08-29_11-09-29\n",
      "  done: false\n",
      "  experiment_id: 6e7db7274362465fbe058a1d26389d60\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -2.49835320620922\n",
      "  neg_mean_loss: 2.49835320620922\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12182\n",
      "  time_since_restore: 12.632246255874634\n",
      "  time_this_iter_s: 12.632246255874634\n",
      "  time_total_s: 12.632246255874634\n",
      "  timestamp: 1630206569\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00011\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12193)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=12193)\u001b[0m \r",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00017:\n",
      "  date: 2021-08-29_11-11-24\n",
      "  done: false\n",
      "  experiment_id: c0f07b3a5d0143abb2f0d10bb227927d\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.7993407071426684\n",
      "  neg_mean_loss: 1.7993407071426684\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12193\n",
      "  time_since_restore: 12.570894241333008\n",
      "  time_this_iter_s: 12.570894241333008\n",
      "  time_total_s: 12.570894241333008\n",
      "  timestamp: 1630206684\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00017\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 150.2/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/1.0 accelerator_type:V, 0.0/16.0 CPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_de1602d26fa597a65349fb8b6a223582)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_11-03-50<br>Number of trials: 36/36 (18 PENDING, 1 RUNNING, 17 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_bc58c_00017</td><td>RUNNING   </td><td>202.117.43.132:12193</td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.79934 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.5709</td><td style=\"text-align: right;\">       1.79934 </td></tr>\n",
       "<tr><td>training_function_bc58c_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00020</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00021</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00022</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00023</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00024</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00025</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00026</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00027</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.82773 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3429</td><td style=\"text-align: right;\">       1.82773 </td></tr>\n",
       "<tr><td>training_function_bc58c_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.61974 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.3733</td><td style=\"text-align: right;\">       1.61974 </td></tr>\n",
       "<tr><td>training_function_bc58c_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.52086 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3946</td><td style=\"text-align: right;\">       1.52086 </td></tr>\n",
       "<tr><td>training_function_bc58c_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.78826 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.7248</td><td style=\"text-align: right;\">       1.78826 </td></tr>\n",
       "<tr><td>training_function_bc58c_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.19777 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3284</td><td style=\"text-align: right;\">       2.19777 </td></tr>\n",
       "<tr><td>training_function_bc58c_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.58648 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.4175</td><td style=\"text-align: right;\">       2.58648 </td></tr>\n",
       "<tr><td>training_function_bc58c_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.915068</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1054</td><td style=\"text-align: right;\">       0.915068</td></tr>\n",
       "<tr><td>training_function_bc58c_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.32586 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1804</td><td style=\"text-align: right;\">       2.32586 </td></tr>\n",
       "<tr><td>training_function_bc58c_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.1691  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1124</td><td style=\"text-align: right;\">       1.1691  </td></tr>\n",
       "<tr><td>training_function_bc58c_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.37975 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1483</td><td style=\"text-align: right;\">       1.37975 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (8 PENDING, 7 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00017:\n",
      "  date: 2021-08-29_11-11-24\n",
      "  done: true\n",
      "  experiment_id: c0f07b3a5d0143abb2f0d10bb227927d\n",
      "  experiment_tag: 17_GAMMA=0.6,THETA=0.003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.7993407071426684\n",
      "  neg_mean_loss: 1.7993407071426684\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12193\n",
      "  time_since_restore: 12.570894241333008\n",
      "  time_this_iter_s: 12.570894241333008\n",
      "  time_total_s: 12.570894241333008\n",
      "  timestamp: 1630206684\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00017\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12198)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=12198)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12198)\u001b[0m frac:0.011212624584717609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12198)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12198)\u001b[0m \n",
      "Training neural network:  58%|█████▊    | 29/50 [00:05<00:03,  5.65it/s, epoch=28, training_loss=0.0739, validation_loss=0.15]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12198)\u001b[0m \n",
      "                                                                                                                              \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00018:\n",
      "  date: 2021-08-29_11-11-42\n",
      "  done: false\n",
      "  experiment_id: 829983c89c884a31b4751366963223e2\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.8058732678372373\n",
      "  neg_mean_loss: 1.8058732678372373\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12198\n",
      "  time_since_restore: 12.073204278945923\n",
      "  time_this_iter_s: 12.073204278945923\n",
      "  time_total_s: 12.073204278945923\n",
      "  timestamp: 1630206702\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00018\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 150.2/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/16.0 CPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_de1602d26fa597a65349fb8b6a223582)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_11-03-50<br>Number of trials: 36/36 (17 PENDING, 1 RUNNING, 18 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_bc58c_00018</td><td>RUNNING   </td><td>202.117.43.132:12198</td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">-1.80587 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.0732</td><td style=\"text-align: right;\">       1.80587 </td></tr>\n",
       "<tr><td>training_function_bc58c_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00020</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00021</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00022</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00023</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00024</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00025</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00026</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00027</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00028</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.82773 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3429</td><td style=\"text-align: right;\">       1.82773 </td></tr>\n",
       "<tr><td>training_function_bc58c_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.61974 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.3733</td><td style=\"text-align: right;\">       1.61974 </td></tr>\n",
       "<tr><td>training_function_bc58c_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.52086 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3946</td><td style=\"text-align: right;\">       1.52086 </td></tr>\n",
       "<tr><td>training_function_bc58c_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.78826 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.7248</td><td style=\"text-align: right;\">       1.78826 </td></tr>\n",
       "<tr><td>training_function_bc58c_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.19777 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3284</td><td style=\"text-align: right;\">       2.19777 </td></tr>\n",
       "<tr><td>training_function_bc58c_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.58648 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.4175</td><td style=\"text-align: right;\">       2.58648 </td></tr>\n",
       "<tr><td>training_function_bc58c_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.915068</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1054</td><td style=\"text-align: right;\">       0.915068</td></tr>\n",
       "<tr><td>training_function_bc58c_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.32586 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1804</td><td style=\"text-align: right;\">       2.32586 </td></tr>\n",
       "<tr><td>training_function_bc58c_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.1691  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1124</td><td style=\"text-align: right;\">       1.1691  </td></tr>\n",
       "<tr><td>training_function_bc58c_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.37975 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1483</td><td style=\"text-align: right;\">       1.37975 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (7 PENDING, 8 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00018:\n",
      "  date: 2021-08-29_11-11-42\n",
      "  done: true\n",
      "  experiment_id: 829983c89c884a31b4751366963223e2\n",
      "  experiment_tag: 18_GAMMA=0.95,THETA=0.001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.8058732678372373\n",
      "  neg_mean_loss: 1.8058732678372373\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12198\n",
      "  time_since_restore: 12.073204278945923\n",
      "  time_this_iter_s: 12.073204278945923\n",
      "  time_total_s: 12.073204278945923\n",
      "  timestamp: 1630206702\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00018\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12184)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=12184)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12184)\u001b[0m frac:0.0070598006644518275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12184)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12184)\u001b[0m \n",
      "Training neural network:  54%|█████▍    | 27/50 [00:05<00:04,  5.33it/s, epoch=26, training_loss=0.0702, validation_loss=0.147]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12184)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00019:\n",
      "  date: 2021-08-29_11-12-02\n",
      "  done: false\n",
      "  experiment_id: cec6762c83ee43f9ba5170f13ddf6726\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.9226620034302653\n",
      "  neg_mean_loss: 1.9226620034302653\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12184\n",
      "  time_since_restore: 12.937299966812134\n",
      "  time_this_iter_s: 12.937299966812134\n",
      "  time_total_s: 12.937299966812134\n",
      "  timestamp: 1630206722\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00019\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 150.3/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/16.0 CPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/1.0 accelerator_type:V, 0.0/16.0 CPU_group_de1602d26fa597a65349fb8b6a223582)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_11-03-50<br>Number of trials: 36/36 (16 PENDING, 1 RUNNING, 19 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_bc58c_00019</td><td>RUNNING   </td><td>202.117.43.132:12184</td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">-1.92266 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.9373</td><td style=\"text-align: right;\">       1.92266 </td></tr>\n",
       "<tr><td>training_function_bc58c_00020</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00021</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00022</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00023</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00024</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00025</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00026</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00027</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00028</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00029</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.82773 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3429</td><td style=\"text-align: right;\">       1.82773 </td></tr>\n",
       "<tr><td>training_function_bc58c_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.61974 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.3733</td><td style=\"text-align: right;\">       1.61974 </td></tr>\n",
       "<tr><td>training_function_bc58c_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.52086 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3946</td><td style=\"text-align: right;\">       1.52086 </td></tr>\n",
       "<tr><td>training_function_bc58c_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.78826 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.7248</td><td style=\"text-align: right;\">       1.78826 </td></tr>\n",
       "<tr><td>training_function_bc58c_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.19777 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3284</td><td style=\"text-align: right;\">       2.19777 </td></tr>\n",
       "<tr><td>training_function_bc58c_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.58648 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.4175</td><td style=\"text-align: right;\">       2.58648 </td></tr>\n",
       "<tr><td>training_function_bc58c_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.915068</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1054</td><td style=\"text-align: right;\">       0.915068</td></tr>\n",
       "<tr><td>training_function_bc58c_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.32586 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1804</td><td style=\"text-align: right;\">       2.32586 </td></tr>\n",
       "<tr><td>training_function_bc58c_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.1691  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1124</td><td style=\"text-align: right;\">       1.1691  </td></tr>\n",
       "<tr><td>training_function_bc58c_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.37975 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1483</td><td style=\"text-align: right;\">       1.37975 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (6 PENDING, 9 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00019:\n",
      "  date: 2021-08-29_11-12-02\n",
      "  done: true\n",
      "  experiment_id: cec6762c83ee43f9ba5170f13ddf6726\n",
      "  experiment_tag: 19_GAMMA=0.9,THETA=0.001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.9226620034302653\n",
      "  neg_mean_loss: 1.9226620034302653\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12184\n",
      "  time_since_restore: 12.937299966812134\n",
      "  time_this_iter_s: 12.937299966812134\n",
      "  time_total_s: 12.937299966812134\n",
      "  timestamp: 1630206722\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00019\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12200)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=12200)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12200)\u001b[0m frac:0.009551495016611296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12200)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12200)\u001b[0m \n",
      "Training neural network:  56%|█████▌    | 28/50 [00:05<00:04,  5.44it/s, epoch=27, training_loss=0.0589, validation_loss=0.147]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12200)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00020:\n",
      "  date: 2021-08-29_11-12-21\n",
      "  done: false\n",
      "  experiment_id: 80c8d9536c33469b9e4749077a3971b5\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.420511968412083\n",
      "  neg_mean_loss: 1.420511968412083\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12200\n",
      "  time_since_restore: 12.312766790390015\n",
      "  time_this_iter_s: 12.312766790390015\n",
      "  time_total_s: 12.312766790390015\n",
      "  timestamp: 1630206741\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00020\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 150.2/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/1.0 accelerator_type:V, 0.0/16.0 CPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_de1602d26fa597a65349fb8b6a223582)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_11-03-50<br>Number of trials: 36/36 (15 PENDING, 1 RUNNING, 20 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_bc58c_00020</td><td>RUNNING   </td><td>202.117.43.132:12200</td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">-1.42051 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3128</td><td style=\"text-align: right;\">       1.42051 </td></tr>\n",
       "<tr><td>training_function_bc58c_00021</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00022</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00023</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00024</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00025</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00026</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00027</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00028</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00029</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00030</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.82773 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3429</td><td style=\"text-align: right;\">       1.82773 </td></tr>\n",
       "<tr><td>training_function_bc58c_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.61974 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.3733</td><td style=\"text-align: right;\">       1.61974 </td></tr>\n",
       "<tr><td>training_function_bc58c_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.52086 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3946</td><td style=\"text-align: right;\">       1.52086 </td></tr>\n",
       "<tr><td>training_function_bc58c_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.78826 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.7248</td><td style=\"text-align: right;\">       1.78826 </td></tr>\n",
       "<tr><td>training_function_bc58c_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.19777 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3284</td><td style=\"text-align: right;\">       2.19777 </td></tr>\n",
       "<tr><td>training_function_bc58c_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.58648 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.4175</td><td style=\"text-align: right;\">       2.58648 </td></tr>\n",
       "<tr><td>training_function_bc58c_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.915068</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1054</td><td style=\"text-align: right;\">       0.915068</td></tr>\n",
       "<tr><td>training_function_bc58c_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.32586 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1804</td><td style=\"text-align: right;\">       2.32586 </td></tr>\n",
       "<tr><td>training_function_bc58c_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.1691  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1124</td><td style=\"text-align: right;\">       1.1691  </td></tr>\n",
       "<tr><td>training_function_bc58c_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.37975 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1483</td><td style=\"text-align: right;\">       1.37975 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (5 PENDING, 10 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00020:\n",
      "  date: 2021-08-29_11-12-21\n",
      "  done: true\n",
      "  experiment_id: 80c8d9536c33469b9e4749077a3971b5\n",
      "  experiment_tag: 20_GAMMA=0.85,THETA=0.001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.420511968412083\n",
      "  neg_mean_loss: 1.420511968412083\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12200\n",
      "  time_since_restore: 12.312766790390015\n",
      "  time_this_iter_s: 12.312766790390015\n",
      "  time_total_s: 12.312766790390015\n",
      "  timestamp: 1630206741\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00020\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12197)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=12197)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12197)\u001b[0m frac:0.006229235880398671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12197)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12197)\u001b[0m \n",
      "Training neural network:  58%|█████▊    | 29/50 [00:05<00:03,  5.71it/s, epoch=28, training_loss=0.0604, validation_loss=0.168]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12197)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00021:\n",
      "  date: 2021-08-29_11-12-40\n",
      "  done: false\n",
      "  experiment_id: 62a5353e1ade49d9a5f23da48d38d0e2\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -0.6972158066274091\n",
      "  neg_mean_loss: 0.6972158066274091\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12197\n",
      "  time_since_restore: 12.00513482093811\n",
      "  time_this_iter_s: 12.00513482093811\n",
      "  time_total_s: 12.00513482093811\n",
      "  timestamp: 1630206760\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00021\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 150.2/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/16.0 CPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/1.0 accelerator_type:V)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_11-03-50<br>Number of trials: 36/36 (14 PENDING, 1 RUNNING, 21 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_bc58c_00021</td><td>RUNNING   </td><td>202.117.43.132:12197</td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">-0.697216</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.0051</td><td style=\"text-align: right;\">       0.697216</td></tr>\n",
       "<tr><td>training_function_bc58c_00022</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00023</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00024</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00025</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00026</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00027</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00028</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00029</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00030</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00031</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.82773 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3429</td><td style=\"text-align: right;\">       1.82773 </td></tr>\n",
       "<tr><td>training_function_bc58c_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.61974 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.3733</td><td style=\"text-align: right;\">       1.61974 </td></tr>\n",
       "<tr><td>training_function_bc58c_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.52086 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3946</td><td style=\"text-align: right;\">       1.52086 </td></tr>\n",
       "<tr><td>training_function_bc58c_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.78826 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.7248</td><td style=\"text-align: right;\">       1.78826 </td></tr>\n",
       "<tr><td>training_function_bc58c_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.19777 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3284</td><td style=\"text-align: right;\">       2.19777 </td></tr>\n",
       "<tr><td>training_function_bc58c_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.58648 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.4175</td><td style=\"text-align: right;\">       2.58648 </td></tr>\n",
       "<tr><td>training_function_bc58c_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.915068</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1054</td><td style=\"text-align: right;\">       0.915068</td></tr>\n",
       "<tr><td>training_function_bc58c_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.32586 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1804</td><td style=\"text-align: right;\">       2.32586 </td></tr>\n",
       "<tr><td>training_function_bc58c_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.1691  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1124</td><td style=\"text-align: right;\">       1.1691  </td></tr>\n",
       "<tr><td>training_function_bc58c_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.37975 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1483</td><td style=\"text-align: right;\">       1.37975 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (4 PENDING, 11 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00021:\n",
      "  date: 2021-08-29_11-12-40\n",
      "  done: true\n",
      "  experiment_id: 62a5353e1ade49d9a5f23da48d38d0e2\n",
      "  experiment_tag: 21_GAMMA=0.8,THETA=0.001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -0.6972158066274091\n",
      "  neg_mean_loss: 0.6972158066274091\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12197\n",
      "  time_since_restore: 12.00513482093811\n",
      "  time_this_iter_s: 12.00513482093811\n",
      "  time_total_s: 12.00513482093811\n",
      "  timestamp: 1630206760\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00021\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12205)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=12205)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12205)\u001b[0m frac:0.009551495016611296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12205)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12205)\u001b[0m \n",
      "Training neural network:  58%|█████▊    | 29/50 [00:05<00:03,  5.65it/s, epoch=28, training_loss=0.0646, validation_loss=0.16]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12205)\u001b[0m \n",
      "                                                                                                                              \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00022:\n",
      "  date: 2021-08-29_11-12-59\n",
      "  done: false\n",
      "  experiment_id: d974f844529c4fa7b4c18854acba97b4\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.4677953461500715\n",
      "  neg_mean_loss: 1.4677953461500715\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12205\n",
      "  time_since_restore: 12.307892084121704\n",
      "  time_this_iter_s: 12.307892084121704\n",
      "  time_total_s: 12.307892084121704\n",
      "  timestamp: 1630206779\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00022\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 150.2/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/16.0 CPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_de1602d26fa597a65349fb8b6a223582)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_11-03-50<br>Number of trials: 36/36 (13 PENDING, 1 RUNNING, 22 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_bc58c_00022</td><td>RUNNING   </td><td>202.117.43.132:12205</td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">-1.4678  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3079</td><td style=\"text-align: right;\">       1.4678  </td></tr>\n",
       "<tr><td>training_function_bc58c_00023</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00024</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00025</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00026</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00027</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00028</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00029</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00030</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00031</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00032</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.82773 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3429</td><td style=\"text-align: right;\">       1.82773 </td></tr>\n",
       "<tr><td>training_function_bc58c_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.61974 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.3733</td><td style=\"text-align: right;\">       1.61974 </td></tr>\n",
       "<tr><td>training_function_bc58c_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.52086 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3946</td><td style=\"text-align: right;\">       1.52086 </td></tr>\n",
       "<tr><td>training_function_bc58c_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.78826 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.7248</td><td style=\"text-align: right;\">       1.78826 </td></tr>\n",
       "<tr><td>training_function_bc58c_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.19777 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3284</td><td style=\"text-align: right;\">       2.19777 </td></tr>\n",
       "<tr><td>training_function_bc58c_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.58648 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.4175</td><td style=\"text-align: right;\">       2.58648 </td></tr>\n",
       "<tr><td>training_function_bc58c_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.915068</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1054</td><td style=\"text-align: right;\">       0.915068</td></tr>\n",
       "<tr><td>training_function_bc58c_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.32586 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1804</td><td style=\"text-align: right;\">       2.32586 </td></tr>\n",
       "<tr><td>training_function_bc58c_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.1691  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1124</td><td style=\"text-align: right;\">       1.1691  </td></tr>\n",
       "<tr><td>training_function_bc58c_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.37975 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1483</td><td style=\"text-align: right;\">       1.37975 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (3 PENDING, 12 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00022:\n",
      "  date: 2021-08-29_11-12-59\n",
      "  done: true\n",
      "  experiment_id: d974f844529c4fa7b4c18854acba97b4\n",
      "  experiment_tag: 22_GAMMA=0.7,THETA=0.001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.4677953461500715\n",
      "  neg_mean_loss: 1.4677953461500715\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12205\n",
      "  time_since_restore: 12.307892084121704\n",
      "  time_this_iter_s: 12.307892084121704\n",
      "  time_total_s: 12.307892084121704\n",
      "  timestamp: 1630206779\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00022\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12183)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=12183)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12183)\u001b[0m frac:0.008305647840531562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12183)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12183)\u001b[0m \n",
      "Training neural network:  56%|█████▌    | 28/50 [00:05<00:04,  5.48it/s, epoch=27, training_loss=0.0688, validation_loss=0.159]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12183)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00023:\n",
      "  date: 2021-08-29_11-13-18\n",
      "  done: false\n",
      "  experiment_id: 5f68e1af8a524408a16111146148140c\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.1944967443436996\n",
      "  neg_mean_loss: 1.1944967443436996\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12183\n",
      "  time_since_restore: 12.337287902832031\n",
      "  time_this_iter_s: 12.337287902832031\n",
      "  time_total_s: 12.337287902832031\n",
      "  timestamp: 1630206798\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00023\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 150.2/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/16.0 CPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/1.0 accelerator_type:V)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_11-03-50<br>Number of trials: 36/36 (12 PENDING, 1 RUNNING, 23 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_bc58c_00023</td><td>RUNNING   </td><td>202.117.43.132:12183</td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">-1.1945  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3373</td><td style=\"text-align: right;\">       1.1945  </td></tr>\n",
       "<tr><td>training_function_bc58c_00024</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00025</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00026</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00027</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00028</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00029</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00030</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00031</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00032</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00033</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.82773 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3429</td><td style=\"text-align: right;\">       1.82773 </td></tr>\n",
       "<tr><td>training_function_bc58c_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.61974 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.3733</td><td style=\"text-align: right;\">       1.61974 </td></tr>\n",
       "<tr><td>training_function_bc58c_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.52086 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3946</td><td style=\"text-align: right;\">       1.52086 </td></tr>\n",
       "<tr><td>training_function_bc58c_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.78826 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.7248</td><td style=\"text-align: right;\">       1.78826 </td></tr>\n",
       "<tr><td>training_function_bc58c_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.19777 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3284</td><td style=\"text-align: right;\">       2.19777 </td></tr>\n",
       "<tr><td>training_function_bc58c_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.58648 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.4175</td><td style=\"text-align: right;\">       2.58648 </td></tr>\n",
       "<tr><td>training_function_bc58c_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.915068</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1054</td><td style=\"text-align: right;\">       0.915068</td></tr>\n",
       "<tr><td>training_function_bc58c_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.32586 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1804</td><td style=\"text-align: right;\">       2.32586 </td></tr>\n",
       "<tr><td>training_function_bc58c_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.1691  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1124</td><td style=\"text-align: right;\">       1.1691  </td></tr>\n",
       "<tr><td>training_function_bc58c_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.37975 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1483</td><td style=\"text-align: right;\">       1.37975 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (2 PENDING, 13 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00023:\n",
      "  date: 2021-08-29_11-13-18\n",
      "  done: true\n",
      "  experiment_id: 5f68e1af8a524408a16111146148140c\n",
      "  experiment_tag: 23_GAMMA=0.6,THETA=0.001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.1944967443436996\n",
      "  neg_mean_loss: 1.1944967443436996\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12183\n",
      "  time_since_restore: 12.337287902832031\n",
      "  time_this_iter_s: 12.337287902832031\n",
      "  time_total_s: 12.337287902832031\n",
      "  timestamp: 1630206798\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00023\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12202)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=12202)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12202)\u001b[0m frac:0.0070598006644518275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12202)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12202)\u001b[0m \n",
      "Training neural network:  56%|█████▌    | 28/50 [00:05<00:04,  5.48it/s, epoch=27, training_loss=0.0823, validation_loss=0.145]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12202)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00024:\n",
      "  date: 2021-08-29_11-13-37\n",
      "  done: false\n",
      "  experiment_id: 59109d7dd53d40ee9d3659317817362f\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.621885661333232\n",
      "  neg_mean_loss: 1.621885661333232\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12202\n",
      "  time_since_restore: 12.327820062637329\n",
      "  time_this_iter_s: 12.327820062637329\n",
      "  time_total_s: 12.327820062637329\n",
      "  timestamp: 1630206817\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00024\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 150.2/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/16.0 CPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/1.0 accelerator_type:V, 0.0/16.0 CPU_group_0_de1602d26fa597a65349fb8b6a223582)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_11-03-50<br>Number of trials: 36/36 (11 PENDING, 1 RUNNING, 24 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_bc58c_00024</td><td>RUNNING   </td><td>202.117.43.132:12202</td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">-1.62189 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3278</td><td style=\"text-align: right;\">       1.62189 </td></tr>\n",
       "<tr><td>training_function_bc58c_00025</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00026</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00027</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00028</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00029</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00030</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00031</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00032</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00033</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00034</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.82773 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3429</td><td style=\"text-align: right;\">       1.82773 </td></tr>\n",
       "<tr><td>training_function_bc58c_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.61974 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.3733</td><td style=\"text-align: right;\">       1.61974 </td></tr>\n",
       "<tr><td>training_function_bc58c_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.52086 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3946</td><td style=\"text-align: right;\">       1.52086 </td></tr>\n",
       "<tr><td>training_function_bc58c_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.78826 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.7248</td><td style=\"text-align: right;\">       1.78826 </td></tr>\n",
       "<tr><td>training_function_bc58c_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.19777 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3284</td><td style=\"text-align: right;\">       2.19777 </td></tr>\n",
       "<tr><td>training_function_bc58c_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.58648 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.4175</td><td style=\"text-align: right;\">       2.58648 </td></tr>\n",
       "<tr><td>training_function_bc58c_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.915068</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1054</td><td style=\"text-align: right;\">       0.915068</td></tr>\n",
       "<tr><td>training_function_bc58c_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.32586 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1804</td><td style=\"text-align: right;\">       2.32586 </td></tr>\n",
       "<tr><td>training_function_bc58c_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.1691  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1124</td><td style=\"text-align: right;\">       1.1691  </td></tr>\n",
       "<tr><td>training_function_bc58c_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.37975 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1483</td><td style=\"text-align: right;\">       1.37975 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (1 PENDING, 14 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00024:\n",
      "  date: 2021-08-29_11-13-37\n",
      "  done: true\n",
      "  experiment_id: 59109d7dd53d40ee9d3659317817362f\n",
      "  experiment_tag: 24_GAMMA=0.95,THETA=0.0003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.621885661333232\n",
      "  neg_mean_loss: 1.621885661333232\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12202\n",
      "  time_since_restore: 12.327820062637329\n",
      "  time_this_iter_s: 12.327820062637329\n",
      "  time_total_s: 12.327820062637329\n",
      "  timestamp: 1630206817\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00024\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12203)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=12203)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12203)\u001b[0m frac:0.008305647840531562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12203)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12203)\u001b[0m \n",
      "Training neural network:  56%|█████▌    | 28/50 [00:05<00:03,  5.55it/s, epoch=27, training_loss=0.0553, validation_loss=0.162]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12203)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00025:\n",
      "  date: 2021-08-29_11-13-56\n",
      "  done: false\n",
      "  experiment_id: 850f231a60124e0ea12e65207f52a36b\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.2685052203612004\n",
      "  neg_mean_loss: 1.2685052203612004\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12203\n",
      "  time_since_restore: 12.206517457962036\n",
      "  time_this_iter_s: 12.206517457962036\n",
      "  time_total_s: 12.206517457962036\n",
      "  timestamp: 1630206836\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00025\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 150.1/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/16.0 CPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_0_de1602d26fa597a65349fb8b6a223582)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_11-03-50<br>Number of trials: 36/36 (10 PENDING, 1 RUNNING, 25 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_bc58c_00025</td><td>RUNNING   </td><td>202.117.43.132:12203</td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">-1.26851 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.2065</td><td style=\"text-align: right;\">       1.26851 </td></tr>\n",
       "<tr><td>training_function_bc58c_00026</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00027</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00028</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00029</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00030</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00031</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00032</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00033</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00034</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00035</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.82773 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3429</td><td style=\"text-align: right;\">       1.82773 </td></tr>\n",
       "<tr><td>training_function_bc58c_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.61974 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.3733</td><td style=\"text-align: right;\">       1.61974 </td></tr>\n",
       "<tr><td>training_function_bc58c_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.52086 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3946</td><td style=\"text-align: right;\">       1.52086 </td></tr>\n",
       "<tr><td>training_function_bc58c_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.78826 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.7248</td><td style=\"text-align: right;\">       1.78826 </td></tr>\n",
       "<tr><td>training_function_bc58c_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.19777 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3284</td><td style=\"text-align: right;\">       2.19777 </td></tr>\n",
       "<tr><td>training_function_bc58c_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.58648 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.4175</td><td style=\"text-align: right;\">       2.58648 </td></tr>\n",
       "<tr><td>training_function_bc58c_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.915068</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1054</td><td style=\"text-align: right;\">       0.915068</td></tr>\n",
       "<tr><td>training_function_bc58c_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.32586 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1804</td><td style=\"text-align: right;\">       2.32586 </td></tr>\n",
       "<tr><td>training_function_bc58c_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.1691  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1124</td><td style=\"text-align: right;\">       1.1691  </td></tr>\n",
       "<tr><td>training_function_bc58c_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.37975 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1483</td><td style=\"text-align: right;\">       1.37975 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (15 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00025:\n",
      "  date: 2021-08-29_11-13-56\n",
      "  done: true\n",
      "  experiment_id: 850f231a60124e0ea12e65207f52a36b\n",
      "  experiment_tag: 25_GAMMA=0.9,THETA=0.0003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.2685052203612004\n",
      "  neg_mean_loss: 1.2685052203612004\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12203\n",
      "  time_since_restore: 12.206517457962036\n",
      "  time_this_iter_s: 12.206517457962036\n",
      "  time_total_s: 12.206517457962036\n",
      "  timestamp: 1630206836\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00025\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12191)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=12191)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12191)\u001b[0m frac:0.0070598006644518275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12191)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12191)\u001b[0m \n",
      "Training neural network:  56%|█████▌    | 28/50 [00:05<00:03,  5.51it/s, epoch=27, training_loss=0.0526, validation_loss=0.164]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12191)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00026:\n",
      "  date: 2021-08-29_11-14-15\n",
      "  done: false\n",
      "  experiment_id: 921619efd0fc4ac996204586d574595b\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.520861701675519\n",
      "  neg_mean_loss: 1.520861701675519\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12191\n",
      "  time_since_restore: 12.512071132659912\n",
      "  time_this_iter_s: 12.512071132659912\n",
      "  time_total_s: 12.512071132659912\n",
      "  timestamp: 1630206855\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00026\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 150.1/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/1.0 accelerator_type:V)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_11-03-50<br>Number of trials: 36/36 (9 PENDING, 1 RUNNING, 26 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_bc58c_00026</td><td>RUNNING   </td><td>202.117.43.132:12191</td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">-1.52086 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.5121</td><td style=\"text-align: right;\">       1.52086 </td></tr>\n",
       "<tr><td>training_function_bc58c_00027</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00028</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00029</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00030</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00031</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00032</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00033</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00034</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00035</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.82773 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3429</td><td style=\"text-align: right;\">       1.82773 </td></tr>\n",
       "<tr><td>training_function_bc58c_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.61974 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.3733</td><td style=\"text-align: right;\">       1.61974 </td></tr>\n",
       "<tr><td>training_function_bc58c_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.52086 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3946</td><td style=\"text-align: right;\">       1.52086 </td></tr>\n",
       "<tr><td>training_function_bc58c_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.78826 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.7248</td><td style=\"text-align: right;\">       1.78826 </td></tr>\n",
       "<tr><td>training_function_bc58c_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.19777 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3284</td><td style=\"text-align: right;\">       2.19777 </td></tr>\n",
       "<tr><td>training_function_bc58c_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.58648 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.4175</td><td style=\"text-align: right;\">       2.58648 </td></tr>\n",
       "<tr><td>training_function_bc58c_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.915068</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1054</td><td style=\"text-align: right;\">       0.915068</td></tr>\n",
       "<tr><td>training_function_bc58c_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.32586 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1804</td><td style=\"text-align: right;\">       2.32586 </td></tr>\n",
       "<tr><td>training_function_bc58c_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.1691  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1124</td><td style=\"text-align: right;\">       1.1691  </td></tr>\n",
       "<tr><td>training_function_bc58c_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.37975 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1483</td><td style=\"text-align: right;\">       1.37975 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00026:\n",
      "  date: 2021-08-29_11-14-15\n",
      "  done: true\n",
      "  experiment_id: 921619efd0fc4ac996204586d574595b\n",
      "  experiment_tag: 26_GAMMA=0.85,THETA=0.0003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.520861701675519\n",
      "  neg_mean_loss: 1.520861701675519\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12191\n",
      "  time_since_restore: 12.512071132659912\n",
      "  time_this_iter_s: 12.512071132659912\n",
      "  time_total_s: 12.512071132659912\n",
      "  timestamp: 1630206855\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00026\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12194)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=12194)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12194)\u001b[0m frac:0.006229235880398671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12194)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12194)\u001b[0m \n",
      "Training neural network:  56%|█████▌    | 28/50 [00:05<00:04,  5.43it/s, epoch=27, training_loss=0.0653, validation_loss=0.151]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12194)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00027:\n",
      "  date: 2021-08-29_11-14-34\n",
      "  done: false\n",
      "  experiment_id: 0e2a84152e0e483f9ec9adf5a3e41a45\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.6394946675621591\n",
      "  neg_mean_loss: 1.6394946675621591\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12194\n",
      "  time_since_restore: 13.249226093292236\n",
      "  time_this_iter_s: 13.249226093292236\n",
      "  time_total_s: 13.249226093292236\n",
      "  timestamp: 1630206874\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00027\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 150.1/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/16.0 CPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_0_de1602d26fa597a65349fb8b6a223582)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_11-03-50<br>Number of trials: 36/36 (8 PENDING, 1 RUNNING, 27 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_bc58c_00027</td><td>RUNNING   </td><td>202.117.43.132:12194</td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">-1.63949 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.2492</td><td style=\"text-align: right;\">       1.63949 </td></tr>\n",
       "<tr><td>training_function_bc58c_00028</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00029</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00030</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00031</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00032</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00033</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00034</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00035</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.82773 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3429</td><td style=\"text-align: right;\">       1.82773 </td></tr>\n",
       "<tr><td>training_function_bc58c_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.61974 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.3733</td><td style=\"text-align: right;\">       1.61974 </td></tr>\n",
       "<tr><td>training_function_bc58c_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.52086 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3946</td><td style=\"text-align: right;\">       1.52086 </td></tr>\n",
       "<tr><td>training_function_bc58c_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.78826 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.7248</td><td style=\"text-align: right;\">       1.78826 </td></tr>\n",
       "<tr><td>training_function_bc58c_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.19777 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3284</td><td style=\"text-align: right;\">       2.19777 </td></tr>\n",
       "<tr><td>training_function_bc58c_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.58648 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.4175</td><td style=\"text-align: right;\">       2.58648 </td></tr>\n",
       "<tr><td>training_function_bc58c_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.915068</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1054</td><td style=\"text-align: right;\">       0.915068</td></tr>\n",
       "<tr><td>training_function_bc58c_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.32586 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1804</td><td style=\"text-align: right;\">       2.32586 </td></tr>\n",
       "<tr><td>training_function_bc58c_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.1691  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1124</td><td style=\"text-align: right;\">       1.1691  </td></tr>\n",
       "<tr><td>training_function_bc58c_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.37975 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1483</td><td style=\"text-align: right;\">       1.37975 </td></tr>\n",
       "<tr><td>training_function_bc58c_00010</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.868935</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.0939</td><td style=\"text-align: right;\">       0.868935</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00027:\n",
      "  date: 2021-08-29_11-14-34\n",
      "  done: true\n",
      "  experiment_id: 0e2a84152e0e483f9ec9adf5a3e41a45\n",
      "  experiment_tag: 27_GAMMA=0.8,THETA=0.0003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.6394946675621591\n",
      "  neg_mean_loss: 1.6394946675621591\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12194\n",
      "  time_since_restore: 13.249226093292236\n",
      "  time_this_iter_s: 13.249226093292236\n",
      "  time_total_s: 13.249226093292236\n",
      "  timestamp: 1630206874\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00027\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12181)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=12181)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12181)\u001b[0m frac:0.010382059800664452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12181)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12181)\u001b[0m \n",
      "Training neural network:  54%|█████▍    | 27/50 [00:05<00:04,  5.31it/s, epoch=26, training_loss=0.0619, validation_loss=0.163]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12181)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00028:\n",
      "  date: 2021-08-29_11-14-53\n",
      "  done: false\n",
      "  experiment_id: 873830c243ac4e72af71fc7f9a499e91\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.4522699070534217\n",
      "  neg_mean_loss: 1.4522699070534217\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12181\n",
      "  time_since_restore: 12.380378246307373\n",
      "  time_this_iter_s: 12.380378246307373\n",
      "  time_total_s: 12.380378246307373\n",
      "  timestamp: 1630206893\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00028\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 150.1/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/16.0 CPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/1.0 accelerator_type:V, 0.0/16.0 CPU_group_0_de1602d26fa597a65349fb8b6a223582)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_11-03-50<br>Number of trials: 36/36 (7 PENDING, 1 RUNNING, 28 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_bc58c_00028</td><td>RUNNING   </td><td>202.117.43.132:12181</td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">-1.45227 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3804</td><td style=\"text-align: right;\">       1.45227 </td></tr>\n",
       "<tr><td>training_function_bc58c_00029</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00030</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00031</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00032</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00033</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00034</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00035</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.82773 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3429</td><td style=\"text-align: right;\">       1.82773 </td></tr>\n",
       "<tr><td>training_function_bc58c_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.61974 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.3733</td><td style=\"text-align: right;\">       1.61974 </td></tr>\n",
       "<tr><td>training_function_bc58c_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.52086 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3946</td><td style=\"text-align: right;\">       1.52086 </td></tr>\n",
       "<tr><td>training_function_bc58c_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.78826 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.7248</td><td style=\"text-align: right;\">       1.78826 </td></tr>\n",
       "<tr><td>training_function_bc58c_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.19777 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3284</td><td style=\"text-align: right;\">       2.19777 </td></tr>\n",
       "<tr><td>training_function_bc58c_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.58648 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.4175</td><td style=\"text-align: right;\">       2.58648 </td></tr>\n",
       "<tr><td>training_function_bc58c_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.915068</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1054</td><td style=\"text-align: right;\">       0.915068</td></tr>\n",
       "<tr><td>training_function_bc58c_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.32586 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1804</td><td style=\"text-align: right;\">       2.32586 </td></tr>\n",
       "<tr><td>training_function_bc58c_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.1691  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1124</td><td style=\"text-align: right;\">       1.1691  </td></tr>\n",
       "<tr><td>training_function_bc58c_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.37975 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1483</td><td style=\"text-align: right;\">       1.37975 </td></tr>\n",
       "<tr><td>training_function_bc58c_00010</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.868935</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.0939</td><td style=\"text-align: right;\">       0.868935</td></tr>\n",
       "<tr><td>training_function_bc58c_00011</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.49835 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.6322</td><td style=\"text-align: right;\">       2.49835 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00028:\n",
      "  date: 2021-08-29_11-14-53\n",
      "  done: true\n",
      "  experiment_id: 873830c243ac4e72af71fc7f9a499e91\n",
      "  experiment_tag: 28_GAMMA=0.7,THETA=0.0003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.4522699070534217\n",
      "  neg_mean_loss: 1.4522699070534217\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12181\n",
      "  time_since_restore: 12.380378246307373\n",
      "  time_this_iter_s: 12.380378246307373\n",
      "  time_total_s: 12.380378246307373\n",
      "  timestamp: 1630206893\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00028\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12196)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=12196)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12196)\u001b[0m frac:0.009966777408637873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12196)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12196)\u001b[0m \n",
      "Training neural network:  56%|█████▌    | 28/50 [00:05<00:04,  5.47it/s, epoch=27, training_loss=0.0693, validation_loss=0.147]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12196)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00029:\n",
      "  date: 2021-08-29_11-15-12\n",
      "  done: false\n",
      "  experiment_id: 126efdabbb004fc1a7a500460a025ad7\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.4677953461500715\n",
      "  neg_mean_loss: 1.4677953461500715\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12196\n",
      "  time_since_restore: 12.171297311782837\n",
      "  time_this_iter_s: 12.171297311782837\n",
      "  time_total_s: 12.171297311782837\n",
      "  timestamp: 1630206912\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00029\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 150.1/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/1.0 accelerator_type:V, 0.0/16.0 CPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_de1602d26fa597a65349fb8b6a223582)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_11-03-50<br>Number of trials: 36/36 (6 PENDING, 1 RUNNING, 29 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_bc58c_00029</td><td>RUNNING   </td><td>202.117.43.132:12196</td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">-1.4678  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1713</td><td style=\"text-align: right;\">       1.4678  </td></tr>\n",
       "<tr><td>training_function_bc58c_00030</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00031</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00032</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00033</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00034</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00035</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.82773 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3429</td><td style=\"text-align: right;\">       1.82773 </td></tr>\n",
       "<tr><td>training_function_bc58c_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.61974 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.3733</td><td style=\"text-align: right;\">       1.61974 </td></tr>\n",
       "<tr><td>training_function_bc58c_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.52086 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3946</td><td style=\"text-align: right;\">       1.52086 </td></tr>\n",
       "<tr><td>training_function_bc58c_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.78826 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.7248</td><td style=\"text-align: right;\">       1.78826 </td></tr>\n",
       "<tr><td>training_function_bc58c_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.19777 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3284</td><td style=\"text-align: right;\">       2.19777 </td></tr>\n",
       "<tr><td>training_function_bc58c_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.58648 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.4175</td><td style=\"text-align: right;\">       2.58648 </td></tr>\n",
       "<tr><td>training_function_bc58c_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.915068</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1054</td><td style=\"text-align: right;\">       0.915068</td></tr>\n",
       "<tr><td>training_function_bc58c_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.32586 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1804</td><td style=\"text-align: right;\">       2.32586 </td></tr>\n",
       "<tr><td>training_function_bc58c_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.1691  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1124</td><td style=\"text-align: right;\">       1.1691  </td></tr>\n",
       "<tr><td>training_function_bc58c_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.37975 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1483</td><td style=\"text-align: right;\">       1.37975 </td></tr>\n",
       "<tr><td>training_function_bc58c_00010</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.868935</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.0939</td><td style=\"text-align: right;\">       0.868935</td></tr>\n",
       "<tr><td>training_function_bc58c_00011</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.49835 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.6322</td><td style=\"text-align: right;\">       2.49835 </td></tr>\n",
       "<tr><td>training_function_bc58c_00012</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-2.05073 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.4113</td><td style=\"text-align: right;\">       2.05073 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00029:\n",
      "  date: 2021-08-29_11-15-12\n",
      "  done: true\n",
      "  experiment_id: 126efdabbb004fc1a7a500460a025ad7\n",
      "  experiment_tag: 29_GAMMA=0.6,THETA=0.0003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.4677953461500715\n",
      "  neg_mean_loss: 1.4677953461500715\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12196\n",
      "  time_since_restore: 12.171297311782837\n",
      "  time_this_iter_s: 12.171297311782837\n",
      "  time_total_s: 12.171297311782837\n",
      "  timestamp: 1630206912\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00029\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12195)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=12195)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12195)\u001b[0m frac:0.007890365448504983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12195)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12195)\u001b[0m \n",
      "Training neural network:  58%|█████▊    | 29/50 [00:05<00:03,  5.62it/s, epoch=28, training_loss=0.069, validation_loss=0.154]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12195)\u001b[0m \n",
      "                                                                                                                              \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00030:\n",
      "  date: 2021-08-29_11-15-31\n",
      "  done: false\n",
      "  experiment_id: 87a02abd27ea46da8b18c45f60ff1c55\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -2.503368527390673\n",
      "  neg_mean_loss: 2.503368527390673\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12195\n",
      "  time_since_restore: 12.053208112716675\n",
      "  time_this_iter_s: 12.053208112716675\n",
      "  time_total_s: 12.053208112716675\n",
      "  timestamp: 1630206931\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00030\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 150.1/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/1.0 accelerator_type:V, 0.0/16.0 CPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_0_de1602d26fa597a65349fb8b6a223582)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_11-03-50<br>Number of trials: 36/36 (5 PENDING, 1 RUNNING, 30 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_bc58c_00030</td><td>RUNNING   </td><td>202.117.43.132:12195</td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">-2.50337 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.0532</td><td style=\"text-align: right;\">       2.50337 </td></tr>\n",
       "<tr><td>training_function_bc58c_00031</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00032</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00033</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00034</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00035</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.82773 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3429</td><td style=\"text-align: right;\">       1.82773 </td></tr>\n",
       "<tr><td>training_function_bc58c_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.61974 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.3733</td><td style=\"text-align: right;\">       1.61974 </td></tr>\n",
       "<tr><td>training_function_bc58c_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.52086 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3946</td><td style=\"text-align: right;\">       1.52086 </td></tr>\n",
       "<tr><td>training_function_bc58c_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.78826 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.7248</td><td style=\"text-align: right;\">       1.78826 </td></tr>\n",
       "<tr><td>training_function_bc58c_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.19777 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3284</td><td style=\"text-align: right;\">       2.19777 </td></tr>\n",
       "<tr><td>training_function_bc58c_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.58648 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.4175</td><td style=\"text-align: right;\">       2.58648 </td></tr>\n",
       "<tr><td>training_function_bc58c_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.915068</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1054</td><td style=\"text-align: right;\">       0.915068</td></tr>\n",
       "<tr><td>training_function_bc58c_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.32586 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1804</td><td style=\"text-align: right;\">       2.32586 </td></tr>\n",
       "<tr><td>training_function_bc58c_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.1691  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1124</td><td style=\"text-align: right;\">       1.1691  </td></tr>\n",
       "<tr><td>training_function_bc58c_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.37975 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1483</td><td style=\"text-align: right;\">       1.37975 </td></tr>\n",
       "<tr><td>training_function_bc58c_00010</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.868935</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.0939</td><td style=\"text-align: right;\">       0.868935</td></tr>\n",
       "<tr><td>training_function_bc58c_00011</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.49835 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.6322</td><td style=\"text-align: right;\">       2.49835 </td></tr>\n",
       "<tr><td>training_function_bc58c_00012</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-2.05073 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.4113</td><td style=\"text-align: right;\">       2.05073 </td></tr>\n",
       "<tr><td>training_function_bc58c_00013</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.51902 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.0335</td><td style=\"text-align: right;\">       1.51902 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00030:\n",
      "  date: 2021-08-29_11-15-31\n",
      "  done: true\n",
      "  experiment_id: 87a02abd27ea46da8b18c45f60ff1c55\n",
      "  experiment_tag: 30_GAMMA=0.95,THETA=0.0001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -2.503368527390673\n",
      "  neg_mean_loss: 2.503368527390673\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12195\n",
      "  time_since_restore: 12.053208112716675\n",
      "  time_this_iter_s: 12.053208112716675\n",
      "  time_total_s: 12.053208112716675\n",
      "  timestamp: 1630206931\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00030\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12192)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=12192)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12192)\u001b[0m frac:0.008305647840531562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12192)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12192)\u001b[0m \n",
      "Training neural network:  52%|█████▏    | 26/50 [00:05<00:04,  5.13it/s, epoch=25, training_loss=0.0695, validation_loss=0.151]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=12192)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00031:\n",
      "  date: 2021-08-29_11-15-50\n",
      "  done: false\n",
      "  experiment_id: e995c99e868a42c5aaad9678b09f080e\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.4149683274632896\n",
      "  neg_mean_loss: 1.4149683274632896\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12192\n",
      "  time_since_restore: 12.593090534210205\n",
      "  time_this_iter_s: 12.593090534210205\n",
      "  time_total_s: 12.593090534210205\n",
      "  timestamp: 1630206950\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00031\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 150.0/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_de1602d26fa597a65349fb8b6a223582)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_11-03-50<br>Number of trials: 36/36 (4 PENDING, 1 RUNNING, 31 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_bc58c_00031</td><td>RUNNING   </td><td>202.117.43.132:12192</td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">-1.41497 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.5931</td><td style=\"text-align: right;\">       1.41497 </td></tr>\n",
       "<tr><td>training_function_bc58c_00032</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00033</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00034</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00035</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.82773 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3429</td><td style=\"text-align: right;\">       1.82773 </td></tr>\n",
       "<tr><td>training_function_bc58c_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.61974 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.3733</td><td style=\"text-align: right;\">       1.61974 </td></tr>\n",
       "<tr><td>training_function_bc58c_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.52086 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3946</td><td style=\"text-align: right;\">       1.52086 </td></tr>\n",
       "<tr><td>training_function_bc58c_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.78826 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.7248</td><td style=\"text-align: right;\">       1.78826 </td></tr>\n",
       "<tr><td>training_function_bc58c_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.19777 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3284</td><td style=\"text-align: right;\">       2.19777 </td></tr>\n",
       "<tr><td>training_function_bc58c_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.58648 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.4175</td><td style=\"text-align: right;\">       2.58648 </td></tr>\n",
       "<tr><td>training_function_bc58c_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.915068</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1054</td><td style=\"text-align: right;\">       0.915068</td></tr>\n",
       "<tr><td>training_function_bc58c_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.32586 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1804</td><td style=\"text-align: right;\">       2.32586 </td></tr>\n",
       "<tr><td>training_function_bc58c_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.1691  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1124</td><td style=\"text-align: right;\">       1.1691  </td></tr>\n",
       "<tr><td>training_function_bc58c_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.37975 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1483</td><td style=\"text-align: right;\">       1.37975 </td></tr>\n",
       "<tr><td>training_function_bc58c_00010</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.868935</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.0939</td><td style=\"text-align: right;\">       0.868935</td></tr>\n",
       "<tr><td>training_function_bc58c_00011</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.49835 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.6322</td><td style=\"text-align: right;\">       2.49835 </td></tr>\n",
       "<tr><td>training_function_bc58c_00012</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-2.05073 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.4113</td><td style=\"text-align: right;\">       2.05073 </td></tr>\n",
       "<tr><td>training_function_bc58c_00013</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.51902 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.0335</td><td style=\"text-align: right;\">       1.51902 </td></tr>\n",
       "<tr><td>training_function_bc58c_00014</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.77972 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.378 </td><td style=\"text-align: right;\">       1.77972 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00031:\n",
      "  date: 2021-08-29_11-15-50\n",
      "  done: true\n",
      "  experiment_id: e995c99e868a42c5aaad9678b09f080e\n",
      "  experiment_tag: 31_GAMMA=0.9,THETA=0.0001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.4149683274632896\n",
      "  neg_mean_loss: 1.4149683274632896\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 12192\n",
      "  time_since_restore: 12.593090534210205\n",
      "  time_this_iter_s: 12.593090534210205\n",
      "  time_total_s: 12.593090534210205\n",
      "  timestamp: 1630206950\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00031\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=28786)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=28786)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=28786)\u001b[0m frac:0.009136212624584718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=28786)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=28786)\u001b[0m \n",
      "Training neural network:  56%|█████▌    | 28/50 [00:05<00:04,  5.47it/s, epoch=27, training_loss=0.0731, validation_loss=0.156]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=28786)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00032:\n",
      "  date: 2021-08-29_11-16-09\n",
      "  done: false\n",
      "  experiment_id: 2777676cc5a4442fb1e07a3e9afbea2b\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.4348838206362784\n",
      "  neg_mean_loss: 1.4348838206362784\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 28786\n",
      "  time_since_restore: 12.223286390304565\n",
      "  time_this_iter_s: 12.223286390304565\n",
      "  time_total_s: 12.223286390304565\n",
      "  timestamp: 1630206969\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00032\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 150.1/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/1.0 accelerator_type:V, 0.0/16.0 CPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_de1602d26fa597a65349fb8b6a223582)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_11-03-50<br>Number of trials: 36/36 (3 PENDING, 1 RUNNING, 32 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_bc58c_00032</td><td>RUNNING   </td><td>202.117.43.132:28786</td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">-1.43488 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.2233</td><td style=\"text-align: right;\">       1.43488 </td></tr>\n",
       "<tr><td>training_function_bc58c_00033</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00034</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00035</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.82773 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3429</td><td style=\"text-align: right;\">       1.82773 </td></tr>\n",
       "<tr><td>training_function_bc58c_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.61974 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.3733</td><td style=\"text-align: right;\">       1.61974 </td></tr>\n",
       "<tr><td>training_function_bc58c_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.52086 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3946</td><td style=\"text-align: right;\">       1.52086 </td></tr>\n",
       "<tr><td>training_function_bc58c_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.78826 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.7248</td><td style=\"text-align: right;\">       1.78826 </td></tr>\n",
       "<tr><td>training_function_bc58c_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.19777 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3284</td><td style=\"text-align: right;\">       2.19777 </td></tr>\n",
       "<tr><td>training_function_bc58c_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.58648 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.4175</td><td style=\"text-align: right;\">       2.58648 </td></tr>\n",
       "<tr><td>training_function_bc58c_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.915068</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1054</td><td style=\"text-align: right;\">       0.915068</td></tr>\n",
       "<tr><td>training_function_bc58c_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.32586 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1804</td><td style=\"text-align: right;\">       2.32586 </td></tr>\n",
       "<tr><td>training_function_bc58c_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.1691  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1124</td><td style=\"text-align: right;\">       1.1691  </td></tr>\n",
       "<tr><td>training_function_bc58c_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.37975 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1483</td><td style=\"text-align: right;\">       1.37975 </td></tr>\n",
       "<tr><td>training_function_bc58c_00010</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.868935</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.0939</td><td style=\"text-align: right;\">       0.868935</td></tr>\n",
       "<tr><td>training_function_bc58c_00011</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.49835 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.6322</td><td style=\"text-align: right;\">       2.49835 </td></tr>\n",
       "<tr><td>training_function_bc58c_00012</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-2.05073 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.4113</td><td style=\"text-align: right;\">       2.05073 </td></tr>\n",
       "<tr><td>training_function_bc58c_00013</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.51902 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.0335</td><td style=\"text-align: right;\">       1.51902 </td></tr>\n",
       "<tr><td>training_function_bc58c_00014</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.77972 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.378 </td><td style=\"text-align: right;\">       1.77972 </td></tr>\n",
       "<tr><td>training_function_bc58c_00015</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.8733  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.548 </td><td style=\"text-align: right;\">       1.8733  </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00032:\n",
      "  date: 2021-08-29_11-16-09\n",
      "  done: true\n",
      "  experiment_id: 2777676cc5a4442fb1e07a3e9afbea2b\n",
      "  experiment_tag: 32_GAMMA=0.85,THETA=0.0001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.4348838206362784\n",
      "  neg_mean_loss: 1.4348838206362784\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 28786\n",
      "  time_since_restore: 12.223286390304565\n",
      "  time_this_iter_s: 12.223286390304565\n",
      "  time_total_s: 12.223286390304565\n",
      "  timestamp: 1630206969\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00032\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=29440)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=29440)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=29440)\u001b[0m frac:0.007475083056478406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=29440)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=29440)\u001b[0m \n",
      "Training neural network:  56%|█████▌    | 28/50 [00:05<00:04,  5.50it/s, epoch=27, training_loss=0.0797, validation_loss=0.149]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=29440)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00033:\n",
      "  date: 2021-08-29_11-16-29\n",
      "  done: false\n",
      "  experiment_id: cffc9fdfe8274956bd89a6e62347d566\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.9415034444752632\n",
      "  neg_mean_loss: 1.9415034444752632\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 29440\n",
      "  time_since_restore: 12.257776975631714\n",
      "  time_this_iter_s: 12.257776975631714\n",
      "  time_total_s: 12.257776975631714\n",
      "  timestamp: 1630206989\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00033\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 150.8/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/1.0 accelerator_type:V, 0.0/16.0 CPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_0_de1602d26fa597a65349fb8b6a223582)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_11-03-50<br>Number of trials: 36/36 (2 PENDING, 1 RUNNING, 33 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_bc58c_00033</td><td>RUNNING   </td><td>202.117.43.132:29440</td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">-1.9415  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.2578</td><td style=\"text-align: right;\">       1.9415  </td></tr>\n",
       "<tr><td>training_function_bc58c_00034</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00035</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.82773 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3429</td><td style=\"text-align: right;\">       1.82773 </td></tr>\n",
       "<tr><td>training_function_bc58c_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.61974 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.3733</td><td style=\"text-align: right;\">       1.61974 </td></tr>\n",
       "<tr><td>training_function_bc58c_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.52086 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3946</td><td style=\"text-align: right;\">       1.52086 </td></tr>\n",
       "<tr><td>training_function_bc58c_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.78826 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.7248</td><td style=\"text-align: right;\">       1.78826 </td></tr>\n",
       "<tr><td>training_function_bc58c_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.19777 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3284</td><td style=\"text-align: right;\">       2.19777 </td></tr>\n",
       "<tr><td>training_function_bc58c_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.58648 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.4175</td><td style=\"text-align: right;\">       2.58648 </td></tr>\n",
       "<tr><td>training_function_bc58c_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.915068</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1054</td><td style=\"text-align: right;\">       0.915068</td></tr>\n",
       "<tr><td>training_function_bc58c_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.32586 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1804</td><td style=\"text-align: right;\">       2.32586 </td></tr>\n",
       "<tr><td>training_function_bc58c_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.1691  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1124</td><td style=\"text-align: right;\">       1.1691  </td></tr>\n",
       "<tr><td>training_function_bc58c_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.37975 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1483</td><td style=\"text-align: right;\">       1.37975 </td></tr>\n",
       "<tr><td>training_function_bc58c_00010</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.868935</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.0939</td><td style=\"text-align: right;\">       0.868935</td></tr>\n",
       "<tr><td>training_function_bc58c_00011</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.49835 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.6322</td><td style=\"text-align: right;\">       2.49835 </td></tr>\n",
       "<tr><td>training_function_bc58c_00012</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-2.05073 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.4113</td><td style=\"text-align: right;\">       2.05073 </td></tr>\n",
       "<tr><td>training_function_bc58c_00013</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.51902 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.0335</td><td style=\"text-align: right;\">       1.51902 </td></tr>\n",
       "<tr><td>training_function_bc58c_00014</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.77972 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.378 </td><td style=\"text-align: right;\">       1.77972 </td></tr>\n",
       "<tr><td>training_function_bc58c_00015</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.8733  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.548 </td><td style=\"text-align: right;\">       1.8733  </td></tr>\n",
       "<tr><td>training_function_bc58c_00016</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-2.5864  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.439 </td><td style=\"text-align: right;\">       2.5864  </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00033:\n",
      "  date: 2021-08-29_11-16-29\n",
      "  done: true\n",
      "  experiment_id: cffc9fdfe8274956bd89a6e62347d566\n",
      "  experiment_tag: 33_GAMMA=0.8,THETA=0.0001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.9415034444752632\n",
      "  neg_mean_loss: 1.9415034444752632\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 29440\n",
      "  time_since_restore: 12.257776975631714\n",
      "  time_this_iter_s: 12.257776975631714\n",
      "  time_total_s: 12.257776975631714\n",
      "  timestamp: 1630206989\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00033\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=30092)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=30092)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=30092)\u001b[0m frac:0.0070598006644518275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=30092)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=30092)\u001b[0m \n",
      "Training neural network:  58%|█████▊    | 29/50 [00:05<00:03,  5.77it/s, epoch=28, training_loss=0.0667, validation_loss=0.153]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=30092)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00034:\n",
      "  date: 2021-08-29_11-16-48\n",
      "  done: false\n",
      "  experiment_id: 481158be06e0438d8d91809c65999e13\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -3.25798188141065\n",
      "  neg_mean_loss: 3.25798188141065\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 30092\n",
      "  time_since_restore: 12.063072204589844\n",
      "  time_this_iter_s: 12.063072204589844\n",
      "  time_total_s: 12.063072204589844\n",
      "  timestamp: 1630207008\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00034\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 150.8/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/16.0 CPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_0_de1602d26fa597a65349fb8b6a223582)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_11-03-50<br>Number of trials: 36/36 (1 PENDING, 1 RUNNING, 34 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_bc58c_00034</td><td>RUNNING   </td><td>202.117.43.132:30092</td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">-3.25798 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.0631</td><td style=\"text-align: right;\">       3.25798 </td></tr>\n",
       "<tr><td>training_function_bc58c_00035</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_bc58c_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.82773 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3429</td><td style=\"text-align: right;\">       1.82773 </td></tr>\n",
       "<tr><td>training_function_bc58c_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.61974 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.3733</td><td style=\"text-align: right;\">       1.61974 </td></tr>\n",
       "<tr><td>training_function_bc58c_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.52086 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3946</td><td style=\"text-align: right;\">       1.52086 </td></tr>\n",
       "<tr><td>training_function_bc58c_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.78826 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.7248</td><td style=\"text-align: right;\">       1.78826 </td></tr>\n",
       "<tr><td>training_function_bc58c_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.19777 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3284</td><td style=\"text-align: right;\">       2.19777 </td></tr>\n",
       "<tr><td>training_function_bc58c_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.58648 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.4175</td><td style=\"text-align: right;\">       2.58648 </td></tr>\n",
       "<tr><td>training_function_bc58c_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.915068</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1054</td><td style=\"text-align: right;\">       0.915068</td></tr>\n",
       "<tr><td>training_function_bc58c_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.32586 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1804</td><td style=\"text-align: right;\">       2.32586 </td></tr>\n",
       "<tr><td>training_function_bc58c_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.1691  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1124</td><td style=\"text-align: right;\">       1.1691  </td></tr>\n",
       "<tr><td>training_function_bc58c_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.37975 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1483</td><td style=\"text-align: right;\">       1.37975 </td></tr>\n",
       "<tr><td>training_function_bc58c_00010</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.868935</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.0939</td><td style=\"text-align: right;\">       0.868935</td></tr>\n",
       "<tr><td>training_function_bc58c_00011</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.49835 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.6322</td><td style=\"text-align: right;\">       2.49835 </td></tr>\n",
       "<tr><td>training_function_bc58c_00012</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-2.05073 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.4113</td><td style=\"text-align: right;\">       2.05073 </td></tr>\n",
       "<tr><td>training_function_bc58c_00013</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.51902 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.0335</td><td style=\"text-align: right;\">       1.51902 </td></tr>\n",
       "<tr><td>training_function_bc58c_00014</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.77972 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.378 </td><td style=\"text-align: right;\">       1.77972 </td></tr>\n",
       "<tr><td>training_function_bc58c_00015</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.8733  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.548 </td><td style=\"text-align: right;\">       1.8733  </td></tr>\n",
       "<tr><td>training_function_bc58c_00016</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-2.5864  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.439 </td><td style=\"text-align: right;\">       2.5864  </td></tr>\n",
       "<tr><td>training_function_bc58c_00017</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.79934 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.5709</td><td style=\"text-align: right;\">       1.79934 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00034:\n",
      "  date: 2021-08-29_11-16-48\n",
      "  done: true\n",
      "  experiment_id: 481158be06e0438d8d91809c65999e13\n",
      "  experiment_tag: 34_GAMMA=0.7,THETA=0.0001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -3.25798188141065\n",
      "  neg_mean_loss: 3.25798188141065\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 30092\n",
      "  time_since_restore: 12.063072204589844\n",
      "  time_this_iter_s: 12.063072204589844\n",
      "  time_total_s: 12.063072204589844\n",
      "  timestamp: 1630207008\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00034\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=31208)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=31208)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=31208)\u001b[0m frac:0.007890365448504983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=31208)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=31208)\u001b[0m \n",
      "Training neural network:  56%|█████▌    | 28/50 [00:05<00:04,  5.44it/s, epoch=27, training_loss=0.0666, validation_loss=0.17]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=31208)\u001b[0m \n",
      "                                                                                                                              \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00035:\n",
      "  date: 2021-08-29_11-17-07\n",
      "  done: false\n",
      "  experiment_id: 80dd14fb7e5a4dae959485d9295bfa79\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -2.2339648847129023\n",
      "  neg_mean_loss: 2.2339648847129023\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 31208\n",
      "  time_since_restore: 12.057929277420044\n",
      "  time_this_iter_s: 12.057929277420044\n",
      "  time_total_s: 12.057929277420044\n",
      "  timestamp: 1630207027\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00035\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 150.8/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 16.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/1.0 accelerator_type:V, 0.0/16.0 CPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_de1602d26fa597a65349fb8b6a223582)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_11-03-50<br>Number of trials: 36/36 (1 RUNNING, 35 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_bc58c_00035</td><td>RUNNING   </td><td>202.117.43.132:31208</td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">-2.23396 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.0579</td><td style=\"text-align: right;\">       2.23396 </td></tr>\n",
       "<tr><td>training_function_bc58c_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.82773 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3429</td><td style=\"text-align: right;\">       1.82773 </td></tr>\n",
       "<tr><td>training_function_bc58c_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.61974 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.3733</td><td style=\"text-align: right;\">       1.61974 </td></tr>\n",
       "<tr><td>training_function_bc58c_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.52086 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3946</td><td style=\"text-align: right;\">       1.52086 </td></tr>\n",
       "<tr><td>training_function_bc58c_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.78826 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.7248</td><td style=\"text-align: right;\">       1.78826 </td></tr>\n",
       "<tr><td>training_function_bc58c_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.19777 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3284</td><td style=\"text-align: right;\">       2.19777 </td></tr>\n",
       "<tr><td>training_function_bc58c_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.58648 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.4175</td><td style=\"text-align: right;\">       2.58648 </td></tr>\n",
       "<tr><td>training_function_bc58c_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.915068</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1054</td><td style=\"text-align: right;\">       0.915068</td></tr>\n",
       "<tr><td>training_function_bc58c_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.32586 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1804</td><td style=\"text-align: right;\">       2.32586 </td></tr>\n",
       "<tr><td>training_function_bc58c_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.1691  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1124</td><td style=\"text-align: right;\">       1.1691  </td></tr>\n",
       "<tr><td>training_function_bc58c_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.37975 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1483</td><td style=\"text-align: right;\">       1.37975 </td></tr>\n",
       "<tr><td>training_function_bc58c_00010</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.868935</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.0939</td><td style=\"text-align: right;\">       0.868935</td></tr>\n",
       "<tr><td>training_function_bc58c_00011</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.49835 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.6322</td><td style=\"text-align: right;\">       2.49835 </td></tr>\n",
       "<tr><td>training_function_bc58c_00012</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-2.05073 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.4113</td><td style=\"text-align: right;\">       2.05073 </td></tr>\n",
       "<tr><td>training_function_bc58c_00013</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.51902 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.0335</td><td style=\"text-align: right;\">       1.51902 </td></tr>\n",
       "<tr><td>training_function_bc58c_00014</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.77972 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.378 </td><td style=\"text-align: right;\">       1.77972 </td></tr>\n",
       "<tr><td>training_function_bc58c_00015</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.8733  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.548 </td><td style=\"text-align: right;\">       1.8733  </td></tr>\n",
       "<tr><td>training_function_bc58c_00016</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-2.5864  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.439 </td><td style=\"text-align: right;\">       2.5864  </td></tr>\n",
       "<tr><td>training_function_bc58c_00017</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.79934 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.5709</td><td style=\"text-align: right;\">       1.79934 </td></tr>\n",
       "<tr><td>training_function_bc58c_00018</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">-1.80587 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.0732</td><td style=\"text-align: right;\">       1.80587 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_bc58c_00035:\n",
      "  date: 2021-08-29_11-17-07\n",
      "  done: true\n",
      "  experiment_id: 80dd14fb7e5a4dae959485d9295bfa79\n",
      "  experiment_tag: 35_GAMMA=0.6,THETA=0.0001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -2.2339648847129023\n",
      "  neg_mean_loss: 2.2339648847129023\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 31208\n",
      "  time_since_restore: 12.057929277420044\n",
      "  time_this_iter_s: 12.057929277420044\n",
      "  time_total_s: 12.057929277420044\n",
      "  timestamp: 1630207027\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc58c_00035\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 154.7/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/32 CPUs, 0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/16.0 CPU_group_de1602d26fa597a65349fb8b6a223582, 0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/16.0 CPU_group_0_de1602d26fa597a65349fb8b6a223582, 0.0/2.0 GPU_group_de1602d26fa597a65349fb8b6a223582)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_11-03-50<br>Number of trials: 36/36 (36 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_bc58c_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.82773 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3429</td><td style=\"text-align: right;\">       1.82773 </td></tr>\n",
       "<tr><td>training_function_bc58c_00001</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.61974 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.3733</td><td style=\"text-align: right;\">       1.61974 </td></tr>\n",
       "<tr><td>training_function_bc58c_00002</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.52086 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3946</td><td style=\"text-align: right;\">       1.52086 </td></tr>\n",
       "<tr><td>training_function_bc58c_00003</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.78826 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.7248</td><td style=\"text-align: right;\">       1.78826 </td></tr>\n",
       "<tr><td>training_function_bc58c_00004</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.19777 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3284</td><td style=\"text-align: right;\">       2.19777 </td></tr>\n",
       "<tr><td>training_function_bc58c_00005</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-2.58648 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.4175</td><td style=\"text-align: right;\">       2.58648 </td></tr>\n",
       "<tr><td>training_function_bc58c_00006</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.915068</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1054</td><td style=\"text-align: right;\">       0.915068</td></tr>\n",
       "<tr><td>training_function_bc58c_00007</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.32586 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1804</td><td style=\"text-align: right;\">       2.32586 </td></tr>\n",
       "<tr><td>training_function_bc58c_00008</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.1691  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1124</td><td style=\"text-align: right;\">       1.1691  </td></tr>\n",
       "<tr><td>training_function_bc58c_00009</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.37975 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1483</td><td style=\"text-align: right;\">       1.37975 </td></tr>\n",
       "<tr><td>training_function_bc58c_00010</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.868935</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.0939</td><td style=\"text-align: right;\">       0.868935</td></tr>\n",
       "<tr><td>training_function_bc58c_00011</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.49835 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.6322</td><td style=\"text-align: right;\">       2.49835 </td></tr>\n",
       "<tr><td>training_function_bc58c_00012</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-2.05073 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.4113</td><td style=\"text-align: right;\">       2.05073 </td></tr>\n",
       "<tr><td>training_function_bc58c_00013</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.51902 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.0335</td><td style=\"text-align: right;\">       1.51902 </td></tr>\n",
       "<tr><td>training_function_bc58c_00014</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.77972 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.378 </td><td style=\"text-align: right;\">       1.77972 </td></tr>\n",
       "<tr><td>training_function_bc58c_00015</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.8733  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.548 </td><td style=\"text-align: right;\">       1.8733  </td></tr>\n",
       "<tr><td>training_function_bc58c_00016</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-2.5864  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.439 </td><td style=\"text-align: right;\">       2.5864  </td></tr>\n",
       "<tr><td>training_function_bc58c_00017</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.79934 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.5709</td><td style=\"text-align: right;\">       1.79934 </td></tr>\n",
       "<tr><td>training_function_bc58c_00018</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">-1.80587 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.0732</td><td style=\"text-align: right;\">       1.80587 </td></tr>\n",
       "<tr><td>training_function_bc58c_00019</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">-1.92266 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.9373</td><td style=\"text-align: right;\">       1.92266 </td></tr>\n",
       "<tr><td>training_function_bc58c_00020</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">-1.42051 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3128</td><td style=\"text-align: right;\">       1.42051 </td></tr>\n",
       "<tr><td>training_function_bc58c_00021</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">-0.697216</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.0051</td><td style=\"text-align: right;\">       0.697216</td></tr>\n",
       "<tr><td>training_function_bc58c_00022</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">-1.4678  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3079</td><td style=\"text-align: right;\">       1.4678  </td></tr>\n",
       "<tr><td>training_function_bc58c_00023</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">-1.1945  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3373</td><td style=\"text-align: right;\">       1.1945  </td></tr>\n",
       "<tr><td>training_function_bc58c_00024</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">-1.62189 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3278</td><td style=\"text-align: right;\">       1.62189 </td></tr>\n",
       "<tr><td>training_function_bc58c_00025</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">-1.26851 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.2065</td><td style=\"text-align: right;\">       1.26851 </td></tr>\n",
       "<tr><td>training_function_bc58c_00026</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">-1.52086 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.5121</td><td style=\"text-align: right;\">       1.52086 </td></tr>\n",
       "<tr><td>training_function_bc58c_00027</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">-1.63949 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.2492</td><td style=\"text-align: right;\">       1.63949 </td></tr>\n",
       "<tr><td>training_function_bc58c_00028</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">-1.45227 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3804</td><td style=\"text-align: right;\">       1.45227 </td></tr>\n",
       "<tr><td>training_function_bc58c_00029</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">-1.4678  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1713</td><td style=\"text-align: right;\">       1.4678  </td></tr>\n",
       "<tr><td>training_function_bc58c_00030</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">-2.50337 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.0532</td><td style=\"text-align: right;\">       2.50337 </td></tr>\n",
       "<tr><td>training_function_bc58c_00031</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">-1.41497 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.5931</td><td style=\"text-align: right;\">       1.41497 </td></tr>\n",
       "<tr><td>training_function_bc58c_00032</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">-1.43488 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.2233</td><td style=\"text-align: right;\">       1.43488 </td></tr>\n",
       "<tr><td>training_function_bc58c_00033</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">-1.9415  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.2578</td><td style=\"text-align: right;\">       1.9415  </td></tr>\n",
       "<tr><td>training_function_bc58c_00034</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">-3.25798 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.0631</td><td style=\"text-align: right;\">       3.25798 </td></tr>\n",
       "<tr><td>training_function_bc58c_00035</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">-2.23396 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.0579</td><td style=\"text-align: right;\">       2.23396 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-29 11:20:57,608\tINFO tune.py:550 -- Total run time: 1027.06 seconds (797.49 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best config:  {'THETA': 0.0001, 'GAMMA': 0.7, 'dataset': 'compas', 'train_dataset_s': <torch.utils.data.dataset.Subset object at 0x7f7cb06c5278>, 'val': <torch.utils.data.dataloader.DataLoader object at 0x7f7cb06c5080>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f7cb8af9278>, 'x_tensor': tensor([[0.0959, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        [0.0959, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        [0.3973, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.1370, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        [0.3151, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        [0.1644, 0.0000, 1.0000,  ..., 1.0000, 0.0000, 0.0000]])}\n",
      "2021-08-29 11:23:04,692 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.003173550587343691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:   8%|▊         | 4/50 [00:06<01:13,  1.60s/it, epoch=3, training_loss=0.109, validation_loss=0.117]\u001b[A\n",
      "Training neural network:  16%|█▌        | 8/50 [00:12<01:04,  1.53s/it, epoch=7, training_loss=0.103, validation_loss=0.112]\u001b[A\n",
      "Training neural network:  24%|██▍       | 12/50 [00:18<00:57,  1.51s/it, epoch=11, training_loss=0.0999, validation_loss=0.111]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:24<00:51,  1.52s/it, epoch=15, training_loss=0.0927, validation_loss=0.113]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:30<00:45,  1.50s/it, epoch=19, training_loss=0.0909, validation_loss=0.113]\u001b[A\n",
      "Training neural network:  48%|████▊     | 24/50 [00:35<00:38,  1.47s/it, epoch=23, training_loss=0.0899, validation_loss=0.116]\u001b[A\n",
      "Training neural network:  56%|█████▌    | 28/50 [00:42<00:32,  1.49s/it, epoch=27, training_loss=0.0894, validation_loss=0.116]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:47<00:26,  1.49s/it, epoch=31, training_loss=0.0882, validation_loss=0.115]\u001b[A\n",
      "Training neural network:  72%|███████▏  | 36/50 [00:53<00:20,  1.49s/it, epoch=35, training_loss=0.0878, validation_loss=0.116]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:59<00:14,  1.47s/it, epoch=39, training_loss=0.0878, validation_loss=0.115]\u001b[A\n",
      "Training neural network:  88%|████████▊ | 44/50 [01:05<00:08,  1.47s/it, epoch=43, training_loss=0.0879, validation_loss=0.117]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [01:11<00:02,  1.45s/it, epoch=47, training_loss=0.0876, validation_loss=0.116]\u001b[A\n",
      "                                                                                                                               \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param selection costs:1154.1499228477478 s\n",
      "path analysis costs:25.367633819580078 s\n",
      "sample separation costs:43.70445489883423 s\n",
      "partial dropout training costs:74.36535143852234 s\n",
      "total time costs:1297.6239266395569 s\n"
     ]
    }
   ],
   "source": [
    "# census\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "BATCH_SIZE=128\n",
    "\n",
    "df=pd.read_csv('data/Census/adult')\n",
    "df_binary, Y, S, Y_true = transform_dataset_census(df)\n",
    "print(np.mean(Y))\n",
    "\n",
    "l_tensor = torch.tensor(Y.reshape(-1, 1).astype(np.float32))\n",
    "x_tensor = torch.tensor(df_binary.to_numpy().astype(np.float32))\n",
    "y_tensor = torch.tensor(Y.reshape(-1, 1).astype(np.float32))\n",
    "s_tensor = torch.tensor(preprocessing.OneHotEncoder().fit_transform(np.array(S).reshape(-1, 1)).toarray())\n",
    "\n",
    "dataset = TensorDataset(x_tensor, y_tensor, l_tensor, s_tensor)  # dataset = CustomDataset(x_tensor, y_tensor)\n",
    "\n",
    "base_size = len(dataset) // 10\n",
    "split = [7 * base_size, 1 * base_size, len(dataset) - 8 * base_size]  # Train, validation, test\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, split)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "x_train_tensor = train_dataset[:][0]\n",
    "y_train_tensor = train_dataset[:][1]\n",
    "l_train_tensor = train_dataset[:][2]\n",
    "s_train_tensor = train_dataset[:][3]\n",
    "\n",
    "global_results = []\n",
    "\n",
    "# get the classification threshold, we use the same scale for compas so 4 instead of 0.5\n",
    "ori_start=time.time()\n",
    "threshold = 0.5\n",
    "\n",
    "net, results = train_and_evaluate(train_loader, val_loader, test_loader, device, input_shape=x_tensor.shape[1],\n",
    "                                    grl_lambda=0, dataset='census')\n",
    "ori_end=time.time()\n",
    "ori_cost_time=ori_end-ori_start\n",
    "print('time costs:{} s'.format(ori_cost_time))\n",
    "\n",
    "result = get_metrics(results, threshold, 0)\n",
    "global_results.append(result)\n",
    "\n",
    "\n",
    "# EA(net,attack_size=10, iter_num=50)\n",
    "\n",
    "Fixate_with_val(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30162, 12)\n",
      "(30162, 1)\n",
      "0.24892248524633645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:   6%|▌         | 3/50 [00:05<01:22,  1.77s/it, epoch=2, training_loss=95.8, validation_loss=5.02]\u001b[A\n",
      "Training neural network:  12%|█▏        | 6/50 [00:11<01:25,  1.95s/it, epoch=5, training_loss=675, validation_loss=936]  \u001b[A\n",
      "Training neural network:  18%|█▊        | 9/50 [00:18<01:25,  2.10s/it, epoch=8, training_loss=5.91e+3, validation_loss=212]\u001b[A\n",
      "Training neural network:  24%|██▍       | 12/50 [00:25<01:24,  2.21s/it, epoch=11, training_loss=2.13e+3, validation_loss=350]\u001b[A\n",
      "Training neural network:  30%|███       | 15/50 [00:32<01:18,  2.24s/it, epoch=14, training_loss=52.4, validation_loss=1.52]  \u001b[A\n",
      "Training neural network:  36%|███▌      | 18/50 [00:39<01:13,  2.30s/it, epoch=17, training_loss=17.1, validation_loss=1.2] \u001b[A\n",
      "Training neural network:  42%|████▏     | 21/50 [00:46<01:07,  2.31s/it, epoch=20, training_loss=10.7, validation_loss=1.26]\u001b[A\n",
      "Training neural network:  48%|████▊     | 24/50 [00:54<01:01,  2.36s/it, epoch=23, training_loss=9.27, validation_loss=1.37]\u001b[A\n",
      "Training neural network:  54%|█████▍    | 27/50 [01:01<00:53,  2.35s/it, epoch=26, training_loss=9.74, validation_loss=1.27]\u001b[A\n",
      "Training neural network:  60%|██████    | 30/50 [01:08<00:46,  2.34s/it, epoch=29, training_loss=10, validation_loss=1.2]   \u001b[A\n",
      "Training neural network:  66%|██████▌   | 33/50 [01:14<00:39,  2.33s/it, epoch=32, training_loss=9.39, validation_loss=1.23]\u001b[A\n",
      "Training neural network:  72%|███████▏  | 36/50 [01:22<00:32,  2.35s/it, epoch=35, training_loss=25.2, validation_loss=41.9]\u001b[A\n",
      "Training neural network:  78%|███████▊  | 39/50 [01:29<00:25,  2.34s/it, epoch=38, training_loss=1.22, validation_loss=0.838]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [01:36<00:18,  2.35s/it, epoch=41, training_loss=1.03, validation_loss=0.833]\u001b[A\n",
      "Training neural network:  90%|█████████ | 45/50 [01:43<00:11,  2.39s/it, epoch=44, training_loss=1.01, validation_loss=0.805]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [01:50<00:04,  2.38s/it, epoch=47, training_loss=1.02, validation_loss=0.82] \u001b[A\n",
      "                                                                                                                            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:115.74208807945251 s\n"
     ]
    }
   ],
   "source": [
    "# credit\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "BATCH_SIZE=128\n",
    "\n",
    "df=pd.read_csv('data/Census/adult')\n",
    "df_binary, Y, S, Y_true = transform_dataset_census(df)\n",
    "print(np.mean(Y))\n",
    "\n",
    "l_tensor = torch.tensor(Y.reshape(-1, 1).astype(np.float32))\n",
    "x_tensor = torch.tensor(df_binary.to_numpy().astype(np.float32))\n",
    "y_tensor = torch.tensor(Y.reshape(-1, 1).astype(np.float32))\n",
    "s_tensor = torch.tensor(preprocessing.OneHotEncoder().fit_transform(np.array(S).reshape(-1, 1)).toarray())\n",
    "\n",
    "dataset = TensorDataset(x_tensor, y_tensor, l_tensor, s_tensor)  # dataset = CustomDataset(x_tensor, y_tensor)\n",
    "\n",
    "base_size = len(dataset) // 10\n",
    "split = [7 * base_size, 1 * base_size, len(dataset) - 8 * base_size]  # Train, validation, test\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, split)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "x_train_tensor = train_dataset[:][0]\n",
    "y_train_tensor = train_dataset[:][1]\n",
    "l_train_tensor = train_dataset[:][2]\n",
    "s_train_tensor = train_dataset[:][3]\n",
    "\n",
    "global_results = []\n",
    "\n",
    "# get the classification threshold, we use the same scale for compas so 4 instead of 0.5\n",
    "ori_start=time.time()\n",
    "threshold = 0.5\n",
    "\n",
    "net, results = train_and_evaluate(train_loader, val_loader, test_loader, device, input_shape=x_tensor.shape[1],\n",
    "                                    grl_lambda=0, dataset='census')\n",
    "ori_end=time.time()\n",
    "ori_cost_time=ori_end-ori_start\n",
    "print('time costs:{} s'.format(ori_cost_time))\n",
    "\n",
    "result = get_metrics(results, threshold, 0)\n",
    "global_results.append(result)\n",
    "\n",
    "\n",
    "# EA(net,attack_size=10, iter_num=50)\n",
    "\n",
    "# Fixate_with_val(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 20)\n",
      "0      False\n",
      "1       True\n",
      "2       True\n",
      "3       True\n",
      "4       True\n",
      "       ...  \n",
      "994     True\n",
      "995     True\n",
      "996     True\n",
      "997    False\n",
      "998     True\n",
      "Name: 67, Length: 999, dtype: bool\n",
      "0.3003003003003003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                               \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:3.540337085723877 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 141.7/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/32 CPUs, 0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/1.0 accelerator_type:V)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_10-39-05<br>Number of trials: 35/36 (35 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_46e9e_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_46e9e_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_46e9e_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_46e9e_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_46e9e_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_46e9e_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_46e9e_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_46e9e_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_46e9e_00008</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_46e9e_00009</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_46e9e_00010</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_46e9e_00011</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_46e9e_00012</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_46e9e_00013</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_46e9e_00014</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_46e9e_00015</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_46e9e_00016</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_46e9e_00017</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_46e9e_00018</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td></tr>\n",
       "<tr><td>training_function_46e9e_00019</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 15 more trials not shown (15 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 143.7/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/1.0 accelerator_type:V)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_10-39-05<br>Number of trials: 36/36 (35 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_46e9e_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_46e9e_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_46e9e_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_46e9e_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_46e9e_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_46e9e_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_46e9e_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_46e9e_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_46e9e_00008</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_46e9e_00009</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_46e9e_00010</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_46e9e_00011</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_46e9e_00012</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_46e9e_00013</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_46e9e_00014</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_46e9e_00015</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_46e9e_00016</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_46e9e_00017</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_46e9e_00018</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td></tr>\n",
       "<tr><td>training_function_46e9e_00019</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m frac:0.2916666666666667\n",
      "Result for training_function_46e9e_00000:\n",
      "  date: 2021-08-29_10-39-14\n",
      "  done: false\n",
      "  experiment_id: e4df24331500447b91307b75d251ad69\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 2.4771428571428573\n",
      "  neg_mean_loss: -2.4771428571428573\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11539\n",
      "  time_since_restore: 1.0780284404754639\n",
      "  time_this_iter_s: 1.0780284404754639\n",
      "  time_total_s: 1.0780284404754639\n",
      "  timestamp: 1630204754\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00000\n",
      "  \n",
      "Result for training_function_46e9e_00000:\n",
      "  date: 2021-08-29_10-39-14\n",
      "  done: true\n",
      "  experiment_id: e4df24331500447b91307b75d251ad69\n",
      "  experiment_tag: 0_GAMMA=0.95,THETA=0.1\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 2.4771428571428573\n",
      "  neg_mean_loss: -2.4771428571428573\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11539\n",
      "  time_since_restore: 1.0780284404754639\n",
      "  time_this_iter_s: 1.0780284404754639\n",
      "  time_total_s: 1.0780284404754639\n",
      "  timestamp: 1630204754\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 142.6/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/1.0 accelerator_type:V, 0.0/8.0 CPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_b732c446212a2c1cca5ef1dadf7b45e0)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_10-39-05<br>Number of trials: 36/36 (34 PENDING, 1 RUNNING, 1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">   loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_46e9e_00001</td><td>RUNNING   </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00002</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00003</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00004</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00005</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00006</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00007</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00008</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00009</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00010</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00011</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00012</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00013</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00014</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00015</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00016</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00017</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00018</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00019</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">2.47714</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.07803</td><td style=\"text-align: right;\">       -2.47714</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11500)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=11500)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=11500)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11500)\u001b[0m \r",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11500)\u001b[0m frac:0.2638888888888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11500)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11500)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00001:\n",
      "  date: 2021-08-29_10-39-22\n",
      "  done: false\n",
      "  experiment_id: a1e48d1c03d7446aa1c24e1c570b3752\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.3080555555555555\n",
      "  neg_mean_loss: -1.3080555555555555\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11500\n",
      "  time_since_restore: 1.0564053058624268\n",
      "  time_this_iter_s: 1.0564053058624268\n",
      "  time_total_s: 1.0564053058624268\n",
      "  timestamp: 1630204762\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00001\n",
      "  \n",
      "Result for training_function_46e9e_00001:\n",
      "  date: 2021-08-29_10-39-22\n",
      "  done: true\n",
      "  experiment_id: a1e48d1c03d7446aa1c24e1c570b3752\n",
      "  experiment_tag: 1_GAMMA=0.9,THETA=0.1\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.3080555555555555\n",
      "  neg_mean_loss: -1.3080555555555555\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11500\n",
      "  time_since_restore: 1.0564053058624268\n",
      "  time_this_iter_s: 1.0564053058624268\n",
      "  time_total_s: 1.0564053058624268\n",
      "  timestamp: 1630204762\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00001\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11513)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=11513)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=11513)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11513)\u001b[0m \r",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11513)\u001b[0m frac:0.2638888888888889\n",
      "Result for training_function_46e9e_00002:\n",
      "  date: 2021-08-29_10-39-29\n",
      "  done: false\n",
      "  experiment_id: da2f79f18b4546b395a67b007825470d\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.1211111111111112\n",
      "  neg_mean_loss: -1.1211111111111112\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11513\n",
      "  time_since_restore: 1.0471150875091553\n",
      "  time_this_iter_s: 1.0471150875091553\n",
      "  time_total_s: 1.0471150875091553\n",
      "  timestamp: 1630204769\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00002\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11513)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11513)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 144.0/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/1.0 accelerator_type:V, 0.0/8.0 CPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_b732c446212a2c1cca5ef1dadf7b45e0)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_10-39-05<br>Number of trials: 36/36 (33 PENDING, 1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">   loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_46e9e_00002</td><td>RUNNING   </td><td>202.117.43.132:11513</td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.12111</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.04712</td><td style=\"text-align: right;\">       -1.12111</td></tr>\n",
       "<tr><td>training_function_46e9e_00003</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00004</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00005</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00006</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00007</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00008</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00009</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00010</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00011</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00012</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00013</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00014</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00015</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">2.47714</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.07803</td><td style=\"text-align: right;\">       -2.47714</td></tr>\n",
       "<tr><td>training_function_46e9e_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.05641</td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00002:\n",
      "  date: 2021-08-29_10-39-29\n",
      "  done: true\n",
      "  experiment_id: da2f79f18b4546b395a67b007825470d\n",
      "  experiment_tag: 2_GAMMA=0.85,THETA=0.1\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.1211111111111112\n",
      "  neg_mean_loss: -1.1211111111111112\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11513\n",
      "  time_since_restore: 1.0471150875091553\n",
      "  time_this_iter_s: 1.0471150875091553\n",
      "  time_total_s: 1.0471150875091553\n",
      "  timestamp: 1630204769\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00002\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11502)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=11502)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=11502)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11502)\u001b[0m \r",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11502)\u001b[0m frac:0.2638888888888889\n",
      "Result for training_function_46e9e_00003:\n",
      "  date: 2021-08-29_10-39-36\n",
      "  done: false\n",
      "  experiment_id: 7e6f29881e644685b767ebe129f1b3e5\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.21765873015873\n",
      "  neg_mean_loss: -1.21765873015873\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11502\n",
      "  time_since_restore: 1.1002981662750244\n",
      "  time_this_iter_s: 1.1002981662750244\n",
      "  time_total_s: 1.1002981662750244\n",
      "  timestamp: 1630204776\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00003\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11502)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11502)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 144.0/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/1.0 accelerator_type:V, 0.0/8.0 CPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_b732c446212a2c1cca5ef1dadf7b45e0)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_10-39-05<br>Number of trials: 36/36 (32 PENDING, 1 RUNNING, 3 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">   loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_46e9e_00003</td><td>RUNNING   </td><td>202.117.43.132:11502</td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.1003 </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00004</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00005</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00006</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00007</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00008</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00009</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00010</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00011</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00012</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00013</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00014</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00015</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">2.47714</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.07803</td><td style=\"text-align: right;\">       -2.47714</td></tr>\n",
       "<tr><td>training_function_46e9e_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.05641</td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.12111</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.04712</td><td style=\"text-align: right;\">       -1.12111</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00003:\n",
      "  date: 2021-08-29_10-39-36\n",
      "  done: true\n",
      "  experiment_id: 7e6f29881e644685b767ebe129f1b3e5\n",
      "  experiment_tag: 3_GAMMA=0.8,THETA=0.1\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.21765873015873\n",
      "  neg_mean_loss: -1.21765873015873\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11502\n",
      "  time_since_restore: 1.1002981662750244\n",
      "  time_this_iter_s: 1.1002981662750244\n",
      "  time_total_s: 1.1002981662750244\n",
      "  timestamp: 1630204776\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00003\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11515)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=11515)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=11515)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11515)\u001b[0m \r",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11515)\u001b[0m frac:0.3194444444444444\n",
      "Result for training_function_46e9e_00004:\n",
      "  date: 2021-08-29_10-39-44\n",
      "  done: false\n",
      "  experiment_id: 37162bbf33ca4c6e8a3eb3869a41227c\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.495\n",
      "  neg_mean_loss: -1.495\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11515\n",
      "  time_since_restore: 1.0820708274841309\n",
      "  time_this_iter_s: 1.0820708274841309\n",
      "  time_total_s: 1.0820708274841309\n",
      "  timestamp: 1630204784\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00004\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 144.0/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/1.0 accelerator_type:V, 0.0/8.0 CPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_b732c446212a2c1cca5ef1dadf7b45e0)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_10-39-05<br>Number of trials: 36/36 (31 PENDING, 1 RUNNING, 4 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">   loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_46e9e_00004</td><td>RUNNING   </td><td>202.117.43.132:11515</td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.08207</td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "<tr><td>training_function_46e9e_00005</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00006</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00007</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00008</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00009</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00010</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00011</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00012</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00013</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00014</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00015</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">2.47714</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.07803</td><td style=\"text-align: right;\">       -2.47714</td></tr>\n",
       "<tr><td>training_function_46e9e_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.05641</td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.12111</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.04712</td><td style=\"text-align: right;\">       -1.12111</td></tr>\n",
       "<tr><td>training_function_46e9e_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.1003 </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00004:\n",
      "  date: 2021-08-29_10-39-44\n",
      "  done: true\n",
      "  experiment_id: 37162bbf33ca4c6e8a3eb3869a41227c\n",
      "  experiment_tag: 4_GAMMA=0.7,THETA=0.1\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.495\n",
      "  neg_mean_loss: -1.495\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11515\n",
      "  time_since_restore: 1.0820708274841309\n",
      "  time_this_iter_s: 1.0820708274841309\n",
      "  time_total_s: 1.0820708274841309\n",
      "  timestamp: 1630204784\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00004\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11515)\u001b[0m \n",
      "                                                               \u001b[A\n",
      "\u001b[2m\u001b[36m(pid=11532)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=11532)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11532)\u001b[0m frac:0.3055555555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11532)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11532)\u001b[0m \r",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00005:\n",
      "  date: 2021-08-29_10-39-52\n",
      "  done: false\n",
      "  experiment_id: dc5d8bd297284d8bb6bbb139c19974eb\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.3080555555555555\n",
      "  neg_mean_loss: -1.3080555555555555\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11532\n",
      "  time_since_restore: 1.0255143642425537\n",
      "  time_this_iter_s: 1.0255143642425537\n",
      "  time_total_s: 1.0255143642425537\n",
      "  timestamp: 1630204792\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00005\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11532)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11532)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 143.9/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/1.0 accelerator_type:V)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_10-39-05<br>Number of trials: 36/36 (30 PENDING, 1 RUNNING, 5 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">   loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_46e9e_00005</td><td>RUNNING   </td><td>202.117.43.132:11532</td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.02551</td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00006</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00007</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00008</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00009</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00010</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00011</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00012</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00013</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00014</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00015</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">2.47714</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.07803</td><td style=\"text-align: right;\">       -2.47714</td></tr>\n",
       "<tr><td>training_function_46e9e_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.05641</td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.12111</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.04712</td><td style=\"text-align: right;\">       -1.12111</td></tr>\n",
       "<tr><td>training_function_46e9e_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.1003 </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.08207</td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00005:\n",
      "  date: 2021-08-29_10-39-52\n",
      "  done: true\n",
      "  experiment_id: dc5d8bd297284d8bb6bbb139c19974eb\n",
      "  experiment_tag: 5_GAMMA=0.6,THETA=0.1\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.3080555555555555\n",
      "  neg_mean_loss: -1.3080555555555555\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11532\n",
      "  time_since_restore: 1.0255143642425537\n",
      "  time_this_iter_s: 1.0255143642425537\n",
      "  time_total_s: 1.0255143642425537\n",
      "  timestamp: 1630204792\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00005\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11481)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=11481)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=11481)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11481)\u001b[0m frac:0.3055555555555556\n",
      "Result for training_function_46e9e_00006:\n",
      "  date: 2021-08-29_10-39-59\n",
      "  done: false\n",
      "  experiment_id: dfd3fb63325a4d61a5f91afcf5b79697\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.4498015873015873\n",
      "  neg_mean_loss: -1.4498015873015873\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11481\n",
      "  time_since_restore: 1.070948600769043\n",
      "  time_this_iter_s: 1.070948600769043\n",
      "  time_total_s: 1.070948600769043\n",
      "  timestamp: 1630204799\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00006\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11481)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11481)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 143.9/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/1.0 accelerator_type:V)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_10-39-05<br>Number of trials: 36/36 (29 PENDING, 1 RUNNING, 6 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">   loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_46e9e_00006</td><td>RUNNING   </td><td>202.117.43.132:11481</td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.4498 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.07095</td><td style=\"text-align: right;\">       -1.4498 </td></tr>\n",
       "<tr><td>training_function_46e9e_00007</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00008</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00009</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00010</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00011</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00012</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00013</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00014</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00015</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">2.47714</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.07803</td><td style=\"text-align: right;\">       -2.47714</td></tr>\n",
       "<tr><td>training_function_46e9e_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.05641</td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.12111</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.04712</td><td style=\"text-align: right;\">       -1.12111</td></tr>\n",
       "<tr><td>training_function_46e9e_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.1003 </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.08207</td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "<tr><td>training_function_46e9e_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.02551</td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00006:\n",
      "  date: 2021-08-29_10-39-59\n",
      "  done: true\n",
      "  experiment_id: dfd3fb63325a4d61a5f91afcf5b79697\n",
      "  experiment_tag: 6_GAMMA=0.95,THETA=0.01\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.4498015873015873\n",
      "  neg_mean_loss: -1.4498015873015873\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11481\n",
      "  time_since_restore: 1.070948600769043\n",
      "  time_this_iter_s: 1.070948600769043\n",
      "  time_total_s: 1.070948600769043\n",
      "  timestamp: 1630204799\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00006\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11542)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=11542)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=11542)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11542)\u001b[0m frac:0.2361111111111111\n",
      "Result for training_function_46e9e_00007:\n",
      "  date: 2021-08-29_10-40-07\n",
      "  done: false\n",
      "  experiment_id: 57d8085d80574be8a5517c222bd815e9\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.21765873015873\n",
      "  neg_mean_loss: -1.21765873015873\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11542\n",
      "  time_since_restore: 1.0544869899749756\n",
      "  time_this_iter_s: 1.0544869899749756\n",
      "  time_total_s: 1.0544869899749756\n",
      "  timestamp: 1630204807\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00007\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11542)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11542)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 143.8/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_10-39-05<br>Number of trials: 36/36 (28 PENDING, 1 RUNNING, 7 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">   loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_46e9e_00007</td><td>RUNNING   </td><td>202.117.43.132:11542</td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.05449</td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00008</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00009</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00010</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00011</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00012</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00013</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00014</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00015</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">2.47714</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.07803</td><td style=\"text-align: right;\">       -2.47714</td></tr>\n",
       "<tr><td>training_function_46e9e_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.05641</td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.12111</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.04712</td><td style=\"text-align: right;\">       -1.12111</td></tr>\n",
       "<tr><td>training_function_46e9e_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.1003 </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.08207</td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "<tr><td>training_function_46e9e_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.02551</td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.4498 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.07095</td><td style=\"text-align: right;\">       -1.4498 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00007:\n",
      "  date: 2021-08-29_10-40-07\n",
      "  done: true\n",
      "  experiment_id: 57d8085d80574be8a5517c222bd815e9\n",
      "  experiment_tag: 7_GAMMA=0.9,THETA=0.01\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.21765873015873\n",
      "  neg_mean_loss: -1.21765873015873\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11542\n",
      "  time_since_restore: 1.0544869899749756\n",
      "  time_this_iter_s: 1.0544869899749756\n",
      "  time_total_s: 1.0544869899749756\n",
      "  timestamp: 1630204807\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00007\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11553)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=11553)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=11553)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11553)\u001b[0m frac:0.2638888888888889\n",
      "Result for training_function_46e9e_00008:\n",
      "  date: 2021-08-29_10-40-14\n",
      "  done: false\n",
      "  experiment_id: b36a4fd412654ad4bb14b80224ab4a76\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 2.6015873015873017\n",
      "  neg_mean_loss: -2.6015873015873017\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11553\n",
      "  time_since_restore: 0.9860763549804688\n",
      "  time_this_iter_s: 0.9860763549804688\n",
      "  time_total_s: 0.9860763549804688\n",
      "  timestamp: 1630204814\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00008\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11553)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11553)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 143.8/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_10-39-05<br>Number of trials: 36/36 (27 PENDING, 1 RUNNING, 8 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">   loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_46e9e_00008</td><td>RUNNING   </td><td>202.117.43.132:11553</td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">2.60159</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.986076</td><td style=\"text-align: right;\">       -2.60159</td></tr>\n",
       "<tr><td>training_function_46e9e_00009</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00010</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00011</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00012</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00013</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00014</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00015</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">2.47714</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07803 </td><td style=\"text-align: right;\">       -2.47714</td></tr>\n",
       "<tr><td>training_function_46e9e_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05641 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.12111</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.04712 </td><td style=\"text-align: right;\">       -1.12111</td></tr>\n",
       "<tr><td>training_function_46e9e_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.1003  </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.08207 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "<tr><td>training_function_46e9e_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.02551 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.4498 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07095 </td><td style=\"text-align: right;\">       -1.4498 </td></tr>\n",
       "<tr><td>training_function_46e9e_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05449 </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00008:\n",
      "  date: 2021-08-29_10-40-14\n",
      "  done: true\n",
      "  experiment_id: b36a4fd412654ad4bb14b80224ab4a76\n",
      "  experiment_tag: 8_GAMMA=0.85,THETA=0.01\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 2.6015873015873017\n",
      "  neg_mean_loss: -2.6015873015873017\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11553\n",
      "  time_since_restore: 0.9860763549804688\n",
      "  time_this_iter_s: 0.9860763549804688\n",
      "  time_total_s: 0.9860763549804688\n",
      "  timestamp: 1630204814\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00008\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11503)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=11503)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=11503)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11503)\u001b[0m frac:0.3333333333333333\n",
      "Result for training_function_46e9e_00009:\n",
      "  date: 2021-08-29_10-40-22\n",
      "  done: false\n",
      "  experiment_id: 75163b7e75d7449dadb0ca382ff5b693\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.495\n",
      "  neg_mean_loss: -1.495\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11503\n",
      "  time_since_restore: 1.0159943103790283\n",
      "  time_this_iter_s: 1.0159943103790283\n",
      "  time_total_s: 1.0159943103790283\n",
      "  timestamp: 1630204822\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00009\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11503)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11503)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 143.8/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/8.0 CPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_10-39-05<br>Number of trials: 36/36 (26 PENDING, 1 RUNNING, 9 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">   loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_46e9e_00009</td><td>RUNNING   </td><td>202.117.43.132:11503</td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.01599 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "<tr><td>training_function_46e9e_00010</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00011</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00012</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00013</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00014</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00015</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">2.47714</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07803 </td><td style=\"text-align: right;\">       -2.47714</td></tr>\n",
       "<tr><td>training_function_46e9e_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05641 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.12111</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.04712 </td><td style=\"text-align: right;\">       -1.12111</td></tr>\n",
       "<tr><td>training_function_46e9e_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.1003  </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.08207 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "<tr><td>training_function_46e9e_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.02551 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.4498 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07095 </td><td style=\"text-align: right;\">       -1.4498 </td></tr>\n",
       "<tr><td>training_function_46e9e_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05449 </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">2.60159</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.986076</td><td style=\"text-align: right;\">       -2.60159</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00009:\n",
      "  date: 2021-08-29_10-40-22\n",
      "  done: true\n",
      "  experiment_id: 75163b7e75d7449dadb0ca382ff5b693\n",
      "  experiment_tag: 9_GAMMA=0.8,THETA=0.01\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.495\n",
      "  neg_mean_loss: -1.495\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11503\n",
      "  time_since_restore: 1.0159943103790283\n",
      "  time_this_iter_s: 1.0159943103790283\n",
      "  time_total_s: 1.0159943103790283\n",
      "  timestamp: 1630204822\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00009\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11518)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=11518)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=11518)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11518)\u001b[0m \r",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11518)\u001b[0m frac:0.2638888888888889\n",
      "Result for training_function_46e9e_00010:\n",
      "  date: 2021-08-29_10-40-29\n",
      "  done: false\n",
      "  experiment_id: 4ca60f05748a4efca03a9cb5d1f6dcba\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.262857142857143\n",
      "  neg_mean_loss: -1.262857142857143\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11518\n",
      "  time_since_restore: 0.9923648834228516\n",
      "  time_this_iter_s: 0.9923648834228516\n",
      "  time_total_s: 0.9923648834228516\n",
      "  timestamp: 1630204829\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00010\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 143.7/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/8.0 CPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_10-39-05<br>Number of trials: 36/36 (25 PENDING, 1 RUNNING, 10 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">   loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_46e9e_00010</td><td>RUNNING   </td><td>202.117.43.132:11518</td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.26286</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.992365</td><td style=\"text-align: right;\">       -1.26286</td></tr>\n",
       "<tr><td>training_function_46e9e_00011</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00012</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00013</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00014</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00015</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00020</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">2.47714</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07803 </td><td style=\"text-align: right;\">       -2.47714</td></tr>\n",
       "<tr><td>training_function_46e9e_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05641 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.12111</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.04712 </td><td style=\"text-align: right;\">       -1.12111</td></tr>\n",
       "<tr><td>training_function_46e9e_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.1003  </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.08207 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "<tr><td>training_function_46e9e_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.02551 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.4498 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07095 </td><td style=\"text-align: right;\">       -1.4498 </td></tr>\n",
       "<tr><td>training_function_46e9e_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05449 </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">2.60159</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.986076</td><td style=\"text-align: right;\">       -2.60159</td></tr>\n",
       "<tr><td>training_function_46e9e_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.01599 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (15 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00010:\n",
      "  date: 2021-08-29_10-40-29\n",
      "  done: true\n",
      "  experiment_id: 4ca60f05748a4efca03a9cb5d1f6dcba\n",
      "  experiment_tag: 10_GAMMA=0.7,THETA=0.01\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.262857142857143\n",
      "  neg_mean_loss: -1.262857142857143\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11518\n",
      "  time_since_restore: 0.9923648834228516\n",
      "  time_this_iter_s: 0.9923648834228516\n",
      "  time_total_s: 0.9923648834228516\n",
      "  timestamp: 1630204829\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00010\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11518)\u001b[0m \n",
      "                                                               \u001b[A\n",
      "\u001b[2m\u001b[36m(pid=11514)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=11514)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11514)\u001b[0m frac:0.3055555555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11514)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=11514)\u001b[0m \n",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00011:\n",
      "  date: 2021-08-29_10-40-37\n",
      "  done: false\n",
      "  experiment_id: f6ce1c20410c4b3eb14cc94ad433cd5c\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.3080555555555555\n",
      "  neg_mean_loss: -1.3080555555555555\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11514\n",
      "  time_since_restore: 0.9972050189971924\n",
      "  time_this_iter_s: 0.9972050189971924\n",
      "  time_total_s: 0.9972050189971924\n",
      "  timestamp: 1630204837\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00011\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 143.7/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_10-39-05<br>Number of trials: 36/36 (24 PENDING, 1 RUNNING, 11 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">   loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_46e9e_00011</td><td>RUNNING   </td><td>202.117.43.132:11514</td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.997205</td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00012</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00013</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00014</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00015</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00020</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00021</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">2.47714</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07803 </td><td style=\"text-align: right;\">       -2.47714</td></tr>\n",
       "<tr><td>training_function_46e9e_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05641 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.12111</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.04712 </td><td style=\"text-align: right;\">       -1.12111</td></tr>\n",
       "<tr><td>training_function_46e9e_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.1003  </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.08207 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "<tr><td>training_function_46e9e_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.02551 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.4498 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07095 </td><td style=\"text-align: right;\">       -1.4498 </td></tr>\n",
       "<tr><td>training_function_46e9e_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05449 </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">2.60159</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.986076</td><td style=\"text-align: right;\">       -2.60159</td></tr>\n",
       "<tr><td>training_function_46e9e_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.01599 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (14 PENDING, 1 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00011:\n",
      "  date: 2021-08-29_10-40-37\n",
      "  done: true\n",
      "  experiment_id: f6ce1c20410c4b3eb14cc94ad433cd5c\n",
      "  experiment_tag: 11_GAMMA=0.6,THETA=0.01\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.3080555555555555\n",
      "  neg_mean_loss: -1.3080555555555555\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11514\n",
      "  time_since_restore: 0.9972050189971924\n",
      "  time_this_iter_s: 0.9972050189971924\n",
      "  time_total_s: 0.9972050189971924\n",
      "  timestamp: 1630204837\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00011\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11501)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=11501)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=11501)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11501)\u001b[0m frac:0.2916666666666667\n",
      "Result for training_function_46e9e_00012:\n",
      "  date: 2021-08-29_10-40-45\n",
      "  done: false\n",
      "  experiment_id: 345c4f222b754fe38b62fec8c85688ef\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.8889682539682539\n",
      "  neg_mean_loss: -0.8889682539682539\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11501\n",
      "  time_since_restore: 1.0664823055267334\n",
      "  time_this_iter_s: 1.0664823055267334\n",
      "  time_total_s: 1.0664823055267334\n",
      "  timestamp: 1630204845\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00012\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 143.7/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_10-39-05<br>Number of trials: 36/36 (23 PENDING, 1 RUNNING, 12 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_46e9e_00012</td><td>RUNNING   </td><td>202.117.43.132:11501</td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">0.888968</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.06648 </td><td style=\"text-align: right;\">      -0.888968</td></tr>\n",
       "<tr><td>training_function_46e9e_00013</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00014</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00015</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00020</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00021</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00022</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">2.47714 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07803 </td><td style=\"text-align: right;\">      -2.47714 </td></tr>\n",
       "<tr><td>training_function_46e9e_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05641 </td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "<tr><td>training_function_46e9e_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.12111 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.04712 </td><td style=\"text-align: right;\">      -1.12111 </td></tr>\n",
       "<tr><td>training_function_46e9e_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.21766 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.1003  </td><td style=\"text-align: right;\">      -1.21766 </td></tr>\n",
       "<tr><td>training_function_46e9e_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.495   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.08207 </td><td style=\"text-align: right;\">      -1.495   </td></tr>\n",
       "<tr><td>training_function_46e9e_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.02551 </td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "<tr><td>training_function_46e9e_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.4498  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07095 </td><td style=\"text-align: right;\">      -1.4498  </td></tr>\n",
       "<tr><td>training_function_46e9e_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.21766 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05449 </td><td style=\"text-align: right;\">      -1.21766 </td></tr>\n",
       "<tr><td>training_function_46e9e_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">2.60159 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.986076</td><td style=\"text-align: right;\">      -2.60159 </td></tr>\n",
       "<tr><td>training_function_46e9e_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.495   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.01599 </td><td style=\"text-align: right;\">      -1.495   </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (13 PENDING, 2 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00012:\n",
      "  date: 2021-08-29_10-40-45\n",
      "  done: true\n",
      "  experiment_id: 345c4f222b754fe38b62fec8c85688ef\n",
      "  experiment_tag: 12_GAMMA=0.95,THETA=0.003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.8889682539682539\n",
      "  neg_mean_loss: -0.8889682539682539\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11501\n",
      "  time_since_restore: 1.0664823055267334\n",
      "  time_this_iter_s: 1.0664823055267334\n",
      "  time_total_s: 1.0664823055267334\n",
      "  timestamp: 1630204845\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00012\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11501)\u001b[0m \n",
      "                                                               \u001b[A\n",
      "\u001b[2m\u001b[36m(pid=11506)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=11506)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=11506)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11506)\u001b[0m frac:0.2777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11506)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11506)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00013:\n",
      "  date: 2021-08-29_10-40-52\n",
      "  done: false\n",
      "  experiment_id: 87c134c266034721ac4977b5234ee58a\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.495\n",
      "  neg_mean_loss: -1.495\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11506\n",
      "  time_since_restore: 1.1047651767730713\n",
      "  time_this_iter_s: 1.1047651767730713\n",
      "  time_total_s: 1.1047651767730713\n",
      "  timestamp: 1630204852\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00013\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 143.6/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/8.0 CPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/1.0 accelerator_type:V, 0.0/8.0 CPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_10-39-05<br>Number of trials: 36/36 (22 PENDING, 1 RUNNING, 13 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">   loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_46e9e_00013</td><td>RUNNING   </td><td>202.117.43.132:11506</td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.10477 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "<tr><td>training_function_46e9e_00014</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00015</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00020</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00021</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00022</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00023</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">2.47714</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07803 </td><td style=\"text-align: right;\">       -2.47714</td></tr>\n",
       "<tr><td>training_function_46e9e_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05641 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.12111</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.04712 </td><td style=\"text-align: right;\">       -1.12111</td></tr>\n",
       "<tr><td>training_function_46e9e_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.1003  </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.08207 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "<tr><td>training_function_46e9e_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.02551 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.4498 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07095 </td><td style=\"text-align: right;\">       -1.4498 </td></tr>\n",
       "<tr><td>training_function_46e9e_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05449 </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">2.60159</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.986076</td><td style=\"text-align: right;\">       -2.60159</td></tr>\n",
       "<tr><td>training_function_46e9e_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.01599 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (12 PENDING, 3 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00013:\n",
      "  date: 2021-08-29_10-40-52\n",
      "  done: true\n",
      "  experiment_id: 87c134c266034721ac4977b5234ee58a\n",
      "  experiment_tag: 13_GAMMA=0.9,THETA=0.003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.495\n",
      "  neg_mean_loss: -1.495\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11506\n",
      "  time_since_restore: 1.1047651767730713\n",
      "  time_this_iter_s: 1.1047651767730713\n",
      "  time_total_s: 1.1047651767730713\n",
      "  timestamp: 1630204852\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00013\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11520)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=11520)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=11520)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11520)\u001b[0m \r",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11520)\u001b[0m frac:0.2638888888888889\n",
      "Result for training_function_46e9e_00014:\n",
      "  date: 2021-08-29_10-41-00\n",
      "  done: false\n",
      "  experiment_id: 7cdc28a8f82c4535a4e96ce56324fa37\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -.inf\n",
      "  neg_mean_loss: .inf\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11520\n",
      "  time_since_restore: 1.0449018478393555\n",
      "  time_this_iter_s: 1.0449018478393555\n",
      "  time_total_s: 1.0449018478393555\n",
      "  timestamp: 1630204860\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00014\n",
      "  \n",
      "2021-08-29 10:41:00,376 - root - WARNING - NaN or Inf found in input tensor.\n",
      "2021-08-29 10:41:00,378 - root - WARNING - NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11520)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11520)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 143.6/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/8.0 CPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/1.0 accelerator_type:V, 0.0/8.0 CPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_10-39-05<br>Number of trials: 36/36 (21 PENDING, 1 RUNNING, 14 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">      loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_46e9e_00014</td><td>RUNNING   </td><td>202.117.43.132:11520</td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-inf      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.0449  </td><td style=\"text-align: right;\">      inf      </td></tr>\n",
       "<tr><td>training_function_46e9e_00015</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00020</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00021</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00022</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00023</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00024</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   2.47714</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07803 </td><td style=\"text-align: right;\">       -2.47714</td></tr>\n",
       "<tr><td>training_function_46e9e_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05641 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   1.12111</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.04712 </td><td style=\"text-align: right;\">       -1.12111</td></tr>\n",
       "<tr><td>training_function_46e9e_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.1003  </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.08207 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "<tr><td>training_function_46e9e_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.02551 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   1.4498 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07095 </td><td style=\"text-align: right;\">       -1.4498 </td></tr>\n",
       "<tr><td>training_function_46e9e_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05449 </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   2.60159</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.986076</td><td style=\"text-align: right;\">       -2.60159</td></tr>\n",
       "<tr><td>training_function_46e9e_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.01599 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (11 PENDING, 4 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11520)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "\u001b[2m\u001b[36m(pid=11520)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00014:\n",
      "  date: 2021-08-29_10-41-00\n",
      "  done: true\n",
      "  experiment_id: 7cdc28a8f82c4535a4e96ce56324fa37\n",
      "  experiment_tag: 14_GAMMA=0.85,THETA=0.003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -.inf\n",
      "  neg_mean_loss: .inf\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11520\n",
      "  time_since_restore: 1.0449018478393555\n",
      "  time_this_iter_s: 1.0449018478393555\n",
      "  time_total_s: 1.0449018478393555\n",
      "  timestamp: 1630204860\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00014\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11490)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=11490)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=11490)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11490)\u001b[0m frac:0.3055555555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11490)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11490)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00015:\n",
      "  date: 2021-08-29_10-41-07\n",
      "  done: false\n",
      "  experiment_id: 1f9319a0964b458bbdf8f54dd94042bd\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.495\n",
      "  neg_mean_loss: -1.495\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11490\n",
      "  time_since_restore: 0.9733438491821289\n",
      "  time_this_iter_s: 0.9733438491821289\n",
      "  time_total_s: 0.9733438491821289\n",
      "  timestamp: 1630204867\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00015\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 143.5/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/1.0 accelerator_type:V, 0.0/8.0 CPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_b732c446212a2c1cca5ef1dadf7b45e0)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_10-39-05<br>Number of trials: 36/36 (20 PENDING, 1 RUNNING, 15 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">   loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_46e9e_00015</td><td>RUNNING   </td><td>202.117.43.132:11490</td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.973344</td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "<tr><td>training_function_46e9e_00016</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00020</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00021</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00022</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00023</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00024</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00025</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">2.47714</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07803 </td><td style=\"text-align: right;\">       -2.47714</td></tr>\n",
       "<tr><td>training_function_46e9e_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05641 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.12111</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.04712 </td><td style=\"text-align: right;\">       -1.12111</td></tr>\n",
       "<tr><td>training_function_46e9e_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.1003  </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.08207 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "<tr><td>training_function_46e9e_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.02551 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.4498 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07095 </td><td style=\"text-align: right;\">       -1.4498 </td></tr>\n",
       "<tr><td>training_function_46e9e_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05449 </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">2.60159</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.986076</td><td style=\"text-align: right;\">       -2.60159</td></tr>\n",
       "<tr><td>training_function_46e9e_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.01599 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (10 PENDING, 5 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00015:\n",
      "  date: 2021-08-29_10-41-07\n",
      "  done: true\n",
      "  experiment_id: 1f9319a0964b458bbdf8f54dd94042bd\n",
      "  experiment_tag: 15_GAMMA=0.8,THETA=0.003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.495\n",
      "  neg_mean_loss: -1.495\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11490\n",
      "  time_since_restore: 0.9733438491821289\n",
      "  time_this_iter_s: 0.9733438491821289\n",
      "  time_total_s: 0.9733438491821289\n",
      "  timestamp: 1630204867\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00015\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11508)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=11508)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=11508)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11508)\u001b[0m \r",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11508)\u001b[0m frac:0.2777777777777778\n",
      "Result for training_function_46e9e_00016:\n",
      "  date: 2021-08-29_10-41-15\n",
      "  done: false\n",
      "  experiment_id: c9b698c36d744efead364ec35d28abfc\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.3080555555555555\n",
      "  neg_mean_loss: -1.3080555555555555\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11508\n",
      "  time_since_restore: 0.9989721775054932\n",
      "  time_this_iter_s: 0.9989721775054932\n",
      "  time_total_s: 0.9989721775054932\n",
      "  timestamp: 1630204875\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00016\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 143.5/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/1.0 accelerator_type:V, 0.0/8.0 CPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_b732c446212a2c1cca5ef1dadf7b45e0)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_10-39-05<br>Number of trials: 36/36 (19 PENDING, 1 RUNNING, 16 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">   loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_46e9e_00016</td><td>RUNNING   </td><td>202.117.43.132:11508</td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.998972</td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00017</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00020</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00021</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00022</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00023</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00024</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00025</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00026</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">2.47714</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07803 </td><td style=\"text-align: right;\">       -2.47714</td></tr>\n",
       "<tr><td>training_function_46e9e_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05641 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.12111</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.04712 </td><td style=\"text-align: right;\">       -1.12111</td></tr>\n",
       "<tr><td>training_function_46e9e_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.1003  </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.08207 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "<tr><td>training_function_46e9e_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.02551 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.4498 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07095 </td><td style=\"text-align: right;\">       -1.4498 </td></tr>\n",
       "<tr><td>training_function_46e9e_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05449 </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">2.60159</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.986076</td><td style=\"text-align: right;\">       -2.60159</td></tr>\n",
       "<tr><td>training_function_46e9e_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.01599 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (9 PENDING, 6 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00016:\n",
      "  date: 2021-08-29_10-41-15\n",
      "  done: true\n",
      "  experiment_id: c9b698c36d744efead364ec35d28abfc\n",
      "  experiment_tag: 16_GAMMA=0.7,THETA=0.003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.3080555555555555\n",
      "  neg_mean_loss: -1.3080555555555555\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11508\n",
      "  time_since_restore: 0.9989721775054932\n",
      "  time_this_iter_s: 0.9989721775054932\n",
      "  time_total_s: 0.9989721775054932\n",
      "  timestamp: 1630204875\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00016\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11508)\u001b[0m \n",
      "                                                               \u001b[A\n",
      "\u001b[2m\u001b[36m(pid=11547)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=11547)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=11547)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11547)\u001b[0m frac:0.20833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11547)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11547)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00017:\n",
      "  date: 2021-08-29_10-41-22\n",
      "  done: false\n",
      "  experiment_id: 6e2c33809f664f5bb8a9feb3871a4dd6\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 2.9944444444444445\n",
      "  neg_mean_loss: -2.9944444444444445\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11547\n",
      "  time_since_restore: 0.9607460498809814\n",
      "  time_this_iter_s: 0.9607460498809814\n",
      "  time_total_s: 0.9607460498809814\n",
      "  timestamp: 1630204882\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00017\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 143.4/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/8.0 CPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_10-39-05<br>Number of trials: 36/36 (18 PENDING, 1 RUNNING, 17 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">   loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_46e9e_00017</td><td>RUNNING   </td><td>202.117.43.132:11547</td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">2.99444</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.960746</td><td style=\"text-align: right;\">       -2.99444</td></tr>\n",
       "<tr><td>training_function_46e9e_00018</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00020</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00021</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00022</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00023</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00024</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00025</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00026</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00027</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">2.47714</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07803 </td><td style=\"text-align: right;\">       -2.47714</td></tr>\n",
       "<tr><td>training_function_46e9e_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05641 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.12111</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.04712 </td><td style=\"text-align: right;\">       -1.12111</td></tr>\n",
       "<tr><td>training_function_46e9e_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.1003  </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.08207 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "<tr><td>training_function_46e9e_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.02551 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.4498 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07095 </td><td style=\"text-align: right;\">       -1.4498 </td></tr>\n",
       "<tr><td>training_function_46e9e_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05449 </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">2.60159</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.986076</td><td style=\"text-align: right;\">       -2.60159</td></tr>\n",
       "<tr><td>training_function_46e9e_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.01599 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (8 PENDING, 7 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00017:\n",
      "  date: 2021-08-29_10-41-22\n",
      "  done: true\n",
      "  experiment_id: 6e2c33809f664f5bb8a9feb3871a4dd6\n",
      "  experiment_tag: 17_GAMMA=0.6,THETA=0.003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 2.9944444444444445\n",
      "  neg_mean_loss: -2.9944444444444445\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11547\n",
      "  time_since_restore: 0.9607460498809814\n",
      "  time_this_iter_s: 0.9607460498809814\n",
      "  time_total_s: 0.9607460498809814\n",
      "  timestamp: 1630204882\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00017\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11484)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=11484)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=11484)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11484)\u001b[0m frac:0.25\n",
      "Result for training_function_46e9e_00018:\n",
      "  date: 2021-08-29_10-41-30\n",
      "  done: false\n",
      "  experiment_id: 22485ff0c6bf4179a943ada6ed479ebd\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.3080555555555555\n",
      "  neg_mean_loss: -1.3080555555555555\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11484\n",
      "  time_since_restore: 0.9559061527252197\n",
      "  time_this_iter_s: 0.9559061527252197\n",
      "  time_total_s: 0.9559061527252197\n",
      "  timestamp: 1630204890\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00018\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 143.4/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/8.0 CPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_10-39-05<br>Number of trials: 36/36 (17 PENDING, 1 RUNNING, 18 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">   loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_46e9e_00018</td><td>RUNNING   </td><td>202.117.43.132:11484</td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.955906</td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00019</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00020</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00021</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00022</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00023</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00024</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00025</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00026</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00027</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00028</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">2.47714</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07803 </td><td style=\"text-align: right;\">       -2.47714</td></tr>\n",
       "<tr><td>training_function_46e9e_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05641 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.12111</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.04712 </td><td style=\"text-align: right;\">       -1.12111</td></tr>\n",
       "<tr><td>training_function_46e9e_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.1003  </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.08207 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "<tr><td>training_function_46e9e_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.02551 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.4498 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07095 </td><td style=\"text-align: right;\">       -1.4498 </td></tr>\n",
       "<tr><td>training_function_46e9e_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05449 </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">2.60159</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.986076</td><td style=\"text-align: right;\">       -2.60159</td></tr>\n",
       "<tr><td>training_function_46e9e_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.01599 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (7 PENDING, 8 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00018:\n",
      "  date: 2021-08-29_10-41-30\n",
      "  done: true\n",
      "  experiment_id: 22485ff0c6bf4179a943ada6ed479ebd\n",
      "  experiment_tag: 18_GAMMA=0.95,THETA=0.001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.3080555555555555\n",
      "  neg_mean_loss: -1.3080555555555555\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11484\n",
      "  time_since_restore: 0.9559061527252197\n",
      "  time_this_iter_s: 0.9559061527252197\n",
      "  time_total_s: 0.9559061527252197\n",
      "  timestamp: 1630204890\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00018\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11484)\u001b[0m \n",
      "                                                               \u001b[A\n",
      "\u001b[2m\u001b[36m(pid=11530)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=11530)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=11530)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11530)\u001b[0m frac:0.25\n",
      "Result for training_function_46e9e_00019:\n",
      "  date: 2021-08-29_10-41-37\n",
      "  done: false\n",
      "  experiment_id: 9c8e87af40e04545bdae50ea210f304a\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.3080555555555555\n",
      "  neg_mean_loss: -1.3080555555555555\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11530\n",
      "  time_since_restore: 1.0176007747650146\n",
      "  time_this_iter_s: 1.0176007747650146\n",
      "  time_total_s: 1.0176007747650146\n",
      "  timestamp: 1630204897\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00019\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11530)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11530)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 143.4/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_b732c446212a2c1cca5ef1dadf7b45e0)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_10-39-05<br>Number of trials: 36/36 (16 PENDING, 1 RUNNING, 19 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">   loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_46e9e_00019</td><td>RUNNING   </td><td>202.117.43.132:11530</td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.0176  </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00020</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00021</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00022</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00023</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00024</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00025</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00026</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00027</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00028</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00029</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">2.47714</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07803 </td><td style=\"text-align: right;\">       -2.47714</td></tr>\n",
       "<tr><td>training_function_46e9e_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05641 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.12111</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.04712 </td><td style=\"text-align: right;\">       -1.12111</td></tr>\n",
       "<tr><td>training_function_46e9e_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.1003  </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.08207 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "<tr><td>training_function_46e9e_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.02551 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.4498 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07095 </td><td style=\"text-align: right;\">       -1.4498 </td></tr>\n",
       "<tr><td>training_function_46e9e_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05449 </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">2.60159</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.986076</td><td style=\"text-align: right;\">       -2.60159</td></tr>\n",
       "<tr><td>training_function_46e9e_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.01599 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (6 PENDING, 9 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00019:\n",
      "  date: 2021-08-29_10-41-37\n",
      "  done: true\n",
      "  experiment_id: 9c8e87af40e04545bdae50ea210f304a\n",
      "  experiment_tag: 19_GAMMA=0.9,THETA=0.001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.3080555555555555\n",
      "  neg_mean_loss: -1.3080555555555555\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11530\n",
      "  time_since_restore: 1.0176007747650146\n",
      "  time_this_iter_s: 1.0176007747650146\n",
      "  time_total_s: 1.0176007747650146\n",
      "  timestamp: 1630204897\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00019\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11486)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=11486)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=11486)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11486)\u001b[0m frac:0.2638888888888889\n",
      "Result for training_function_46e9e_00020:\n",
      "  date: 2021-08-29_10-41-45\n",
      "  done: false\n",
      "  experiment_id: 99c8bb41005741459706e70500fec466\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 2.87\n",
      "  neg_mean_loss: -2.87\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11486\n",
      "  time_since_restore: 1.0158233642578125\n",
      "  time_this_iter_s: 1.0158233642578125\n",
      "  time_total_s: 1.0158233642578125\n",
      "  timestamp: 1630204905\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00020\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11486)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11486)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 143.3/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_b732c446212a2c1cca5ef1dadf7b45e0)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_10-39-05<br>Number of trials: 36/36 (15 PENDING, 1 RUNNING, 20 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">   loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_46e9e_00020</td><td>RUNNING   </td><td>202.117.43.132:11486</td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">2.87   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.01582 </td><td style=\"text-align: right;\">       -2.87   </td></tr>\n",
       "<tr><td>training_function_46e9e_00021</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00022</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00023</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00024</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00025</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00026</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00027</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00028</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00029</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00030</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">2.47714</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07803 </td><td style=\"text-align: right;\">       -2.47714</td></tr>\n",
       "<tr><td>training_function_46e9e_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05641 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.12111</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.04712 </td><td style=\"text-align: right;\">       -1.12111</td></tr>\n",
       "<tr><td>training_function_46e9e_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.1003  </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.08207 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "<tr><td>training_function_46e9e_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.02551 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.4498 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07095 </td><td style=\"text-align: right;\">       -1.4498 </td></tr>\n",
       "<tr><td>training_function_46e9e_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05449 </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">2.60159</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.986076</td><td style=\"text-align: right;\">       -2.60159</td></tr>\n",
       "<tr><td>training_function_46e9e_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.01599 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (5 PENDING, 10 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00020:\n",
      "  date: 2021-08-29_10-41-45\n",
      "  done: true\n",
      "  experiment_id: 99c8bb41005741459706e70500fec466\n",
      "  experiment_tag: 20_GAMMA=0.85,THETA=0.001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 2.87\n",
      "  neg_mean_loss: -2.87\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11486\n",
      "  time_since_restore: 1.0158233642578125\n",
      "  time_this_iter_s: 1.0158233642578125\n",
      "  time_total_s: 1.0158233642578125\n",
      "  timestamp: 1630204905\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00020\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11483)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=11483)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=11483)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11483)\u001b[0m frac:0.2777777777777778\n",
      "Result for training_function_46e9e_00021:\n",
      "  date: 2021-08-29_10-41-52\n",
      "  done: false\n",
      "  experiment_id: a3c3edb77eec4e5c8a5c2b28410b9d7f\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.262857142857143\n",
      "  neg_mean_loss: -1.262857142857143\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11483\n",
      "  time_since_restore: 0.9846489429473877\n",
      "  time_this_iter_s: 0.9846489429473877\n",
      "  time_total_s: 0.9846489429473877\n",
      "  timestamp: 1630204912\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00021\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 143.3/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/1.0 accelerator_type:V, 0.0/8.0 CPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_10-39-05<br>Number of trials: 36/36 (14 PENDING, 1 RUNNING, 21 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">   loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_46e9e_00021</td><td>RUNNING   </td><td>202.117.43.132:11483</td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">1.26286</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.984649</td><td style=\"text-align: right;\">       -1.26286</td></tr>\n",
       "<tr><td>training_function_46e9e_00022</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00023</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00024</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00025</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00026</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00027</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00028</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00029</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00030</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00031</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">2.47714</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07803 </td><td style=\"text-align: right;\">       -2.47714</td></tr>\n",
       "<tr><td>training_function_46e9e_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05641 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.12111</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.04712 </td><td style=\"text-align: right;\">       -1.12111</td></tr>\n",
       "<tr><td>training_function_46e9e_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.1003  </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.08207 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "<tr><td>training_function_46e9e_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.02551 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.4498 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07095 </td><td style=\"text-align: right;\">       -1.4498 </td></tr>\n",
       "<tr><td>training_function_46e9e_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05449 </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">2.60159</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.986076</td><td style=\"text-align: right;\">       -2.60159</td></tr>\n",
       "<tr><td>training_function_46e9e_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.01599 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (4 PENDING, 11 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00021:\n",
      "  date: 2021-08-29_10-41-52\n",
      "  done: true\n",
      "  experiment_id: a3c3edb77eec4e5c8a5c2b28410b9d7f\n",
      "  experiment_tag: 21_GAMMA=0.8,THETA=0.001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.262857142857143\n",
      "  neg_mean_loss: -1.262857142857143\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11483\n",
      "  time_since_restore: 0.9846489429473877\n",
      "  time_this_iter_s: 0.9846489429473877\n",
      "  time_total_s: 0.9846489429473877\n",
      "  timestamp: 1630204912\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00021\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11483)\u001b[0m \n",
      "                                                               \u001b[A\n",
      "\u001b[2m\u001b[36m(pid=11487)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=11487)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=11487)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11487)\u001b[0m frac:0.2777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11487)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11487)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00022:\n",
      "  date: 2021-08-29_10-41-59\n",
      "  done: false\n",
      "  experiment_id: 5aceab49f3a24873a78517c170733b44\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.3080555555555555\n",
      "  neg_mean_loss: -1.3080555555555555\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11487\n",
      "  time_since_restore: 0.972684383392334\n",
      "  time_this_iter_s: 0.972684383392334\n",
      "  time_total_s: 0.972684383392334\n",
      "  timestamp: 1630204919\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00022\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 143.2/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/1.0 accelerator_type:V, 0.0/8.0 CPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_10-39-05<br>Number of trials: 36/36 (13 PENDING, 1 RUNNING, 22 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">   loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_46e9e_00022</td><td>RUNNING   </td><td>202.117.43.132:11487</td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.972684</td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00023</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00024</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00025</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00026</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00027</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00028</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00029</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00030</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00031</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00032</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">2.47714</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07803 </td><td style=\"text-align: right;\">       -2.47714</td></tr>\n",
       "<tr><td>training_function_46e9e_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05641 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.12111</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.04712 </td><td style=\"text-align: right;\">       -1.12111</td></tr>\n",
       "<tr><td>training_function_46e9e_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.1003  </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.08207 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "<tr><td>training_function_46e9e_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.02551 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.4498 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07095 </td><td style=\"text-align: right;\">       -1.4498 </td></tr>\n",
       "<tr><td>training_function_46e9e_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05449 </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">2.60159</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.986076</td><td style=\"text-align: right;\">       -2.60159</td></tr>\n",
       "<tr><td>training_function_46e9e_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.01599 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (3 PENDING, 12 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00022:\n",
      "  date: 2021-08-29_10-41-59\n",
      "  done: true\n",
      "  experiment_id: 5aceab49f3a24873a78517c170733b44\n",
      "  experiment_tag: 22_GAMMA=0.7,THETA=0.001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.3080555555555555\n",
      "  neg_mean_loss: -1.3080555555555555\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11487\n",
      "  time_since_restore: 0.972684383392334\n",
      "  time_this_iter_s: 0.972684383392334\n",
      "  time_total_s: 0.972684383392334\n",
      "  timestamp: 1630204919\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00022\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11504)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=11504)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=11504)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11504)\u001b[0m frac:0.3333333333333333\n",
      "Result for training_function_46e9e_00023:\n",
      "  date: 2021-08-29_10-42-07\n",
      "  done: false\n",
      "  experiment_id: 20ce8cca46d74c9395d8b431daee2085\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.1211111111111112\n",
      "  neg_mean_loss: -1.1211111111111112\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11504\n",
      "  time_since_restore: 0.9771158695220947\n",
      "  time_this_iter_s: 0.9771158695220947\n",
      "  time_total_s: 0.9771158695220947\n",
      "  timestamp: 1630204927\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00023\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 143.2/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/1.0 accelerator_type:V, 0.0/8.0 CPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_10-39-05<br>Number of trials: 36/36 (12 PENDING, 1 RUNNING, 23 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">   loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_46e9e_00023</td><td>RUNNING   </td><td>202.117.43.132:11504</td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">1.12111</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.977116</td><td style=\"text-align: right;\">       -1.12111</td></tr>\n",
       "<tr><td>training_function_46e9e_00024</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00025</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00026</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00027</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00028</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00029</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00030</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00031</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00032</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00033</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">2.47714</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07803 </td><td style=\"text-align: right;\">       -2.47714</td></tr>\n",
       "<tr><td>training_function_46e9e_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05641 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.12111</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.04712 </td><td style=\"text-align: right;\">       -1.12111</td></tr>\n",
       "<tr><td>training_function_46e9e_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.1003  </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.08207 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "<tr><td>training_function_46e9e_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.02551 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.4498 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07095 </td><td style=\"text-align: right;\">       -1.4498 </td></tr>\n",
       "<tr><td>training_function_46e9e_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05449 </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">2.60159</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.986076</td><td style=\"text-align: right;\">       -2.60159</td></tr>\n",
       "<tr><td>training_function_46e9e_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.01599 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (2 PENDING, 13 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00023:\n",
      "  date: 2021-08-29_10-42-07\n",
      "  done: true\n",
      "  experiment_id: 20ce8cca46d74c9395d8b431daee2085\n",
      "  experiment_tag: 23_GAMMA=0.6,THETA=0.001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.1211111111111112\n",
      "  neg_mean_loss: -1.1211111111111112\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11504\n",
      "  time_since_restore: 0.9771158695220947\n",
      "  time_this_iter_s: 0.9771158695220947\n",
      "  time_total_s: 0.9771158695220947\n",
      "  timestamp: 1630204927\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00023\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11504)\u001b[0m \n",
      "                                                               \u001b[A\n",
      "\u001b[2m\u001b[36m(pid=11482)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=11482)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11482)\u001b[0m frac:0.2222222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11482)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11482)\u001b[0m \r",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00024:\n",
      "  date: 2021-08-29_10-42-14\n",
      "  done: false\n",
      "  experiment_id: e7ea3c1283204d68a25fe575fed46aa3\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.3080555555555555\n",
      "  neg_mean_loss: -1.3080555555555555\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11482\n",
      "  time_since_restore: 1.0400478839874268\n",
      "  time_this_iter_s: 1.0400478839874268\n",
      "  time_total_s: 1.0400478839874268\n",
      "  timestamp: 1630204934\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00024\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11482)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11482)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 143.2/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/1.0 accelerator_type:V, 0.0/8.0 CPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_10-39-05<br>Number of trials: 36/36 (11 PENDING, 1 RUNNING, 24 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">   loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_46e9e_00024</td><td>RUNNING   </td><td>202.117.43.132:11482</td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.04005 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00025</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00026</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00027</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00028</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00029</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00030</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00031</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00032</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00033</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00034</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">2.47714</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07803 </td><td style=\"text-align: right;\">       -2.47714</td></tr>\n",
       "<tr><td>training_function_46e9e_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05641 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.12111</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.04712 </td><td style=\"text-align: right;\">       -1.12111</td></tr>\n",
       "<tr><td>training_function_46e9e_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.1003  </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.08207 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "<tr><td>training_function_46e9e_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.02551 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.4498 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07095 </td><td style=\"text-align: right;\">       -1.4498 </td></tr>\n",
       "<tr><td>training_function_46e9e_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05449 </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">2.60159</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.986076</td><td style=\"text-align: right;\">       -2.60159</td></tr>\n",
       "<tr><td>training_function_46e9e_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.01599 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (1 PENDING, 14 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00024:\n",
      "  date: 2021-08-29_10-42-14\n",
      "  done: true\n",
      "  experiment_id: e7ea3c1283204d68a25fe575fed46aa3\n",
      "  experiment_tag: 24_GAMMA=0.95,THETA=0.0003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.3080555555555555\n",
      "  neg_mean_loss: -1.3080555555555555\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11482\n",
      "  time_since_restore: 1.0400478839874268\n",
      "  time_this_iter_s: 1.0400478839874268\n",
      "  time_total_s: 1.0400478839874268\n",
      "  timestamp: 1630204934\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00024\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11499)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=11499)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=11499)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11499)\u001b[0m \r",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11499)\u001b[0m frac:0.2638888888888889\n",
      "Result for training_function_46e9e_00025:\n",
      "  date: 2021-08-29_10-42-21\n",
      "  done: false\n",
      "  experiment_id: 8a5253bafdb44e5ca9d8b7f0f3aefdc8\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.4046031746031744\n",
      "  neg_mean_loss: -1.4046031746031744\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11499\n",
      "  time_since_restore: 1.0701570510864258\n",
      "  time_this_iter_s: 1.0701570510864258\n",
      "  time_total_s: 1.0701570510864258\n",
      "  timestamp: 1630204941\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00025\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11499)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11499)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 143.1/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/8.0 CPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/1.0 accelerator_type:V)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_10-39-05<br>Number of trials: 36/36 (10 PENDING, 1 RUNNING, 25 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">   loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_46e9e_00025</td><td>RUNNING   </td><td>202.117.43.132:11499</td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">1.4046 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07016 </td><td style=\"text-align: right;\">       -1.4046 </td></tr>\n",
       "<tr><td>training_function_46e9e_00026</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00027</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00028</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00029</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00030</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00031</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00032</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00033</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00034</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00035</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">2.47714</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07803 </td><td style=\"text-align: right;\">       -2.47714</td></tr>\n",
       "<tr><td>training_function_46e9e_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05641 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.12111</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.04712 </td><td style=\"text-align: right;\">       -1.12111</td></tr>\n",
       "<tr><td>training_function_46e9e_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.1003  </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.08207 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "<tr><td>training_function_46e9e_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.02551 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.4498 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07095 </td><td style=\"text-align: right;\">       -1.4498 </td></tr>\n",
       "<tr><td>training_function_46e9e_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05449 </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">2.60159</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.986076</td><td style=\"text-align: right;\">       -2.60159</td></tr>\n",
       "<tr><td>training_function_46e9e_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.01599 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (15 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00025:\n",
      "  date: 2021-08-29_10-42-21\n",
      "  done: true\n",
      "  experiment_id: 8a5253bafdb44e5ca9d8b7f0f3aefdc8\n",
      "  experiment_tag: 25_GAMMA=0.9,THETA=0.0003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.4046031746031744\n",
      "  neg_mean_loss: -1.4046031746031744\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11499\n",
      "  time_since_restore: 1.0701570510864258\n",
      "  time_this_iter_s: 1.0701570510864258\n",
      "  time_total_s: 1.0701570510864258\n",
      "  timestamp: 1630204941\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00025\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11498)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=11498)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=11498)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11498)\u001b[0m frac:0.2777777777777778\n",
      "Result for training_function_46e9e_00026:\n",
      "  date: 2021-08-29_10-42-29\n",
      "  done: false\n",
      "  experiment_id: 5b071c70b5b148f88d47a8ae60735614\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.3080555555555555\n",
      "  neg_mean_loss: -1.3080555555555555\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11498\n",
      "  time_since_restore: 0.9798531532287598\n",
      "  time_this_iter_s: 0.9798531532287598\n",
      "  time_total_s: 0.9798531532287598\n",
      "  timestamp: 1630204949\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00026\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11498)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11498)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 143.1/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/8.0 CPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/1.0 accelerator_type:V)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_10-39-05<br>Number of trials: 36/36 (9 PENDING, 1 RUNNING, 26 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">   loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_46e9e_00026</td><td>RUNNING   </td><td>202.117.43.132:11498</td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.979853</td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00027</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00028</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00029</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00030</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00031</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00032</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00033</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00034</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00035</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">2.47714</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07803 </td><td style=\"text-align: right;\">       -2.47714</td></tr>\n",
       "<tr><td>training_function_46e9e_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05641 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.12111</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.04712 </td><td style=\"text-align: right;\">       -1.12111</td></tr>\n",
       "<tr><td>training_function_46e9e_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.1003  </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.08207 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "<tr><td>training_function_46e9e_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.02551 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.4498 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07095 </td><td style=\"text-align: right;\">       -1.4498 </td></tr>\n",
       "<tr><td>training_function_46e9e_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05449 </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">2.60159</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.986076</td><td style=\"text-align: right;\">       -2.60159</td></tr>\n",
       "<tr><td>training_function_46e9e_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.01599 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00026:\n",
      "  date: 2021-08-29_10-42-29\n",
      "  done: true\n",
      "  experiment_id: 5b071c70b5b148f88d47a8ae60735614\n",
      "  experiment_tag: 26_GAMMA=0.85,THETA=0.0003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.3080555555555555\n",
      "  neg_mean_loss: -1.3080555555555555\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11498\n",
      "  time_since_restore: 0.9798531532287598\n",
      "  time_this_iter_s: 0.9798531532287598\n",
      "  time_total_s: 0.9798531532287598\n",
      "  timestamp: 1630204949\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00026\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11510)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=11510)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=11510)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11510)\u001b[0m frac:0.2361111111111111\n",
      "Result for training_function_46e9e_00027:\n",
      "  date: 2021-08-29_10-42-36\n",
      "  done: false\n",
      "  experiment_id: ce7ad66d74394c8fabd0a5415e57fbe9\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.3080555555555555\n",
      "  neg_mean_loss: -1.3080555555555555\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11510\n",
      "  time_since_restore: 1.0090701580047607\n",
      "  time_this_iter_s: 1.0090701580047607\n",
      "  time_total_s: 1.0090701580047607\n",
      "  timestamp: 1630204956\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00027\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11510)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11510)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 143.0/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/1.0 accelerator_type:V, 0.0/8.0 CPU_group_b732c446212a2c1cca5ef1dadf7b45e0)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_10-39-05<br>Number of trials: 36/36 (8 PENDING, 1 RUNNING, 27 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">   loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_46e9e_00027</td><td>RUNNING   </td><td>202.117.43.132:11510</td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.00907 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00028</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00029</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00030</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00031</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00032</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00033</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00034</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00035</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">2.47714</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07803 </td><td style=\"text-align: right;\">       -2.47714</td></tr>\n",
       "<tr><td>training_function_46e9e_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05641 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.12111</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.04712 </td><td style=\"text-align: right;\">       -1.12111</td></tr>\n",
       "<tr><td>training_function_46e9e_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.1003  </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.08207 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "<tr><td>training_function_46e9e_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.02551 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.4498 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07095 </td><td style=\"text-align: right;\">       -1.4498 </td></tr>\n",
       "<tr><td>training_function_46e9e_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05449 </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">2.60159</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.986076</td><td style=\"text-align: right;\">       -2.60159</td></tr>\n",
       "<tr><td>training_function_46e9e_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.01599 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "<tr><td>training_function_46e9e_00010</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.26286</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.992365</td><td style=\"text-align: right;\">       -1.26286</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00027:\n",
      "  date: 2021-08-29_10-42-36\n",
      "  done: true\n",
      "  experiment_id: ce7ad66d74394c8fabd0a5415e57fbe9\n",
      "  experiment_tag: 27_GAMMA=0.8,THETA=0.0003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.3080555555555555\n",
      "  neg_mean_loss: -1.3080555555555555\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11510\n",
      "  time_since_restore: 1.0090701580047607\n",
      "  time_this_iter_s: 1.0090701580047607\n",
      "  time_total_s: 1.0090701580047607\n",
      "  timestamp: 1630204956\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00027\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11496)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=11496)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=11496)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11496)\u001b[0m \r",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11496)\u001b[0m frac:0.3055555555555556\n",
      "Result for training_function_46e9e_00028:\n",
      "  date: 2021-08-29_10-42-44\n",
      "  done: false\n",
      "  experiment_id: 6f36ad55560048569a113de147946cc0\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.21765873015873\n",
      "  neg_mean_loss: -1.21765873015873\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11496\n",
      "  time_since_restore: 1.0224418640136719\n",
      "  time_this_iter_s: 1.0224418640136719\n",
      "  time_total_s: 1.0224418640136719\n",
      "  timestamp: 1630204964\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00028\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11496)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11496)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 143.0/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/1.0 accelerator_type:V, 0.0/8.0 CPU_group_b732c446212a2c1cca5ef1dadf7b45e0)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_10-39-05<br>Number of trials: 36/36 (7 PENDING, 1 RUNNING, 28 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">   loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_46e9e_00028</td><td>RUNNING   </td><td>202.117.43.132:11496</td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.02244 </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00029</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00030</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00031</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00032</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00033</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00034</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00035</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">2.47714</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07803 </td><td style=\"text-align: right;\">       -2.47714</td></tr>\n",
       "<tr><td>training_function_46e9e_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05641 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.12111</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.04712 </td><td style=\"text-align: right;\">       -1.12111</td></tr>\n",
       "<tr><td>training_function_46e9e_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.1003  </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.08207 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "<tr><td>training_function_46e9e_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.02551 </td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "<tr><td>training_function_46e9e_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.4498 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07095 </td><td style=\"text-align: right;\">       -1.4498 </td></tr>\n",
       "<tr><td>training_function_46e9e_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.21766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05449 </td><td style=\"text-align: right;\">       -1.21766</td></tr>\n",
       "<tr><td>training_function_46e9e_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">2.60159</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.986076</td><td style=\"text-align: right;\">       -2.60159</td></tr>\n",
       "<tr><td>training_function_46e9e_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.495  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.01599 </td><td style=\"text-align: right;\">       -1.495  </td></tr>\n",
       "<tr><td>training_function_46e9e_00010</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.26286</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.992365</td><td style=\"text-align: right;\">       -1.26286</td></tr>\n",
       "<tr><td>training_function_46e9e_00011</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.30806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.997205</td><td style=\"text-align: right;\">       -1.30806</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00028:\n",
      "  date: 2021-08-29_10-42-44\n",
      "  done: true\n",
      "  experiment_id: 6f36ad55560048569a113de147946cc0\n",
      "  experiment_tag: 28_GAMMA=0.7,THETA=0.0003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.21765873015873\n",
      "  neg_mean_loss: -1.21765873015873\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11496\n",
      "  time_since_restore: 1.0224418640136719\n",
      "  time_this_iter_s: 1.0224418640136719\n",
      "  time_total_s: 1.0224418640136719\n",
      "  timestamp: 1630204964\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00028\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11485)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=11485)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=11485)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11485)\u001b[0m \r",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11485)\u001b[0m frac:0.3055555555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11485)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11485)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00029:\n",
      "  date: 2021-08-29_10-42-51\n",
      "  done: false\n",
      "  experiment_id: 68794bab1a2a46ffa37ea6edfb0e811d\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.3080555555555555\n",
      "  neg_mean_loss: -1.3080555555555555\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11485\n",
      "  time_since_restore: 1.0406928062438965\n",
      "  time_this_iter_s: 1.0406928062438965\n",
      "  time_total_s: 1.0406928062438965\n",
      "  timestamp: 1630204971\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00029\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 143.0/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/8.0 CPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_10-39-05<br>Number of trials: 36/36 (6 PENDING, 1 RUNNING, 29 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_46e9e_00029</td><td>RUNNING   </td><td>202.117.43.132:11485</td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.04069 </td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "<tr><td>training_function_46e9e_00030</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00031</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00032</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00033</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00034</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00035</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">2.47714 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07803 </td><td style=\"text-align: right;\">      -2.47714 </td></tr>\n",
       "<tr><td>training_function_46e9e_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05641 </td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "<tr><td>training_function_46e9e_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.12111 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.04712 </td><td style=\"text-align: right;\">      -1.12111 </td></tr>\n",
       "<tr><td>training_function_46e9e_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.21766 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.1003  </td><td style=\"text-align: right;\">      -1.21766 </td></tr>\n",
       "<tr><td>training_function_46e9e_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.495   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.08207 </td><td style=\"text-align: right;\">      -1.495   </td></tr>\n",
       "<tr><td>training_function_46e9e_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.02551 </td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "<tr><td>training_function_46e9e_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.4498  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07095 </td><td style=\"text-align: right;\">      -1.4498  </td></tr>\n",
       "<tr><td>training_function_46e9e_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.21766 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05449 </td><td style=\"text-align: right;\">      -1.21766 </td></tr>\n",
       "<tr><td>training_function_46e9e_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">2.60159 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.986076</td><td style=\"text-align: right;\">      -2.60159 </td></tr>\n",
       "<tr><td>training_function_46e9e_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.495   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.01599 </td><td style=\"text-align: right;\">      -1.495   </td></tr>\n",
       "<tr><td>training_function_46e9e_00010</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.26286 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.992365</td><td style=\"text-align: right;\">      -1.26286 </td></tr>\n",
       "<tr><td>training_function_46e9e_00011</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.997205</td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "<tr><td>training_function_46e9e_00012</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">0.888968</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.06648 </td><td style=\"text-align: right;\">      -0.888968</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00029:\n",
      "  date: 2021-08-29_10-42-51\n",
      "  done: true\n",
      "  experiment_id: 68794bab1a2a46ffa37ea6edfb0e811d\n",
      "  experiment_tag: 29_GAMMA=0.6,THETA=0.0003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.3080555555555555\n",
      "  neg_mean_loss: -1.3080555555555555\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11485\n",
      "  time_since_restore: 1.0406928062438965\n",
      "  time_this_iter_s: 1.0406928062438965\n",
      "  time_total_s: 1.0406928062438965\n",
      "  timestamp: 1630204971\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00029\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11497)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=11497)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=11497)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11497)\u001b[0m \r",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11497)\u001b[0m frac:0.25\n",
      "Result for training_function_46e9e_00030:\n",
      "  date: 2021-08-29_10-42-59\n",
      "  done: false\n",
      "  experiment_id: 44276f11ab6f4cd7aee36d629c7f2fc5\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.0307142857142857\n",
      "  neg_mean_loss: -1.0307142857142857\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11497\n",
      "  time_since_restore: 0.9799609184265137\n",
      "  time_this_iter_s: 0.9799609184265137\n",
      "  time_total_s: 0.9799609184265137\n",
      "  timestamp: 1630204979\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00030\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 142.9/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/8.0 CPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_10-39-05<br>Number of trials: 36/36 (5 PENDING, 1 RUNNING, 30 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_46e9e_00030</td><td>RUNNING   </td><td>202.117.43.132:11497</td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">1.03071 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.979961</td><td style=\"text-align: right;\">      -1.03071 </td></tr>\n",
       "<tr><td>training_function_46e9e_00031</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00032</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00033</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00034</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00035</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">2.47714 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07803 </td><td style=\"text-align: right;\">      -2.47714 </td></tr>\n",
       "<tr><td>training_function_46e9e_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05641 </td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "<tr><td>training_function_46e9e_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.12111 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.04712 </td><td style=\"text-align: right;\">      -1.12111 </td></tr>\n",
       "<tr><td>training_function_46e9e_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.21766 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.1003  </td><td style=\"text-align: right;\">      -1.21766 </td></tr>\n",
       "<tr><td>training_function_46e9e_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.495   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.08207 </td><td style=\"text-align: right;\">      -1.495   </td></tr>\n",
       "<tr><td>training_function_46e9e_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.02551 </td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "<tr><td>training_function_46e9e_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.4498  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07095 </td><td style=\"text-align: right;\">      -1.4498  </td></tr>\n",
       "<tr><td>training_function_46e9e_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.21766 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05449 </td><td style=\"text-align: right;\">      -1.21766 </td></tr>\n",
       "<tr><td>training_function_46e9e_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">2.60159 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.986076</td><td style=\"text-align: right;\">      -2.60159 </td></tr>\n",
       "<tr><td>training_function_46e9e_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.495   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.01599 </td><td style=\"text-align: right;\">      -1.495   </td></tr>\n",
       "<tr><td>training_function_46e9e_00010</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.26286 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.992365</td><td style=\"text-align: right;\">      -1.26286 </td></tr>\n",
       "<tr><td>training_function_46e9e_00011</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.997205</td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "<tr><td>training_function_46e9e_00012</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">0.888968</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.06648 </td><td style=\"text-align: right;\">      -0.888968</td></tr>\n",
       "<tr><td>training_function_46e9e_00013</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">1.495   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.10477 </td><td style=\"text-align: right;\">      -1.495   </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00030:\n",
      "  date: 2021-08-29_10-42-59\n",
      "  done: true\n",
      "  experiment_id: 44276f11ab6f4cd7aee36d629c7f2fc5\n",
      "  experiment_tag: 30_GAMMA=0.95,THETA=0.0001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.0307142857142857\n",
      "  neg_mean_loss: -1.0307142857142857\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11497\n",
      "  time_since_restore: 0.9799609184265137\n",
      "  time_this_iter_s: 0.9799609184265137\n",
      "  time_total_s: 0.9799609184265137\n",
      "  timestamp: 1630204979\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00030\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11497)\u001b[0m \n",
      "                                                               \u001b[A\n",
      "\u001b[2m\u001b[36m(pid=11495)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=11495)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=11495)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11495)\u001b[0m frac:0.25\n",
      "Result for training_function_46e9e_00031:\n",
      "  date: 2021-08-29_10-43-06\n",
      "  done: false\n",
      "  experiment_id: 1931e398cbd34f8fac0b2960c1caf5b3\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.1211111111111112\n",
      "  neg_mean_loss: -1.1211111111111112\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11495\n",
      "  time_since_restore: 0.974902868270874\n",
      "  time_this_iter_s: 0.974902868270874\n",
      "  time_total_s: 0.974902868270874\n",
      "  timestamp: 1630204986\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00031\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 142.9/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/8.0 CPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/1.0 accelerator_type:V, 0.0/8.0 CPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_b732c446212a2c1cca5ef1dadf7b45e0)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_10-39-05<br>Number of trials: 36/36 (4 PENDING, 1 RUNNING, 31 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">       loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_46e9e_00031</td><td>RUNNING   </td><td>202.117.43.132:11495</td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">   1.12111 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.974903</td><td style=\"text-align: right;\">      -1.12111 </td></tr>\n",
       "<tr><td>training_function_46e9e_00032</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00033</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00034</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00035</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   2.47714 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07803 </td><td style=\"text-align: right;\">      -2.47714 </td></tr>\n",
       "<tr><td>training_function_46e9e_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05641 </td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "<tr><td>training_function_46e9e_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   1.12111 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.04712 </td><td style=\"text-align: right;\">      -1.12111 </td></tr>\n",
       "<tr><td>training_function_46e9e_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   1.21766 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.1003  </td><td style=\"text-align: right;\">      -1.21766 </td></tr>\n",
       "<tr><td>training_function_46e9e_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   1.495   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.08207 </td><td style=\"text-align: right;\">      -1.495   </td></tr>\n",
       "<tr><td>training_function_46e9e_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.02551 </td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "<tr><td>training_function_46e9e_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   1.4498  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07095 </td><td style=\"text-align: right;\">      -1.4498  </td></tr>\n",
       "<tr><td>training_function_46e9e_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   1.21766 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05449 </td><td style=\"text-align: right;\">      -1.21766 </td></tr>\n",
       "<tr><td>training_function_46e9e_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   2.60159 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.986076</td><td style=\"text-align: right;\">      -2.60159 </td></tr>\n",
       "<tr><td>training_function_46e9e_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   1.495   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.01599 </td><td style=\"text-align: right;\">      -1.495   </td></tr>\n",
       "<tr><td>training_function_46e9e_00010</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   1.26286 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.992365</td><td style=\"text-align: right;\">      -1.26286 </td></tr>\n",
       "<tr><td>training_function_46e9e_00011</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.997205</td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "<tr><td>training_function_46e9e_00012</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">   0.888968</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.06648 </td><td style=\"text-align: right;\">      -0.888968</td></tr>\n",
       "<tr><td>training_function_46e9e_00013</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">   1.495   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.10477 </td><td style=\"text-align: right;\">      -1.495   </td></tr>\n",
       "<tr><td>training_function_46e9e_00014</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-inf       </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.0449  </td><td style=\"text-align: right;\">     inf       </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00031:\n",
      "  date: 2021-08-29_10-43-06\n",
      "  done: true\n",
      "  experiment_id: 1931e398cbd34f8fac0b2960c1caf5b3\n",
      "  experiment_tag: 31_GAMMA=0.9,THETA=0.0001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 1.1211111111111112\n",
      "  neg_mean_loss: -1.1211111111111112\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 11495\n",
      "  time_since_restore: 0.974902868270874\n",
      "  time_this_iter_s: 0.974902868270874\n",
      "  time_total_s: 0.974902868270874\n",
      "  timestamp: 1630204986\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00031\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11495)\u001b[0m \n",
      "                                                               \u001b[A\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=27619)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=27619)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=27619)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=27619)\u001b[0m frac:0.20833333333333334\n",
      "Result for training_function_46e9e_00032:\n",
      "  date: 2021-08-29_10-43-14\n",
      "  done: false\n",
      "  experiment_id: 63ea337ed42a4ee1a74a6e7b51cfed48\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 2.87\n",
      "  neg_mean_loss: -2.87\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 27619\n",
      "  time_since_restore: 0.9508011341094971\n",
      "  time_this_iter_s: 0.9508011341094971\n",
      "  time_total_s: 0.9508011341094971\n",
      "  timestamp: 1630204994\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00032\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=27619)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=27619)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 142.9/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/8.0 CPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/1.0 accelerator_type:V, 0.0/8.0 CPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_b732c446212a2c1cca5ef1dadf7b45e0)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_10-39-05<br>Number of trials: 36/36 (3 PENDING, 1 RUNNING, 32 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">       loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_46e9e_00032</td><td>RUNNING   </td><td>202.117.43.132:27619</td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">   2.87    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.950801</td><td style=\"text-align: right;\">      -2.87    </td></tr>\n",
       "<tr><td>training_function_46e9e_00033</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00034</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00035</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   2.47714 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07803 </td><td style=\"text-align: right;\">      -2.47714 </td></tr>\n",
       "<tr><td>training_function_46e9e_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05641 </td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "<tr><td>training_function_46e9e_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   1.12111 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.04712 </td><td style=\"text-align: right;\">      -1.12111 </td></tr>\n",
       "<tr><td>training_function_46e9e_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   1.21766 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.1003  </td><td style=\"text-align: right;\">      -1.21766 </td></tr>\n",
       "<tr><td>training_function_46e9e_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   1.495   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.08207 </td><td style=\"text-align: right;\">      -1.495   </td></tr>\n",
       "<tr><td>training_function_46e9e_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.02551 </td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "<tr><td>training_function_46e9e_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   1.4498  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07095 </td><td style=\"text-align: right;\">      -1.4498  </td></tr>\n",
       "<tr><td>training_function_46e9e_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   1.21766 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05449 </td><td style=\"text-align: right;\">      -1.21766 </td></tr>\n",
       "<tr><td>training_function_46e9e_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   2.60159 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.986076</td><td style=\"text-align: right;\">      -2.60159 </td></tr>\n",
       "<tr><td>training_function_46e9e_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   1.495   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.01599 </td><td style=\"text-align: right;\">      -1.495   </td></tr>\n",
       "<tr><td>training_function_46e9e_00010</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   1.26286 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.992365</td><td style=\"text-align: right;\">      -1.26286 </td></tr>\n",
       "<tr><td>training_function_46e9e_00011</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.997205</td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "<tr><td>training_function_46e9e_00012</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">   0.888968</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.06648 </td><td style=\"text-align: right;\">      -0.888968</td></tr>\n",
       "<tr><td>training_function_46e9e_00013</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">   1.495   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.10477 </td><td style=\"text-align: right;\">      -1.495   </td></tr>\n",
       "<tr><td>training_function_46e9e_00014</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-inf       </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.0449  </td><td style=\"text-align: right;\">     inf       </td></tr>\n",
       "<tr><td>training_function_46e9e_00015</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">   1.495   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.973344</td><td style=\"text-align: right;\">      -1.495   </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00032:\n",
      "  date: 2021-08-29_10-43-14\n",
      "  done: true\n",
      "  experiment_id: 63ea337ed42a4ee1a74a6e7b51cfed48\n",
      "  experiment_tag: 32_GAMMA=0.85,THETA=0.0001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 2.87\n",
      "  neg_mean_loss: -2.87\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 27619\n",
      "  time_since_restore: 0.9508011341094971\n",
      "  time_this_iter_s: 0.9508011341094971\n",
      "  time_total_s: 0.9508011341094971\n",
      "  timestamp: 1630204994\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00032\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=27936)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=27936)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=27936)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=27936)\u001b[0m frac:0.2222222222222222\n",
      "Result for training_function_46e9e_00033:\n",
      "  date: 2021-08-29_10-43-22\n",
      "  done: false\n",
      "  experiment_id: 0f2b5e4df0d74964b9b80399186c57e8\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 2.6015873015873017\n",
      "  neg_mean_loss: -2.6015873015873017\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 27936\n",
      "  time_since_restore: 0.9490818977355957\n",
      "  time_this_iter_s: 0.9490818977355957\n",
      "  time_total_s: 0.9490818977355957\n",
      "  timestamp: 1630205002\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00033\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 142.9/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/8.0 CPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/1.0 accelerator_type:V)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_10-39-05<br>Number of trials: 36/36 (2 PENDING, 1 RUNNING, 33 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">       loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_46e9e_00033</td><td>RUNNING   </td><td>202.117.43.132:27936</td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">   2.60159 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.949082</td><td style=\"text-align: right;\">      -2.60159 </td></tr>\n",
       "<tr><td>training_function_46e9e_00034</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00035</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   2.47714 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07803 </td><td style=\"text-align: right;\">      -2.47714 </td></tr>\n",
       "<tr><td>training_function_46e9e_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05641 </td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "<tr><td>training_function_46e9e_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   1.12111 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.04712 </td><td style=\"text-align: right;\">      -1.12111 </td></tr>\n",
       "<tr><td>training_function_46e9e_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   1.21766 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.1003  </td><td style=\"text-align: right;\">      -1.21766 </td></tr>\n",
       "<tr><td>training_function_46e9e_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   1.495   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.08207 </td><td style=\"text-align: right;\">      -1.495   </td></tr>\n",
       "<tr><td>training_function_46e9e_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.02551 </td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "<tr><td>training_function_46e9e_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   1.4498  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07095 </td><td style=\"text-align: right;\">      -1.4498  </td></tr>\n",
       "<tr><td>training_function_46e9e_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   1.21766 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05449 </td><td style=\"text-align: right;\">      -1.21766 </td></tr>\n",
       "<tr><td>training_function_46e9e_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   2.60159 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.986076</td><td style=\"text-align: right;\">      -2.60159 </td></tr>\n",
       "<tr><td>training_function_46e9e_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   1.495   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.01599 </td><td style=\"text-align: right;\">      -1.495   </td></tr>\n",
       "<tr><td>training_function_46e9e_00010</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   1.26286 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.992365</td><td style=\"text-align: right;\">      -1.26286 </td></tr>\n",
       "<tr><td>training_function_46e9e_00011</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.997205</td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "<tr><td>training_function_46e9e_00012</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">   0.888968</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.06648 </td><td style=\"text-align: right;\">      -0.888968</td></tr>\n",
       "<tr><td>training_function_46e9e_00013</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">   1.495   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.10477 </td><td style=\"text-align: right;\">      -1.495   </td></tr>\n",
       "<tr><td>training_function_46e9e_00014</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-inf       </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.0449  </td><td style=\"text-align: right;\">     inf       </td></tr>\n",
       "<tr><td>training_function_46e9e_00015</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">   1.495   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.973344</td><td style=\"text-align: right;\">      -1.495   </td></tr>\n",
       "<tr><td>training_function_46e9e_00016</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">   1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.998972</td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00033:\n",
      "  date: 2021-08-29_10-43-22\n",
      "  done: true\n",
      "  experiment_id: 0f2b5e4df0d74964b9b80399186c57e8\n",
      "  experiment_tag: 33_GAMMA=0.8,THETA=0.0001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 2.6015873015873017\n",
      "  neg_mean_loss: -2.6015873015873017\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 27936\n",
      "  time_since_restore: 0.9490818977355957\n",
      "  time_this_iter_s: 0.9490818977355957\n",
      "  time_total_s: 0.9490818977355957\n",
      "  timestamp: 1630205002\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00033\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=27936)\u001b[0m \n",
      "                                                               \u001b[A\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=28187)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=28187)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=28187)\u001b[0m frac:0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=28187)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=28187)\u001b[0m \r",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00034:\n",
      "  date: 2021-08-29_10-43-30\n",
      "  done: false\n",
      "  experiment_id: e6b3d338ea7b49d9862e6610abcda395\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 2.726031746031746\n",
      "  neg_mean_loss: -2.726031746031746\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 28187\n",
      "  time_since_restore: 0.9316112995147705\n",
      "  time_this_iter_s: 0.9316112995147705\n",
      "  time_total_s: 0.9316112995147705\n",
      "  timestamp: 1630205010\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00034\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=28187)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=28187)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 142.9/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/8.0 CPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/2.0 GPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/1.0 accelerator_type:V)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_10-39-05<br>Number of trials: 36/36 (1 PENDING, 1 RUNNING, 34 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">       loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_46e9e_00034</td><td>RUNNING   </td><td>202.117.43.132:28187</td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">   2.72603 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.931611</td><td style=\"text-align: right;\">      -2.72603 </td></tr>\n",
       "<tr><td>training_function_46e9e_00035</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_46e9e_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   2.47714 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07803 </td><td style=\"text-align: right;\">      -2.47714 </td></tr>\n",
       "<tr><td>training_function_46e9e_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05641 </td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "<tr><td>training_function_46e9e_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   1.12111 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.04712 </td><td style=\"text-align: right;\">      -1.12111 </td></tr>\n",
       "<tr><td>training_function_46e9e_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   1.21766 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.1003  </td><td style=\"text-align: right;\">      -1.21766 </td></tr>\n",
       "<tr><td>training_function_46e9e_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   1.495   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.08207 </td><td style=\"text-align: right;\">      -1.495   </td></tr>\n",
       "<tr><td>training_function_46e9e_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.02551 </td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "<tr><td>training_function_46e9e_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   1.4498  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07095 </td><td style=\"text-align: right;\">      -1.4498  </td></tr>\n",
       "<tr><td>training_function_46e9e_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   1.21766 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05449 </td><td style=\"text-align: right;\">      -1.21766 </td></tr>\n",
       "<tr><td>training_function_46e9e_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   2.60159 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.986076</td><td style=\"text-align: right;\">      -2.60159 </td></tr>\n",
       "<tr><td>training_function_46e9e_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   1.495   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.01599 </td><td style=\"text-align: right;\">      -1.495   </td></tr>\n",
       "<tr><td>training_function_46e9e_00010</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   1.26286 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.992365</td><td style=\"text-align: right;\">      -1.26286 </td></tr>\n",
       "<tr><td>training_function_46e9e_00011</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.997205</td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "<tr><td>training_function_46e9e_00012</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">   0.888968</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.06648 </td><td style=\"text-align: right;\">      -0.888968</td></tr>\n",
       "<tr><td>training_function_46e9e_00013</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">   1.495   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.10477 </td><td style=\"text-align: right;\">      -1.495   </td></tr>\n",
       "<tr><td>training_function_46e9e_00014</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-inf       </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.0449  </td><td style=\"text-align: right;\">     inf       </td></tr>\n",
       "<tr><td>training_function_46e9e_00015</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">   1.495   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.973344</td><td style=\"text-align: right;\">      -1.495   </td></tr>\n",
       "<tr><td>training_function_46e9e_00016</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">   1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.998972</td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "<tr><td>training_function_46e9e_00017</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">   2.99444 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.960746</td><td style=\"text-align: right;\">      -2.99444 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00034:\n",
      "  date: 2021-08-29_10-43-30\n",
      "  done: true\n",
      "  experiment_id: e6b3d338ea7b49d9862e6610abcda395\n",
      "  experiment_tag: 34_GAMMA=0.7,THETA=0.0001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 2.726031746031746\n",
      "  neg_mean_loss: -2.726031746031746\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 28187\n",
      "  time_since_restore: 0.9316112995147705\n",
      "  time_this_iter_s: 0.9316112995147705\n",
      "  time_total_s: 0.9316112995147705\n",
      "  timestamp: 1630205010\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00034\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=28584)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=28584)\u001b[0m   parser = argparse.ArgumentParser(\n",
      "\u001b[2m\u001b[36m(pid=28584)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=28584)\u001b[0m frac:0.2222222222222222\n",
      "Result for training_function_46e9e_00035:\n",
      "  date: 2021-08-29_10-43-38\n",
      "  done: false\n",
      "  experiment_id: 3eeff242d09f465cac09cc68a3a7c5b2\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.9855158730158731\n",
      "  neg_mean_loss: -0.9855158730158731\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 28584\n",
      "  time_since_restore: 0.9617328643798828\n",
      "  time_this_iter_s: 0.9617328643798828\n",
      "  time_total_s: 0.9617328643798828\n",
      "  timestamp: 1630205018\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00035\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 142.9/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_b732c446212a2c1cca5ef1dadf7b45e0)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_10-39-05<br>Number of trials: 36/36 (1 RUNNING, 35 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">       loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_46e9e_00035</td><td>RUNNING   </td><td>202.117.43.132:28584</td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">   0.985516</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.961733</td><td style=\"text-align: right;\">      -0.985516</td></tr>\n",
       "<tr><td>training_function_46e9e_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   2.47714 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07803 </td><td style=\"text-align: right;\">      -2.47714 </td></tr>\n",
       "<tr><td>training_function_46e9e_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05641 </td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "<tr><td>training_function_46e9e_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   1.12111 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.04712 </td><td style=\"text-align: right;\">      -1.12111 </td></tr>\n",
       "<tr><td>training_function_46e9e_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   1.21766 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.1003  </td><td style=\"text-align: right;\">      -1.21766 </td></tr>\n",
       "<tr><td>training_function_46e9e_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   1.495   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.08207 </td><td style=\"text-align: right;\">      -1.495   </td></tr>\n",
       "<tr><td>training_function_46e9e_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.02551 </td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "<tr><td>training_function_46e9e_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   1.4498  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07095 </td><td style=\"text-align: right;\">      -1.4498  </td></tr>\n",
       "<tr><td>training_function_46e9e_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   1.21766 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05449 </td><td style=\"text-align: right;\">      -1.21766 </td></tr>\n",
       "<tr><td>training_function_46e9e_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   2.60159 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.986076</td><td style=\"text-align: right;\">      -2.60159 </td></tr>\n",
       "<tr><td>training_function_46e9e_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   1.495   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.01599 </td><td style=\"text-align: right;\">      -1.495   </td></tr>\n",
       "<tr><td>training_function_46e9e_00010</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   1.26286 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.992365</td><td style=\"text-align: right;\">      -1.26286 </td></tr>\n",
       "<tr><td>training_function_46e9e_00011</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.997205</td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "<tr><td>training_function_46e9e_00012</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">   0.888968</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.06648 </td><td style=\"text-align: right;\">      -0.888968</td></tr>\n",
       "<tr><td>training_function_46e9e_00013</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">   1.495   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.10477 </td><td style=\"text-align: right;\">      -1.495   </td></tr>\n",
       "<tr><td>training_function_46e9e_00014</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-inf       </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.0449  </td><td style=\"text-align: right;\">     inf       </td></tr>\n",
       "<tr><td>training_function_46e9e_00015</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">   1.495   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.973344</td><td style=\"text-align: right;\">      -1.495   </td></tr>\n",
       "<tr><td>training_function_46e9e_00016</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">   1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.998972</td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "<tr><td>training_function_46e9e_00017</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">   2.99444 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.960746</td><td style=\"text-align: right;\">      -2.99444 </td></tr>\n",
       "<tr><td>training_function_46e9e_00018</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">   1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.955906</td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_46e9e_00035:\n",
      "  date: 2021-08-29_10-43-38\n",
      "  done: true\n",
      "  experiment_id: 3eeff242d09f465cac09cc68a3a7c5b2\n",
      "  experiment_tag: 35_GAMMA=0.6,THETA=0.0001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.9855158730158731\n",
      "  neg_mean_loss: -0.9855158730158731\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 28584\n",
      "  time_since_restore: 0.9617328643798828\n",
      "  time_this_iter_s: 0.9617328643798828\n",
      "  time_total_s: 0.9617328643798828\n",
      "  timestamp: 1630205018\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 46e9e_00035\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=28584)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=28584)\u001b[0m \r",
      "                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 140.4/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/32 CPUs, 0/2 GPUs, 0.0/70.41 GiB heap, 0.0/34.17 GiB objects (0.0/2.0 GPU_group_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_0_b732c446212a2c1cca5ef1dadf7b45e0, 0.0/8.0 CPU_group_b732c446212a2c1cca5ef1dadf7b45e0)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-29_10-39-05<br>Number of trials: 36/36 (36 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">       loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_46e9e_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   2.47714 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07803 </td><td style=\"text-align: right;\">      -2.47714 </td></tr>\n",
       "<tr><td>training_function_46e9e_00001</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05641 </td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "<tr><td>training_function_46e9e_00002</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   1.12111 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.04712 </td><td style=\"text-align: right;\">      -1.12111 </td></tr>\n",
       "<tr><td>training_function_46e9e_00003</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   1.21766 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.1003  </td><td style=\"text-align: right;\">      -1.21766 </td></tr>\n",
       "<tr><td>training_function_46e9e_00004</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   1.495   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.08207 </td><td style=\"text-align: right;\">      -1.495   </td></tr>\n",
       "<tr><td>training_function_46e9e_00005</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">   1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.02551 </td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "<tr><td>training_function_46e9e_00006</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   1.4498  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07095 </td><td style=\"text-align: right;\">      -1.4498  </td></tr>\n",
       "<tr><td>training_function_46e9e_00007</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   1.21766 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.05449 </td><td style=\"text-align: right;\">      -1.21766 </td></tr>\n",
       "<tr><td>training_function_46e9e_00008</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   2.60159 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.986076</td><td style=\"text-align: right;\">      -2.60159 </td></tr>\n",
       "<tr><td>training_function_46e9e_00009</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   1.495   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.01599 </td><td style=\"text-align: right;\">      -1.495   </td></tr>\n",
       "<tr><td>training_function_46e9e_00010</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   1.26286 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.992365</td><td style=\"text-align: right;\">      -1.26286 </td></tr>\n",
       "<tr><td>training_function_46e9e_00011</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">   1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.997205</td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "<tr><td>training_function_46e9e_00012</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">   0.888968</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.06648 </td><td style=\"text-align: right;\">      -0.888968</td></tr>\n",
       "<tr><td>training_function_46e9e_00013</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">   1.495   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.10477 </td><td style=\"text-align: right;\">      -1.495   </td></tr>\n",
       "<tr><td>training_function_46e9e_00014</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-inf       </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.0449  </td><td style=\"text-align: right;\">     inf       </td></tr>\n",
       "<tr><td>training_function_46e9e_00015</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">   1.495   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.973344</td><td style=\"text-align: right;\">      -1.495   </td></tr>\n",
       "<tr><td>training_function_46e9e_00016</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">   1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.998972</td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "<tr><td>training_function_46e9e_00017</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">   2.99444 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.960746</td><td style=\"text-align: right;\">      -2.99444 </td></tr>\n",
       "<tr><td>training_function_46e9e_00018</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">   1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.955906</td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "<tr><td>training_function_46e9e_00019</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">   1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.0176  </td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "<tr><td>training_function_46e9e_00020</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">   2.87    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.01582 </td><td style=\"text-align: right;\">      -2.87    </td></tr>\n",
       "<tr><td>training_function_46e9e_00021</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">   1.26286 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.984649</td><td style=\"text-align: right;\">      -1.26286 </td></tr>\n",
       "<tr><td>training_function_46e9e_00022</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">   1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.972684</td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "<tr><td>training_function_46e9e_00023</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">   1.12111 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.977116</td><td style=\"text-align: right;\">      -1.12111 </td></tr>\n",
       "<tr><td>training_function_46e9e_00024</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">   1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.04005 </td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "<tr><td>training_function_46e9e_00025</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">   1.4046  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.07016 </td><td style=\"text-align: right;\">      -1.4046  </td></tr>\n",
       "<tr><td>training_function_46e9e_00026</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">   1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.979853</td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "<tr><td>training_function_46e9e_00027</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">   1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.00907 </td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "<tr><td>training_function_46e9e_00028</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">   1.21766 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.02244 </td><td style=\"text-align: right;\">      -1.21766 </td></tr>\n",
       "<tr><td>training_function_46e9e_00029</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">   1.30806 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.04069 </td><td style=\"text-align: right;\">      -1.30806 </td></tr>\n",
       "<tr><td>training_function_46e9e_00030</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">   1.03071 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.979961</td><td style=\"text-align: right;\">      -1.03071 </td></tr>\n",
       "<tr><td>training_function_46e9e_00031</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">   1.12111 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.974903</td><td style=\"text-align: right;\">      -1.12111 </td></tr>\n",
       "<tr><td>training_function_46e9e_00032</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">   2.87    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.950801</td><td style=\"text-align: right;\">      -2.87    </td></tr>\n",
       "<tr><td>training_function_46e9e_00033</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">   2.60159 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.949082</td><td style=\"text-align: right;\">      -2.60159 </td></tr>\n",
       "<tr><td>training_function_46e9e_00034</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">   2.72603 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.931611</td><td style=\"text-align: right;\">      -2.72603 </td></tr>\n",
       "<tr><td>training_function_46e9e_00035</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">   0.985516</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.961733</td><td style=\"text-align: right;\">      -0.985516</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-29 10:43:39,922\tINFO tune.py:550 -- Total run time: 274.90 seconds (273.90 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best config:  {'THETA': 0.003, 'GAMMA': 0.95, 'dataset': 'compas', 'train_dataset_s': <torch.utils.data.dataset.Subset object at 0x7f7cb885bac8>, 'val': <torch.utils.data.dataloader.DataLoader object at 0x7f7cb885b358>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f7cb88264e0>, 'x_tensor': tensor([[0.1176, 0.0000, 1.0000,  ..., 0.6667, 0.0000, 0.0000],\n",
      "        [0.2059, 1.0000, 0.0000,  ..., 1.0000, 0.6667, 0.0000],\n",
      "        [0.2353, 0.0000, 1.0000,  ..., 1.0000, 0.3333, 1.0000],\n",
      "        ...,\n",
      "        [0.2941, 1.0000, 0.0000,  ..., 0.3333, 0.3333, 1.0000],\n",
      "        [0.2059, 1.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        [0.1176, 0.0000, 0.0000,  ..., 0.3333, 0.0000, 0.0000]])}\n",
      "2021-08-29 10:43:41,275 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frac:0.1847041847041847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                               \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param selection costs:276.2505269050598 s\n",
      "path analysis costs:1.7441551685333252 s\n",
      "sample separation costs:0.060423851013183594 s\n",
      "partial dropout training costs:2.6956090927124023 s\n",
      "total time costs:280.7680766582489 s\n"
     ]
    }
   ],
   "source": [
    "# credit\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "BATCH_SIZE=128\n",
    "\n",
    "df=pd.read_csv('data/Credit/german_credit',sep=' ')\n",
    "df_binary, Y, S, Y_true = transform_dataset_credit(df)\n",
    "print(np.mean(Y))\n",
    "\n",
    "l_tensor = torch.tensor(Y.reshape(-1, 1).astype(np.float32))\n",
    "x_tensor = torch.tensor(df_binary.to_numpy().astype(np.float32))\n",
    "y_tensor = torch.tensor(Y.reshape(-1, 1).astype(np.float32))\n",
    "s_tensor = torch.tensor(preprocessing.OneHotEncoder().fit_transform(np.array(S).reshape(-1, 1)).toarray())\n",
    "\n",
    "dataset = TensorDataset(x_tensor, y_tensor, l_tensor, s_tensor)  # dataset = CustomDataset(x_tensor, y_tensor)\n",
    "\n",
    "base_size = len(dataset) // 10\n",
    "split = [7 * base_size, 1 * base_size, len(dataset) - 8 * base_size]  # Train, validation, test\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, split)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "x_train_tensor = train_dataset[:][0]\n",
    "y_train_tensor = train_dataset[:][1]\n",
    "l_train_tensor = train_dataset[:][2]\n",
    "s_train_tensor = train_dataset[:][3]\n",
    "\n",
    "global_results = []\n",
    "\n",
    "# get the classification threshold, we use the same scale for compas so 4 instead of 0.5\n",
    "ori_start=time.time()\n",
    "threshold = 0.5\n",
    "\n",
    "net, results = train_and_evaluate(train_loader, val_loader, test_loader, device, input_shape=x_tensor.shape[1],\n",
    "                                    grl_lambda=0,dataset='credit')\n",
    "ori_end=time.time()\n",
    "ori_cost_time=ori_end-ori_start\n",
    "print('time costs:{} s'.format(ori_cost_time))\n",
    "\n",
    "result = get_metrics(results, threshold, 0)\n",
    "global_results.append(result)\n",
    "\n",
    "\n",
    "# EA(net,attack_size=10, iter_num=50)\n",
    "\n",
    "Fixate_with_val(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DP</th>\n",
       "      <th>EO</th>\n",
       "      <th>DP ratio</th>\n",
       "      <th>acc</th>\n",
       "      <th>acc_ci_min</th>\n",
       "      <th>acc_ci_max</th>\n",
       "      <th>f1</th>\n",
       "      <th>acc_high_risk</th>\n",
       "      <th>acc_ci_min_high_risk</th>\n",
       "      <th>acc_ci_max_high_risk</th>\n",
       "      <th>f1_high_risk</th>\n",
       "      <th>adversarial_fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.123297</td>\n",
       "      <td>0.126556</td>\n",
       "      <td>2.120338</td>\n",
       "      <td>0.747265</td>\n",
       "      <td>0.736300</td>\n",
       "      <td>0.758231</td>\n",
       "      <td>0.631801</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007382</td>\n",
       "      <td>0.147948</td>\n",
       "      <td>0.969668</td>\n",
       "      <td>0.674843</td>\n",
       "      <td>0.663023</td>\n",
       "      <td>0.686662</td>\n",
       "      <td>0.556598</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.086705</td>\n",
       "      <td>0.322508</td>\n",
       "      <td>0.359876</td>\n",
       "      <td>0.731190</td>\n",
       "      <td>0.720003</td>\n",
       "      <td>0.742376</td>\n",
       "      <td>0.501468</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.176090</td>\n",
       "      <td>0.059334</td>\n",
       "      <td>2.869724</td>\n",
       "      <td>0.844216</td>\n",
       "      <td>0.835066</td>\n",
       "      <td>0.853367</td>\n",
       "      <td>0.780222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.181129</td>\n",
       "      <td>0.053537</td>\n",
       "      <td>2.811293</td>\n",
       "      <td>0.842890</td>\n",
       "      <td>0.833708</td>\n",
       "      <td>0.852072</td>\n",
       "      <td>0.781413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.182894</td>\n",
       "      <td>0.047922</td>\n",
       "      <td>2.952932</td>\n",
       "      <td>0.840404</td>\n",
       "      <td>0.831164</td>\n",
       "      <td>0.849645</td>\n",
       "      <td>0.776250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.177158</td>\n",
       "      <td>0.043377</td>\n",
       "      <td>2.849877</td>\n",
       "      <td>0.842890</td>\n",
       "      <td>0.833708</td>\n",
       "      <td>0.852072</td>\n",
       "      <td>0.779130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.175198</td>\n",
       "      <td>0.034583</td>\n",
       "      <td>2.724609</td>\n",
       "      <td>0.847696</td>\n",
       "      <td>0.838630</td>\n",
       "      <td>0.856763</td>\n",
       "      <td>0.787318</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.171366</td>\n",
       "      <td>0.056238</td>\n",
       "      <td>2.789402</td>\n",
       "      <td>0.844548</td>\n",
       "      <td>0.835405</td>\n",
       "      <td>0.853690</td>\n",
       "      <td>0.780133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.192203</td>\n",
       "      <td>0.070368</td>\n",
       "      <td>3.087721</td>\n",
       "      <td>0.845210</td>\n",
       "      <td>0.836084</td>\n",
       "      <td>0.854337</td>\n",
       "      <td>0.784536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.173314</td>\n",
       "      <td>0.040379</td>\n",
       "      <td>2.714996</td>\n",
       "      <td>0.841564</td>\n",
       "      <td>0.832351</td>\n",
       "      <td>0.850778</td>\n",
       "      <td>0.778152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.167421</td>\n",
       "      <td>0.058461</td>\n",
       "      <td>2.683115</td>\n",
       "      <td>0.841896</td>\n",
       "      <td>0.832690</td>\n",
       "      <td>0.851102</td>\n",
       "      <td>0.776723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.186728</td>\n",
       "      <td>0.104884</td>\n",
       "      <td>3.178491</td>\n",
       "      <td>0.841399</td>\n",
       "      <td>0.832181</td>\n",
       "      <td>0.850616</td>\n",
       "      <td>0.775850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DP        EO  DP ratio       acc  acc_ci_min  acc_ci_max        f1  \\\n",
       "0   0.123297  0.126556  2.120338  0.747265    0.736300    0.758231  0.631801   \n",
       "1   0.007382  0.147948  0.969668  0.674843    0.663023    0.686662  0.556598   \n",
       "2   0.086705  0.322508  0.359876  0.731190    0.720003    0.742376  0.501468   \n",
       "3   0.176090  0.059334  2.869724  0.844216    0.835066    0.853367  0.780222   \n",
       "4   0.181129  0.053537  2.811293  0.842890    0.833708    0.852072  0.781413   \n",
       "5   0.182894  0.047922  2.952932  0.840404    0.831164    0.849645  0.776250   \n",
       "6   0.177158  0.043377  2.849877  0.842890    0.833708    0.852072  0.779130   \n",
       "7   0.175198  0.034583  2.724609  0.847696    0.838630    0.856763  0.787318   \n",
       "8   0.171366  0.056238  2.789402  0.844548    0.835405    0.853690  0.780133   \n",
       "9   0.192203  0.070368  3.087721  0.845210    0.836084    0.854337  0.784536   \n",
       "10  0.173314  0.040379  2.714996  0.841564    0.832351    0.850778  0.778152   \n",
       "11  0.167421  0.058461  2.683115  0.841896    0.832690    0.851102  0.776723   \n",
       "12  0.186728  0.104884  3.178491  0.841399    0.832181    0.850616  0.775850   \n",
       "\n",
       "    acc_high_risk  acc_ci_min_high_risk  acc_ci_max_high_risk f1_high_risk  \\\n",
       "0             1.0                   1.0                   1.0         None   \n",
       "1             NaN                   NaN                   NaN          NaN   \n",
       "2             NaN                   NaN                   NaN          NaN   \n",
       "3             NaN                   NaN                   NaN          NaN   \n",
       "4             NaN                   NaN                   NaN          NaN   \n",
       "5             NaN                   NaN                   NaN          NaN   \n",
       "6             NaN                   NaN                   NaN          NaN   \n",
       "7             NaN                   NaN                   NaN          NaN   \n",
       "8             NaN                   NaN                   NaN          NaN   \n",
       "9             NaN                   NaN                   NaN          NaN   \n",
       "10            NaN                   NaN                   NaN          NaN   \n",
       "11            NaN                   NaN                   NaN          NaN   \n",
       "12            NaN                   NaN                   NaN          NaN   \n",
       "\n",
       "    adversarial_fraction  \n",
       "0               0.000000  \n",
       "1               0.000474  \n",
       "2               0.000474  \n",
       "3               0.000000  \n",
       "4               0.000000  \n",
       "5               0.000000  \n",
       "6               0.000000  \n",
       "7               0.000000  \n",
       "8               0.000000  \n",
       "9               0.000000  \n",
       "10              0.000000  \n",
       "11              0.000000  \n",
       "12              0.000000  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(global_results)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attack:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:   4%|▍         | 2/50 [00:05<02:00,  2.51s/it, epoch=1, training_loss=683, validation_loss=15.2]\u001b[A\n",
      "Training neural network:  10%|█         | 5/50 [00:12<01:50,  2.45s/it, epoch=4, training_loss=1.51e+3, validation_loss=395]\u001b[A\n",
      "Training neural network:  16%|█▌        | 8/50 [00:19<01:43,  2.46s/it, epoch=7, training_loss=2.7e+3, validation_loss=1.66]\u001b[A\n",
      "Training neural network:  22%|██▏       | 11/50 [00:26<01:33,  2.40s/it, epoch=10, training_loss=1.25e+3, validation_loss=58.5]\u001b[A\n",
      "Training neural network:  28%|██▊       | 14/50 [00:33<01:26,  2.41s/it, epoch=13, training_loss=109, validation_loss=1.2]     \u001b[A\n",
      "Training neural network:  34%|███▍      | 17/50 [00:41<01:19,  2.41s/it, epoch=16, training_loss=5.08e+3, validation_loss=1.82]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:48<01:11,  2.38s/it, epoch=19, training_loss=8.84, validation_loss=0.913]  \u001b[A\n",
      "Training neural network:  46%|████▌     | 23/50 [00:55<01:04,  2.38s/it, epoch=22, training_loss=2.63, validation_loss=0.867]\u001b[A\n",
      "Training neural network:  52%|█████▏    | 26/50 [01:02<00:57,  2.38s/it, epoch=25, training_loss=4.18, validation_loss=1.28] \u001b[A\n",
      "Training neural network:  58%|█████▊    | 29/50 [01:09<00:50,  2.39s/it, epoch=28, training_loss=2.13, validation_loss=0.835]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [01:16<00:42,  2.38s/it, epoch=31, training_loss=3.03, validation_loss=0.777]\u001b[A\n",
      "Training neural network:  70%|███████   | 35/50 [01:23<00:35,  2.39s/it, epoch=34, training_loss=3.16, validation_loss=0.867]\u001b[A\n",
      "Training neural network:  76%|███████▌  | 38/50 [01:30<00:27,  2.28s/it, epoch=37, training_loss=1.43, validation_loss=0.767]\u001b[A\n",
      "Training neural network:  82%|████████▏ | 41/50 [01:36<00:19,  2.20s/it, epoch=40, training_loss=1.44, validation_loss=0.76] \u001b[A\n",
      "Training neural network:  88%|████████▊ | 44/50 [01:41<00:12,  2.06s/it, epoch=43, training_loss=1.47, validation_loss=0.766]\u001b[A\n",
      "Training neural network:  94%|█████████▍| 47/50 [01:46<00:06,  2.01s/it, epoch=46, training_loss=1.48, validation_loss=0.758]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [01:53<00:00,  2.11s/it, epoch=49, training_loss=1.58, validation_loss=0.761]\u001b[A\n",
      "Attack:   0%|          | 0/10 [01:54<?, ?it/s, DP=0.0867, EO=0.323, DP ratio=0.36, acc=0.731, acc_ci_min=0.72, acc_ci_max=0.742, f1=0.501, adversarial_fraction=0.000474]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "attack_done!\n",
      "time costs:1439.961210012436 s\n",
      "time costs:1439.9616725444794 s\n"
     ]
    }
   ],
   "source": [
    "EA(net,attack_size=10, iter_num=50,dataset='census')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3990)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=3990)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3990)\u001b[0m frac:0.2711794019933555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3990)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3990)\u001b[0m \n",
      "Training neural network:  60%|██████    | 30/50 [00:05<00:03,  6.00it/s, epoch=29, training_loss=0.0631, validation_loss=0.116]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3990)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 193.0/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_02729c523de6b6b9cd3cc0e2dcc12fef, 0.0/8.0 CPU_group_02729c523de6b6b9cd3cc0e2dcc12fef, 0.0/8.0 CPU_group_0_02729c523de6b6b9cd3cc0e2dcc12fef, 0.0/2.0 GPU_group_0_02729c523de6b6b9cd3cc0e2dcc12fef)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 35/36 (34 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_2b59d_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_2b59d_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_2b59d_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_2b59d_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_2b59d_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td></tr>\n",
       "<tr><td>training_function_2b59d_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_2b59d_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_2b59d_00008</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_2b59d_00009</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_2b59d_00010</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_2b59d_00011</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td></tr>\n",
       "<tr><td>training_function_2b59d_00012</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_2b59d_00013</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_2b59d_00014</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_2b59d_00015</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_2b59d_00016</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_2b59d_00017</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td></tr>\n",
       "<tr><td>training_function_2b59d_00018</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td></tr>\n",
       "<tr><td>training_function_2b59d_00019</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 15 more trials not shown (15 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-15 23:14:04,695\tWARNING ray_trial_executor.py:713 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00000:\n",
      "  date: 2021-08-15_23-12-40\n",
      "  done: false\n",
      "  experiment_id: 71ae9c66574a455bb5969283f9a1a53f\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.546685171054064\n",
      "  neg_mean_loss: 1.546685171054064\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3990\n",
      "  time_since_restore: 11.353987455368042\n",
      "  time_this_iter_s: 11.353987455368042\n",
      "  time_total_s: 11.353987455368042\n",
      "  timestamp: 1629040360\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00000\n",
      "  \n",
      "Result for training_function_2b59d_00000:\n",
      "  date: 2021-08-15_23-12-40\n",
      "  done: true\n",
      "  experiment_id: 71ae9c66574a455bb5969283f9a1a53f\n",
      "  experiment_tag: 0_GAMMA=0.95,THETA=0.1\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.546685171054064\n",
      "  neg_mean_loss: 1.546685171054064\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3990\n",
      "  time_since_restore: 11.353987455368042\n",
      "  time_this_iter_s: 11.353987455368042\n",
      "  time_total_s: 11.353987455368042\n",
      "  timestamp: 1629040360\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 192.4/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/2.0 GPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/1.0 accelerator_type:V, 0.0/8.0 CPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_e3bd4c59f2d91b181c5149fd09a4afa3)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 36/36 (34 PENDING, 1 RUNNING, 1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00001</td><td>RUNNING   </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00002</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00003</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00004</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00005</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00006</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00007</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00008</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00009</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00010</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00011</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00012</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00013</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00014</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00015</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00016</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00017</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00018</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00019</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.54669</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">          11.354</td><td style=\"text-align: right;\">        1.54669</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3925)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=3925)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3925)\u001b[0m frac:0.2691029900332226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3925)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=3925)\u001b[0m \r",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 193.0/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 36/36 (34 PENDING, 1 RUNNING, 1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00001</td><td>RUNNING   </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00002</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00003</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00004</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00005</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00006</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00007</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00008</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00009</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00010</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00011</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00012</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00013</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00014</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00015</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00016</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00017</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00018</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00019</td><td>PENDING   </td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.54669</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">          11.354</td><td style=\"text-align: right;\">        1.54669</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3925)\u001b[0m \n",
      "Training neural network:  64%|██████▍   | 32/50 [00:05<00:02,  6.33it/s, epoch=31, training_loss=0.0782, validation_loss=0.119]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3925)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00001:\n",
      "  date: 2021-08-15_23-14-22\n",
      "  done: false\n",
      "  experiment_id: 72183e4ece5342ddbe140d5de56a4925\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -0.9450451774067407\n",
      "  neg_mean_loss: 0.9450451774067407\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3925\n",
      "  time_since_restore: 11.009065628051758\n",
      "  time_this_iter_s: 11.009065628051758\n",
      "  time_total_s: 11.009065628051758\n",
      "  timestamp: 1629040462\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 193.0/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 36/36 (34 PENDING, 1 RUNNING, 1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00001</td><td>RUNNING   </td><td>202.117.43.132:3925</td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-0.945045</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.0091</td><td style=\"text-align: right;\">       0.945045</td></tr>\n",
       "<tr><td>training_function_2b59d_00002</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00003</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00004</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00005</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00006</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00007</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00008</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00009</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00010</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00011</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00012</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00013</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00014</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00015</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00016</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00017</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00018</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00019</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.54669 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.354 </td><td style=\"text-align: right;\">       1.54669 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00001:\n",
      "  date: 2021-08-15_23-14-22\n",
      "  done: true\n",
      "  experiment_id: 72183e4ece5342ddbe140d5de56a4925\n",
      "  experiment_tag: 1_GAMMA=0.9,THETA=0.1\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -0.9450451774067407\n",
      "  neg_mean_loss: 0.9450451774067407\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3925\n",
      "  time_since_restore: 11.009065628051758\n",
      "  time_this_iter_s: 11.009065628051758\n",
      "  time_total_s: 11.009065628051758\n",
      "  timestamp: 1629040462\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00001\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3946)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=3946)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3946)\u001b[0m frac:0.27782392026578073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3946)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3946)\u001b[0m \n",
      "Training neural network:  64%|██████▍   | 32/50 [00:05<00:02,  6.27it/s, epoch=31, training_loss=0.0798, validation_loss=0.126]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3946)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00002:\n",
      "  date: 2021-08-15_23-14-39\n",
      "  done: false\n",
      "  experiment_id: 975d0afc3fbc49ab95417a8a47777367\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.2041039260685025\n",
      "  neg_mean_loss: 1.2041039260685025\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3946\n",
      "  time_since_restore: 10.570286750793457\n",
      "  time_this_iter_s: 10.570286750793457\n",
      "  time_total_s: 10.570286750793457\n",
      "  timestamp: 1629040479\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00002\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 193.1/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 36/36 (33 PENDING, 1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00002</td><td>RUNNING   </td><td>202.117.43.132:3946</td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.2041  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5703</td><td style=\"text-align: right;\">       1.2041  </td></tr>\n",
       "<tr><td>training_function_2b59d_00003</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00004</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00005</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00006</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00007</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00008</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00009</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00010</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00011</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00012</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00013</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00014</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00015</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00016</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00017</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00018</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00019</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.54669 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.354 </td><td style=\"text-align: right;\">       1.54669 </td></tr>\n",
       "<tr><td>training_function_2b59d_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-0.945045</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.0091</td><td style=\"text-align: right;\">       0.945045</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00002:\n",
      "  date: 2021-08-15_23-14-39\n",
      "  done: true\n",
      "  experiment_id: 975d0afc3fbc49ab95417a8a47777367\n",
      "  experiment_tag: 2_GAMMA=0.85,THETA=0.1\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.2041039260685025\n",
      "  neg_mean_loss: 1.2041039260685025\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3946\n",
      "  time_since_restore: 10.570286750793457\n",
      "  time_this_iter_s: 10.570286750793457\n",
      "  time_total_s: 10.570286750793457\n",
      "  timestamp: 1629040479\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00002\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-15 23:14:40,318\tWARNING util.py:164 -- The `start_trial` operation took 0.512 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=3975)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=3975)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3975)\u001b[0m frac:0.2865448504983389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3975)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3975)\u001b[0m \n",
      "Training neural network:  62%|██████▏   | 31/50 [00:05<00:03,  6.01it/s, epoch=30, training_loss=0.0776, validation_loss=0.123]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3975)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00003:\n",
      "  date: 2021-08-15_23-14-57\n",
      "  done: false\n",
      "  experiment_id: 133a6fde792348f48144132b8135c12d\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.7395810649719443\n",
      "  neg_mean_loss: 1.7395810649719443\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3975\n",
      "  time_since_restore: 11.576780796051025\n",
      "  time_this_iter_s: 11.576780796051025\n",
      "  time_total_s: 11.576780796051025\n",
      "  timestamp: 1629040497\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00003\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 193.0/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/1.0 accelerator_type:V, 0.0/8.0 CPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_e3bd4c59f2d91b181c5149fd09a4afa3)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 36/36 (32 PENDING, 1 RUNNING, 3 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00003</td><td>RUNNING   </td><td>202.117.43.132:3975</td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.73958 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.5768</td><td style=\"text-align: right;\">       1.73958 </td></tr>\n",
       "<tr><td>training_function_2b59d_00004</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00005</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00006</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00007</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00008</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00009</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00010</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00011</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00012</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00013</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00014</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00015</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00016</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00017</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00018</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00019</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.54669 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.354 </td><td style=\"text-align: right;\">       1.54669 </td></tr>\n",
       "<tr><td>training_function_2b59d_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-0.945045</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.0091</td><td style=\"text-align: right;\">       0.945045</td></tr>\n",
       "<tr><td>training_function_2b59d_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.2041  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5703</td><td style=\"text-align: right;\">       1.2041  </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00003:\n",
      "  date: 2021-08-15_23-14-57\n",
      "  done: true\n",
      "  experiment_id: 133a6fde792348f48144132b8135c12d\n",
      "  experiment_tag: 3_GAMMA=0.8,THETA=0.1\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.7395810649719443\n",
      "  neg_mean_loss: 1.7395810649719443\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3975\n",
      "  time_since_restore: 11.576780796051025\n",
      "  time_this_iter_s: 11.576780796051025\n",
      "  time_total_s: 11.576780796051025\n",
      "  timestamp: 1629040497\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00003\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3973)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=3973)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3973)\u001b[0m frac:0.2911129568106312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3973)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3973)\u001b[0m \n",
      "Training neural network:  58%|█████▊    | 29/50 [00:05<00:03,  5.77it/s, epoch=28, training_loss=0.0643, validation_loss=0.123]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3973)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00004:\n",
      "  date: 2021-08-15_23-15-16\n",
      "  done: false\n",
      "  experiment_id: 0884fd8aa0b94cf5821014f107214e6b\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.4037532680855158\n",
      "  neg_mean_loss: 1.4037532680855158\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3973\n",
      "  time_since_restore: 12.041970252990723\n",
      "  time_this_iter_s: 12.041970252990723\n",
      "  time_total_s: 12.041970252990723\n",
      "  timestamp: 1629040516\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00004\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 193.1/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/8.0 CPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/1.0 accelerator_type:V, 0.0/8.0 CPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 36/36 (31 PENDING, 1 RUNNING, 4 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00004</td><td>RUNNING   </td><td>202.117.43.132:3973</td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.40375 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.042 </td><td style=\"text-align: right;\">       1.40375 </td></tr>\n",
       "<tr><td>training_function_2b59d_00005</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00006</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00007</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00008</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00009</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00010</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00011</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00012</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00013</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00014</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00015</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00016</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00017</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00018</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00019</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.54669 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.354 </td><td style=\"text-align: right;\">       1.54669 </td></tr>\n",
       "<tr><td>training_function_2b59d_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-0.945045</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.0091</td><td style=\"text-align: right;\">       0.945045</td></tr>\n",
       "<tr><td>training_function_2b59d_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.2041  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5703</td><td style=\"text-align: right;\">       1.2041  </td></tr>\n",
       "<tr><td>training_function_2b59d_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.73958 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.5768</td><td style=\"text-align: right;\">       1.73958 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00004:\n",
      "  date: 2021-08-15_23-15-16\n",
      "  done: true\n",
      "  experiment_id: 0884fd8aa0b94cf5821014f107214e6b\n",
      "  experiment_tag: 4_GAMMA=0.7,THETA=0.1\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.4037532680855158\n",
      "  neg_mean_loss: 1.4037532680855158\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3973\n",
      "  time_since_restore: 12.041970252990723\n",
      "  time_this_iter_s: 12.041970252990723\n",
      "  time_total_s: 12.041970252990723\n",
      "  timestamp: 1629040516\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00004\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3961)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=3961)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3961)\u001b[0m frac:0.27159468438538203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3961)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3961)\u001b[0m \n",
      "Training neural network:  64%|██████▍   | 32/50 [00:05<00:02,  6.32it/s, epoch=31, training_loss=0.0556, validation_loss=0.124]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3961)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00005:\n",
      "  date: 2021-08-15_23-15-34\n",
      "  done: false\n",
      "  experiment_id: b24035fdd1c8460fa1a60ec237dd39b9\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.6524269157371765\n",
      "  neg_mean_loss: 1.6524269157371765\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3961\n",
      "  time_since_restore: 11.22634744644165\n",
      "  time_this_iter_s: 11.22634744644165\n",
      "  time_total_s: 11.22634744644165\n",
      "  timestamp: 1629040534\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00005\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 193.0/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/1.0 accelerator_type:V, 0.0/8.0 CPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 36/36 (30 PENDING, 1 RUNNING, 5 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00005</td><td>RUNNING   </td><td>202.117.43.132:3961</td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.65243 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2263</td><td style=\"text-align: right;\">       1.65243 </td></tr>\n",
       "<tr><td>training_function_2b59d_00006</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00007</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00008</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00009</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00010</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00011</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00012</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00013</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00014</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00015</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00016</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00017</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00018</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00019</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.54669 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.354 </td><td style=\"text-align: right;\">       1.54669 </td></tr>\n",
       "<tr><td>training_function_2b59d_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-0.945045</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.0091</td><td style=\"text-align: right;\">       0.945045</td></tr>\n",
       "<tr><td>training_function_2b59d_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.2041  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5703</td><td style=\"text-align: right;\">       1.2041  </td></tr>\n",
       "<tr><td>training_function_2b59d_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.73958 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.5768</td><td style=\"text-align: right;\">       1.73958 </td></tr>\n",
       "<tr><td>training_function_2b59d_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.40375 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.042 </td><td style=\"text-align: right;\">       1.40375 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00005:\n",
      "  date: 2021-08-15_23-15-34\n",
      "  done: true\n",
      "  experiment_id: b24035fdd1c8460fa1a60ec237dd39b9\n",
      "  experiment_tag: 5_GAMMA=0.6,THETA=0.1\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.6524269157371765\n",
      "  neg_mean_loss: 1.6524269157371765\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3961\n",
      "  time_since_restore: 11.22634744644165\n",
      "  time_this_iter_s: 11.22634744644165\n",
      "  time_total_s: 11.22634744644165\n",
      "  timestamp: 1629040534\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00005\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3964)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=3964)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3964)\u001b[0m frac:0.04318936877076412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3964)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3964)\u001b[0m \n",
      "Training neural network:  70%|███████   | 35/50 [00:05<00:02,  6.78it/s, epoch=34, training_loss=0.0513, validation_loss=0.13]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3964)\u001b[0m \n",
      "                                                                                                                              \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00006:\n",
      "  date: 2021-08-15_23-15-51\n",
      "  done: false\n",
      "  experiment_id: c92cbd24c06b4d8487ae112d9430679a\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.290615678205255\n",
      "  neg_mean_loss: 1.290615678205255\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3964\n",
      "  time_since_restore: 10.572830438613892\n",
      "  time_this_iter_s: 10.572830438613892\n",
      "  time_total_s: 10.572830438613892\n",
      "  timestamp: 1629040551\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00006\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 193.0/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/8.0 CPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/1.0 accelerator_type:V)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 36/36 (29 PENDING, 1 RUNNING, 6 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00006</td><td>RUNNING   </td><td>202.117.43.132:3964</td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-1.29062 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5728</td><td style=\"text-align: right;\">       1.29062 </td></tr>\n",
       "<tr><td>training_function_2b59d_00007</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00008</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00009</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00010</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00011</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00012</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00013</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00014</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00015</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00016</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00017</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00018</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00019</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.54669 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.354 </td><td style=\"text-align: right;\">       1.54669 </td></tr>\n",
       "<tr><td>training_function_2b59d_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-0.945045</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.0091</td><td style=\"text-align: right;\">       0.945045</td></tr>\n",
       "<tr><td>training_function_2b59d_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.2041  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5703</td><td style=\"text-align: right;\">       1.2041  </td></tr>\n",
       "<tr><td>training_function_2b59d_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.73958 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.5768</td><td style=\"text-align: right;\">       1.73958 </td></tr>\n",
       "<tr><td>training_function_2b59d_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.40375 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.042 </td><td style=\"text-align: right;\">       1.40375 </td></tr>\n",
       "<tr><td>training_function_2b59d_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.65243 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2263</td><td style=\"text-align: right;\">       1.65243 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00006:\n",
      "  date: 2021-08-15_23-15-51\n",
      "  done: true\n",
      "  experiment_id: c92cbd24c06b4d8487ae112d9430679a\n",
      "  experiment_tag: 6_GAMMA=0.95,THETA=0.01\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.290615678205255\n",
      "  neg_mean_loss: 1.290615678205255\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3964\n",
      "  time_since_restore: 10.572830438613892\n",
      "  time_this_iter_s: 10.572830438613892\n",
      "  time_total_s: 10.572830438613892\n",
      "  timestamp: 1629040551\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00006\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3982)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=3982)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3982)\u001b[0m frac:0.049003322259136214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3982)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3982)\u001b[0m \n",
      "Training neural network:  66%|██████▌   | 33/50 [00:05<00:02,  6.46it/s, epoch=32, training_loss=0.0769, validation_loss=0.126]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3982)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00007:\n",
      "  date: 2021-08-15_23-16-09\n",
      "  done: false\n",
      "  experiment_id: d7a5077daa8e47d4b49114d05a49e3ae\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -0.8569942529977604\n",
      "  neg_mean_loss: 0.8569942529977604\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3982\n",
      "  time_since_restore: 11.24129343032837\n",
      "  time_this_iter_s: 11.24129343032837\n",
      "  time_total_s: 11.24129343032837\n",
      "  timestamp: 1629040569\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00007\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 193.1/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/8.0 CPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/1.0 accelerator_type:V, 0.0/8.0 CPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 36/36 (28 PENDING, 1 RUNNING, 7 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00007</td><td>RUNNING   </td><td>202.117.43.132:3982</td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-0.856994</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2413</td><td style=\"text-align: right;\">       0.856994</td></tr>\n",
       "<tr><td>training_function_2b59d_00008</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00009</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00010</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00011</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00012</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00013</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00014</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00015</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00016</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00017</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00018</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00019</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.54669 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.354 </td><td style=\"text-align: right;\">       1.54669 </td></tr>\n",
       "<tr><td>training_function_2b59d_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-0.945045</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.0091</td><td style=\"text-align: right;\">       0.945045</td></tr>\n",
       "<tr><td>training_function_2b59d_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.2041  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5703</td><td style=\"text-align: right;\">       1.2041  </td></tr>\n",
       "<tr><td>training_function_2b59d_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.73958 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.5768</td><td style=\"text-align: right;\">       1.73958 </td></tr>\n",
       "<tr><td>training_function_2b59d_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.40375 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.042 </td><td style=\"text-align: right;\">       1.40375 </td></tr>\n",
       "<tr><td>training_function_2b59d_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.65243 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2263</td><td style=\"text-align: right;\">       1.65243 </td></tr>\n",
       "<tr><td>training_function_2b59d_00006</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-1.29062 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5728</td><td style=\"text-align: right;\">       1.29062 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00007:\n",
      "  date: 2021-08-15_23-16-09\n",
      "  done: true\n",
      "  experiment_id: d7a5077daa8e47d4b49114d05a49e3ae\n",
      "  experiment_tag: 7_GAMMA=0.9,THETA=0.01\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -0.8569942529977604\n",
      "  neg_mean_loss: 0.8569942529977604\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3982\n",
      "  time_since_restore: 11.24129343032837\n",
      "  time_this_iter_s: 11.24129343032837\n",
      "  time_total_s: 11.24129343032837\n",
      "  timestamp: 1629040569\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00007\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3933)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=3933)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3933)\u001b[0m frac:0.042774086378737544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3933)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3933)\u001b[0m \n",
      "Training neural network:  60%|██████    | 30/50 [00:05<00:03,  5.83it/s, epoch=29, training_loss=0.058, validation_loss=0.122]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3933)\u001b[0m \n",
      "                                                                                                                              \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00008:\n",
      "  date: 2021-08-15_23-16-28\n",
      "  done: false\n",
      "  experiment_id: 907ffa0e28264c11bf838fa9bbad2854\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -2.758651742755977\n",
      "  neg_mean_loss: 2.758651742755977\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3933\n",
      "  time_since_restore: 12.319682121276855\n",
      "  time_this_iter_s: 12.319682121276855\n",
      "  time_total_s: 12.319682121276855\n",
      "  timestamp: 1629040588\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00008\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 193.1/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/2.0 GPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_e3bd4c59f2d91b181c5149fd09a4afa3)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 36/36 (27 PENDING, 1 RUNNING, 8 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00008</td><td>RUNNING   </td><td>202.117.43.132:3933</td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-2.75865 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3197</td><td style=\"text-align: right;\">       2.75865 </td></tr>\n",
       "<tr><td>training_function_2b59d_00009</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00010</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00011</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00012</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00013</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00014</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00015</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00016</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00017</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00018</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00019</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.54669 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.354 </td><td style=\"text-align: right;\">       1.54669 </td></tr>\n",
       "<tr><td>training_function_2b59d_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-0.945045</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.0091</td><td style=\"text-align: right;\">       0.945045</td></tr>\n",
       "<tr><td>training_function_2b59d_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.2041  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5703</td><td style=\"text-align: right;\">       1.2041  </td></tr>\n",
       "<tr><td>training_function_2b59d_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.73958 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.5768</td><td style=\"text-align: right;\">       1.73958 </td></tr>\n",
       "<tr><td>training_function_2b59d_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.40375 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.042 </td><td style=\"text-align: right;\">       1.40375 </td></tr>\n",
       "<tr><td>training_function_2b59d_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.65243 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2263</td><td style=\"text-align: right;\">       1.65243 </td></tr>\n",
       "<tr><td>training_function_2b59d_00006</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-1.29062 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5728</td><td style=\"text-align: right;\">       1.29062 </td></tr>\n",
       "<tr><td>training_function_2b59d_00007</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-0.856994</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2413</td><td style=\"text-align: right;\">       0.856994</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00008:\n",
      "  date: 2021-08-15_23-16-28\n",
      "  done: true\n",
      "  experiment_id: 907ffa0e28264c11bf838fa9bbad2854\n",
      "  experiment_tag: 8_GAMMA=0.85,THETA=0.01\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -2.758651742755977\n",
      "  neg_mean_loss: 2.758651742755977\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3933\n",
      "  time_since_restore: 12.319682121276855\n",
      "  time_this_iter_s: 12.319682121276855\n",
      "  time_total_s: 12.319682121276855\n",
      "  timestamp: 1629040588\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00008\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3983)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=3983)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3983)\u001b[0m frac:0.044850498338870434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3983)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3983)\u001b[0m \n",
      "Training neural network:  62%|██████▏   | 31/50 [00:05<00:03,  6.11it/s, epoch=30, training_loss=0.0684, validation_loss=0.134]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3983)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00009:\n",
      "  date: 2021-08-15_23-16-46\n",
      "  done: false\n",
      "  experiment_id: 5a2477cf5e9141959186404ea3967e80\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -2.4138271559240616\n",
      "  neg_mean_loss: 2.4138271559240616\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3983\n",
      "  time_since_restore: 11.76058578491211\n",
      "  time_this_iter_s: 11.76058578491211\n",
      "  time_total_s: 11.76058578491211\n",
      "  timestamp: 1629040606\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00009\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 193.0/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/8.0 CPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/1.0 accelerator_type:V, 0.0/8.0 CPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 36/36 (26 PENDING, 1 RUNNING, 9 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00009</td><td>RUNNING   </td><td>202.117.43.132:3983</td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-2.41383 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.7606</td><td style=\"text-align: right;\">       2.41383 </td></tr>\n",
       "<tr><td>training_function_2b59d_00010</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00011</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00012</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00013</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00014</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00015</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00016</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00017</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00018</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00019</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.54669 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.354 </td><td style=\"text-align: right;\">       1.54669 </td></tr>\n",
       "<tr><td>training_function_2b59d_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-0.945045</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.0091</td><td style=\"text-align: right;\">       0.945045</td></tr>\n",
       "<tr><td>training_function_2b59d_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.2041  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5703</td><td style=\"text-align: right;\">       1.2041  </td></tr>\n",
       "<tr><td>training_function_2b59d_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.73958 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.5768</td><td style=\"text-align: right;\">       1.73958 </td></tr>\n",
       "<tr><td>training_function_2b59d_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.40375 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.042 </td><td style=\"text-align: right;\">       1.40375 </td></tr>\n",
       "<tr><td>training_function_2b59d_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.65243 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2263</td><td style=\"text-align: right;\">       1.65243 </td></tr>\n",
       "<tr><td>training_function_2b59d_00006</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-1.29062 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5728</td><td style=\"text-align: right;\">       1.29062 </td></tr>\n",
       "<tr><td>training_function_2b59d_00007</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-0.856994</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2413</td><td style=\"text-align: right;\">       0.856994</td></tr>\n",
       "<tr><td>training_function_2b59d_00008</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-2.75865 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3197</td><td style=\"text-align: right;\">       2.75865 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00009:\n",
      "  date: 2021-08-15_23-16-46\n",
      "  done: true\n",
      "  experiment_id: 5a2477cf5e9141959186404ea3967e80\n",
      "  experiment_tag: 9_GAMMA=0.8,THETA=0.01\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -2.4138271559240616\n",
      "  neg_mean_loss: 2.4138271559240616\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3983\n",
      "  time_since_restore: 11.76058578491211\n",
      "  time_this_iter_s: 11.76058578491211\n",
      "  time_total_s: 11.76058578491211\n",
      "  timestamp: 1629040606\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00009\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3939)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=3939)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3939)\u001b[0m frac:0.04443521594684385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3939)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3939)\u001b[0m \n",
      "Training neural network:  64%|██████▍   | 32/50 [00:05<00:02,  6.22it/s, epoch=31, training_loss=0.0572, validation_loss=0.134]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3939)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00010:\n",
      "  date: 2021-08-15_23-17-04\n",
      "  done: false\n",
      "  experiment_id: 5f3d1687c3e84f6fb0c6ca1184389ff2\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.5487984676380437\n",
      "  neg_mean_loss: 1.5487984676380437\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3939\n",
      "  time_since_restore: 11.403700113296509\n",
      "  time_this_iter_s: 11.403700113296509\n",
      "  time_total_s: 11.403700113296509\n",
      "  timestamp: 1629040624\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00010\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 193.1/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/1.0 accelerator_type:V, 0.0/8.0 CPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 36/36 (25 PENDING, 1 RUNNING, 10 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00010</td><td>RUNNING   </td><td>202.117.43.132:3939</td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-1.5488  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.4037</td><td style=\"text-align: right;\">       1.5488  </td></tr>\n",
       "<tr><td>training_function_2b59d_00011</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00012</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00013</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00014</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00015</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00016</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00017</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00018</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00019</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00020</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.54669 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.354 </td><td style=\"text-align: right;\">       1.54669 </td></tr>\n",
       "<tr><td>training_function_2b59d_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-0.945045</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.0091</td><td style=\"text-align: right;\">       0.945045</td></tr>\n",
       "<tr><td>training_function_2b59d_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.2041  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5703</td><td style=\"text-align: right;\">       1.2041  </td></tr>\n",
       "<tr><td>training_function_2b59d_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.73958 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.5768</td><td style=\"text-align: right;\">       1.73958 </td></tr>\n",
       "<tr><td>training_function_2b59d_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.40375 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.042 </td><td style=\"text-align: right;\">       1.40375 </td></tr>\n",
       "<tr><td>training_function_2b59d_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.65243 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2263</td><td style=\"text-align: right;\">       1.65243 </td></tr>\n",
       "<tr><td>training_function_2b59d_00006</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-1.29062 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5728</td><td style=\"text-align: right;\">       1.29062 </td></tr>\n",
       "<tr><td>training_function_2b59d_00007</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-0.856994</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2413</td><td style=\"text-align: right;\">       0.856994</td></tr>\n",
       "<tr><td>training_function_2b59d_00008</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-2.75865 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3197</td><td style=\"text-align: right;\">       2.75865 </td></tr>\n",
       "<tr><td>training_function_2b59d_00009</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-2.41383 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.7606</td><td style=\"text-align: right;\">       2.41383 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (15 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00010:\n",
      "  date: 2021-08-15_23-17-04\n",
      "  done: true\n",
      "  experiment_id: 5f3d1687c3e84f6fb0c6ca1184389ff2\n",
      "  experiment_tag: 10_GAMMA=0.7,THETA=0.01\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.5487984676380437\n",
      "  neg_mean_loss: 1.5487984676380437\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3939\n",
      "  time_since_restore: 11.403700113296509\n",
      "  time_this_iter_s: 11.403700113296509\n",
      "  time_total_s: 11.403700113296509\n",
      "  timestamp: 1629040624\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00010\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3927)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=3927)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3927)\u001b[0m frac:0.044850498338870434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3927)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3927)\u001b[0m \n",
      "Training neural network:  46%|████▌     | 23/50 [00:05<00:06,  4.39it/s, epoch=22, training_loss=0.0608, validation_loss=0.129]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3927)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00011:\n",
      "  date: 2021-08-15_23-17-27\n",
      "  done: false\n",
      "  experiment_id: ce08ed53b3e14c1189b082c4c6513ca3\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -2.2239510022867104\n",
      "  neg_mean_loss: 2.2239510022867104\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3927\n",
      "  time_since_restore: 15.178611755371094\n",
      "  time_this_iter_s: 15.178611755371094\n",
      "  time_total_s: 15.178611755371094\n",
      "  timestamp: 1629040647\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00011\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 193.4/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/1.0 accelerator_type:V, 0.0/8.0 CPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 36/36 (24 PENDING, 1 RUNNING, 11 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00011</td><td>RUNNING   </td><td>202.117.43.132:3927</td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-2.22395 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1786</td><td style=\"text-align: right;\">       2.22395 </td></tr>\n",
       "<tr><td>training_function_2b59d_00012</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00013</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00014</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00015</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00016</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00017</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00018</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00019</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00020</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00021</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.54669 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.354 </td><td style=\"text-align: right;\">       1.54669 </td></tr>\n",
       "<tr><td>training_function_2b59d_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-0.945045</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.0091</td><td style=\"text-align: right;\">       0.945045</td></tr>\n",
       "<tr><td>training_function_2b59d_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.2041  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5703</td><td style=\"text-align: right;\">       1.2041  </td></tr>\n",
       "<tr><td>training_function_2b59d_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.73958 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.5768</td><td style=\"text-align: right;\">       1.73958 </td></tr>\n",
       "<tr><td>training_function_2b59d_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.40375 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.042 </td><td style=\"text-align: right;\">       1.40375 </td></tr>\n",
       "<tr><td>training_function_2b59d_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.65243 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2263</td><td style=\"text-align: right;\">       1.65243 </td></tr>\n",
       "<tr><td>training_function_2b59d_00006</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-1.29062 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5728</td><td style=\"text-align: right;\">       1.29062 </td></tr>\n",
       "<tr><td>training_function_2b59d_00007</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-0.856994</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2413</td><td style=\"text-align: right;\">       0.856994</td></tr>\n",
       "<tr><td>training_function_2b59d_00008</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-2.75865 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3197</td><td style=\"text-align: right;\">       2.75865 </td></tr>\n",
       "<tr><td>training_function_2b59d_00009</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-2.41383 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.7606</td><td style=\"text-align: right;\">       2.41383 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (14 PENDING, 1 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00011:\n",
      "  date: 2021-08-15_23-17-27\n",
      "  done: true\n",
      "  experiment_id: ce08ed53b3e14c1189b082c4c6513ca3\n",
      "  experiment_tag: 11_GAMMA=0.6,THETA=0.01\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -2.2239510022867104\n",
      "  neg_mean_loss: 2.2239510022867104\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3927\n",
      "  time_since_restore: 15.178611755371094\n",
      "  time_this_iter_s: 15.178611755371094\n",
      "  time_total_s: 15.178611755371094\n",
      "  timestamp: 1629040647\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00011\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3959)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=3959)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3959)\u001b[0m frac:0.02159468438538206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3959)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3959)\u001b[0m \n",
      "Training neural network:  66%|██████▌   | 33/50 [00:05<00:02,  6.45it/s, epoch=32, training_loss=0.0639, validation_loss=0.127]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3959)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00012:\n",
      "  date: 2021-08-15_23-17-45\n",
      "  done: false\n",
      "  experiment_id: 756cd95e3d11471aae3a798d6edf43c4\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -0.9965748976864611\n",
      "  neg_mean_loss: 0.9965748976864611\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3959\n",
      "  time_since_restore: 11.617405891418457\n",
      "  time_this_iter_s: 11.617405891418457\n",
      "  time_total_s: 11.617405891418457\n",
      "  timestamp: 1629040665\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00012\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 193.4/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/2.0 GPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/1.0 accelerator_type:V, 0.0/8.0 CPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_e3bd4c59f2d91b181c5149fd09a4afa3)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 36/36 (23 PENDING, 1 RUNNING, 12 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00012</td><td>RUNNING   </td><td>202.117.43.132:3959</td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">-0.996575</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.6174</td><td style=\"text-align: right;\">       0.996575</td></tr>\n",
       "<tr><td>training_function_2b59d_00013</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00014</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00015</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00016</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00017</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00018</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00019</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00020</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00021</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00022</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.54669 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.354 </td><td style=\"text-align: right;\">       1.54669 </td></tr>\n",
       "<tr><td>training_function_2b59d_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-0.945045</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.0091</td><td style=\"text-align: right;\">       0.945045</td></tr>\n",
       "<tr><td>training_function_2b59d_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.2041  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5703</td><td style=\"text-align: right;\">       1.2041  </td></tr>\n",
       "<tr><td>training_function_2b59d_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.73958 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.5768</td><td style=\"text-align: right;\">       1.73958 </td></tr>\n",
       "<tr><td>training_function_2b59d_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.40375 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.042 </td><td style=\"text-align: right;\">       1.40375 </td></tr>\n",
       "<tr><td>training_function_2b59d_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.65243 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2263</td><td style=\"text-align: right;\">       1.65243 </td></tr>\n",
       "<tr><td>training_function_2b59d_00006</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-1.29062 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5728</td><td style=\"text-align: right;\">       1.29062 </td></tr>\n",
       "<tr><td>training_function_2b59d_00007</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-0.856994</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2413</td><td style=\"text-align: right;\">       0.856994</td></tr>\n",
       "<tr><td>training_function_2b59d_00008</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-2.75865 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3197</td><td style=\"text-align: right;\">       2.75865 </td></tr>\n",
       "<tr><td>training_function_2b59d_00009</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-2.41383 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.7606</td><td style=\"text-align: right;\">       2.41383 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (13 PENDING, 2 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00012:\n",
      "  date: 2021-08-15_23-17-45\n",
      "  done: true\n",
      "  experiment_id: 756cd95e3d11471aae3a798d6edf43c4\n",
      "  experiment_tag: 12_GAMMA=0.95,THETA=0.003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -0.9965748976864611\n",
      "  neg_mean_loss: 0.9965748976864611\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3959\n",
      "  time_since_restore: 11.617405891418457\n",
      "  time_this_iter_s: 11.617405891418457\n",
      "  time_total_s: 11.617405891418457\n",
      "  timestamp: 1629040665\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00012\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3932)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=3932)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3932)\u001b[0m frac:0.01910299003322259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3932)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3932)\u001b[0m \n",
      "Training neural network:  62%|██████▏   | 31/50 [00:05<00:03,  6.10it/s, epoch=30, training_loss=0.0615, validation_loss=0.117]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3932)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00013:\n",
      "  date: 2021-08-15_23-18-03\n",
      "  done: false\n",
      "  experiment_id: d6a28478380440d29ead1181f2c0a202\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.151164058525622\n",
      "  neg_mean_loss: 1.151164058525622\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3932\n",
      "  time_since_restore: 11.264608144760132\n",
      "  time_this_iter_s: 11.264608144760132\n",
      "  time_total_s: 11.264608144760132\n",
      "  timestamp: 1629040683\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00013\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 192.8/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 36/36 (22 PENDING, 1 RUNNING, 13 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00013</td><td>RUNNING   </td><td>202.117.43.132:3932</td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">-1.15116 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2646</td><td style=\"text-align: right;\">       1.15116 </td></tr>\n",
       "<tr><td>training_function_2b59d_00014</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00015</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00016</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00017</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00018</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00019</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00020</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00021</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00022</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00023</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.54669 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.354 </td><td style=\"text-align: right;\">       1.54669 </td></tr>\n",
       "<tr><td>training_function_2b59d_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-0.945045</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.0091</td><td style=\"text-align: right;\">       0.945045</td></tr>\n",
       "<tr><td>training_function_2b59d_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.2041  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5703</td><td style=\"text-align: right;\">       1.2041  </td></tr>\n",
       "<tr><td>training_function_2b59d_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.73958 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.5768</td><td style=\"text-align: right;\">       1.73958 </td></tr>\n",
       "<tr><td>training_function_2b59d_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.40375 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.042 </td><td style=\"text-align: right;\">       1.40375 </td></tr>\n",
       "<tr><td>training_function_2b59d_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">-1.65243 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2263</td><td style=\"text-align: right;\">       1.65243 </td></tr>\n",
       "<tr><td>training_function_2b59d_00006</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-1.29062 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5728</td><td style=\"text-align: right;\">       1.29062 </td></tr>\n",
       "<tr><td>training_function_2b59d_00007</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-0.856994</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2413</td><td style=\"text-align: right;\">       0.856994</td></tr>\n",
       "<tr><td>training_function_2b59d_00008</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-2.75865 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3197</td><td style=\"text-align: right;\">       2.75865 </td></tr>\n",
       "<tr><td>training_function_2b59d_00009</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">  0.01 </td><td style=\"text-align: right;\">-2.41383 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.7606</td><td style=\"text-align: right;\">       2.41383 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (12 PENDING, 3 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00013:\n",
      "  date: 2021-08-15_23-18-03\n",
      "  done: true\n",
      "  experiment_id: d6a28478380440d29ead1181f2c0a202\n",
      "  experiment_tag: 13_GAMMA=0.9,THETA=0.003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.151164058525622\n",
      "  neg_mean_loss: 1.151164058525622\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3932\n",
      "  time_since_restore: 11.264608144760132\n",
      "  time_this_iter_s: 11.264608144760132\n",
      "  time_total_s: 11.264608144760132\n",
      "  timestamp: 1629040683\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00013\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=4000)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=4000)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=4000)\u001b[0m frac:0.020764119601328904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=4000)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=4000)\u001b[0m \n",
      "Training neural network:  60%|██████    | 30/50 [00:05<00:03,  5.89it/s, epoch=29, training_loss=0.0625, validation_loss=0.121]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=4000)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00014:\n",
      "  date: 2021-08-15_23-18-21\n",
      "  done: false\n",
      "  experiment_id: 862ac148a1e844c195229c4ffaec431e\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -0.9363318336567524\n",
      "  neg_mean_loss: 0.9363318336567524\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 4000\n",
      "  time_since_restore: 11.854262351989746\n",
      "  time_this_iter_s: 11.854262351989746\n",
      "  time_total_s: 11.854262351989746\n",
      "  timestamp: 1629040701\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00014\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 192.8/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/2.0 GPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/1.0 accelerator_type:V, 0.0/8.0 CPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_e3bd4c59f2d91b181c5149fd09a4afa3)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 36/36 (21 PENDING, 1 RUNNING, 14 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00014</td><td>RUNNING   </td><td>202.117.43.132:4000</td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-0.936332</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.8543</td><td style=\"text-align: right;\">       0.936332</td></tr>\n",
       "<tr><td>training_function_2b59d_00015</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00016</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00017</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00018</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00019</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00020</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00021</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00022</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00023</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00024</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.54669 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.354 </td><td style=\"text-align: right;\">       1.54669 </td></tr>\n",
       "<tr><td>training_function_2b59d_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-0.945045</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.0091</td><td style=\"text-align: right;\">       0.945045</td></tr>\n",
       "<tr><td>training_function_2b59d_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.2041  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5703</td><td style=\"text-align: right;\">       1.2041  </td></tr>\n",
       "<tr><td>training_function_2b59d_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.73958 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.5768</td><td style=\"text-align: right;\">       1.73958 </td></tr>\n",
       "<tr><td>training_function_2b59d_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.40375 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.042 </td><td style=\"text-align: right;\">       1.40375 </td></tr>\n",
       "<tr><td>training_function_2b59d_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.65243 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2263</td><td style=\"text-align: right;\">       1.65243 </td></tr>\n",
       "<tr><td>training_function_2b59d_00006</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.29062 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5728</td><td style=\"text-align: right;\">       1.29062 </td></tr>\n",
       "<tr><td>training_function_2b59d_00007</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.856994</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2413</td><td style=\"text-align: right;\">       0.856994</td></tr>\n",
       "<tr><td>training_function_2b59d_00008</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.75865 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3197</td><td style=\"text-align: right;\">       2.75865 </td></tr>\n",
       "<tr><td>training_function_2b59d_00009</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.41383 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.7606</td><td style=\"text-align: right;\">       2.41383 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (11 PENDING, 4 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00014:\n",
      "  date: 2021-08-15_23-18-21\n",
      "  done: true\n",
      "  experiment_id: 862ac148a1e844c195229c4ffaec431e\n",
      "  experiment_tag: 14_GAMMA=0.85,THETA=0.003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -0.9363318336567524\n",
      "  neg_mean_loss: 0.9363318336567524\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 4000\n",
      "  time_since_restore: 11.854262351989746\n",
      "  time_this_iter_s: 11.854262351989746\n",
      "  time_total_s: 11.854262351989746\n",
      "  timestamp: 1629040701\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00014\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3986)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=3986)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3986)\u001b[0m frac:0.019933554817275746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3986)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3986)\u001b[0m \n",
      "Training neural network:  58%|█████▊    | 29/50 [00:05<00:03,  5.80it/s, epoch=28, training_loss=0.0695, validation_loss=0.127]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3986)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00015:\n",
      "  date: 2021-08-15_23-18-40\n",
      "  done: false\n",
      "  experiment_id: 53401d55098348d98f3ace65abbebe1a\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.1497539112624617\n",
      "  neg_mean_loss: 1.1497539112624617\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3986\n",
      "  time_since_restore: 12.121771574020386\n",
      "  time_this_iter_s: 12.121771574020386\n",
      "  time_total_s: 12.121771574020386\n",
      "  timestamp: 1629040720\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00015\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 192.8/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/8.0 CPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/1.0 accelerator_type:V, 0.0/8.0 CPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 36/36 (20 PENDING, 1 RUNNING, 15 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00015</td><td>RUNNING   </td><td>202.117.43.132:3986</td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.14975 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1218</td><td style=\"text-align: right;\">       1.14975 </td></tr>\n",
       "<tr><td>training_function_2b59d_00016</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00017</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00018</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00019</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00020</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00021</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00022</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00023</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00024</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00025</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.54669 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.354 </td><td style=\"text-align: right;\">       1.54669 </td></tr>\n",
       "<tr><td>training_function_2b59d_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-0.945045</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.0091</td><td style=\"text-align: right;\">       0.945045</td></tr>\n",
       "<tr><td>training_function_2b59d_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.2041  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5703</td><td style=\"text-align: right;\">       1.2041  </td></tr>\n",
       "<tr><td>training_function_2b59d_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.73958 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.5768</td><td style=\"text-align: right;\">       1.73958 </td></tr>\n",
       "<tr><td>training_function_2b59d_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.40375 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.042 </td><td style=\"text-align: right;\">       1.40375 </td></tr>\n",
       "<tr><td>training_function_2b59d_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.65243 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2263</td><td style=\"text-align: right;\">       1.65243 </td></tr>\n",
       "<tr><td>training_function_2b59d_00006</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.29062 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5728</td><td style=\"text-align: right;\">       1.29062 </td></tr>\n",
       "<tr><td>training_function_2b59d_00007</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.856994</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2413</td><td style=\"text-align: right;\">       0.856994</td></tr>\n",
       "<tr><td>training_function_2b59d_00008</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.75865 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3197</td><td style=\"text-align: right;\">       2.75865 </td></tr>\n",
       "<tr><td>training_function_2b59d_00009</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.41383 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.7606</td><td style=\"text-align: right;\">       2.41383 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (10 PENDING, 5 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00015:\n",
      "  date: 2021-08-15_23-18-40\n",
      "  done: true\n",
      "  experiment_id: 53401d55098348d98f3ace65abbebe1a\n",
      "  experiment_tag: 15_GAMMA=0.8,THETA=0.003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.1497539112624617\n",
      "  neg_mean_loss: 1.1497539112624617\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3986\n",
      "  time_since_restore: 12.121771574020386\n",
      "  time_this_iter_s: 12.121771574020386\n",
      "  time_total_s: 12.121771574020386\n",
      "  timestamp: 1629040720\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00015\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3950)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=3950)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3950)\u001b[0m frac:0.02159468438538206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3950)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3950)\u001b[0m \n",
      "Training neural network:  56%|█████▌    | 28/50 [00:05<00:04,  5.50it/s, epoch=27, training_loss=0.064, validation_loss=0.125]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3950)\u001b[0m \n",
      "                                                                                                                              \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00016:\n",
      "  date: 2021-08-15_23-18-58\n",
      "  done: false\n",
      "  experiment_id: f3576b8092754185bfa73cb60b95185a\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.1145865650364837\n",
      "  neg_mean_loss: 1.1145865650364837\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3950\n",
      "  time_since_restore: 12.166290283203125\n",
      "  time_this_iter_s: 12.166290283203125\n",
      "  time_total_s: 12.166290283203125\n",
      "  timestamp: 1629040738\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00016\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 192.8/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/2.0 GPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/1.0 accelerator_type:V, 0.0/8.0 CPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_e3bd4c59f2d91b181c5149fd09a4afa3)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 36/36 (19 PENDING, 1 RUNNING, 16 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00016</td><td>RUNNING   </td><td>202.117.43.132:3950</td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.11459 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1663</td><td style=\"text-align: right;\">       1.11459 </td></tr>\n",
       "<tr><td>training_function_2b59d_00017</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00018</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00019</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00020</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00021</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00022</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00023</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00024</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00025</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00026</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.54669 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.354 </td><td style=\"text-align: right;\">       1.54669 </td></tr>\n",
       "<tr><td>training_function_2b59d_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-0.945045</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.0091</td><td style=\"text-align: right;\">       0.945045</td></tr>\n",
       "<tr><td>training_function_2b59d_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.2041  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5703</td><td style=\"text-align: right;\">       1.2041  </td></tr>\n",
       "<tr><td>training_function_2b59d_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.73958 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.5768</td><td style=\"text-align: right;\">       1.73958 </td></tr>\n",
       "<tr><td>training_function_2b59d_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.40375 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.042 </td><td style=\"text-align: right;\">       1.40375 </td></tr>\n",
       "<tr><td>training_function_2b59d_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.65243 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2263</td><td style=\"text-align: right;\">       1.65243 </td></tr>\n",
       "<tr><td>training_function_2b59d_00006</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.29062 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5728</td><td style=\"text-align: right;\">       1.29062 </td></tr>\n",
       "<tr><td>training_function_2b59d_00007</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.856994</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2413</td><td style=\"text-align: right;\">       0.856994</td></tr>\n",
       "<tr><td>training_function_2b59d_00008</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.75865 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3197</td><td style=\"text-align: right;\">       2.75865 </td></tr>\n",
       "<tr><td>training_function_2b59d_00009</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.41383 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.7606</td><td style=\"text-align: right;\">       2.41383 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (9 PENDING, 6 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00016:\n",
      "  date: 2021-08-15_23-18-58\n",
      "  done: true\n",
      "  experiment_id: f3576b8092754185bfa73cb60b95185a\n",
      "  experiment_tag: 16_GAMMA=0.7,THETA=0.003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.1145865650364837\n",
      "  neg_mean_loss: 1.1145865650364837\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3950\n",
      "  time_since_restore: 12.166290283203125\n",
      "  time_this_iter_s: 12.166290283203125\n",
      "  time_total_s: 12.166290283203125\n",
      "  timestamp: 1629040738\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00016\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3940)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=3940)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3940)\u001b[0m frac:0.015365448504983389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3940)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3940)\u001b[0m \n",
      "Training neural network:  60%|██████    | 30/50 [00:05<00:03,  5.86it/s, epoch=29, training_loss=0.0698, validation_loss=0.119]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3940)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00017:\n",
      "  date: 2021-08-15_23-19-16\n",
      "  done: false\n",
      "  experiment_id: ed4a744e794f433db25d102841d2be1d\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -0.7493895102364158\n",
      "  neg_mean_loss: 0.7493895102364158\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3940\n",
      "  time_since_restore: 11.891430377960205\n",
      "  time_this_iter_s: 11.891430377960205\n",
      "  time_total_s: 11.891430377960205\n",
      "  timestamp: 1629040756\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00017\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 192.8/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/8.0 CPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_e3bd4c59f2d91b181c5149fd09a4afa3)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 36/36 (18 PENDING, 1 RUNNING, 17 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00017</td><td>RUNNING   </td><td>202.117.43.132:3940</td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-0.74939 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.8914</td><td style=\"text-align: right;\">       0.74939 </td></tr>\n",
       "<tr><td>training_function_2b59d_00018</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00019</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00020</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00021</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00022</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00023</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00024</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00025</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00026</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00027</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.54669 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.354 </td><td style=\"text-align: right;\">       1.54669 </td></tr>\n",
       "<tr><td>training_function_2b59d_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-0.945045</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.0091</td><td style=\"text-align: right;\">       0.945045</td></tr>\n",
       "<tr><td>training_function_2b59d_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.2041  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5703</td><td style=\"text-align: right;\">       1.2041  </td></tr>\n",
       "<tr><td>training_function_2b59d_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.73958 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.5768</td><td style=\"text-align: right;\">       1.73958 </td></tr>\n",
       "<tr><td>training_function_2b59d_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.40375 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.042 </td><td style=\"text-align: right;\">       1.40375 </td></tr>\n",
       "<tr><td>training_function_2b59d_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.65243 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2263</td><td style=\"text-align: right;\">       1.65243 </td></tr>\n",
       "<tr><td>training_function_2b59d_00006</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.29062 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5728</td><td style=\"text-align: right;\">       1.29062 </td></tr>\n",
       "<tr><td>training_function_2b59d_00007</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.856994</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2413</td><td style=\"text-align: right;\">       0.856994</td></tr>\n",
       "<tr><td>training_function_2b59d_00008</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.75865 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3197</td><td style=\"text-align: right;\">       2.75865 </td></tr>\n",
       "<tr><td>training_function_2b59d_00009</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.41383 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.7606</td><td style=\"text-align: right;\">       2.41383 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (8 PENDING, 7 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00017:\n",
      "  date: 2021-08-15_23-19-16\n",
      "  done: true\n",
      "  experiment_id: ed4a744e794f433db25d102841d2be1d\n",
      "  experiment_tag: 17_GAMMA=0.6,THETA=0.003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -0.7493895102364158\n",
      "  neg_mean_loss: 0.7493895102364158\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3940\n",
      "  time_since_restore: 11.891430377960205\n",
      "  time_this_iter_s: 11.891430377960205\n",
      "  time_total_s: 11.891430377960205\n",
      "  timestamp: 1629040756\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00017\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3924)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=3924)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3924)\u001b[0m frac:0.020348837209302327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3924)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3924)\u001b[0m \n",
      "Training neural network:  56%|█████▌    | 28/50 [00:05<00:03,  5.60it/s, epoch=27, training_loss=0.0701, validation_loss=0.13]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3924)\u001b[0m \n",
      "                                                                                                                              \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00018:\n",
      "  date: 2021-08-15_23-19-35\n",
      "  done: false\n",
      "  experiment_id: bc44d8dfb15647cba5dbf72e7def8ab6\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -0.9494097609773505\n",
      "  neg_mean_loss: 0.9494097609773505\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3924\n",
      "  time_since_restore: 12.247200012207031\n",
      "  time_this_iter_s: 12.247200012207031\n",
      "  time_total_s: 12.247200012207031\n",
      "  timestamp: 1629040775\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00018\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 192.7/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 36/36 (17 PENDING, 1 RUNNING, 18 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00018</td><td>RUNNING   </td><td>202.117.43.132:3924</td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">-0.94941 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.2472</td><td style=\"text-align: right;\">       0.94941 </td></tr>\n",
       "<tr><td>training_function_2b59d_00019</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00020</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00021</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00022</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00023</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00024</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00025</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00026</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00027</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00028</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.54669 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.354 </td><td style=\"text-align: right;\">       1.54669 </td></tr>\n",
       "<tr><td>training_function_2b59d_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-0.945045</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.0091</td><td style=\"text-align: right;\">       0.945045</td></tr>\n",
       "<tr><td>training_function_2b59d_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.2041  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5703</td><td style=\"text-align: right;\">       1.2041  </td></tr>\n",
       "<tr><td>training_function_2b59d_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.73958 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.5768</td><td style=\"text-align: right;\">       1.73958 </td></tr>\n",
       "<tr><td>training_function_2b59d_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.40375 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.042 </td><td style=\"text-align: right;\">       1.40375 </td></tr>\n",
       "<tr><td>training_function_2b59d_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.65243 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2263</td><td style=\"text-align: right;\">       1.65243 </td></tr>\n",
       "<tr><td>training_function_2b59d_00006</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.29062 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5728</td><td style=\"text-align: right;\">       1.29062 </td></tr>\n",
       "<tr><td>training_function_2b59d_00007</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.856994</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2413</td><td style=\"text-align: right;\">       0.856994</td></tr>\n",
       "<tr><td>training_function_2b59d_00008</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.75865 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3197</td><td style=\"text-align: right;\">       2.75865 </td></tr>\n",
       "<tr><td>training_function_2b59d_00009</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.41383 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.7606</td><td style=\"text-align: right;\">       2.41383 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (7 PENDING, 8 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00018:\n",
      "  date: 2021-08-15_23-19-35\n",
      "  done: true\n",
      "  experiment_id: bc44d8dfb15647cba5dbf72e7def8ab6\n",
      "  experiment_tag: 18_GAMMA=0.95,THETA=0.001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -0.9494097609773505\n",
      "  neg_mean_loss: 0.9494097609773505\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3924\n",
      "  time_since_restore: 12.247200012207031\n",
      "  time_this_iter_s: 12.247200012207031\n",
      "  time_total_s: 12.247200012207031\n",
      "  timestamp: 1629040775\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00018\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3918)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=3918)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3918)\u001b[0m frac:0.018687707641196014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3918)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3918)\u001b[0m \n",
      "Training neural network:  68%|██████▊   | 34/50 [00:05<00:02,  6.67it/s, epoch=33, training_loss=0.0666, validation_loss=0.143]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3918)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00019:\n",
      "  date: 2021-08-15_23-19-53\n",
      "  done: false\n",
      "  experiment_id: 33aea093f56c4b3fb105520e90271442\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.0247774207195404\n",
      "  neg_mean_loss: 1.0247774207195404\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3918\n",
      "  time_since_restore: 11.294758558273315\n",
      "  time_this_iter_s: 11.294758558273315\n",
      "  time_total_s: 11.294758558273315\n",
      "  timestamp: 1629040793\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00019\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 192.7/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/1.0 accelerator_type:V, 0.0/8.0 CPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 36/36 (16 PENDING, 1 RUNNING, 19 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00019</td><td>RUNNING   </td><td>202.117.43.132:3918</td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">-1.02478 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2948</td><td style=\"text-align: right;\">       1.02478 </td></tr>\n",
       "<tr><td>training_function_2b59d_00020</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00021</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00022</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00023</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00024</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00025</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00026</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00027</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00028</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00029</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.54669 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.354 </td><td style=\"text-align: right;\">       1.54669 </td></tr>\n",
       "<tr><td>training_function_2b59d_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-0.945045</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.0091</td><td style=\"text-align: right;\">       0.945045</td></tr>\n",
       "<tr><td>training_function_2b59d_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.2041  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5703</td><td style=\"text-align: right;\">       1.2041  </td></tr>\n",
       "<tr><td>training_function_2b59d_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.73958 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.5768</td><td style=\"text-align: right;\">       1.73958 </td></tr>\n",
       "<tr><td>training_function_2b59d_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.40375 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.042 </td><td style=\"text-align: right;\">       1.40375 </td></tr>\n",
       "<tr><td>training_function_2b59d_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.65243 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2263</td><td style=\"text-align: right;\">       1.65243 </td></tr>\n",
       "<tr><td>training_function_2b59d_00006</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.29062 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5728</td><td style=\"text-align: right;\">       1.29062 </td></tr>\n",
       "<tr><td>training_function_2b59d_00007</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.856994</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2413</td><td style=\"text-align: right;\">       0.856994</td></tr>\n",
       "<tr><td>training_function_2b59d_00008</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.75865 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3197</td><td style=\"text-align: right;\">       2.75865 </td></tr>\n",
       "<tr><td>training_function_2b59d_00009</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.41383 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.7606</td><td style=\"text-align: right;\">       2.41383 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (6 PENDING, 9 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00019:\n",
      "  date: 2021-08-15_23-19-53\n",
      "  done: true\n",
      "  experiment_id: 33aea093f56c4b3fb105520e90271442\n",
      "  experiment_tag: 19_GAMMA=0.9,THETA=0.001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.0247774207195404\n",
      "  neg_mean_loss: 1.0247774207195404\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3918\n",
      "  time_since_restore: 11.294758558273315\n",
      "  time_this_iter_s: 11.294758558273315\n",
      "  time_total_s: 11.294758558273315\n",
      "  timestamp: 1629040793\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00019\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3919)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=3919)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3919)\u001b[0m frac:0.018272425249169437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3919)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3919)\u001b[0m \n",
      "Training neural network:  64%|██████▍   | 32/50 [00:05<00:02,  6.24it/s, epoch=31, training_loss=0.0496, validation_loss=0.125]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3919)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00020:\n",
      "  date: 2021-08-15_23-20-11\n",
      "  done: false\n",
      "  experiment_id: 6e300138470a40e59054a5acbfe0295e\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.0160582659079278\n",
      "  neg_mean_loss: 1.0160582659079278\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3919\n",
      "  time_since_restore: 11.160614967346191\n",
      "  time_this_iter_s: 11.160614967346191\n",
      "  time_total_s: 11.160614967346191\n",
      "  timestamp: 1629040811\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00020\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 192.7/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/1.0 accelerator_type:V, 0.0/8.0 CPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_e3bd4c59f2d91b181c5149fd09a4afa3)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 36/36 (15 PENDING, 1 RUNNING, 20 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00020</td><td>RUNNING   </td><td>202.117.43.132:3919</td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">-1.01606 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.1606</td><td style=\"text-align: right;\">       1.01606 </td></tr>\n",
       "<tr><td>training_function_2b59d_00021</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00022</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00023</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00024</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00025</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00026</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00027</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00028</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00029</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00030</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.54669 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.354 </td><td style=\"text-align: right;\">       1.54669 </td></tr>\n",
       "<tr><td>training_function_2b59d_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-0.945045</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.0091</td><td style=\"text-align: right;\">       0.945045</td></tr>\n",
       "<tr><td>training_function_2b59d_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.2041  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5703</td><td style=\"text-align: right;\">       1.2041  </td></tr>\n",
       "<tr><td>training_function_2b59d_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.73958 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.5768</td><td style=\"text-align: right;\">       1.73958 </td></tr>\n",
       "<tr><td>training_function_2b59d_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.40375 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.042 </td><td style=\"text-align: right;\">       1.40375 </td></tr>\n",
       "<tr><td>training_function_2b59d_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.65243 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2263</td><td style=\"text-align: right;\">       1.65243 </td></tr>\n",
       "<tr><td>training_function_2b59d_00006</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.29062 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5728</td><td style=\"text-align: right;\">       1.29062 </td></tr>\n",
       "<tr><td>training_function_2b59d_00007</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.856994</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2413</td><td style=\"text-align: right;\">       0.856994</td></tr>\n",
       "<tr><td>training_function_2b59d_00008</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.75865 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3197</td><td style=\"text-align: right;\">       2.75865 </td></tr>\n",
       "<tr><td>training_function_2b59d_00009</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.41383 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.7606</td><td style=\"text-align: right;\">       2.41383 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (5 PENDING, 10 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00020:\n",
      "  date: 2021-08-15_23-20-11\n",
      "  done: true\n",
      "  experiment_id: 6e300138470a40e59054a5acbfe0295e\n",
      "  experiment_tag: 20_GAMMA=0.85,THETA=0.001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.0160582659079278\n",
      "  neg_mean_loss: 1.0160582659079278\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3919\n",
      "  time_since_restore: 11.160614967346191\n",
      "  time_this_iter_s: 11.160614967346191\n",
      "  time_total_s: 11.160614967346191\n",
      "  timestamp: 1629040811\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00020\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3926)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=3926)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3926)\u001b[0m frac:0.018687707641196014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3926)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3926)\u001b[0m \n",
      "Training neural network:  62%|██████▏   | 31/50 [00:05<00:03,  6.20it/s, epoch=30, training_loss=0.0714, validation_loss=0.118]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3926)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00021:\n",
      "  date: 2021-08-15_23-20-28\n",
      "  done: false\n",
      "  experiment_id: 193f1603c6884caa8ed9c3ca74845928\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.319664143312352\n",
      "  neg_mean_loss: 1.319664143312352\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3926\n",
      "  time_since_restore: 11.341264486312866\n",
      "  time_this_iter_s: 11.341264486312866\n",
      "  time_total_s: 11.341264486312866\n",
      "  timestamp: 1629040828\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00021\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 192.7/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/8.0 CPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_e3bd4c59f2d91b181c5149fd09a4afa3)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 36/36 (14 PENDING, 1 RUNNING, 21 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00021</td><td>RUNNING   </td><td>202.117.43.132:3926</td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">-1.31966 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.3413</td><td style=\"text-align: right;\">       1.31966 </td></tr>\n",
       "<tr><td>training_function_2b59d_00022</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00023</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00024</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00025</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00026</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00027</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00028</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00029</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00030</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00031</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.54669 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.354 </td><td style=\"text-align: right;\">       1.54669 </td></tr>\n",
       "<tr><td>training_function_2b59d_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-0.945045</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.0091</td><td style=\"text-align: right;\">       0.945045</td></tr>\n",
       "<tr><td>training_function_2b59d_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.2041  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5703</td><td style=\"text-align: right;\">       1.2041  </td></tr>\n",
       "<tr><td>training_function_2b59d_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.73958 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.5768</td><td style=\"text-align: right;\">       1.73958 </td></tr>\n",
       "<tr><td>training_function_2b59d_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.40375 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.042 </td><td style=\"text-align: right;\">       1.40375 </td></tr>\n",
       "<tr><td>training_function_2b59d_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.65243 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2263</td><td style=\"text-align: right;\">       1.65243 </td></tr>\n",
       "<tr><td>training_function_2b59d_00006</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.29062 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5728</td><td style=\"text-align: right;\">       1.29062 </td></tr>\n",
       "<tr><td>training_function_2b59d_00007</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.856994</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2413</td><td style=\"text-align: right;\">       0.856994</td></tr>\n",
       "<tr><td>training_function_2b59d_00008</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.75865 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3197</td><td style=\"text-align: right;\">       2.75865 </td></tr>\n",
       "<tr><td>training_function_2b59d_00009</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.41383 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.7606</td><td style=\"text-align: right;\">       2.41383 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (4 PENDING, 11 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00021:\n",
      "  date: 2021-08-15_23-20-28\n",
      "  done: true\n",
      "  experiment_id: 193f1603c6884caa8ed9c3ca74845928\n",
      "  experiment_tag: 21_GAMMA=0.8,THETA=0.001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.319664143312352\n",
      "  neg_mean_loss: 1.319664143312352\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3926\n",
      "  time_since_restore: 11.341264486312866\n",
      "  time_this_iter_s: 11.341264486312866\n",
      "  time_total_s: 11.341264486312866\n",
      "  timestamp: 1629040828\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00021\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3922)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=3922)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3922)\u001b[0m frac:0.01744186046511628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3922)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3922)\u001b[0m \n",
      "Training neural network:  64%|██████▍   | 32/50 [00:05<00:02,  6.28it/s, epoch=31, training_loss=0.077, validation_loss=0.114]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3922)\u001b[0m \n",
      "                                                                                                                              \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00022:\n",
      "  date: 2021-08-15_23-20-47\n",
      "  done: false\n",
      "  experiment_id: aa5b6bae20ea4d71ba6d558ef3887424\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -0.9205385738735776\n",
      "  neg_mean_loss: 0.9205385738735776\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3922\n",
      "  time_since_restore: 11.47895097732544\n",
      "  time_this_iter_s: 11.47895097732544\n",
      "  time_total_s: 11.47895097732544\n",
      "  timestamp: 1629040847\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00022\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 192.7/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/8.0 CPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 36/36 (13 PENDING, 1 RUNNING, 22 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00022</td><td>RUNNING   </td><td>202.117.43.132:3922</td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">-0.920539</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.479 </td><td style=\"text-align: right;\">       0.920539</td></tr>\n",
       "<tr><td>training_function_2b59d_00023</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00024</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00025</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00026</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00027</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00028</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00029</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00030</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00031</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00032</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.54669 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.354 </td><td style=\"text-align: right;\">       1.54669 </td></tr>\n",
       "<tr><td>training_function_2b59d_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-0.945045</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.0091</td><td style=\"text-align: right;\">       0.945045</td></tr>\n",
       "<tr><td>training_function_2b59d_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.2041  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5703</td><td style=\"text-align: right;\">       1.2041  </td></tr>\n",
       "<tr><td>training_function_2b59d_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.73958 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.5768</td><td style=\"text-align: right;\">       1.73958 </td></tr>\n",
       "<tr><td>training_function_2b59d_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.40375 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.042 </td><td style=\"text-align: right;\">       1.40375 </td></tr>\n",
       "<tr><td>training_function_2b59d_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.65243 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2263</td><td style=\"text-align: right;\">       1.65243 </td></tr>\n",
       "<tr><td>training_function_2b59d_00006</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.29062 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5728</td><td style=\"text-align: right;\">       1.29062 </td></tr>\n",
       "<tr><td>training_function_2b59d_00007</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.856994</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2413</td><td style=\"text-align: right;\">       0.856994</td></tr>\n",
       "<tr><td>training_function_2b59d_00008</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.75865 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3197</td><td style=\"text-align: right;\">       2.75865 </td></tr>\n",
       "<tr><td>training_function_2b59d_00009</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.41383 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.7606</td><td style=\"text-align: right;\">       2.41383 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (3 PENDING, 12 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00022:\n",
      "  date: 2021-08-15_23-20-47\n",
      "  done: true\n",
      "  experiment_id: aa5b6bae20ea4d71ba6d558ef3887424\n",
      "  experiment_tag: 22_GAMMA=0.7,THETA=0.001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -0.9205385738735776\n",
      "  neg_mean_loss: 0.9205385738735776\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3922\n",
      "  time_since_restore: 11.47895097732544\n",
      "  time_this_iter_s: 11.47895097732544\n",
      "  time_total_s: 11.47895097732544\n",
      "  timestamp: 1629040847\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00022\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3915)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=3915)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3915)\u001b[0m frac:0.016611295681063124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3915)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3915)\u001b[0m \n",
      "Training neural network:  70%|███████   | 35/50 [00:05<00:02,  6.85it/s, epoch=34, training_loss=0.06, validation_loss=0.125]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3915)\u001b[0m \n",
      "                                                                                                                             \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00023:\n",
      "  date: 2021-08-15_23-21-03\n",
      "  done: false\n",
      "  experiment_id: 0c6ed7e7be704df295d50b3b7da5b737\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.1692807301276356\n",
      "  neg_mean_loss: 1.1692807301276356\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3915\n",
      "  time_since_restore: 10.491031646728516\n",
      "  time_this_iter_s: 10.491031646728516\n",
      "  time_total_s: 10.491031646728516\n",
      "  timestamp: 1629040863\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00023\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 192.7/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/1.0 accelerator_type:V, 0.0/8.0 CPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_e3bd4c59f2d91b181c5149fd09a4afa3)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 36/36 (12 PENDING, 1 RUNNING, 23 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00023</td><td>RUNNING   </td><td>202.117.43.132:3915</td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">-1.16928 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.491 </td><td style=\"text-align: right;\">       1.16928 </td></tr>\n",
       "<tr><td>training_function_2b59d_00024</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00025</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00026</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00027</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00028</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00029</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00030</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00031</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00032</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00033</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.54669 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.354 </td><td style=\"text-align: right;\">       1.54669 </td></tr>\n",
       "<tr><td>training_function_2b59d_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-0.945045</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.0091</td><td style=\"text-align: right;\">       0.945045</td></tr>\n",
       "<tr><td>training_function_2b59d_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.2041  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5703</td><td style=\"text-align: right;\">       1.2041  </td></tr>\n",
       "<tr><td>training_function_2b59d_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.73958 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.5768</td><td style=\"text-align: right;\">       1.73958 </td></tr>\n",
       "<tr><td>training_function_2b59d_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.40375 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.042 </td><td style=\"text-align: right;\">       1.40375 </td></tr>\n",
       "<tr><td>training_function_2b59d_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.65243 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2263</td><td style=\"text-align: right;\">       1.65243 </td></tr>\n",
       "<tr><td>training_function_2b59d_00006</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.29062 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5728</td><td style=\"text-align: right;\">       1.29062 </td></tr>\n",
       "<tr><td>training_function_2b59d_00007</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.856994</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2413</td><td style=\"text-align: right;\">       0.856994</td></tr>\n",
       "<tr><td>training_function_2b59d_00008</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.75865 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3197</td><td style=\"text-align: right;\">       2.75865 </td></tr>\n",
       "<tr><td>training_function_2b59d_00009</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.41383 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.7606</td><td style=\"text-align: right;\">       2.41383 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (2 PENDING, 13 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00023:\n",
      "  date: 2021-08-15_23-21-03\n",
      "  done: true\n",
      "  experiment_id: 0c6ed7e7be704df295d50b3b7da5b737\n",
      "  experiment_tag: 23_GAMMA=0.6,THETA=0.001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.1692807301276356\n",
      "  neg_mean_loss: 1.1692807301276356\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3915\n",
      "  time_since_restore: 10.491031646728516\n",
      "  time_this_iter_s: 10.491031646728516\n",
      "  time_total_s: 10.491031646728516\n",
      "  timestamp: 1629040863\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00023\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3921)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=3921)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3921)\u001b[0m frac:0.020764119601328904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3921)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3921)\u001b[0m \n",
      "Training neural network:  64%|██████▍   | 32/50 [00:05<00:02,  6.24it/s, epoch=31, training_loss=0.0564, validation_loss=0.127]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3921)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00024:\n",
      "  date: 2021-08-15_23-21-21\n",
      "  done: false\n",
      "  experiment_id: de471e985471401197e207230437e2a8\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.4421822332571521\n",
      "  neg_mean_loss: 1.4421822332571521\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3921\n",
      "  time_since_restore: 10.93539547920227\n",
      "  time_this_iter_s: 10.93539547920227\n",
      "  time_total_s: 10.93539547920227\n",
      "  timestamp: 1629040881\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00024\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 192.7/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/2.0 GPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/1.0 accelerator_type:V)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 36/36 (11 PENDING, 1 RUNNING, 24 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00024</td><td>RUNNING   </td><td>202.117.43.132:3921</td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">-1.44218 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.9354</td><td style=\"text-align: right;\">       1.44218 </td></tr>\n",
       "<tr><td>training_function_2b59d_00025</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00026</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00027</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00028</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00029</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00030</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00031</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00032</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00033</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00034</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.54669 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.354 </td><td style=\"text-align: right;\">       1.54669 </td></tr>\n",
       "<tr><td>training_function_2b59d_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-0.945045</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.0091</td><td style=\"text-align: right;\">       0.945045</td></tr>\n",
       "<tr><td>training_function_2b59d_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.2041  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5703</td><td style=\"text-align: right;\">       1.2041  </td></tr>\n",
       "<tr><td>training_function_2b59d_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.73958 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.5768</td><td style=\"text-align: right;\">       1.73958 </td></tr>\n",
       "<tr><td>training_function_2b59d_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.40375 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.042 </td><td style=\"text-align: right;\">       1.40375 </td></tr>\n",
       "<tr><td>training_function_2b59d_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.65243 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2263</td><td style=\"text-align: right;\">       1.65243 </td></tr>\n",
       "<tr><td>training_function_2b59d_00006</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.29062 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5728</td><td style=\"text-align: right;\">       1.29062 </td></tr>\n",
       "<tr><td>training_function_2b59d_00007</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.856994</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2413</td><td style=\"text-align: right;\">       0.856994</td></tr>\n",
       "<tr><td>training_function_2b59d_00008</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.75865 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3197</td><td style=\"text-align: right;\">       2.75865 </td></tr>\n",
       "<tr><td>training_function_2b59d_00009</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.41383 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.7606</td><td style=\"text-align: right;\">       2.41383 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (1 PENDING, 14 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00024:\n",
      "  date: 2021-08-15_23-21-21\n",
      "  done: true\n",
      "  experiment_id: de471e985471401197e207230437e2a8\n",
      "  experiment_tag: 24_GAMMA=0.95,THETA=0.0003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.4421822332571521\n",
      "  neg_mean_loss: 1.4421822332571521\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3921\n",
      "  time_since_restore: 10.93539547920227\n",
      "  time_this_iter_s: 10.93539547920227\n",
      "  time_total_s: 10.93539547920227\n",
      "  timestamp: 1629040881\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00024\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3917)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=3917)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3917)\u001b[0m frac:0.019933554817275746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3917)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3917)\u001b[0m \n",
      "Training neural network:  66%|██████▌   | 33/50 [00:05<00:02,  6.48it/s, epoch=32, training_loss=0.0529, validation_loss=0.145]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3917)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00025:\n",
      "  date: 2021-08-15_23-21-39\n",
      "  done: false\n",
      "  experiment_id: e37f93bdad1a47479e40491a59d5a4b5\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.8900197793520264\n",
      "  neg_mean_loss: 1.8900197793520264\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3917\n",
      "  time_since_restore: 11.15917682647705\n",
      "  time_this_iter_s: 11.15917682647705\n",
      "  time_total_s: 11.15917682647705\n",
      "  timestamp: 1629040899\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00025\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 192.6/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/1.0 accelerator_type:V, 0.0/8.0 CPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_e3bd4c59f2d91b181c5149fd09a4afa3)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 36/36 (10 PENDING, 1 RUNNING, 25 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00025</td><td>RUNNING   </td><td>202.117.43.132:3917</td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">-1.89002 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.1592</td><td style=\"text-align: right;\">       1.89002 </td></tr>\n",
       "<tr><td>training_function_2b59d_00026</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00027</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00028</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00029</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00030</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00031</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00032</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00033</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00034</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00035</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.54669 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.354 </td><td style=\"text-align: right;\">       1.54669 </td></tr>\n",
       "<tr><td>training_function_2b59d_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-0.945045</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.0091</td><td style=\"text-align: right;\">       0.945045</td></tr>\n",
       "<tr><td>training_function_2b59d_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.2041  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5703</td><td style=\"text-align: right;\">       1.2041  </td></tr>\n",
       "<tr><td>training_function_2b59d_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.73958 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.5768</td><td style=\"text-align: right;\">       1.73958 </td></tr>\n",
       "<tr><td>training_function_2b59d_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.40375 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.042 </td><td style=\"text-align: right;\">       1.40375 </td></tr>\n",
       "<tr><td>training_function_2b59d_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.65243 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2263</td><td style=\"text-align: right;\">       1.65243 </td></tr>\n",
       "<tr><td>training_function_2b59d_00006</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.29062 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5728</td><td style=\"text-align: right;\">       1.29062 </td></tr>\n",
       "<tr><td>training_function_2b59d_00007</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.856994</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2413</td><td style=\"text-align: right;\">       0.856994</td></tr>\n",
       "<tr><td>training_function_2b59d_00008</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.75865 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3197</td><td style=\"text-align: right;\">       2.75865 </td></tr>\n",
       "<tr><td>training_function_2b59d_00009</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.41383 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.7606</td><td style=\"text-align: right;\">       2.41383 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (15 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00025:\n",
      "  date: 2021-08-15_23-21-39\n",
      "  done: true\n",
      "  experiment_id: e37f93bdad1a47479e40491a59d5a4b5\n",
      "  experiment_tag: 25_GAMMA=0.9,THETA=0.0003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.8900197793520264\n",
      "  neg_mean_loss: 1.8900197793520264\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3917\n",
      "  time_since_restore: 11.15917682647705\n",
      "  time_this_iter_s: 11.15917682647705\n",
      "  time_total_s: 11.15917682647705\n",
      "  timestamp: 1629040899\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00025\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3923)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=3923)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3923)\u001b[0m frac:0.023255813953488372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3923)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3923)\u001b[0m \n",
      "Training neural network:  62%|██████▏   | 31/50 [00:05<00:03,  6.05it/s, epoch=30, training_loss=0.0643, validation_loss=0.131]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3923)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00026:\n",
      "  date: 2021-08-15_23-21-57\n",
      "  done: false\n",
      "  experiment_id: c69323e4505942aa91628cfafa878d58\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.913641792518014\n",
      "  neg_mean_loss: 1.913641792518014\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3923\n",
      "  time_since_restore: 11.218393325805664\n",
      "  time_this_iter_s: 11.218393325805664\n",
      "  time_total_s: 11.218393325805664\n",
      "  timestamp: 1629040917\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00026\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 192.6/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/8.0 CPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/1.0 accelerator_type:V, 0.0/8.0 CPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 36/36 (9 PENDING, 1 RUNNING, 26 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00026</td><td>RUNNING   </td><td>202.117.43.132:3923</td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">-1.91364 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2184</td><td style=\"text-align: right;\">       1.91364 </td></tr>\n",
       "<tr><td>training_function_2b59d_00027</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00028</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00029</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00030</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00031</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00032</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00033</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00034</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00035</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.54669 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.354 </td><td style=\"text-align: right;\">       1.54669 </td></tr>\n",
       "<tr><td>training_function_2b59d_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-0.945045</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.0091</td><td style=\"text-align: right;\">       0.945045</td></tr>\n",
       "<tr><td>training_function_2b59d_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.2041  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5703</td><td style=\"text-align: right;\">       1.2041  </td></tr>\n",
       "<tr><td>training_function_2b59d_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.73958 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.5768</td><td style=\"text-align: right;\">       1.73958 </td></tr>\n",
       "<tr><td>training_function_2b59d_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.40375 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.042 </td><td style=\"text-align: right;\">       1.40375 </td></tr>\n",
       "<tr><td>training_function_2b59d_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.65243 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2263</td><td style=\"text-align: right;\">       1.65243 </td></tr>\n",
       "<tr><td>training_function_2b59d_00006</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.29062 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5728</td><td style=\"text-align: right;\">       1.29062 </td></tr>\n",
       "<tr><td>training_function_2b59d_00007</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.856994</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2413</td><td style=\"text-align: right;\">       0.856994</td></tr>\n",
       "<tr><td>training_function_2b59d_00008</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.75865 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3197</td><td style=\"text-align: right;\">       2.75865 </td></tr>\n",
       "<tr><td>training_function_2b59d_00009</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.41383 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.7606</td><td style=\"text-align: right;\">       2.41383 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00026:\n",
      "  date: 2021-08-15_23-21-57\n",
      "  done: true\n",
      "  experiment_id: c69323e4505942aa91628cfafa878d58\n",
      "  experiment_tag: 26_GAMMA=0.85,THETA=0.0003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.913641792518014\n",
      "  neg_mean_loss: 1.913641792518014\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3923\n",
      "  time_since_restore: 11.218393325805664\n",
      "  time_this_iter_s: 11.218393325805664\n",
      "  time_total_s: 11.218393325805664\n",
      "  timestamp: 1629040917\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00026\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3916)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=3916)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3916)\u001b[0m frac:0.02367109634551495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3916)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3916)\u001b[0m \n",
      "Training neural network:  66%|██████▌   | 33/50 [00:05<00:02,  6.49it/s, epoch=32, training_loss=0.062, validation_loss=0.128]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3916)\u001b[0m \n",
      "                                                                                                                              \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00027:\n",
      "  date: 2021-08-15_23-22-14\n",
      "  done: false\n",
      "  experiment_id: 578f920f362a4ff1b2fb2ec9181a6301\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.3246997157746347\n",
      "  neg_mean_loss: 1.3246997157746347\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3916\n",
      "  time_since_restore: 11.109864711761475\n",
      "  time_this_iter_s: 11.109864711761475\n",
      "  time_total_s: 11.109864711761475\n",
      "  timestamp: 1629040934\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00027\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 192.7/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/2.0 GPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/1.0 accelerator_type:V, 0.0/8.0 CPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_e3bd4c59f2d91b181c5149fd09a4afa3)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 36/36 (8 PENDING, 1 RUNNING, 27 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00027</td><td>RUNNING   </td><td>202.117.43.132:3916</td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">-1.3247  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.1099</td><td style=\"text-align: right;\">       1.3247  </td></tr>\n",
       "<tr><td>training_function_2b59d_00028</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00029</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00030</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00031</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00032</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00033</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00034</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00035</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.54669 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.354 </td><td style=\"text-align: right;\">       1.54669 </td></tr>\n",
       "<tr><td>training_function_2b59d_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-0.945045</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.0091</td><td style=\"text-align: right;\">       0.945045</td></tr>\n",
       "<tr><td>training_function_2b59d_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.2041  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5703</td><td style=\"text-align: right;\">       1.2041  </td></tr>\n",
       "<tr><td>training_function_2b59d_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.73958 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.5768</td><td style=\"text-align: right;\">       1.73958 </td></tr>\n",
       "<tr><td>training_function_2b59d_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.40375 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.042 </td><td style=\"text-align: right;\">       1.40375 </td></tr>\n",
       "<tr><td>training_function_2b59d_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.65243 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2263</td><td style=\"text-align: right;\">       1.65243 </td></tr>\n",
       "<tr><td>training_function_2b59d_00006</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.29062 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5728</td><td style=\"text-align: right;\">       1.29062 </td></tr>\n",
       "<tr><td>training_function_2b59d_00007</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.856994</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2413</td><td style=\"text-align: right;\">       0.856994</td></tr>\n",
       "<tr><td>training_function_2b59d_00008</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.75865 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3197</td><td style=\"text-align: right;\">       2.75865 </td></tr>\n",
       "<tr><td>training_function_2b59d_00009</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.41383 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.7606</td><td style=\"text-align: right;\">       2.41383 </td></tr>\n",
       "<tr><td>training_function_2b59d_00010</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.5488  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.4037</td><td style=\"text-align: right;\">       1.5488  </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00027:\n",
      "  date: 2021-08-15_23-22-14\n",
      "  done: true\n",
      "  experiment_id: 578f920f362a4ff1b2fb2ec9181a6301\n",
      "  experiment_tag: 27_GAMMA=0.8,THETA=0.0003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.3246997157746347\n",
      "  neg_mean_loss: 1.3246997157746347\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3916\n",
      "  time_since_restore: 11.109864711761475\n",
      "  time_this_iter_s: 11.109864711761475\n",
      "  time_total_s: 11.109864711761475\n",
      "  timestamp: 1629040934\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00027\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3920)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=3920)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3920)\u001b[0m frac:0.0170265780730897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3920)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3920)\u001b[0m \n",
      "Training neural network:  60%|██████    | 30/50 [00:05<00:03,  5.94it/s, epoch=29, training_loss=0.0613, validation_loss=0.131]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3920)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00028:\n",
      "  date: 2021-08-15_23-22-32\n",
      "  done: false\n",
      "  experiment_id: 2bc4fe4a34f94f4abc0fd9727034a5d7\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -2.0269679506161586\n",
      "  neg_mean_loss: 2.0269679506161586\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3920\n",
      "  time_since_restore: 11.617727041244507\n",
      "  time_this_iter_s: 11.617727041244507\n",
      "  time_total_s: 11.617727041244507\n",
      "  timestamp: 1629040952\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00028\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 192.6/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/8.0 CPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_e3bd4c59f2d91b181c5149fd09a4afa3)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 36/36 (7 PENDING, 1 RUNNING, 28 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00028</td><td>RUNNING   </td><td>202.117.43.132:3920</td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">-2.02697 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.6177</td><td style=\"text-align: right;\">       2.02697 </td></tr>\n",
       "<tr><td>training_function_2b59d_00029</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00030</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00031</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00032</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00033</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00034</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00035</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.54669 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.354 </td><td style=\"text-align: right;\">       1.54669 </td></tr>\n",
       "<tr><td>training_function_2b59d_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-0.945045</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.0091</td><td style=\"text-align: right;\">       0.945045</td></tr>\n",
       "<tr><td>training_function_2b59d_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.2041  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5703</td><td style=\"text-align: right;\">       1.2041  </td></tr>\n",
       "<tr><td>training_function_2b59d_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.73958 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.5768</td><td style=\"text-align: right;\">       1.73958 </td></tr>\n",
       "<tr><td>training_function_2b59d_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.40375 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.042 </td><td style=\"text-align: right;\">       1.40375 </td></tr>\n",
       "<tr><td>training_function_2b59d_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.65243 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2263</td><td style=\"text-align: right;\">       1.65243 </td></tr>\n",
       "<tr><td>training_function_2b59d_00006</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.29062 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5728</td><td style=\"text-align: right;\">       1.29062 </td></tr>\n",
       "<tr><td>training_function_2b59d_00007</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.856994</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2413</td><td style=\"text-align: right;\">       0.856994</td></tr>\n",
       "<tr><td>training_function_2b59d_00008</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.75865 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3197</td><td style=\"text-align: right;\">       2.75865 </td></tr>\n",
       "<tr><td>training_function_2b59d_00009</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.41383 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.7606</td><td style=\"text-align: right;\">       2.41383 </td></tr>\n",
       "<tr><td>training_function_2b59d_00010</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.5488  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.4037</td><td style=\"text-align: right;\">       1.5488  </td></tr>\n",
       "<tr><td>training_function_2b59d_00011</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.22395 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1786</td><td style=\"text-align: right;\">       2.22395 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00028:\n",
      "  date: 2021-08-15_23-22-32\n",
      "  done: true\n",
      "  experiment_id: 2bc4fe4a34f94f4abc0fd9727034a5d7\n",
      "  experiment_tag: 28_GAMMA=0.7,THETA=0.0003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -2.0269679506161586\n",
      "  neg_mean_loss: 2.0269679506161586\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3920\n",
      "  time_since_restore: 11.617727041244507\n",
      "  time_this_iter_s: 11.617727041244507\n",
      "  time_total_s: 11.617727041244507\n",
      "  timestamp: 1629040952\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00028\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3910)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=3910)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3910)\u001b[0m frac:0.01744186046511628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3910)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3910)\u001b[0m \n",
      "Training neural network:  64%|██████▍   | 32/50 [00:05<00:02,  6.28it/s, epoch=31, training_loss=0.0575, validation_loss=0.119]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3910)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00029:\n",
      "  date: 2021-08-15_23-22-49\n",
      "  done: false\n",
      "  experiment_id: b2b167dccde34509b3d3ab5152b8a12d\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -0.8036304460872236\n",
      "  neg_mean_loss: 0.8036304460872236\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3910\n",
      "  time_since_restore: 11.358154535293579\n",
      "  time_this_iter_s: 11.358154535293579\n",
      "  time_total_s: 11.358154535293579\n",
      "  timestamp: 1629040969\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00029\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 192.6/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/8.0 CPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_e3bd4c59f2d91b181c5149fd09a4afa3)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 36/36 (6 PENDING, 1 RUNNING, 29 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00029</td><td>RUNNING   </td><td>202.117.43.132:3910</td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">-0.80363 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.3582</td><td style=\"text-align: right;\">       0.80363 </td></tr>\n",
       "<tr><td>training_function_2b59d_00030</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00031</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00032</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00033</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00034</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00035</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.54669 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.354 </td><td style=\"text-align: right;\">       1.54669 </td></tr>\n",
       "<tr><td>training_function_2b59d_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-0.945045</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.0091</td><td style=\"text-align: right;\">       0.945045</td></tr>\n",
       "<tr><td>training_function_2b59d_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.2041  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5703</td><td style=\"text-align: right;\">       1.2041  </td></tr>\n",
       "<tr><td>training_function_2b59d_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.73958 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.5768</td><td style=\"text-align: right;\">       1.73958 </td></tr>\n",
       "<tr><td>training_function_2b59d_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.40375 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.042 </td><td style=\"text-align: right;\">       1.40375 </td></tr>\n",
       "<tr><td>training_function_2b59d_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.65243 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2263</td><td style=\"text-align: right;\">       1.65243 </td></tr>\n",
       "<tr><td>training_function_2b59d_00006</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.29062 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5728</td><td style=\"text-align: right;\">       1.29062 </td></tr>\n",
       "<tr><td>training_function_2b59d_00007</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.856994</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2413</td><td style=\"text-align: right;\">       0.856994</td></tr>\n",
       "<tr><td>training_function_2b59d_00008</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.75865 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3197</td><td style=\"text-align: right;\">       2.75865 </td></tr>\n",
       "<tr><td>training_function_2b59d_00009</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.41383 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.7606</td><td style=\"text-align: right;\">       2.41383 </td></tr>\n",
       "<tr><td>training_function_2b59d_00010</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.5488  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.4037</td><td style=\"text-align: right;\">       1.5488  </td></tr>\n",
       "<tr><td>training_function_2b59d_00011</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.22395 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1786</td><td style=\"text-align: right;\">       2.22395 </td></tr>\n",
       "<tr><td>training_function_2b59d_00012</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-0.996575</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.6174</td><td style=\"text-align: right;\">       0.996575</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00029:\n",
      "  date: 2021-08-15_23-22-49\n",
      "  done: true\n",
      "  experiment_id: b2b167dccde34509b3d3ab5152b8a12d\n",
      "  experiment_tag: 29_GAMMA=0.6,THETA=0.0003\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -0.8036304460872236\n",
      "  neg_mean_loss: 0.8036304460872236\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3910\n",
      "  time_since_restore: 11.358154535293579\n",
      "  time_this_iter_s: 11.358154535293579\n",
      "  time_total_s: 11.358154535293579\n",
      "  timestamp: 1629040969\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00029\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3911)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=3911)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3911)\u001b[0m frac:0.018687707641196014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3911)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3911)\u001b[0m \n",
      "Training neural network:  66%|██████▌   | 33/50 [00:05<00:02,  6.49it/s, epoch=32, training_loss=0.0626, validation_loss=0.128]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3911)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00030:\n",
      "  date: 2021-08-15_23-23-07\n",
      "  done: false\n",
      "  experiment_id: d50183067fad4bf7842996ae09b90d61\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.2297251138293486\n",
      "  neg_mean_loss: 1.2297251138293486\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3911\n",
      "  time_since_restore: 11.037068128585815\n",
      "  time_this_iter_s: 11.037068128585815\n",
      "  time_total_s: 11.037068128585815\n",
      "  timestamp: 1629040987\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00030\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 192.6/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/2.0 GPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/1.0 accelerator_type:V, 0.0/8.0 CPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 36/36 (5 PENDING, 1 RUNNING, 30 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00030</td><td>RUNNING   </td><td>202.117.43.132:3911</td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">-1.22973 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.0371</td><td style=\"text-align: right;\">       1.22973 </td></tr>\n",
       "<tr><td>training_function_2b59d_00031</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00032</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00033</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00034</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00035</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.54669 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.354 </td><td style=\"text-align: right;\">       1.54669 </td></tr>\n",
       "<tr><td>training_function_2b59d_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-0.945045</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.0091</td><td style=\"text-align: right;\">       0.945045</td></tr>\n",
       "<tr><td>training_function_2b59d_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.2041  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5703</td><td style=\"text-align: right;\">       1.2041  </td></tr>\n",
       "<tr><td>training_function_2b59d_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.73958 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.5768</td><td style=\"text-align: right;\">       1.73958 </td></tr>\n",
       "<tr><td>training_function_2b59d_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.40375 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.042 </td><td style=\"text-align: right;\">       1.40375 </td></tr>\n",
       "<tr><td>training_function_2b59d_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.65243 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2263</td><td style=\"text-align: right;\">       1.65243 </td></tr>\n",
       "<tr><td>training_function_2b59d_00006</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.29062 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5728</td><td style=\"text-align: right;\">       1.29062 </td></tr>\n",
       "<tr><td>training_function_2b59d_00007</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.856994</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2413</td><td style=\"text-align: right;\">       0.856994</td></tr>\n",
       "<tr><td>training_function_2b59d_00008</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.75865 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3197</td><td style=\"text-align: right;\">       2.75865 </td></tr>\n",
       "<tr><td>training_function_2b59d_00009</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.41383 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.7606</td><td style=\"text-align: right;\">       2.41383 </td></tr>\n",
       "<tr><td>training_function_2b59d_00010</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.5488  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.4037</td><td style=\"text-align: right;\">       1.5488  </td></tr>\n",
       "<tr><td>training_function_2b59d_00011</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.22395 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1786</td><td style=\"text-align: right;\">       2.22395 </td></tr>\n",
       "<tr><td>training_function_2b59d_00012</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-0.996575</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.6174</td><td style=\"text-align: right;\">       0.996575</td></tr>\n",
       "<tr><td>training_function_2b59d_00013</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.15116 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2646</td><td style=\"text-align: right;\">       1.15116 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00030:\n",
      "  date: 2021-08-15_23-23-07\n",
      "  done: true\n",
      "  experiment_id: d50183067fad4bf7842996ae09b90d61\n",
      "  experiment_tag: 30_GAMMA=0.95,THETA=0.0001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.2297251138293486\n",
      "  neg_mean_loss: 1.2297251138293486\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3911\n",
      "  time_since_restore: 11.037068128585815\n",
      "  time_this_iter_s: 11.037068128585815\n",
      "  time_total_s: 11.037068128585815\n",
      "  timestamp: 1629040987\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00030\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3912)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=3912)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3912)\u001b[0m frac:0.023255813953488372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3912)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3912)\u001b[0m \n",
      "Training neural network:  68%|██████▊   | 34/50 [00:05<00:02,  6.50it/s, epoch=33, training_loss=0.0733, validation_loss=0.124]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3912)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00031:\n",
      "  date: 2021-08-15_23-23-25\n",
      "  done: false\n",
      "  experiment_id: 735e8a399a5b4552bdbd08338e9dafd1\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.208602651420241\n",
      "  neg_mean_loss: 1.208602651420241\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3912\n",
      "  time_since_restore: 11.928167343139648\n",
      "  time_this_iter_s: 11.928167343139648\n",
      "  time_total_s: 11.928167343139648\n",
      "  timestamp: 1629041005\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00031\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 192.9/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/2.0 GPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/1.0 accelerator_type:V)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 36/36 (4 PENDING, 1 RUNNING, 31 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00031</td><td>RUNNING   </td><td>202.117.43.132:3912</td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">-1.2086  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.9282</td><td style=\"text-align: right;\">       1.2086  </td></tr>\n",
       "<tr><td>training_function_2b59d_00032</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00033</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00034</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00035</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00000</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.54669 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.354 </td><td style=\"text-align: right;\">       1.54669 </td></tr>\n",
       "<tr><td>training_function_2b59d_00001</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-0.945045</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.0091</td><td style=\"text-align: right;\">       0.945045</td></tr>\n",
       "<tr><td>training_function_2b59d_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.2041  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5703</td><td style=\"text-align: right;\">       1.2041  </td></tr>\n",
       "<tr><td>training_function_2b59d_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.73958 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.5768</td><td style=\"text-align: right;\">       1.73958 </td></tr>\n",
       "<tr><td>training_function_2b59d_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.40375 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.042 </td><td style=\"text-align: right;\">       1.40375 </td></tr>\n",
       "<tr><td>training_function_2b59d_00005</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.65243 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2263</td><td style=\"text-align: right;\">       1.65243 </td></tr>\n",
       "<tr><td>training_function_2b59d_00006</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.29062 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5728</td><td style=\"text-align: right;\">       1.29062 </td></tr>\n",
       "<tr><td>training_function_2b59d_00007</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.856994</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2413</td><td style=\"text-align: right;\">       0.856994</td></tr>\n",
       "<tr><td>training_function_2b59d_00008</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.75865 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3197</td><td style=\"text-align: right;\">       2.75865 </td></tr>\n",
       "<tr><td>training_function_2b59d_00009</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.41383 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.7606</td><td style=\"text-align: right;\">       2.41383 </td></tr>\n",
       "<tr><td>training_function_2b59d_00010</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.5488  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.4037</td><td style=\"text-align: right;\">       1.5488  </td></tr>\n",
       "<tr><td>training_function_2b59d_00011</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.22395 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1786</td><td style=\"text-align: right;\">       2.22395 </td></tr>\n",
       "<tr><td>training_function_2b59d_00012</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-0.996575</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.6174</td><td style=\"text-align: right;\">       0.996575</td></tr>\n",
       "<tr><td>training_function_2b59d_00013</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.15116 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2646</td><td style=\"text-align: right;\">       1.15116 </td></tr>\n",
       "<tr><td>training_function_2b59d_00014</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-0.936332</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.8543</td><td style=\"text-align: right;\">       0.936332</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00031:\n",
      "  date: 2021-08-15_23-23-25\n",
      "  done: true\n",
      "  experiment_id: 735e8a399a5b4552bdbd08338e9dafd1\n",
      "  experiment_tag: 31_GAMMA=0.9,THETA=0.0001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.208602651420241\n",
      "  neg_mean_loss: 1.208602651420241\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 3912\n",
      "  time_since_restore: 11.928167343139648\n",
      "  time_this_iter_s: 11.928167343139648\n",
      "  time_total_s: 11.928167343139648\n",
      "  timestamp: 1629041005\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00031\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=22534)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=22534)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=22534)\u001b[0m frac:0.0170265780730897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=22534)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=22534)\u001b[0m \n",
      "Training neural network:  56%|█████▌    | 28/50 [00:05<00:03,  5.50it/s, epoch=27, training_loss=0.053, validation_loss=0.118]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=22534)\u001b[0m \n",
      "                                                                                                                              \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00032:\n",
      "  date: 2021-08-15_23-23-49\n",
      "  done: false\n",
      "  experiment_id: 1e5cc93e35d248609355a174475e5d5f\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.8954116182180105\n",
      "  neg_mean_loss: 1.8954116182180105\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 22534\n",
      "  time_since_restore: 12.864393949508667\n",
      "  time_this_iter_s: 12.864393949508667\n",
      "  time_total_s: 12.864393949508667\n",
      "  timestamp: 1629041029\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00032\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 193.1/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/2.0 GPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/1.0 accelerator_type:V)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 36/36 (3 PENDING, 1 RUNNING, 32 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00032</td><td>RUNNING   </td><td>202.117.43.132:22534</td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">-1.89541 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.8644</td><td style=\"text-align: right;\">       1.89541 </td></tr>\n",
       "<tr><td>training_function_2b59d_00033</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00034</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00035</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.54669 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.354 </td><td style=\"text-align: right;\">       1.54669 </td></tr>\n",
       "<tr><td>training_function_2b59d_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-0.945045</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.0091</td><td style=\"text-align: right;\">       0.945045</td></tr>\n",
       "<tr><td>training_function_2b59d_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.2041  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5703</td><td style=\"text-align: right;\">       1.2041  </td></tr>\n",
       "<tr><td>training_function_2b59d_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.73958 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.5768</td><td style=\"text-align: right;\">       1.73958 </td></tr>\n",
       "<tr><td>training_function_2b59d_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.40375 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.042 </td><td style=\"text-align: right;\">       1.40375 </td></tr>\n",
       "<tr><td>training_function_2b59d_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.65243 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2263</td><td style=\"text-align: right;\">       1.65243 </td></tr>\n",
       "<tr><td>training_function_2b59d_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.29062 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5728</td><td style=\"text-align: right;\">       1.29062 </td></tr>\n",
       "<tr><td>training_function_2b59d_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.856994</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2413</td><td style=\"text-align: right;\">       0.856994</td></tr>\n",
       "<tr><td>training_function_2b59d_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.75865 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3197</td><td style=\"text-align: right;\">       2.75865 </td></tr>\n",
       "<tr><td>training_function_2b59d_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.41383 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.7606</td><td style=\"text-align: right;\">       2.41383 </td></tr>\n",
       "<tr><td>training_function_2b59d_00010</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.5488  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.4037</td><td style=\"text-align: right;\">       1.5488  </td></tr>\n",
       "<tr><td>training_function_2b59d_00011</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.22395 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1786</td><td style=\"text-align: right;\">       2.22395 </td></tr>\n",
       "<tr><td>training_function_2b59d_00012</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-0.996575</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.6174</td><td style=\"text-align: right;\">       0.996575</td></tr>\n",
       "<tr><td>training_function_2b59d_00013</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.15116 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2646</td><td style=\"text-align: right;\">       1.15116 </td></tr>\n",
       "<tr><td>training_function_2b59d_00014</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-0.936332</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.8543</td><td style=\"text-align: right;\">       0.936332</td></tr>\n",
       "<tr><td>training_function_2b59d_00015</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.14975 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1218</td><td style=\"text-align: right;\">       1.14975 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00032:\n",
      "  date: 2021-08-15_23-23-49\n",
      "  done: true\n",
      "  experiment_id: 1e5cc93e35d248609355a174475e5d5f\n",
      "  experiment_tag: 32_GAMMA=0.85,THETA=0.0001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.8954116182180105\n",
      "  neg_mean_loss: 1.8954116182180105\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 22534\n",
      "  time_since_restore: 12.864393949508667\n",
      "  time_this_iter_s: 12.864393949508667\n",
      "  time_total_s: 12.864393949508667\n",
      "  timestamp: 1629041029\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00032\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=22801)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=22801)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=22801)\u001b[0m frac:0.01910299003322259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=22801)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=22801)\u001b[0m \n",
      "Training neural network:  68%|██████▊   | 34/50 [00:05<00:02,  6.61it/s, epoch=33, training_loss=0.0536, validation_loss=0.125]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=22801)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00033:\n",
      "  date: 2021-08-15_23-24-06\n",
      "  done: false\n",
      "  experiment_id: b50b953969664f1bbb9a078436e81be9\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -2.8284826393295455\n",
      "  neg_mean_loss: 2.8284826393295455\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 22801\n",
      "  time_since_restore: 10.56589412689209\n",
      "  time_this_iter_s: 10.56589412689209\n",
      "  time_total_s: 10.56589412689209\n",
      "  timestamp: 1629041046\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00033\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 193.2/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/2.0 GPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/1.0 accelerator_type:V, 0.0/8.0 CPU_group_e3bd4c59f2d91b181c5149fd09a4afa3)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 36/36 (2 PENDING, 1 RUNNING, 33 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00033</td><td>RUNNING   </td><td>202.117.43.132:22801</td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">-2.82848 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5659</td><td style=\"text-align: right;\">       2.82848 </td></tr>\n",
       "<tr><td>training_function_2b59d_00034</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00035</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.54669 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.354 </td><td style=\"text-align: right;\">       1.54669 </td></tr>\n",
       "<tr><td>training_function_2b59d_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-0.945045</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.0091</td><td style=\"text-align: right;\">       0.945045</td></tr>\n",
       "<tr><td>training_function_2b59d_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.2041  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5703</td><td style=\"text-align: right;\">       1.2041  </td></tr>\n",
       "<tr><td>training_function_2b59d_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.73958 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.5768</td><td style=\"text-align: right;\">       1.73958 </td></tr>\n",
       "<tr><td>training_function_2b59d_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.40375 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.042 </td><td style=\"text-align: right;\">       1.40375 </td></tr>\n",
       "<tr><td>training_function_2b59d_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.65243 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2263</td><td style=\"text-align: right;\">       1.65243 </td></tr>\n",
       "<tr><td>training_function_2b59d_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.29062 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5728</td><td style=\"text-align: right;\">       1.29062 </td></tr>\n",
       "<tr><td>training_function_2b59d_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.856994</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2413</td><td style=\"text-align: right;\">       0.856994</td></tr>\n",
       "<tr><td>training_function_2b59d_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.75865 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3197</td><td style=\"text-align: right;\">       2.75865 </td></tr>\n",
       "<tr><td>training_function_2b59d_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.41383 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.7606</td><td style=\"text-align: right;\">       2.41383 </td></tr>\n",
       "<tr><td>training_function_2b59d_00010</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.5488  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.4037</td><td style=\"text-align: right;\">       1.5488  </td></tr>\n",
       "<tr><td>training_function_2b59d_00011</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.22395 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1786</td><td style=\"text-align: right;\">       2.22395 </td></tr>\n",
       "<tr><td>training_function_2b59d_00012</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-0.996575</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.6174</td><td style=\"text-align: right;\">       0.996575</td></tr>\n",
       "<tr><td>training_function_2b59d_00013</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.15116 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2646</td><td style=\"text-align: right;\">       1.15116 </td></tr>\n",
       "<tr><td>training_function_2b59d_00014</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-0.936332</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.8543</td><td style=\"text-align: right;\">       0.936332</td></tr>\n",
       "<tr><td>training_function_2b59d_00015</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.14975 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1218</td><td style=\"text-align: right;\">       1.14975 </td></tr>\n",
       "<tr><td>training_function_2b59d_00016</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.11459 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1663</td><td style=\"text-align: right;\">       1.11459 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00033:\n",
      "  date: 2021-08-15_23-24-06\n",
      "  done: true\n",
      "  experiment_id: b50b953969664f1bbb9a078436e81be9\n",
      "  experiment_tag: 33_GAMMA=0.8,THETA=0.0001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -2.8284826393295455\n",
      "  neg_mean_loss: 2.8284826393295455\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 22801\n",
      "  time_since_restore: 10.56589412689209\n",
      "  time_this_iter_s: 10.56589412689209\n",
      "  time_total_s: 10.56589412689209\n",
      "  timestamp: 1629041046\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00033\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=22987)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=22987)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=22987)\u001b[0m frac:0.018687707641196014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=22987)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=22987)\u001b[0m \n",
      "Training neural network:  62%|██████▏   | 31/50 [00:05<00:03,  6.05it/s, epoch=30, training_loss=0.0583, validation_loss=0.135]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=22987)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00034:\n",
      "  date: 2021-08-15_23-24-25\n",
      "  done: false\n",
      "  experiment_id: 4d6a548c9a164ff98a09b2fc86b10e9d\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.4828068203963973\n",
      "  neg_mean_loss: 1.4828068203963973\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 22987\n",
      "  time_since_restore: 12.07369351387024\n",
      "  time_this_iter_s: 12.07369351387024\n",
      "  time_total_s: 12.07369351387024\n",
      "  timestamp: 1629041065\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00034\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 193.3/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/2.0 GPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/1.0 accelerator_type:V, 0.0/8.0 CPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 36/36 (1 PENDING, 1 RUNNING, 34 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00034</td><td>RUNNING   </td><td>202.117.43.132:22987</td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">-1.48281 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.0737</td><td style=\"text-align: right;\">       1.48281 </td></tr>\n",
       "<tr><td>training_function_2b59d_00035</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_function_2b59d_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.54669 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.354 </td><td style=\"text-align: right;\">       1.54669 </td></tr>\n",
       "<tr><td>training_function_2b59d_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-0.945045</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.0091</td><td style=\"text-align: right;\">       0.945045</td></tr>\n",
       "<tr><td>training_function_2b59d_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.2041  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5703</td><td style=\"text-align: right;\">       1.2041  </td></tr>\n",
       "<tr><td>training_function_2b59d_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.73958 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.5768</td><td style=\"text-align: right;\">       1.73958 </td></tr>\n",
       "<tr><td>training_function_2b59d_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.40375 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.042 </td><td style=\"text-align: right;\">       1.40375 </td></tr>\n",
       "<tr><td>training_function_2b59d_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.65243 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2263</td><td style=\"text-align: right;\">       1.65243 </td></tr>\n",
       "<tr><td>training_function_2b59d_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.29062 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5728</td><td style=\"text-align: right;\">       1.29062 </td></tr>\n",
       "<tr><td>training_function_2b59d_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.856994</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2413</td><td style=\"text-align: right;\">       0.856994</td></tr>\n",
       "<tr><td>training_function_2b59d_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.75865 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3197</td><td style=\"text-align: right;\">       2.75865 </td></tr>\n",
       "<tr><td>training_function_2b59d_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.41383 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.7606</td><td style=\"text-align: right;\">       2.41383 </td></tr>\n",
       "<tr><td>training_function_2b59d_00010</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.5488  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.4037</td><td style=\"text-align: right;\">       1.5488  </td></tr>\n",
       "<tr><td>training_function_2b59d_00011</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.22395 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1786</td><td style=\"text-align: right;\">       2.22395 </td></tr>\n",
       "<tr><td>training_function_2b59d_00012</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-0.996575</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.6174</td><td style=\"text-align: right;\">       0.996575</td></tr>\n",
       "<tr><td>training_function_2b59d_00013</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.15116 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2646</td><td style=\"text-align: right;\">       1.15116 </td></tr>\n",
       "<tr><td>training_function_2b59d_00014</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-0.936332</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.8543</td><td style=\"text-align: right;\">       0.936332</td></tr>\n",
       "<tr><td>training_function_2b59d_00015</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.14975 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1218</td><td style=\"text-align: right;\">       1.14975 </td></tr>\n",
       "<tr><td>training_function_2b59d_00016</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.11459 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1663</td><td style=\"text-align: right;\">       1.11459 </td></tr>\n",
       "<tr><td>training_function_2b59d_00017</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-0.74939 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.8914</td><td style=\"text-align: right;\">       0.74939 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00034:\n",
      "  date: 2021-08-15_23-24-25\n",
      "  done: true\n",
      "  experiment_id: 4d6a548c9a164ff98a09b2fc86b10e9d\n",
      "  experiment_tag: 34_GAMMA=0.7,THETA=0.0001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.4828068203963973\n",
      "  neg_mean_loss: 1.4828068203963973\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 22987\n",
      "  time_since_restore: 12.07369351387024\n",
      "  time_this_iter_s: 12.07369351387024\n",
      "  time_total_s: 12.07369351387024\n",
      "  timestamp: 1629041065\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00034\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=23382)\u001b[0m /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ray/workers/default_worker.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(pid=23382)\u001b[0m   parser = argparse.ArgumentParser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=23382)\u001b[0m frac:0.0170265780730897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=23382)\u001b[0m \n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=23382)\u001b[0m \n",
      "Training neural network:  62%|██████▏   | 31/50 [00:05<00:03,  6.07it/s, epoch=30, training_loss=0.0649, validation_loss=0.128]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=23382)\u001b[0m \n",
      "                                                                                                                               \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00035:\n",
      "  date: 2021-08-15_23-24-44\n",
      "  done: false\n",
      "  experiment_id: db9da005167d487ab0091e776f80bcf0\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.9138332017240807\n",
      "  neg_mean_loss: 1.9138332017240807\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 23382\n",
      "  time_since_restore: 11.822307586669922\n",
      "  time_this_iter_s: 11.822307586669922\n",
      "  time_total_s: 11.822307586669922\n",
      "  timestamp: 1629041084\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00035\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 193.4/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/32 CPUs, 2.0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/8.0 CPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/1.0 accelerator_type:V, 0.0/2.0 GPU_group_e3bd4c59f2d91b181c5149fd09a4afa3)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 36/36 (1 RUNNING, 35 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00035</td><td>RUNNING   </td><td>202.117.43.132:23382</td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">-1.91383 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.8223</td><td style=\"text-align: right;\">       1.91383 </td></tr>\n",
       "<tr><td>training_function_2b59d_00000</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.54669 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.354 </td><td style=\"text-align: right;\">       1.54669 </td></tr>\n",
       "<tr><td>training_function_2b59d_00001</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-0.945045</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.0091</td><td style=\"text-align: right;\">       0.945045</td></tr>\n",
       "<tr><td>training_function_2b59d_00002</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.2041  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5703</td><td style=\"text-align: right;\">       1.2041  </td></tr>\n",
       "<tr><td>training_function_2b59d_00003</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.73958 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.5768</td><td style=\"text-align: right;\">       1.73958 </td></tr>\n",
       "<tr><td>training_function_2b59d_00004</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.40375 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.042 </td><td style=\"text-align: right;\">       1.40375 </td></tr>\n",
       "<tr><td>training_function_2b59d_00005</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.65243 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2263</td><td style=\"text-align: right;\">       1.65243 </td></tr>\n",
       "<tr><td>training_function_2b59d_00006</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.29062 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5728</td><td style=\"text-align: right;\">       1.29062 </td></tr>\n",
       "<tr><td>training_function_2b59d_00007</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.856994</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2413</td><td style=\"text-align: right;\">       0.856994</td></tr>\n",
       "<tr><td>training_function_2b59d_00008</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.75865 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3197</td><td style=\"text-align: right;\">       2.75865 </td></tr>\n",
       "<tr><td>training_function_2b59d_00009</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.41383 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.7606</td><td style=\"text-align: right;\">       2.41383 </td></tr>\n",
       "<tr><td>training_function_2b59d_00010</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.5488  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.4037</td><td style=\"text-align: right;\">       1.5488  </td></tr>\n",
       "<tr><td>training_function_2b59d_00011</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.22395 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1786</td><td style=\"text-align: right;\">       2.22395 </td></tr>\n",
       "<tr><td>training_function_2b59d_00012</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-0.996575</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.6174</td><td style=\"text-align: right;\">       0.996575</td></tr>\n",
       "<tr><td>training_function_2b59d_00013</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.15116 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2646</td><td style=\"text-align: right;\">       1.15116 </td></tr>\n",
       "<tr><td>training_function_2b59d_00014</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-0.936332</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.8543</td><td style=\"text-align: right;\">       0.936332</td></tr>\n",
       "<tr><td>training_function_2b59d_00015</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.14975 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1218</td><td style=\"text-align: right;\">       1.14975 </td></tr>\n",
       "<tr><td>training_function_2b59d_00016</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.11459 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1663</td><td style=\"text-align: right;\">       1.11459 </td></tr>\n",
       "<tr><td>training_function_2b59d_00017</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-0.74939 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.8914</td><td style=\"text-align: right;\">       0.74939 </td></tr>\n",
       "<tr><td>training_function_2b59d_00018</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">-0.94941 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.2472</td><td style=\"text-align: right;\">       0.94941 </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_function_2b59d_00035:\n",
      "  date: 2021-08-15_23-24-44\n",
      "  done: true\n",
      "  experiment_id: db9da005167d487ab0091e776f80bcf0\n",
      "  experiment_tag: 35_GAMMA=0.6,THETA=0.0001\n",
      "  hostname: amax\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: -1.9138332017240807\n",
      "  neg_mean_loss: 1.9138332017240807\n",
      "  node_ip: 202.117.43.132\n",
      "  pid: 23382\n",
      "  time_since_restore: 11.822307586669922\n",
      "  time_this_iter_s: 11.822307586669922\n",
      "  time_total_s: 11.822307586669922\n",
      "  timestamp: 1629041084\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2b59d_00035\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 196.1/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/32 CPUs, 0/2 GPUs, 0.0/40.67 GiB heap, 0.0/20.33 GiB objects (0.0/2.0 GPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/1.0 accelerator_type:V, 0.0/8.0 CPU_group_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/2.0 GPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3, 0.0/8.0 CPU_group_0_e3bd4c59f2d91b181c5149fd09a4afa3)<br>Result logdir: /data2/gxq/ray_results/training_function_2021-08-15_23-12-13<br>Number of trials: 36/36 (36 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  GAMMA</th><th style=\"text-align: right;\">  THETA</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_2b59d_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.54669 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.354 </td><td style=\"text-align: right;\">       1.54669 </td></tr>\n",
       "<tr><td>training_function_2b59d_00001</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-0.945045</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.0091</td><td style=\"text-align: right;\">       0.945045</td></tr>\n",
       "<tr><td>training_function_2b59d_00002</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.2041  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5703</td><td style=\"text-align: right;\">       1.2041  </td></tr>\n",
       "<tr><td>training_function_2b59d_00003</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.73958 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.5768</td><td style=\"text-align: right;\">       1.73958 </td></tr>\n",
       "<tr><td>training_function_2b59d_00004</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.40375 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.042 </td><td style=\"text-align: right;\">       1.40375 </td></tr>\n",
       "<tr><td>training_function_2b59d_00005</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.1   </td><td style=\"text-align: right;\">-1.65243 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2263</td><td style=\"text-align: right;\">       1.65243 </td></tr>\n",
       "<tr><td>training_function_2b59d_00006</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.29062 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5728</td><td style=\"text-align: right;\">       1.29062 </td></tr>\n",
       "<tr><td>training_function_2b59d_00007</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-0.856994</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2413</td><td style=\"text-align: right;\">       0.856994</td></tr>\n",
       "<tr><td>training_function_2b59d_00008</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.75865 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3197</td><td style=\"text-align: right;\">       2.75865 </td></tr>\n",
       "<tr><td>training_function_2b59d_00009</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.41383 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.7606</td><td style=\"text-align: right;\">       2.41383 </td></tr>\n",
       "<tr><td>training_function_2b59d_00010</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-1.5488  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.4037</td><td style=\"text-align: right;\">       1.5488  </td></tr>\n",
       "<tr><td>training_function_2b59d_00011</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.01  </td><td style=\"text-align: right;\">-2.22395 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1786</td><td style=\"text-align: right;\">       2.22395 </td></tr>\n",
       "<tr><td>training_function_2b59d_00012</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-0.996575</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.6174</td><td style=\"text-align: right;\">       0.996575</td></tr>\n",
       "<tr><td>training_function_2b59d_00013</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.15116 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2646</td><td style=\"text-align: right;\">       1.15116 </td></tr>\n",
       "<tr><td>training_function_2b59d_00014</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-0.936332</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.8543</td><td style=\"text-align: right;\">       0.936332</td></tr>\n",
       "<tr><td>training_function_2b59d_00015</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.14975 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1218</td><td style=\"text-align: right;\">       1.14975 </td></tr>\n",
       "<tr><td>training_function_2b59d_00016</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-1.11459 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1663</td><td style=\"text-align: right;\">       1.11459 </td></tr>\n",
       "<tr><td>training_function_2b59d_00017</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.003 </td><td style=\"text-align: right;\">-0.74939 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.8914</td><td style=\"text-align: right;\">       0.74939 </td></tr>\n",
       "<tr><td>training_function_2b59d_00018</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">-0.94941 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.2472</td><td style=\"text-align: right;\">       0.94941 </td></tr>\n",
       "<tr><td>training_function_2b59d_00019</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">-1.02478 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2948</td><td style=\"text-align: right;\">       1.02478 </td></tr>\n",
       "<tr><td>training_function_2b59d_00020</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">-1.01606 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.1606</td><td style=\"text-align: right;\">       1.01606 </td></tr>\n",
       "<tr><td>training_function_2b59d_00021</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">-1.31966 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.3413</td><td style=\"text-align: right;\">       1.31966 </td></tr>\n",
       "<tr><td>training_function_2b59d_00022</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">-0.920539</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.479 </td><td style=\"text-align: right;\">       0.920539</td></tr>\n",
       "<tr><td>training_function_2b59d_00023</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.001 </td><td style=\"text-align: right;\">-1.16928 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.491 </td><td style=\"text-align: right;\">       1.16928 </td></tr>\n",
       "<tr><td>training_function_2b59d_00024</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">-1.44218 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.9354</td><td style=\"text-align: right;\">       1.44218 </td></tr>\n",
       "<tr><td>training_function_2b59d_00025</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">-1.89002 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.1592</td><td style=\"text-align: right;\">       1.89002 </td></tr>\n",
       "<tr><td>training_function_2b59d_00026</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">-1.91364 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.2184</td><td style=\"text-align: right;\">       1.91364 </td></tr>\n",
       "<tr><td>training_function_2b59d_00027</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">-1.3247  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.1099</td><td style=\"text-align: right;\">       1.3247  </td></tr>\n",
       "<tr><td>training_function_2b59d_00028</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">-2.02697 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.6177</td><td style=\"text-align: right;\">       2.02697 </td></tr>\n",
       "<tr><td>training_function_2b59d_00029</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0003</td><td style=\"text-align: right;\">-0.80363 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.3582</td><td style=\"text-align: right;\">       0.80363 </td></tr>\n",
       "<tr><td>training_function_2b59d_00030</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.95</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">-1.22973 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.0371</td><td style=\"text-align: right;\">       1.22973 </td></tr>\n",
       "<tr><td>training_function_2b59d_00031</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">-1.2086  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.9282</td><td style=\"text-align: right;\">       1.2086  </td></tr>\n",
       "<tr><td>training_function_2b59d_00032</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.85</td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">-1.89541 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.8644</td><td style=\"text-align: right;\">       1.89541 </td></tr>\n",
       "<tr><td>training_function_2b59d_00033</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">-2.82848 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5659</td><td style=\"text-align: right;\">       2.82848 </td></tr>\n",
       "<tr><td>training_function_2b59d_00034</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">-1.48281 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.0737</td><td style=\"text-align: right;\">       1.48281 </td></tr>\n",
       "<tr><td>training_function_2b59d_00035</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\"> 0.0001</td><td style=\"text-align: right;\">-1.91383 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.8223</td><td style=\"text-align: right;\">       1.91383 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-15 23:28:33,244\tINFO tune.py:550 -- Total run time: 980.11 seconds (751.87 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best config:  {'THETA': 0.0001, 'GAMMA': 0.8, 'dataset': 'census', 'train_dataset_s': <torch.utils.data.dataset.Subset object at 0x7f3b5e2de710>, 'val': <torch.utils.data.dataloader.DataLoader object at 0x7f3b5e053710>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f3b5e053588>, 'x_tensor': tensor([[0.5205, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        [0.6027, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        [0.2740, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.2877, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        [0.5342, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        [0.1096, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000]])}\n",
      "2021-08-15 23:30:42,919 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004357711254262978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:   8%|▊         | 4/50 [00:06<01:10,  1.53s/it, epoch=3, training_loss=0.11, validation_loss=0.109]\u001b[A\n",
      "Training neural network:  16%|█▌        | 8/50 [00:12<01:05,  1.57s/it, epoch=7, training_loss=0.104, validation_loss=0.109]\u001b[A\n",
      "Training neural network:  24%|██▍       | 12/50 [00:22<01:14,  1.97s/it, epoch=11, training_loss=0.1, validation_loss=0.109]\u001b[A\n",
      "Training neural network:  30%|███       | 15/50 [00:28<01:09,  1.99s/it, epoch=14, training_loss=0.0925, validation_loss=0.109]\u001b[A\n",
      "Training neural network:  38%|███▊      | 19/50 [00:34<00:55,  1.80s/it, epoch=18, training_loss=0.0907, validation_loss=0.111]\u001b[A\n",
      "Training neural network:  46%|████▌     | 23/50 [00:40<00:45,  1.68s/it, epoch=22, training_loss=0.0901, validation_loss=0.11] \u001b[A\n",
      "Training neural network:  54%|█████▍    | 27/50 [00:45<00:36,  1.59s/it, epoch=26, training_loss=0.0889, validation_loss=0.111]\u001b[A\n",
      "Training neural network:  62%|██████▏   | 31/50 [00:51<00:29,  1.54s/it, epoch=30, training_loss=0.0878, validation_loss=0.11] \u001b[A\n",
      "Training neural network:  70%|███████   | 35/50 [00:57<00:22,  1.48s/it, epoch=34, training_loss=0.0876, validation_loss=0.111]\u001b[A\n",
      "Training neural network:  78%|███████▊  | 39/50 [01:02<00:16,  1.47s/it, epoch=38, training_loss=0.0877, validation_loss=0.112]\u001b[A\n",
      "Training neural network:  86%|████████▌ | 43/50 [01:08<00:10,  1.46s/it, epoch=42, training_loss=0.0876, validation_loss=0.11] \u001b[A\n",
      "Training neural network:  94%|█████████▍| 47/50 [01:14<00:04,  1.44s/it, epoch=46, training_loss=0.0879, validation_loss=0.112]\u001b[A\n",
      "                                                                                                                               \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-15 23:33:11,660 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004262978400909436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:   8%|▊         | 4/50 [00:05<01:04,  1.40s/it, epoch=3, training_loss=0.111, validation_loss=0.111]\u001b[A\n",
      "Training neural network:  16%|█▌        | 8/50 [00:11<01:00,  1.45s/it, epoch=7, training_loss=0.105, validation_loss=0.116]\u001b[A\n",
      "Training neural network:  24%|██▍       | 12/50 [00:16<00:53,  1.41s/it, epoch=11, training_loss=0.1, validation_loss=0.112]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:22<00:47,  1.41s/it, epoch=15, training_loss=0.0927, validation_loss=0.109]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:28<00:42,  1.42s/it, epoch=19, training_loss=0.091, validation_loss=0.111] \u001b[A\n",
      "Training neural network:  48%|████▊     | 24/50 [00:34<00:36,  1.42s/it, epoch=23, training_loss=0.0895, validation_loss=0.111]\u001b[A\n",
      "Training neural network:  56%|█████▌    | 28/50 [00:39<00:31,  1.43s/it, epoch=27, training_loss=0.0888, validation_loss=0.111]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:45<00:26,  1.45s/it, epoch=31, training_loss=0.0875, validation_loss=0.111]\u001b[A\n",
      "Training neural network:  72%|███████▏  | 36/50 [00:51<00:20,  1.45s/it, epoch=35, training_loss=0.0874, validation_loss=0.113]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:57<00:14,  1.43s/it, epoch=39, training_loss=0.0868, validation_loss=0.111]\u001b[A\n",
      "Training neural network:  88%|████████▊ | 44/50 [01:02<00:08,  1.43s/it, epoch=43, training_loss=0.0868, validation_loss=0.113]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [01:08<00:02,  1.42s/it, epoch=47, training_loss=0.0871, validation_loss=0.112]\u001b[A\n",
      "                                                                                                                               \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-15 23:35:35,576 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004026146267525578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:   6%|▌         | 3/50 [00:05<01:32,  1.97s/it, epoch=2, training_loss=0.113, validation_loss=0.111]\u001b[A\n",
      "Training neural network:  12%|█▏        | 6/50 [00:10<01:19,  1.81s/it, epoch=5, training_loss=0.109, validation_loss=0.112]\u001b[A\n",
      "Training neural network:  20%|██        | 10/50 [00:16<01:02,  1.55s/it, epoch=9, training_loss=0.104, validation_loss=0.11]\u001b[A\n",
      "Training neural network:  28%|██▊       | 14/50 [00:22<00:55,  1.53s/it, epoch=13, training_loss=0.0955, validation_loss=0.11]\u001b[A\n",
      "Training neural network:  36%|███▌      | 18/50 [00:28<00:47,  1.49s/it, epoch=17, training_loss=0.0933, validation_loss=0.11]\u001b[A\n",
      "Training neural network:  44%|████▍     | 22/50 [00:33<00:40,  1.46s/it, epoch=21, training_loss=0.091, validation_loss=0.11] \u001b[A\n",
      "Training neural network:  52%|█████▏    | 26/50 [00:39<00:35,  1.49s/it, epoch=25, training_loss=0.0907, validation_loss=0.11]\u001b[A\n",
      "Training neural network:  60%|██████    | 30/50 [00:45<00:29,  1.46s/it, epoch=29, training_loss=0.089, validation_loss=0.108]\u001b[A\n",
      "Training neural network:  68%|██████▊   | 34/50 [00:51<00:23,  1.45s/it, epoch=33, training_loss=0.0891, validation_loss=0.11]\u001b[A\n",
      "Training neural network:  76%|███████▌  | 38/50 [00:57<00:17,  1.47s/it, epoch=37, training_loss=0.089, validation_loss=0.108]\u001b[A\n",
      "Training neural network:  84%|████████▍ | 42/50 [01:03<00:11,  1.48s/it, epoch=41, training_loss=0.0887, validation_loss=0.109]\u001b[A\n",
      "Training neural network:  92%|█████████▏| 46/50 [01:08<00:05,  1.43s/it, epoch=45, training_loss=0.0882, validation_loss=0.109]\u001b[A\n",
      "Training neural network: 100%|██████████| 50/50 [01:14<00:00,  1.47s/it, epoch=49, training_loss=0.0884, validation_loss=0.11] \u001b[A\n",
      "                                                                                                                              \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-15 23:38:04,592 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004641909814323607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:   8%|▊         | 4/50 [00:06<01:10,  1.53s/it, epoch=3, training_loss=0.111, validation_loss=0.109]\u001b[A\n",
      "Training neural network:  16%|█▌        | 8/50 [00:12<01:02,  1.50s/it, epoch=7, training_loss=0.105, validation_loss=0.114]\u001b[A\n",
      "Training neural network:  24%|██▍       | 12/50 [00:17<00:55,  1.45s/it, epoch=11, training_loss=0.101, validation_loss=0.11]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:23<00:49,  1.45s/it, epoch=15, training_loss=0.0934, validation_loss=0.11]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:29<00:43,  1.43s/it, epoch=19, training_loss=0.0922, validation_loss=0.109]\u001b[A\n",
      "Training neural network:  48%|████▊     | 24/50 [00:34<00:37,  1.43s/it, epoch=23, training_loss=0.0908, validation_loss=0.109]\u001b[A\n",
      "Training neural network:  56%|█████▌    | 28/50 [00:40<00:32,  1.46s/it, epoch=27, training_loss=0.0899, validation_loss=0.108]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:46<00:26,  1.48s/it, epoch=31, training_loss=0.0882, validation_loss=0.109]\u001b[A\n",
      "Training neural network:  72%|███████▏  | 36/50 [00:52<00:20,  1.47s/it, epoch=35, training_loss=0.0883, validation_loss=0.11] \u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:58<00:14,  1.46s/it, epoch=39, training_loss=0.0886, validation_loss=0.11]\u001b[A\n",
      "Training neural network:  88%|████████▊ | 44/50 [01:04<00:08,  1.44s/it, epoch=43, training_loss=0.0874, validation_loss=0.11]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [01:09<00:02,  1.45s/it, epoch=47, training_loss=0.0887, validation_loss=0.109]\u001b[A\n",
      "                                                                                                                               \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-15 23:40:26,863 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004168245547555892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:   8%|▊         | 4/50 [00:05<01:07,  1.47s/it, epoch=3, training_loss=0.111, validation_loss=0.11]\u001b[A\n",
      "Training neural network:  16%|█▌        | 8/50 [00:11<01:00,  1.45s/it, epoch=7, training_loss=0.106, validation_loss=0.109]\u001b[A\n",
      "Training neural network:  24%|██▍       | 12/50 [00:17<00:57,  1.50s/it, epoch=11, training_loss=0.102, validation_loss=0.108]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:23<00:50,  1.48s/it, epoch=15, training_loss=0.0936, validation_loss=0.106]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:29<00:43,  1.45s/it, epoch=19, training_loss=0.0919, validation_loss=0.107]\u001b[A\n",
      "Training neural network:  48%|████▊     | 24/50 [00:35<00:37,  1.46s/it, epoch=23, training_loss=0.0912, validation_loss=0.107]\u001b[A\n",
      "Training neural network:  56%|█████▌    | 28/50 [00:40<00:31,  1.45s/it, epoch=27, training_loss=0.0895, validation_loss=0.109]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:46<00:26,  1.45s/it, epoch=31, training_loss=0.0896, validation_loss=0.108]\u001b[A\n",
      "Training neural network:  72%|███████▏  | 36/50 [00:52<00:20,  1.44s/it, epoch=35, training_loss=0.0884, validation_loss=0.108]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:58<00:14,  1.44s/it, epoch=39, training_loss=0.088, validation_loss=0.107] \u001b[A\n",
      "Training neural network:  88%|████████▊ | 44/50 [01:03<00:08,  1.45s/it, epoch=43, training_loss=0.0883, validation_loss=0.107]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [01:09<00:02,  1.43s/it, epoch=47, training_loss=0.088, validation_loss=0.108] \u001b[A\n",
      "                                                                                                                              \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-15 23:42:49,292 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0037893141341417205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:   8%|▊         | 4/50 [00:05<01:04,  1.39s/it, epoch=3, training_loss=0.11, validation_loss=0.113]\u001b[A\n",
      "Training neural network:  16%|█▌        | 8/50 [00:11<00:58,  1.40s/it, epoch=7, training_loss=0.105, validation_loss=0.113]\u001b[A\n",
      "Training neural network:  24%|██▍       | 12/50 [00:16<00:54,  1.42s/it, epoch=11, training_loss=0.0998, validation_loss=0.11]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:22<00:48,  1.43s/it, epoch=15, training_loss=0.0923, validation_loss=0.109]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:28<00:43,  1.44s/it, epoch=19, training_loss=0.0914, validation_loss=0.11] \u001b[A\n",
      "Training neural network:  48%|████▊     | 24/50 [00:34<00:37,  1.45s/it, epoch=23, training_loss=0.0906, validation_loss=0.108]\u001b[A\n",
      "Training neural network:  56%|█████▌    | 28/50 [00:40<00:32,  1.46s/it, epoch=27, training_loss=0.0895, validation_loss=0.11] \u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:46<00:26,  1.45s/it, epoch=31, training_loss=0.0887, validation_loss=0.111]\u001b[A\n",
      "Training neural network:  72%|███████▏  | 36/50 [00:51<00:20,  1.45s/it, epoch=35, training_loss=0.0875, validation_loss=0.107]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:57<00:14,  1.43s/it, epoch=39, training_loss=0.0882, validation_loss=0.11] \u001b[A\n",
      "Training neural network:  88%|████████▊ | 44/50 [01:03<00:08,  1.44s/it, epoch=43, training_loss=0.0881, validation_loss=0.11]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [01:09<00:02,  1.46s/it, epoch=47, training_loss=0.0878, validation_loss=0.109]\u001b[A\n",
      "                                                                                                                               \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-15 23:45:13,401 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.0044524441076165214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:   8%|▊         | 4/50 [00:05<01:03,  1.37s/it, epoch=3, training_loss=0.11, validation_loss=0.113]\u001b[A\n",
      "Training neural network:  16%|█▌        | 8/50 [00:11<01:01,  1.47s/it, epoch=7, training_loss=0.104, validation_loss=0.108]\u001b[A\n",
      "Training neural network:  24%|██▍       | 12/50 [00:17<00:54,  1.43s/it, epoch=11, training_loss=0.102, validation_loss=0.108]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:22<00:48,  1.43s/it, epoch=15, training_loss=0.0928, validation_loss=0.108]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:28<00:43,  1.44s/it, epoch=19, training_loss=0.0913, validation_loss=0.108]\u001b[A\n",
      "Training neural network:  48%|████▊     | 24/50 [00:34<00:36,  1.41s/it, epoch=23, training_loss=0.0906, validation_loss=0.108]\u001b[A\n",
      "Training neural network:  56%|█████▌    | 28/50 [00:39<00:30,  1.40s/it, epoch=27, training_loss=0.0895, validation_loss=0.108]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:45<00:25,  1.41s/it, epoch=31, training_loss=0.0881, validation_loss=0.11] \u001b[A\n",
      "Training neural network:  72%|███████▏  | 36/50 [00:51<00:19,  1.42s/it, epoch=35, training_loss=0.0878, validation_loss=0.109]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:56<00:13,  1.38s/it, epoch=39, training_loss=0.0885, validation_loss=0.11] \u001b[A\n",
      "Training neural network:  88%|████████▊ | 44/50 [01:02<00:08,  1.44s/it, epoch=43, training_loss=0.0877, validation_loss=0.109]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [01:08<00:02,  1.46s/it, epoch=47, training_loss=0.0869, validation_loss=0.109]\u001b[A\n",
      "                                                                                                                               \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-15 23:47:33,363 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004262978400909436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:   8%|▊         | 4/50 [00:05<01:06,  1.44s/it, epoch=3, training_loss=0.113, validation_loss=0.113]\u001b[A\n",
      "Training neural network:  16%|█▌        | 8/50 [00:11<01:00,  1.44s/it, epoch=7, training_loss=0.108, validation_loss=0.109]\u001b[A\n",
      "Training neural network:  24%|██▍       | 12/50 [00:17<00:55,  1.45s/it, epoch=11, training_loss=0.104, validation_loss=0.107]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:23<00:49,  1.47s/it, epoch=15, training_loss=0.0967, validation_loss=0.107]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:28<00:42,  1.43s/it, epoch=19, training_loss=0.096, validation_loss=0.107] \u001b[A\n",
      "Training neural network:  48%|████▊     | 24/50 [00:34<00:36,  1.40s/it, epoch=23, training_loss=0.0951, validation_loss=0.108]\u001b[A\n",
      "Training neural network:  56%|█████▌    | 28/50 [00:40<00:31,  1.42s/it, epoch=27, training_loss=0.094, validation_loss=0.109] \u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:46<00:27,  1.52s/it, epoch=31, training_loss=0.094, validation_loss=0.108]\u001b[A\n",
      "Training neural network:  72%|███████▏  | 36/50 [00:55<00:24,  1.74s/it, epoch=35, training_loss=0.0932, validation_loss=0.106]\u001b[A\n",
      "Training neural network:  78%|███████▊  | 39/50 [01:01<00:19,  1.78s/it, epoch=38, training_loss=0.0931, validation_loss=0.11] \u001b[A\n",
      "Training neural network:  86%|████████▌ | 43/50 [01:07<00:11,  1.65s/it, epoch=42, training_loss=0.093, validation_loss=0.107]\u001b[A\n",
      "Training neural network:  94%|█████████▍| 47/50 [01:12<00:04,  1.57s/it, epoch=46, training_loss=0.0928, validation_loss=0.108]\u001b[A\n",
      "                                                                                                                               \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-15 23:49:56,839 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.00407351269420235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:   8%|▊         | 4/50 [00:05<01:05,  1.42s/it, epoch=3, training_loss=0.111, validation_loss=0.112]\u001b[A\n",
      "Training neural network:  16%|█▌        | 8/50 [00:11<00:57,  1.37s/it, epoch=7, training_loss=0.104, validation_loss=0.112]\u001b[A\n",
      "Training neural network:  24%|██▍       | 12/50 [00:16<00:53,  1.42s/it, epoch=11, training_loss=0.1, validation_loss=0.113]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:22<00:48,  1.44s/it, epoch=15, training_loss=0.0931, validation_loss=0.108]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:28<00:42,  1.42s/it, epoch=19, training_loss=0.0911, validation_loss=0.11] \u001b[A\n",
      "Training neural network:  48%|████▊     | 24/50 [00:34<00:36,  1.42s/it, epoch=23, training_loss=0.09, validation_loss=0.108] \u001b[A\n",
      "Training neural network:  56%|█████▌    | 28/50 [00:39<00:31,  1.41s/it, epoch=27, training_loss=0.0885, validation_loss=0.109]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:45<00:25,  1.42s/it, epoch=31, training_loss=0.0881, validation_loss=0.109]\u001b[A\n",
      "Training neural network:  72%|███████▏  | 36/50 [00:50<00:19,  1.41s/it, epoch=35, training_loss=0.0881, validation_loss=0.108]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:56<00:14,  1.42s/it, epoch=39, training_loss=0.0877, validation_loss=0.111]\u001b[A\n",
      "Training neural network:  88%|████████▊ | 44/50 [01:02<00:08,  1.41s/it, epoch=43, training_loss=0.0873, validation_loss=0.111]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [01:07<00:02,  1.40s/it, epoch=47, training_loss=0.0878, validation_loss=0.11] \u001b[A\n",
      "                                                                                                                              \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-15 23:52:15,671 - py.warnings - WARNING - /data2/gxq/pathanl/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "frac:0.004784009094353922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training neural network:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Training neural network:   8%|▊         | 4/50 [00:05<01:05,  1.42s/it, epoch=3, training_loss=0.111, validation_loss=0.112]\u001b[A\n",
      "Training neural network:  16%|█▌        | 8/50 [00:11<01:00,  1.44s/it, epoch=7, training_loss=0.105, validation_loss=0.112]\u001b[A\n",
      "Training neural network:  24%|██▍       | 12/50 [00:17<00:55,  1.47s/it, epoch=11, training_loss=0.101, validation_loss=0.11]\u001b[A\n",
      "Training neural network:  32%|███▏      | 16/50 [00:23<00:48,  1.43s/it, epoch=15, training_loss=0.0927, validation_loss=0.11]\u001b[A\n",
      "Training neural network:  40%|████      | 20/50 [00:29<00:43,  1.46s/it, epoch=19, training_loss=0.0907, validation_loss=0.111]\u001b[A\n",
      "Training neural network:  48%|████▊     | 24/50 [00:35<00:38,  1.47s/it, epoch=23, training_loss=0.0895, validation_loss=0.11] \u001b[A\n",
      "Training neural network:  56%|█████▌    | 28/50 [00:40<00:31,  1.44s/it, epoch=27, training_loss=0.0891, validation_loss=0.112]\u001b[A\n",
      "Training neural network:  64%|██████▍   | 32/50 [00:46<00:26,  1.45s/it, epoch=31, training_loss=0.0875, validation_loss=0.109]\u001b[A\n",
      "Training neural network:  72%|███████▏  | 36/50 [00:52<00:20,  1.45s/it, epoch=35, training_loss=0.0885, validation_loss=0.112]\u001b[A\n",
      "Training neural network:  80%|████████  | 40/50 [00:57<00:14,  1.43s/it, epoch=39, training_loss=0.0873, validation_loss=0.11] \u001b[A\n",
      "Training neural network:  88%|████████▊ | 44/50 [01:03<00:08,  1.45s/it, epoch=43, training_loss=0.087, validation_loss=0.111]\u001b[A\n",
      "Training neural network:  96%|█████████▌| 48/50 [01:09<00:02,  1.46s/it, epoch=47, training_loss=0.0876, validation_loss=0.111]\u001b[A\n",
      "                                                                                                                               \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time costs:2544.1231966018677 s\n"
     ]
    }
   ],
   "source": [
    "Fixate_with_val(10,dataset='census')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
